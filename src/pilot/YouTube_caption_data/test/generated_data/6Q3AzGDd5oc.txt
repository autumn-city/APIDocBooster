all right
so today's session is as i said in the
classroom
instead of doing hyper challenge i
thought it would take
too little time so i mean we would have
a lot of time
if we just talk about python autographs
so i actually merge the two
so neural nets and back property so yeah
so this today i'll talk about
these the learning frameworks just a
brief introduction then
logistic regression then neural networks
then back propagation then autograph how
how autograph is implemented in python
so that it does feedback propagation for
you
and uh we just i've already briefly
talked about logistic regression in the
i think in the last class in the last uh
theory session
but we'll just dive a bit deeper into it
and then how we can
evolve that into a hidden multi-layer
perceptron which is basically a
logistic regression with a new hidden
layer inside
all right so deep learning frameworks
so there are a lot of lead learning
libraries out there
and i think these five are the most
popular ones the piano was probably the
first
popular deep learning framework i'm sure
there was something
less popular than that previously but
fianna is the one that i use
the first used to you know learn deep
learnings
and take it was already developed in the
2014 2015.
and it was developed by engineers in
yoshi banjos groups so you can see how
important
it was then cafe is a good learning
framework in c
plus i think these days now it supports
python and java
all that but basically it started as a c
plus framework so it's really fast and
it
was developed in uc berkeley i'm not
sure it's as popular as it was
these days mxnet is something
supported by amazon and i've never used
it
i heard that it's also fast and scalable
meaning that it's
uh if you have like distribute a system
or you want to
you want to run a cloud and then you
want to
put something on top of the cloud system
maybe nx that is the one to go
i'm not sure if amazon is actually a
support but it's developing it's it's a
i think it's a apache project
anyways it's all open source and
the remaining two tensorflow and tight
torch are
probably the most important the most
popular ones out there
tensorflow's 1.0 is uh
there's a difference between tensorflow
1.2.0 but we'll first
talk about 1.0 tensorflow 1.0 is a
compile
that compile and execute so before you
start training your model you need to
compile your tensorflow written model
into a binary code and then you can
launch it into the vram
the video memory and then it'll run so
it's uh
but once it's compiled it's pretty fast
but there's a lot of big
there's a lot of boilerplate that you
need to like you need to
define the session and then you need to
run the section inside and
there's a lot of like tedious work that
you need to do
before you can actually run tensorflow
it's supposed to be fast because it was
developed for
employment or so it's a
deployment-oriented framework so if you
if you're a large company like google
and you want to serve a lot of people
basically all the people in the world
and that you i think that was in their
mind when they were developing
it was more like for developers or
enterprises rather than
researchers uh pine torch on the other
hand
so high torch came from torch the torch
is written in
i'm not sure if you ever used lula
before but
came from torch written in lua and then
it was adopted adapted to
python and deepline before deepmind was
acquired by google
they were using torch so all their
ataris and all their like you know early
early uh
earlier research works were all written
in lua or
in torch and then they were and they had
a hard time
transforming or transporting their
porting their torch code to a tensorflow
a model that was back in place before
so it's a compiler as you know so you
don't have to pre-compile your model you
can just write the code
and then you launch it and then it will
just compile as you go so it's very
fluid and very dynamic
it's easier to use than tensorboard you
can do more stuff
with high torch then tensorflow one
point
depends uh yeah it's supposed to be soil
but i'm not sure if it's faster
it's supposed to be slow and it's good
for research and
the i'm sure many of you already saw
this graph
which is that typewriter is catching up
on vegetable or
actually it's exceeding the popularity
exceeding i suppose because tensorflow
came before pytorch so it was
probably like the standard thing that
you you use back in
like 2017 2016 in 2018 as well but high
torch was because
it's beginning to get a lot of gain a
lot of popularity you can see that
uh gold mine and there's there's that
line uh the that line is tensorflow and
the bold line is
old pipers like these these these blue
lines are all fibers
and you can see that this is the number
of
frameworks mentioned in academic papers
like cbpr or
acl or neurops especially in cvpr
see this so this this purple thing is
this cdpr especially pr so tensorflow
was i think this is which one is the
purple one i think this is a purple one
so tensorflow used to be
yeah yeah this one this this one is
this is tensorflow cpr this is five cstr
and you can see that
until like mid-2018 people are using
tensorflow more often when they were
riding papers but
since the midnight mid 2018 is like
looks like going like this
and it's actually a lot like the tesla
is like actually stagnating or maybe
decreasing and by torches all
increase people are more and more people
are using python for research purposes
and this is the same in archive so that
was uh here before it was just
it was regular conferences like cdpr acl
new york city enlp
this is archive but and it's the same
trend in archives so
red thing is pi torch uh yellow thing is
tensorflow and you can see that the
number of times that each framework was
mentioned in archived paper uh here is
yeah right here just they're starting to
like they're switching places now
uh i'm not sure if terrace i don't think
hence is
a framework on its own because it's
running on top of either
piano or tensorflow so i'm not sure if
you can call that
uh there are other stuff i've never i've
never seen trainer
or tntk before but yeah these two are
really up there and i think i purchased
it probably a lot more people will be
using pipework
i heard that the students who come to a
google internship
they ask their posts if they can use
titles instead of tensorflow when
they're
in fact in google which is really weird
so
like students are all trained in tight
torch so much that
they're asking for their google managers
if they can use
tensorflow yeah so
yeah there's a lot of concern for them
inside people
so they came up with tensorflow 2.0
which is trying to be
more similar to pytorch which is lazy
execution so it's
more like compiling those and before it
was it was
oh sorry it's compiled as you go so
before tesla 1.0 was
compiled then go that's
2.0 is compiled as you know so
it's very similar i'm not
really sure what the difference between
the two now is
and jax is something that is gaining
a lot of popularity inside google so jax
is
this it was developed by a small team
inside google uh led by some
famous professor and it supports highway
friendship so it's a very low level it
doesn't have any like confidence or
transformers inside already
but it has a very powerful low-level
apis so that you can do higher order
differentiations like you can get
hessians which is a second-order
differentiation
so i think this will this will
definitely go somewhere
it's not as popular as piper's but i
think it is a
good popularity all right any questions
so far
i yeah this is this is the intro to the
learning very much
moving on all right
all right local regression
so as so logistic regression is such a
fundamental statistical classifier that
it is
being used everywhere in all domains not
not just computer science and not just
machine learning but
if you if there's statistics involved
the logistic regression is always there
so if you
it's real it's important that you at
least understand the concept
and yeah it's a well-studied model used
since 19th century
so like uh it's even used in like
biomedical domain as well
not just biology also in economics
not really an expert in statistics but
i'm pretty sure it's
used in all fields out there that needs
to classify that needs to perform
binary classification and the it is
such a well-studied model that
in machine learning you usually use it
for binary classification but it is more
used for
quick study of the analysis of code
coefficients
so like how well your model has learned
and what's the meaning of the
coefficient and how
powerful it is to like describe the
descriptive data
and all kinds of that kind of stuff like
that's what statisticians are
interested in like if it's if your model
is a not
great it's a good estimator of the true
distribution
or underlying distribution that your
your sample data cannot actually model
but we don't but in machine learning
that's not really
a big concern because we dump such a lot
of data onto the model we
really don't care about the
uh the true that the true true dance and
the true like
the entire data set and the sample data
and the discrepancy between the two
i mean some people are interested but
usually when you do like transform type
of thing
you dump entire internet text into
gp3 and you don't really care about
whether it
really reflects the true distribution
of text data because you are dumping old
text data
so yeah anyway so uh
yeah it's an important thing it's an
important model and uh it's
uh basically uh logistic regression you
can you can actually
write uh logistic regression using
python
you don't have to use before we use
scikit-learn to write
i mean to implement logistic regression
but you can do the same thing
totally with type and then you start if
you start adding more
hidden layers then that becomes treated
for a neural network and then if you
change your
hidden layer with convex then that
becomes your convolutional neural
networks and all that so it's a very
it's like the
starting point of your neural network so
as i briefly mentioned it looks like the
the model
expression looks like this so here this
is the b is usually an explanation
it's a euler's constant and
how it is derived i think i've also
talked about this so there's a
probability which is which
lies in the range between zero and one
so if you think about like coin flipping
or winning a lottery or whatever
and if you if you have a certain
probability then you can transform that
into odds which is like how many times
you are likely to win
given the probability so odds four is
like
um so what does that mean so one up
four you're like four times more likely
to win
compared to losing and one is like you
are equally likely to win or lose it's
like one to one one to one ratio uh this
is like
yeah this there's like zero point ninety
percent ninety percent you're
losing and like out of hundred eleven
times you're winning
your unit you're winning nine eighty
nine percent the eighty nine times
you're losing
that kind of stuff so this is this lies
in the region
zero one this lies in the range zero to
uh positive infinity so that's that's
actually already like kind of relaxing
your model space and if you put log on
top of it
and then that becomes logic so this is
odds
and if you put log on top of it then you
call that logit so there
there's that's where logistic regression
comes from
because you're using you're trying to
model a logit function the logic
function
thankfully lies between negative
infinity plus infinity
so now you're using the entire space so
for example if you were trying to model
a p
with a w transpose x plus b then it is
hard to
you know tune your parameters which
which are the
w and v so that your output
lies in zero and one it's hard to like
you know control your
theta your learnable parameters such
that it is this function the co domain
will be
zero to one but if you use if you
if you're if you're using this as a co
domain then your
models parameters w transpose x plus b
your model parameters will have a much
higher freedom
and it's not not as restricted as before
so that's why people
transform probability to logic and then
try to model that using
wt double transpose x v
and then if you do some linear algebra i
mean not linear if you do some algebra
you know
you model this so here beta is the thing
that's
sorry beta transpose x
plus beta0 that's basically this
so you're linearly approximating your
logit and then you do some
algebra you put you put log here the log
goes here and then you do some
you put it you try to you know make put
some piece around and then
this is what you get and then this is
what you get it's the same thing
here and here is the same thing so
that's how you get
uh one plus exponential to the negative
theta transpose x plus b
uh one over so this is
what you usually see as a logistic
expression
so pretty it's pretty straightforward
right so there's there's a motivation
for
disregard it's not just like you know
somebody came up with the sigmoid
function
and then just put put the uh the linear
approximation inside sigma function
there's like a story
right and yeah so yeah
you can put this into a vector form like
this
so here there will be an x zero x to the
power zero term which
approximates which which is same as just
uh just the constant or the bias or the
insert intercept is the same thing
and you want to learn theta such that
uh you you you can your your model will
approximates
this probability so here y and x are
given to you as benefit and theta is the
one that you can control as i said you
can control theta to
minimize your loss and we'll talk about
the loss
in a couple of slides right right okay
so
here we have the uh here we have the
vector form of
logistic regression and as i said x is
your data set
so here for example let's say that you
are trying to classify an image
into a into a binary class so you put
this very famous
figure into logistic regression
and you can transform your
with your image into a very long vector
you have to it's not just that you can
you have to so
here there if you have an image of a
person
then you can slice it horizontally and
then put it
to it like this then your second will
come here
then third will come here into a very
long horizontal vector
so this is your horizontal vector and
i'm just i'm just you know
the same approximating this true image
into a binary vector
because in actuality uh these will have
all
real values like zero point five zero
point one zero point five five or
whatever i'm just
for the sake of argument i'm just
transforming them into zero effect
so here this there is a
pixel black pixel here there's
white pixel and that's so it's a black
and white image and then you put that
into your x and then you
you can approximate how if the
probability of it being a certain class
which
is yeah i don't
all right i for i think i forgot to say
that this is a man or woman classifier
so man or woman
so given that image we want to classify
whether the given image is of a man or a
woman
and if it's a man it's always a one if
this woman is zero or it could be the
other one doesn't it
and yeah you need to learn this which is
the learnable parameters correctly to
predict for x which is the
x is the image representation so here
this is this is the only thing that we
need to we can learn
and before i say that we use cross
to learn to train logistic logistic
regression model
here i'm going a bit in a different
direction it's more statistically
motivated
so here when you there's if you have a
model
and if you have a parameter to estimate
this true value you can use
you can use a lot of estimating method
and one of the most popular way to
estimate the parameter
is the maximum likelihood estimate which
is
so if you've already taken
the basic machine learning class there's
a concept called bias and variance
tradeoff
and like when you're estimating a
parameter
for example let's say that you you have
a space and your true
uh your true
your true distribution is like this and
then if you're approximating
its distribution but you're all you're
probably
you're you're let's say that this is
your true
true distribution and your
predict or your learned distribution and
it looks like
this then
uh this has a bias so because your true
distribution the mean of true
this region lives here but your mean of
your approximate distribution is here so
there's
a bias here and if you're let me see if
i can erase that
and if you're probably if you're
approximately this region looks like
this
then the mean lies in the same same same
position here the
both the x's the true distribution your
predicted ones the the circles
their mean is in the same place but now
your
circles the approximate distribution has
like a larger variance
it is so you can't really be sure that
it has learned the truth distribute
because now it's like
shooting everywhere it's just that each
the mean of your shooting
is just happens to be in the same place
as a true distribution but you're
shooting everywhere so it's
not really very useful and so there's
like five different trades
and mle is unbiased estimated so
if you use mle like maximum likelihood
estimate to to to
learn a parameter of your of your model
then eventually
it will get to the true position it will
actually learn the optimal
parameter so next unlikely investment is
it's a very popular method to estimate
your parameters
all right
and how how how you proceed with maximum
likelihood estimate uh
mle is that you uh let's see so there's
a like
since it's a likelihood estimate and you
want to maximize it so there's a
likelihood function
this is your probability function and
there's a
likelihood function which is that given
the data you want to you want your model
to
maximally explain the given data
so here there's y y and x so there's
like
n number of samples and you're going
through all of those
each one at a time and you're
multiplying the probability that you
will see that exact data
given your model so here you're putting
your y ice
sample into your model and then you're
multiplying its
probability and you want to maximize it
which is basically saying even this
given my model i want i want my model to
i want my
i want to calculate what's the
probability of seeing all these data
given my
my model so this is what you're doing
basically you're multiplying it so
and since it's a binary classifier you
can use bernoulli's distribution
here this is exactly the brand-new
distribution
which is which is like
p p times p raised to the power of k
1 minus p or e to the power of 1 minus k
or n or with 1 minus p
actually i'm not i'm forgotten i think
it was all minuscule
yeah yeah some young actually
a bit confused binomial distribution so
binomial is multiple there's multiple
trials so generally yeah this is
a distribution so k is the the class
and p is a probability and you can see
it is exactly the same form
the y is the class here and h theta x i
this is your prediction so this is your
y hat basically and you're so basic what
you're doing is you're transforming
you're replacing this with a burn load
for an only distribution
and there is a uh what how do you call
this this is
i think this you call this phi
so basically you're multiplying a lot of
probabilities
and since each the probability of seeing
your data
given this function is really low it'll
be like zero point something
basically and if there are a lot of that
if you fit 100 samples thousand samples
maybe
millions of samples if you multiply
those small probability again and again
again you'll
looks like understand
right so your multiplication becomes
addition so now you don't have to deal
with like 0.000 it's more stable and you
can actually calculate it with computers
so that's why you use log likelihood
function and log is a
monotonic function so minimizing or
maximizing your log is equal to
minimizing maximizing
the term inside and
if you put log what happens if you put
log
here if you put log on top
in front of this then it becomes like
this which is
cross entropy function the cross entropy
function is actually
putting a log term in front of bernoulli
distribution so that's why we
use cross-entropy in the beginning when
we're talking when we were talking about
just how to train the logistic
regression in the previous class
we just straight dived into
cross-entropy but it is actually just
a putting log term in front of a
bernoulli distribution
that's how things are motivated and you
want to divide everything by the number
of samples so just to get them get an
average
right so please remember this because
we'll be using this throughout
the entire entire class today
and yeah there's not much
yeah it's just that we maximize the
negative log likelihood so
as i said you this is this is going to
be your loss function in the
optimization sense
in statistical learning you want to
maximize your likelihood
but in optimization sense you want to
minimize your loss so
likely you want to put it put a negative
like minus sign
on in front of it so that that becomes a
proper loss function
so negative log likelihood is your loss
function because if you minimize your
negative logarithm
you're actually maximizing a lot you're
likely
so nll negative likely you can minimize
it by doing pretty descent
right so far uh any question
oh yeah i
sometimes i just forget to look at take
a look at the chatbots
neural networks so okay just a
motivating
motivating example so what a neuron is
why do we call it neural
networks so neuron so neuron is uh
you you get you get a lot of these like
french looking kind of thing
they will receive information they'll
receive some chemical
substance from nearby other neurons
and then if it receives certain amount
of chemical
substance i forgot what it was i think
it was
does anybody remember
so this is the one that you actually
receive something
so uh
yeah okay we will move on all right
there's a i feel
something or
all right yeah some some chemical
substances so a long time ago since i
learned biology but yeah if you remember
neurotransmitter not not exactly a
neurotransmitter is like the function of
that
function of the chemical substance
anyway yeah that so there's there will
be a neural transmitter so like here
like very small particles given from
this
this this guy and then it is it
it is propagated through this exon and
if there are enough
number or amount of uh chemical
substance
uh accumulated inside that it'll this
neuron will fire
the electric signal towards like here
here here here here so basically
propagating
information through out it's throughout
the neighboring neurons and then the
neighboring runs will do the same thing
so your like neurons will fire
information
throughout your brain and it's it's
actually not just
like a single it's not a unidirectional
phenomenon
because if you think about fifa neural
networks it always starts from
the bottom and goes to top so it's a new
unidirectional thing but neurons
actually is bi-directional so
like it can go it can take a loop and
it doesn't always have to start at the
bottom sometimes it starts
like in the middle of your in the middle
of your brain it just you know fires
to the outwards i still killed yeah
yeah thanks yeah that was
that was the one that i tried to
remember yeah
all right so it's so in the same
principle so
uh if if you have a single artificial
neuron then
information so this is the dendrite
basically so there's like a branch here
which which is the same thing as here
or telodendria
uh yeah what yeah so basically this this
part here is this part
and if you if there's enough information
accumulated inside then it'll fire which
is fire so fire being like a binder
there's a it's a binary action it's fire
or low fiber so it's binary
that's why you usually use a single
function
that's a little bit
like this so if it reaches a certain
potential
if your accumulated information reaches
a certain potential like
here then it's it's it's gonna fire like
one and if not
just gonna fire snap on fire it's just
gonna be space zero it's gonna stay
zero so it's that's how artificial
neuron is
motivated and yeah here's the learnable
weights then there's the bias so
basically it is if
you write in the vector form it will be
double transpose b
and then there's a sigmoid function on
in front so that is your single neuron
and yeah okay now now there's a metal
room so if you have a 128 by 120 image
and you
put that through a neuron a single
neuron or syndrome
then basically this is going to be this
here will be 16 000
16 000 dimensional input and
everything will be accumulated collected
inside a single neuron and
if it reaches a certain potential it'll
fire and
if it fires it's a man if it doesn't
fire it's a woman
you can think of it as a linear class
like a linear classifier because here
w transpose xb is a linear term
and you can yeah you can transform that
into a exactly 16
384 elements and
sigmoid function looks like this so
i says i said that this is usually used
as a signal function
to mimic maybe i can grow better
to mimic the behavior of actual neuron
and if you think about this
what is this so a single artificial
neuron with a sigmoid activation
function
it is a y it is a
any takers from online
no we're good
so single artificial neuron with a
sigmoid activation function
is exactly logistic regression so that
is why we start with logistic regression
even though we want to learn neural
networks
all right so moving on
so our neural net so this so neural
networks is just adding another layer
between the logistic direction input and
logistic ratio output you just add a
hidden layer
so let's get to that so let's think of a
hidden layer of
four neurons so there's one single layer
between the input
and and between the input and the output
there's a hidden layer so this is your
hidden layer
and there are four neurons so four
artificial neurons
and let's say that they all use sigmoid
output sigmoid explanation
so here is sigmoid this is also this
little sigmoid sigmoid
uh okay this this is a really bad
drawing
like this
and also this is binary classifier we
still want to classify a given image
into man or woman so this is
still a binary classifier so all sigmoid
functions
so if you use sigmoid functions
everywhere then
each hidden neuron there are foreign
neuron
will receive inputs from all the pixels
there are 16 000 dimensional inputs so
from all 16 000 elements each hidden
neuron will receive information and
it will fire but with if it's
if something is accumulated if not and
it's not if
it'll not fire if there's not enough
information
so you can see that they will each do
its own job
and you can think of this for this
first first layer input to the hidden
it's actually a group of four logistic
regression classifiers
because here there's a single logistic
regression classifier
because it's artificial neuron with
activity with a
sigmoid sigmoid activation function
here this is another uh maybe i should
use a different color
this one also logistic regression
function and
this one also another logistic reversion
function
all right this one so it is a
if you remember it could be seen as an
ensemble because you're using four
logistic regressions on top of the same
input
and ideally they will they will serve a
different
role or they'll learn a different
function that leads to
a better classification of man or woman
so
if you look at them semantically we can
think of something like
let's say maybe we can think of this of
the first classifier
the first logistic regression classifier
this one
maybe it is a classifier or having a
long hair or not a given
a image it'll just focus on whether the
human image
has a lot of hair or not and the second
one
i mean i mean you can't force to do you
can't force your
ensemble which is logistic functions to
do this but like
semantically maybe something like this
could happen
and maybe the second one focus on
mustache like if there's something some
hair
on your on the face of the given image
and if there's a ribbon
if there's a makeup like makeup being
like some like a lot of color color
contrast
so they'll all be zeros or ones because
this is going
through the sigmoid activation function
so i mean it won't be exactly zero it'll
be a range it'll be a value between zero
over one so
for example if this this one if this guy
fires 0.8
uh 0.1 0.1
0.9 then this is probably
a woman
right so that's how things are done
inside inside the neural network with
his single hidden neural
single hidden uh layer
so like if the if the weights here
weight one weight two
weight three weight four are properly
tuned
then it will uh
yeah then given given like 0.8 0.1 0.1
0.9
then it will lead to the final logistic
reaction here
classifying the given image to a woman
so like 0.8 or 0.9 and
if it's the other way around if it was
0.1 here's 0.9 uh 0.2
0.1 then probably the logistic
regression classifier the last layer
will
min like 0.1 or something
hopefully this is what what is happening
inside your
neural number so you can't think okay a
lot of questions
if you don't use any activation function
will there be still will still be a
neural network for like in embeddings
do you mean legislative regression
contained by your networks
all right first question by rushta
so if you don't use any activation
function it's all linear and if you just
if you keep everything linear inside
your multiple layers of
multiple hidden layers then there's no
difference between having no layer
and a lot of layers because without
hidden layers
without the activation function then
your y hat is equal to w
n times w unless n minus one times
times w uh one x
which is your input
uh this is this entire chain of matrix
multiplications
can be approximated by a single matrix
because there's no
nonlinear elements inside if you just
keep everything linear
there is no difference between the power
of this guy i mean this guy
and the power of this bag so it's not a
neural net i mean
that's technically not what people call
neural networks neural networks you
usually have a non-linear activation
functions
between the layers you mean low
distribution contained by neural
networks
only when only when the hidden layers
use sigmoid activation functions
if it's using rail u or if it's using
10h then they cannot be seen as logistic
regression because
no longer this output will be zero over
one so
you can see my point can you actually
get the specific features in the h1 hn
then how can
we attribute the features in the
entry not really sure what you mean by
an attribute
like feature attribution like
interpretability is that we're talking
about
okay i'm to give uh um
more time to elaborate uh
is that four layers or one layer
containing four pieces
it is one layer containing four features
because there's one
two three four because before here
before it was just
pixel value it was either zero or one if
there's black dot it's the one
if it's a if it's a blank it's zero so
there's no semantic
meaning to the pixel but hopefully your
hidden layer with four logistic
regressions inside has picked up a
semantic meaning of the picture
which facilitates accurate prediction of
men or women
so now it's a feature long hair mustache
ribbon makeup that now you can think of
that as p
i mean better feature than pixel values
yep okay
right
oh what's happening
all right yeah okay so yeah before
these are the low-level logistic ratio
functions and
this is a high-level logistic version
function working on top of
easy features to classify manual
movement
so it's a it is receiving a better
feature that's why if you add multiple
layers of hidden layers
hopefully it'll make better features out
of given pixel images
so if you this is just a single hidden
layer but if you add more
more hidden layers like three or four or
maybe like 100 hidden layers
like in residual networks present then
hopefully
it'll learn better and better and better
features so that the last classifier
which is essentially a logistic
regression because always if you're
using binary class
if you're doing binary classification
the top layer is always using a sigmoid
function so
you can always think of the top layer as
a logistic regression function
and before the entire process is just
coming up with a better feature
so if you hopefully adding more features
will
do that for you i mean adding more
layers will do that for you
right so here this four dimensional this
four dimensional
because there were four four uh four
neurons you can think of this as a four
dimensional input to the last
low distribution classifier before it
was 106
thousand dimensional input now it's four
dimensional influence so
it's a much better manageable size than
before
so here this is called a latent
representation
here it was the x the x was actually
just just
just the image vector right so it's just
uh
the raw representation there's nothing
to it you just take the pixel values and
just you just give it to the
to your network but here in the in the
hidden layer what the hitler has learned
like this being 0.8 0.1 0.2 0.8
now this vector 0.8 0.1
0.2 0.8 this four-dimensional vector is
a latent
representation of the given image so
it's a it's a more like lower
dimensional
vector that represents the image but
that representation
is tuned towards after prediction of
manual movement it's not it's not a
general purpose representation because
you're
you're tuning you're learning the entire
thing to to make it
perform man or woman classification
so the learned lower dimensional vector
will be
tuned towards that it is not just
any likely representation it's just a
latent representation
for men or roman classification
uh
yeah so the question was do we specify
what kind of feature
each like hidden neuron should learn or
is it just arbitrary
and the answer is this arbitrary we hope
that you'll learn something useful
and if you have taken a look at deep
neural network basics
if you have like a really
deep neural deep convolutional neural
networks then the lower layers will
learn some like a brush or
or a contour information like this and
your
upper layer will start to learn like
eyes
and then your another upper layer will
start to learn like the partial
facial features and so on and so forth
so it's like
more if you add more layers and layers
it'll learn more higher than the higher
level semantics
so yeah it is doing feature selection uh
on the show that's the power of
your neural networks because you don't
have to do it for them as i said in the
very beginning in the first class
introduction
i said that the power of deep learning
is that you don't have to do feature
engineering uh to the degree that we
used to do in the in the classical era
okay just uh okay before we go training
does adding a hidden layer increase
number of features only by
one uh
i don't really uh not sure what you're
getting at if so before
if there was no hidden there it was just
sixteen thousand dimensional input
directly putting propagated to the
output but now if we
we added one hidden layer which led to
four dimensional features
but that's just arbitrary you can use
four neurons you can use 16 neurons you
can use hundred euros doesn't really
matter
just uh it's a hyper parameter
all right i think i should move on i
don't want to spend i'll
yeah i'll answer the questions in class
or if we have some
if we have some time after the after
this today's session
i'll try to answer all your questions
but for now we'll move on
all right so training so we've take a
look at how the difference between
logistic regression
and uh mlp which is
multi-layer perceptron so perceptron is
so i haven't talked about perceptron but
perceptron is basically
almost the same as a single artificial
neuron if it doesn't have
uh i'm not really sure on this but you
can look it up but i think the
difference between a perceptron
and a neuron is that whether there is a
non-linear activation function so if
there's no
so perceptron is used for regression uh
because there's no activation function
and if you use a dominant to make
nonlinear activation then that becomes a
neuron
but yeah this is old really like old old
school
so if you so it's multi-layered
perceptions like multiplayer neurons
basically
anyway so we call that nlp feed for
neural network we call it nlp as well or
fifa network is also fine so once you
have that we need to start training it
so
this is this following section following
section or subset is about how to train
them
so as i said this is a sixteen thousand
dimensional input
and there's four dimensional input
coming in here four dimensional input
and then this uh it'll have to lead to a
one dimensional output
so in between between here there's 16
one six three eight four by four because
it's a matrix you want to
compress your sixteen thousand
dimensional input into four dimensional
output right so that you need a matrix
that looks like this
here of the 16k this is 4k i mean this
one so it's a very
vertically really long really long
matrix so that's
the parameter that you need to learn and
now in the second stage you're
compressing a four-dimensional input
into one dimensional output so all you
need is a
four-dimensional vector so total in
total you need this amount of parameters
trained properly to do a binary
classification and
note that there is no bias terminal so
there there should be a bias term like
here
bias bias bias and vice and also there
should be a bias here which is always
one which is bias but i'm just ignoring
that
for the sake of mathematical uh clarity
i'm just going to ignore old vice terms
and just deal with the matrices
all right so okay again i'm just going
to assume that also i'm just consuming
everything is just sigma
and we're still going to use because
this is still binary classification
problems so
we go through the same same principle
which is maximum likelihood
estimation or using the cross center
which is the same thing
so given given given a 16
000 dimensional input and one
dimensional output
zero or one we want to minimize
nll which is negative of likelihood
function so it's the same principle and
the way you do it is
yeah it's the same thing the way you do
it is you need to the gradient descent
and there are a lot of parameters that
you need to learn basically sixteen
thousand dimensional
by four plus four the plus four this is
the plus four part
and for each weight or each parameter
you need to update them numerically and
iteratively
one step at a time and so the for was
basically
this is your gradient descent expression
so your new
w1 will be old w1
minus a step size which is some step
size like 0.1 0.01 or 0.001 so some some
step size that you choose is hyper
parameter and you need this value
specifically so you need to but what is
this this is
your loss function which is negative so
here nll
is your loss function so exactly
so we want to have a loss function of y
y hat partial derivative of w1
and this is the same thing here right so
you need this
specific value to take a step towards a
lower
region in your loss space and your law
space consists of how many dimensions
it's a gigantic space consisting of this
many
dimensions
so 60 about 64 000 dimensional
i'm just going to say 64 000.
because you need to your loss function
your
loss space is controlled by all the
parameters
of your model and all the parameters of
your model their number is 64 000
approximate so your loss space
consists of six it's a 64 000
dimensional
space and uh
until now we always talked about a
one-dimensional space where like the
loss function looks like this
this is your theta this is your loss
this is your loss
and you want to find a theta star
starting from some theta zero
and you want to take like this kind of
step now it's
not one dimensional it's 64 000
dimensional so it's a really gigantic
space
and each dimension corresponds to
a single parameter so w1 like w2 w3 v11
like and they consist they can comprise
the entire plus space and whichever
direction or whichever axis that you
take you need to take it in such a
manner that it'll lead to
a lower loss term in the end
and you do that for all the you take
turn
each you take each turn here in w1w3
like oh
64 000 times and you want to update them
in such a manner that you go
to you go towards the global or local
minimum
like this so that that this is just one
one of the axis
that you're that that's where the action
is happening
you need to do this for v1 so you in
both in both cases you need this term
you need
this term so now we need to
actually derive this term in order to
actually do the gradient
all right a couple more questions what
is the use of bias for bias term when
your
input is not normalized then it is a
good idea to use bias
if you're uh so if your
if your inputs start if your input
looks like this and you want to do
linear regression then you can just
if your line can pass through the origin
zero
zero but if your input looks like this
then you you really need the bias term
now because
you can't start like if you have just w
transpose x then your
linear regression terms will just rotate
whatever the center of rotation is the
origin but it so you need divisor so
that your
center rotation is now here and
the ideal one would be like this this
one so that is why you need to buy a
store
all right
another google bias time and neural
network answer pops up
yep that's one way to go yeah actually
yeah self study is
probably better than me just answering
the question
if you think about it simple math yeah i
think it's the same as as i do
all right moving on so as i said the
lesson is that you want to learn you
need to derive this term
somehow so that you can plug that into
your gradient descent steps
so that's where back propagation comes
in
any questions so far
it's not all right all right so from now
on
um i'm gonna talk in terms of a general
neural network where there are l number
of layers
so l number of layers here
and there's some number of neurons per
layer
so this nothing's like nothing's fixed
it's so it's like
we're trying to make it as generic as
possible
so that if you when you derive a
expression you can just plug it into
your specific
neural network so multiple layers
multiple output nodes
with l capital l layers
and uh your
entire neural network can be expressed
like this
so c here you can think of the c as a
loss function which is the same as l
so why here y here is y
here y hat is this entire thing
so it's a nested function so you start
from
this function here which this function
is which
which transforms your input x to a
hidden representation or latent
representation
a one which is the first so
this is exactly that oh
again there's no bias term i mean there
could be bias for me here with just
everything always said i mean always set
to one but you can forget
forget about bystar so here this thing
is corresponds to this
and the second one here responds to
here which just probably transforms to
a2
like this and then you do it again again
and again again so it's a
there's multiple there's a multiple
nested function
and we start from here
uh we're gonna define some terms so that
we can motivate how we can do back
propagation
so uh oh there is bias from here so
there is
just increase so okay so here we're just
taking a look at a single hidden layer
so there's input
there's output and this is a hidden
layer
and if you magnify it
and there's a bias term but i'm just
going to ignore the bias term from now
and there's the weight so this is l
flare
and l between the l the uh j and
yeah this is between the j and k's like
layers
now let's just keep it there let's just
keep this so this is l minus one this is
this is l and between the between the
two layers
there should be a matrix of the size
i think this changes the number of
neurons here and k the
k is like the number of neurons and
these numbers in each layer so there
should be a matrix of size
j times k right
and here the matrix size of this should
be k times m
so that's why the uh the single weight
or single parameter
in this layer is wl which is the elf
layer
uh k and j which is the index of the
matrix so there's a
k row j column
and the same thing would be here w l
plus one
uh k throw and call and column something
like that
and a single neuron consists of a
pre-activated value and the
post-activated value
the pre-activated value which is z so
this is
else layer case neuron pre-activation of
pre-activation
value which is just the alternative
which is just a
w transpose
i'm not i don't want to say x so it's
all the value here i'm just going to
call that
uh the actually they should be a
l minus one because
here there will be also a's and a's and
a's and z's
z's c's right so z
in the else layer consists of a's
multiplied by corresponding weights and
all summed up
so it's a l vector form
transpose w l
am i making sense here yeah
this is z l
k actually it's uh so it should be
kj so changing so it's
colon colon
it wait this is this is
one one one one two three
so all right so we should circle so it
should be
comma column so this is the first
keythrow
entire pump like if you remember the
slicing stuff
so a l minus 1
transpose wk wlk
comma column equals zkl so which is
pretty
which looks pretty complicated but if
you break it down into like if you think
about programming this
in using python or numpy you can kind of
see what's what i'm trying to get at
here
so anyway you have the z and then once
you put z
through a activation function which
could be a sigmoid function a relative
function 10h function doesn't really
matter but
some activated function so that function
is actually we're just going to call it
f here we're going to specify which
activation function we're going to use
we're going to just use some non-linear
function
and we're going to call that so a k
a l k is actually just f of zlk
right so now we have all the
parts that we we have all the terms that
we need to derive the back propagation
algorithm
all right remember this oh here actually
here's a better
expression so z k l is w k j l
uh a l s one j plus plus bias term
and as i said oh here we're actually so
this
is f z okay
and then z l plus one m is again so
there's
a similarity here this is just the next
the z in the next layer so it's
you're iterating repeating this process
layer by layer
here you collect the the a's
multiplied by w and then just that's how
you derive the z
and you put it through the activation
function you get the a and then you use
that a again to arrive to the
next layer of z so on and so forth
all right so if you try to take the
derivative of the loss function c
with respect to input then this is your
chain uh their chain of derivatives
because what you want to get is d c
d x and
you can break it down to d c d
uh because your last year there should
be
some some some c
here which is receives a y the true one
and the a else right so
you want to start with a l if you want
to break it down if you want to break
down
dc dx into multiple chain of derivatives
then you should start with a l and then
a l was derived by zl right
so you d a l
b z l because zl you put zl through the
non-linear activation function and then
you do that again
with how do you direct how you how you
derive the l is you use the a
l minus one the a is from the previous
players
a and this one so let's go for until you
go to the very end which is
z1 here um
these part this part
all the z's here
are derived from the x the actual input
so
here z's are derived by x so that that's
how you get the final
parts of your chain of derivatives
right so yeah you're using the chain
rule to break down this thing so
no question here it's pretty pretty
straightforward so that's
like in order to do this a l and c and
all that that's why we
defined the als and zls in the previous
slide
right
okay no questions good all right so you
take that
take the previously derived chain of the
derivatives and then you can actually
substitute
this one which is a l was what al was f
zl put through the f so derivative of a
l
with respect to zl is exactly this which
is
easy is just f prime dl
right so you put f prime
f uh yeah so so uh here we're using
abbreviated notation
f l equals f c l
so that is why f l there's only f l here
f l prime
then w d c l a a d
a and l minus one so that was
the cl is what was what it was
exactly this one i'm going to ignore the
viceroy so
this was w uh
l transpose a l minus one so that's why
you have w l only you're
the you're you're differentiating zl
with respect to a l minus one
here right so you're only left with wl
so that's why you have wl so this here
this is here
and then this is here again zero again
all the way until you're left with the
very first w1
which is like z's here
z1 is basically w1 transpose x
so that's why there's w1 w1 all right
very simple so it's just a simple
substitution and then
there's a bit of a trick so this is what
this this here
is a derivative and the gradient
is a transpose of the derivative so here
this
this is a derivative and this is
gradient so you want to do a transpose
on the entire thing
so this is uh d c d
x and this is gradient of c respect with
respect to x
so this if you do a trend so this is
uh transpose of dx so if you transpose
on the entire thing then they like the
order is
reversed and there's like transpositive
matrix matrices so there's transposes
matrices
matrices and the entire thing the order
is is reversed
so that's uh there's my sudden
change of change of order here and then
we now so we have we have this defined
the gradient of c with respect to the
input x
and now we define the delta to to
motivate the back propagation like the
recursive nature of that
propagation so here uh there's a new
term here which is delta l
and it looks like this
it's uh somewhere like like like this
much
so if you if you define this as a delta
l
then here is
delta l minus one and somewhere over
here will be
delta l minus two so on and so forth
until the very last time like
until you reach delta one right so this
if you you can define delta l as this
which is which is like a part of your
of your gradient and the the
semantics or the meaning of delta l is
how much the cost
or the loss function because delta l you
can you can so this is a
this entire thing you can collapse this
you can collapse this into a single term
which is
uh dc dz l
like here your delta l even though it's
so it's a chain of derivatives and chain
of derivatives you can collect it into a
single term and if you collapse it
it'll look like this and which is just
saying that
in this neuron in this neuron
the input to this neuron which is the z
the change to the z how does it affect
the cost function or the loss function
so you have a loss function which is
maximum likelihood estimate and which is
like
which is basically a cross entropy or a
negative one likelihood
and the effect that a
perturbation or to change the z that
takes
it influences the uh your your loss
function
that's what delta l k is
so you you can define that term in every
single neuron like here
as well here as well here as well like
every single neuron has its own z
and then you can think of it think of a
think of a
meaning of changing the input to that
specific neuron and how it affects the
final
cost function for the loss function so
that's what z
delta lk is and then
uh right so we have this gradient of c
with respect to x and this we have
defined
in the previous slide the delta l you
can
define each leg you can write delta l
in each layer so as i said uh there's
there's delta l minus one here there's l
delta l minus two there's delta l minus
three l minus four all the way down to
delta one so this is what's happening
here delta one delta two
built-in mess with delta l and of course
in the higher limit the upper layers the
delta term
the chain of derivatives will be shorter
in the lower layer
like in the layer one or layer two the
third chain of the ribbon is
where the delta will be really long like
like this this
so you can think of you can see how it
is decreasing as you go upwards
and you can see some there's some like
overlapping terms in all the
like here this much
is exactly this much right
and unfortunately there's a delta l2 let
me just
maybe i can write right down here delta
delta l minus 2 equals f
l minus 2 prime w of l minus 1
transpose f
l minus 1 prime w of l transpose
f l prime
gradient of a l c right so this is your
delta l two
and again this watch is
in here
right so you can see a pattern
except for the first two terms
for the first two terms here
two terms here you can rewrite delta l
with the previous delta
l plus one right so there's a recursive
nature
so you can write this as f
l minus one prime w
w l transpose and
delta l you can rewrite this as
f l minus 2 prime w l minus 1 transpose
and delta l minus 1
right so if you start from the top if
you can get this
and you can reuse this you can reuse
delta l
to get the value of delta l minus 1 and
then once you
get the delta l minus 1 you can reuse
that to get get the value of delta l
minus two
minus three l minus four all the way
down to delta one and that's why you do
backtrack when you start from the top
and then you go to the bottom
and you reuse the delta delta terms
all the way through yep
so yeah recursively defined
yeah so what so you're not having delta
term expressed
alone is not very useful because what
you really want is
derivative um
partial derivative of your loss function
or the cost function with respect to
the w's in all all the matrices like w
is here w is here w 0 if you want
that that term in order to degrade the
descent to take a step
towards the new value of your w your
friend
that's this is how you derive it using
the delta if you have the delta term
if you know the value of delta and if
you know the value of your
a's the activate activated values then
you can just multiply them
i mean it's more like an outer product
because delta l is a column vector
and a l is what transpose is a is a
horizontal vector it's row vector and if
you multiply them then you'll get a
matrix and that's what you actually want
you want the entire
matrix worth of derivatives
because every every layer is a matrix
right
every layer is a matrix so you want a
same size derivative values to
update your weight matrices so
if you have delta so you have the
recursively defined delta
else and then you can simply multiply
delta l to your previous
aim activated value a then that's how
you get the
the derivative of your cost function
with respect to all the matrices in your
entire
neural network so you do that by
starting from here
start from here you update this then you
go down you
and then you will move on to the
previous layer reuse a l
delta l and then move then calculate w
they calculate the derivatives here and
then you move on the next one
you get the w l minus two and then you
calculate the matrices different
derivatives here and then you move on
and move on
so that's how things are like repeatedly
processed
right so yeah
the uh the caveat is uh
that actually you can do forward crop as
well so back prop is you start from the
top and then you go to the bottom so
that's the back problem you
you irregularly update your parameters
or
iteratively you derive your derivative
of c with with respect to each
parameters but you can do four troubles
you can start from the bottom let's
start from the bottom here
and then move on to the next layer next
layer the next layer next layer and this
you know derive the the derived
derivative
of the c with respect to w but that
means you're going to do a lot of
the same process all over again in the
in the first layer you need to calculate
the entire thing and then get the dot
and then get the
get the gradient of the w one respect to
the c
if you can move to delta two you can
move on to second layer and then get
uh w w2c and move on to like the last
layer and then you get wl
uh delta greater than l gradient w l
minus one c
you can do this but it's just wasted
effort because you're doing the same
thing
again and again and again again the same
the same part being
this much you're doing the same here and
this like this one you're doing the same
time
same thing here again so which which is
waste difference so that's why you do
that problem
but when you do backdrop there are
certain it's going to be much faster
because you don't do
as much calculation as in the forward
problem but you need to
remember everything that's happening
inside the node so you need to remember
or
memorize f prime f l prime
and a lk for each node so that you can
readily
calculate delta l minus 1 and the
gradient of the
c with respect to the matrices because
here because delta is
dynamically calculated but in order to
dynamically calculate delta
you need this value and these are
already given you you need
in your model they are already stored in
your model so you don't need to like
do extra work for this but for this you
need extra work you need to
store this somewhere in your memory and
in order to calculate
gradient of your c with respect to
matrices you are going to get
you calculate delta but you still need
to memorize the a l minus one
somewhere in your memory so that's why
yeah that's why uh training your neural
network takes a lot of your video
video memory because you need to have
you have certain overheads that you
can't you need to
maintain in order to fix back
propagation
uh yeah and this is just a
fully connected feed for a neural
network if you have a confidence or
recurrentness or transformer then
this entire this exact derivation won't
work because this
entire derivation was done under the
assumption that you are dealing with
feed from neural network fully connected
but if you're doing transformers or
refrain neural networks then they have
different derivation
which i won't go into and go into detail
anymore this
really helps if you think about 24
blocks of transformer
which is gpt do you think you can change
you can do chain
rule derivative that's
yeah it's just yeah i don't think
anybody can do that
and unfortunately because nobody can do
it
you can use high torch or tensorflow or
any other red package that will do that
for you
so yeah this is the last section
any any questions so far until here
no
all right yeah this is this could be a
bit mathematical but it's
i think it's a good idea to actually at
least you know go through it once
so that you can when you
build a model in python you can imagine
what's happening when you do backdrop in
your pi forge
like when you call backward function in
your pi version
it is going through this process
but of course with that's when you're
when your model is
fully collected for neural network
okay as i said nobody wants to do chain
nobody wants to do a chain of
derivatives on their own so we use
computers we use power of computer
and every old all the like tensorflow
theano
uh pi torch mxf they probably have the
same
auto grid engine inside which is just
vector multiplied multiplied by jacobian
matrix
and let's get into that
right so in practice computer does that
propagation for you
and the important thing is a neural
network or any
any model that you build in your pie
torture tensor flow it is represented
as a directed a cyclic graph so it's a
graph represent your model is
represented as a graph and each node
is a computation and you'll see that so
each yeah each of them maintains a
mathematical
operation if it's a sum if it's a mean
or multiplication
that product uh your node will represent
that
and each node contains the derivative of
the math operation
so that's for uh that's for like i don't
know
if you want to i don't know i'll yeah
i'll talk about it in the next play
and the error signal is propagated from
the autonomous vehicle so this means
that it is doing back propagation
so let's think of a very simple program
on that program where your x is a matrix
two by two
two matrix filled with ones
and the a a variable is x plus b
b variable is a times a times three and
c variable is the mean
operation applied to the b the b
variable
it's a there's it's not a neural network
right it's just a math
it's just algebra so your
your c is what your c is mean of
3 times x plus 2 squared
right this is your i mean that your x
should be actually
a matrix so all these operations x plus
two
eight times eight times three these are
element-wise operations
because they're if you remember the
broadcasting
two is broadcasted as two two two two
right
and times three is broadcasted as
multiplied by three three three three
element wise
they're all broadcast and then and
finally you do the mean operation which
is taking
all this all the the four elements in
your x matrix and then
doing another version now
like you can think of this as a bag
structure as i said
so there's a graph so your a is unknown
your b is a node c is a node
and your a node will consist of x plus
two operations your b node will because
it's a times a times three operation
and c node this just averaging out the b
and actually to make it more even more
simpler so
you break down your a times a times
three the a times a from three into two
separate operations which is a times a
and b times three so a times a and b
prime
b yeah b prime three
so let's go there's one more one more
one more note here
now given this given this each what you
can think of what each node is doing
internally which is
in thai torch every node every node has
its own
gradient function so every node being a
single operation like sum mean division
differentiation
division like subtraction every like all
the operations
each node has a corresponding gradient
function
and i'm just making this up i'm pretty
sure it's very similar to
what what the actual implementation is
but if you add
a constant value to your input then it
is
the gradient function corresponding to
that is add constant
so internally there's add constant like
match
to your your node your a node and in the
b prime node which is basically you're
just multiplying it by yourself
which is a times n um i'm not sure how
it's implemented but i'm going to
i'm just going to call this power
because your top this is the power of
two
actually constant plus two
and that next thing is your multi you're
multiplying your input
with a constant number of three so this
is mole constant
multiplied by three and the last
gradient function is mean which is just
a unitary operation so these are so this
is a
binary operation because it requires
another
argument it's binary operation binary
operation this is unitary operation
this is the unit operation and each
operation has its own gradient function
and each gradient function has a forward
part and backward part
so in order you can actually define your
own
new gradient function it's just the
functions you can define it
using python program or piper's program
so there's a
class called class grad function
and then you can inherit from this graph
function to direct to
you know come up with your own grading
function and in order to do that you
need to
define the forward method and the
backward method this is the
minimum and the forward method is
computing the forward propagate the
forward propagation so add constant
the forward part is just plus plus
something plus given
if you call this r1
in the forward method all you do is just
plus argument and then you save the
input
and the miscellaneous for back for the
backward propagation
so you say the arg one and the given
input x into some container
and then you reuse that when you're
doing back propagation
so forward part is that backward is
given
given the delta l so because we're we're
using the delta term again so given
delta l
your the the role of the backward
function is to calculate delta l minus
one
so given previous error you want to
calculate
its own error and
of course in the way along the way you
want to do this if necessary so if
if your operation involves a learnable
parameter
you need a gradient of the c with
respect to its parameter
and that's how and you can just multiply
this delta l
with this input and its miscellaneous
miscellaneous being this you need you
needed to
store this in the forward process
somewhere so that you can reuse it in
the backward process when you need to
calculate the gradient of c with respect
to w and
you can imagine that here in the add
constant there is a learnable parameter
so
you don't have to do this you don't have
to do this in
ball constant or power or mean actually
not none of this requires like learnable
trend because there is no learnable
parameter
in the entire math program so you never
need to do this in this chain but if you
have like
theta or double or whatever level
parameter then your
gradient function will do this for you
when you're when you call the backboard
operation all right
so in the mathematical form
uh there's a question
three three zero zero three
foreign
multiplied by
my right so okay so
yeah as i said you you once you have the
gradient function defined then
what when you call the backward function
what happens is exactly
this so you calculate the partial
derivative of c with respect to b which
is so this was
this is input to c so in the backward
you calculate this term and then between
b and a prime you calculate this term
and between b prime and a you copy this
term in this terms
okay you're doing the back propagation
chain and
if you calculate this then this can be
reused in
oh okay oh right so yeah i'm just
rewriting
this stuff a bit so this this part can
be rewritten
like this because because
[Music]
let me see
yeah you multiply this then you get this
one
here this is this which is
yeah except for this you collapse the
entire term so
what what what's happening here is that
you can think of this as the delta
so here the c value so
partial derivative of c with respect to
b is when you
change b how c changes so that's like if
you think of c as
like a cost function there's no cost
function it's just it's just a mean term
but if you think of c
it's like a loss term or some final term
that you want to
two then this term is basically delta
l which is how your final term changes
with respect to your input which is b
this term is delta l minus 1
which is b prime being the input so how
in this part
your input changes the final term c and
so on and so forth so
again i mean like delta 2 delta one i i
would say
and and then you you can rewrite these
this term here
right this part like this you can
rewrite this term like this and then if
you look at it then there's a some term
being recycled which is
this one is recycled here this term is
recycled here this side is
recycled here and kick i mean can be
recycled so
delta l is recycled in deriving delta
l minus one right because this is this
is delta l minus one
and delta l minus one is used again to
uh to derive the value of delta two and
then the same
delta two is reused in the in deriving
the value of delta l1 as
well so you can see exactly what's
happening it's the same thing
like this yeah the same thing is
happening so all this thing
is implemented in tight work so it's
hyper just even more flexible it doesn't
have it it not only just do it does
that propagate or fully connected
network it does that propagation for any
math program any math problem this is
just
some math program i've written without
any meaning
there's no meaning to it i just i've
just written it for a demonstration
but it can still do backdrop
like like this it's a background and it
can be any
mathematical program so that's why you
can write countless
recurrent lens transformers gans vas
whatever whatever you can write in va
and it'll
do backdrop because it has the gradient
function
yeah the grad functions embedded into
all the nodes inside
so yeah that's the uh uh and of course i
i've said something about hector
jacobian matrix multiplication
uh that's applied when these values are
no longer
scalars so uh like plus two plus like
times eight
times three like this is a very very
simple matrix and
if you if there's like a learnable
parameter between
this between these bits like if certain
if some
some step requires a matrix w then that
then you start to require like jacobian
matrix and
you do like vector jacobian matrix
multiplication and
if you're interested in all the
mathematical stuff you can take a look
at the wikipedia back propagation page
it is a very
uh detailed uh detailer algorithm
outline there
yeah it's okay so this is how autograd
is like
crudely it's a crude description of how
autograph is implemented and how it's
operated when you call the backward
function in pi first
all right this is the okay this is the
end of the end of the class
and uh one more question miscellaneous
is
learning when you don't have label
vector to help you how does aerobic
property there's no backdrop
on no there is back problem for
non-supervised learning
i mean if you do again if you call if
you can't call vaes organs or
auto encoders unsupervised learning then
there is still a background
but if you do clustering then there is
no background
so i think there should be a distinction
between
a learnable unsupervised writing and on
like non-parametric
unsupervised learning
foreign
ken does not have labels cans uh they
don't have annotate they don't require
annotated labels but they still have
labels coming from real
images and fake images real images being
one fake images being zero
but they're still labeled if you do auto
encoders then there's reconstruction
error so reconstruction area you need
the original x image so that's your
label
yeah so the concept of label is pretty
flexible these things
[Music]
transformer
foreign
foreign
okay so yeah i'm just going to answer
the questions and you can leave whatever
you want
yeah the class is ended for today
um
um
foreign
is there any different way to decide the
learning writing or training
uh definitely no there is no definite
way it's all
dark magic so you you use like the
actual exponentially decaying learning
rate you use like dynamically
uh adjusted learning right there's like
hell have like all different whole lot
of different ways to
tune your learning right and it's still
uh there's no like
definite answer what's the way to do it
all right okay so i think yeah we can
end the class for today
well transposon
okay
foreign
all right this is the end of class on
thursday