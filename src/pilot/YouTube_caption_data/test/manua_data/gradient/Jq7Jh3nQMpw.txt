In this module we'll go over the process of
learning parameters i.e., training.
In particular we'll talk about gradient descent.
Gradient descent is a method to find the minimum
of a function.
It can be applied to function on multiple
variables, but for this example we'll do a
toy example with just one dimension.
So in gradient ascent we basically start off
with a random guess for our parameter and,
in this case, we'll use a subscript 0 to indicate
that it's our first guess.
We want to find the value of the parameter
that minimizes the function, so we want to
move in this direction.
We can do this by adding a small positive
number to the parameter value.
Examining the sign of the derivative, we see
that itâ€™s the opposite sign of the number
we would like to add.
Therefore we can simply add a number of proportional
to the negative of the slope or derivative.
Similarly, for on this side of the function,
we'd like to move in a negative direction.
So we can do this by adding a negative number.
Examining the sign of the derivative, we see
it's opposite to the sign of the number that
we would like to add.
Therefore we can simply add a number proportional
to the negative of the derivative.
So in general gradient descent is recursively
calculated.
We start off with an initial guess and for
the first iteration we simply add a value
proportional to the derivative.
We update the parameter value and we repeat
for the second iteration.
And we continue to the k-th iteration.
The parameter theta is known as a learning
rate, usually selected empirically.
Now let's clarify the process with an example.
So we have our loss function and we start
off with an initial value of negative 4.
So we calculate the derivative at that point,
in this case it's -112, and we'll set our
learning rate to 1 over 20.
We calculate the first iteration.
We update our parameter value and it generates
a new loss value, as follows, in this case it's 50.
And the loss generated from the first iteration
is less than our initial guess.
For the next iteration, we'll use a previous
parameter estimate of 1.6.
We use the same learning rate.
We update the parameter value.
The parameter value for the second iteration
is -1.76 and you can see by the plot that
the loss value for the second iteration is
smaller than the loss value for the first iteration.
There are several ways to start the process
of gradient descent.
We could run up for a set number of iterations.
But, let's go over another way.
So one way is to see if the loss starts increasing.
Let's record a few iterations of gradient
descent in the following table.
For the initial guess we get a loss of value
of 250.
We continue with the first iteration and the
value of the loss obtained is 150.
We see that 150 is smaller than 250, so we
keep going.
For the second iteration we get 50 and because
50 is smaller than 150, we keep going.
In this final iteration, which we see that
the loss is 100 because 100 is not smaller
than 50 we can stop gradient descent.
And we use the value of the parameter where
the loss was 50 i.e., -2.5.
One problem of gradient descent is selecting
the learning rate.
So in the last example we used a value of
120.
But let's see what happens when we use a larger
value of one over five.
Calculating the first iteration the value
of a parameter is 18.
This is so large and won't even fit on our
graph.
If your learning rate is too big, you'll miss
the minimum point.
Let's see another problem.
So let's see what happens when we choose a
very small learning rate.
So in this example, we choose a learning rate
of 1 over 240, and we'll perform three iterations
of gradient descent.
And we can see our parameter value has barely
changed.
The problem with this is it will take too
long to reach a minimum.
So we'll go over how to select a better learning
rate in other sections.
Let's continue on with the process of learning
parameters.