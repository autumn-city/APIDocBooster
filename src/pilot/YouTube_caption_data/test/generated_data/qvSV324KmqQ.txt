hey it's me again and we're doing coding
i also want to ask you all to pretend
that i'm wearing a different shirt and
that i didn't record these all back to
back
all right so you're going to find in the
slides uh
or if you're not in the class in the
description of this video
a link to this notebook right here and
you will
come up with something like this which
doesn't really look like a notebook does
it
and you just need to open it with google
colab if you don't see this
link right here you can drop down
connect with more apps and just find it
all right so after you open it it will
go here
all right and you'll see the notebook
but you won't actually be able to edit
this notebook
because i don't want you all changing at
the same time so you just need to go in
save a copy and drive and you'll be
brought to a new copy which you can edit
and run on all that good stuff
and we're going to start going through
this code and showing you now of course
we did just learn um about
nonlinearities and convolutions and of
course we're going to be working with
those
this will basically be though the same
code as our first
pytorch walkthrough but we're going to
show you how to do those new things now
all right so of course like before we
just install the dependencies
we import what we need we have torch
torch vision
and of course all of these we also
define our hyper parameters
like before so we have our input size
which is set by the task which is 784
which is 28 by 28 images
we have our hidden layer which we could
set to whatever we want we have a number
of classes which again is set by the
task and we have our number of epochs
which is how many times we run through
the data set
so we'll set this a little bit lower
because we're going to do a little bit
of testing today
um batch size something that we haven't
gotten to and
probably won't be able to get to at
least in the class
on youtube we may be able to which is
essentially
the amount of data we look at all at
once the amount of images we're going to
look at
at once and then we can find a gradient
based on all of those images that we
generalize
instead of just a single image at a time
it's a very
useful thing and something that you will
like to learn at some point
um so our learning rate of course we
also set
um we said something fairly small like
before but
we can test around it if we want to try
something different so now we download
the data um we're using the
the torch vision data sets so we can
just download them this very quickly
these are the generators it's how we
enumerate over our data sets so that we
can actually do our training
to load that and then here's the good
stuff here's our model
all right so we're going to start with a
very simple model we're going to start
with a just fully connected layers
just back to back to back um and we're
going to see how that
turns out so right now we have the full
engine one to two to two to three
this one goes of course from it's same
size the same size it's gonna wake
up back to back i'm actually gonna get
rid of one of these just to make it a
little bit simpler
so we just have one two three which is
gonna go from input size to hidden size
hidden size to hidden size and then
hidden size to numb classes so we're
going to have
we're going to have that and of course
we have made in size being 600 which we
set above
so we're just going to define this run
it that's going to be our first network
that we're going to test right here
we're initializing our network using
this and then this right here is
checking whether we have cuda available
um cuda is the nvidia package
um there are these cuda cores on the new
nvidia graphics cards
that will speed up uh the training of
your network if you have them enabled
which is this is what this is checking
um but in practice and in pi torch we're
going to have to send our network to
cuda vectors instead of the normal pi
torch vectors
it doesn't really matter too much but it
would speed it up which
we're not going to be doing it but you
can't do it on your own look up cuda if
you have an nvidia graphics card
all right so now we're going to define
our loss function we're using
cross-entropy loss again
which is the loss that i described in in
lecture which is essentially treating
each of the outputs as a probability
it's slightly more complicated than that
but that's the gist of it and then we
are taking the
um the loss based off of how accurate
the top one
is and then we have our optimizer which
is going to be actual sgd so of course
we do already know this one uh totally
and we are actually going to use it so
there we go and then this is our
training loop right here something very
simple just going to do three
epochs of training and let's see how it
goes um so you'll notice that uh with
the
uh just fully connected layers it does
converge fairly quickly uh if we look at
it it's
converging to reasonable losses um in
just a couple of epochs
and we'll actually see it drop pretty
low so
even with just simple fully connected
layers this is like what they would have
in the days before non-linearities we
still perform pretty well
um and actually we want to check our
accuracy we get
80 which is not bad at all um that would
be you know
fairly good for back in the day like
before people knew about
uh or before people had these
multi-layered neural networks and all
this
um that would have been pretty good but
that was a long time ago that's not that
great today
um so now we want to make our first
change to the network so
we've talked about non-linearities i've
hyped them up quite a bit so let's try
actually using one
so here we define relu here's how in pi
torch this is how we define the relu
layer
so you just use the neural network dot
relu from
pi pytorch and all that um you can look
up the nn
part of pi torch if you'd like to see
all of the different layers that we can
include
um so now that we've defined this we
don't need to find multiple versions of
them if we want to use it multiple times
all rails are the same they're just the
max function so we can just
do that like this cell so we say the
output is now going to be self.relu
of out and we're just going to have to
put this in between
both of the different layers that we
have already
so now we have a relu in between each of
the fully connected uh we don't need it
at the end here we just need it in
between them
so now this entire thing is uh three
linear layers separated by
non-linearities so they do not combine
and this entire thing is now a
non-linear function we need to rerun
this to reset what our network is
we need to rerun this to reinitialize as
a new network and we do need to rerun
this too
because we are passing the parameters of
the network into the optimizer so we
need to do that again
and this is all of the parameters like
i've said before like the
weight vectors and all of that and as we
need to convolutions it will be the uh
the kernels and all this too do all get
passed as dot parameters from our
network
all right now we can start the training
and we can see how
uh how well the hype holds up um so you
start to see
that it seems to be converging slower um
so
you know i've talked up nonlinearities
and their importance
and all of this and now we have these
non-linear functions so we expect this
to be
wonderful and great and all of that uh
but it is converging slower and when we
go to check the accuracy we do see
70 so it is 10 worse
so what gives why why is it doing this
um i'll give you a moment
to try to think about why this is
happening on your own um
and try to try to give it any sort of
compelling reason why this might happen
i'd say
think about back propagation think about
what the derivative of the rayleigh
looks like and think about why it might
be
converging slower and does it actually
mean that it's worse
so hopefully you've thought about that
for a second
cool um so i'll give you an answer now
so
when we're running relu like we saw
before it deletes essentially
all of the negative values so it's
getting rid of all of the negative
values that are in our network
we aren't passing them forward and we
aren't back propagating to them
and because of that we actually have
many fewer of our parameters actually
updating especially from an
initialization
when we have a gaussian distribution
where some of them are negative
we actually see that we are not updating
as quickly as if we didn't have the relu
now that isn't to say that the relu
isn't
isn't better so it's just that we have a
very limited amount of data right now we
only have three epochs
and we aren't doing any tuning of our
parameters or anything like that
um so if we were to give it more data
um and we give it longer the rayleigh
would outperform
the regular affine fully connected
layers
it will actually have a higher bound so
because
the affine layers can only be a linear
function they actually
cap out earlier they're only able to get
probably around 85 percent accuracy
but with a rayleigh if we were to train
it and properly do it we could get 95 to
98
accuracy um just by doing that so
it is a big difference um and
we i don't want i don't want your
takeaway to be that really who sucks um
it does converge slowly though and i
want you to
acknowledge this fault of relu and like
what that means
all right so now that we've done relu um
we've done non-linearities that's all
well and good
let's get to convolution so convolutions
are the much
bigger step in terms of upping the
performance here
um and upping like like all of these
like seeing this number go down quicker
the convergence will be much faster
with convolution so here's how we define
our convolutional layer so this is a an
nn.conf 2d
um so this is a two dimension
two-dimensional convolution which is the
ones that we've learned about
um so we just need to define its
parameters now so we have the input
channels
i'll give you a second to think on what
that should be we're taking an
mnist how many channels does mnus have
that's right it has one so of course
it's gray scale so it only has a one
channel if it were rpg it would have the
three channels so
keep that in mind for the output
channels we can pick something
totally arbitrary uh let's go with 10
i don't know so we're going to use those
10 so that'll be 10 different 4x4
filters
we set the kernel size here as 4x4
so we have 4x4 filters we have 10 of
them we're taking in one channel
and then for the stride we know that our
28 by 28 images are divisible by
four so we can actually do stride one
and know that we will actually come out
with a proper answer
um it's a slight trick for you but
nothing
like too fancy i'm sure you can figure
out why that is um
so now we end up uh like with our
convolutional layer all set so we can
actually add it to our forward now
so we have our output be it self.conf1
um only column and we take an x and we
need to make sure that we actually
change our fully connected layer so now
it takes in the output of the conf one
now we aren't actually done now uh
so we see that we are actually producing
a multi-dimensional
uh tensor from our convolution so we
actually have
you know we have a 10 by something by
something um i'm really trying to
figure out what those somethings are um
you know what i'm actually i'm going to
change it for you i'm going to say that
this is
seven by seven how about that all right
new problem it's 7 7x7 now
so now we decide how big this is and we
know that these fully connected layers
these affine layers as they might be
called
as i've been calling them subtly
we can only take in a vector so they can
only take in a one dimensional tensor so
we actually are going to need to convert
it in some way
so the very first thing we're going to
want to do is we're going to want to
reshape
this output so we have a three we have a
three-dimensional output here we want to
make it a one-dimensional output
and you know how do we do that luckily
pi torch has something built in that is
very nice for this so we're going to use
the dot
view function and if we use dot view and
we give it the first parameter as
negative one this is going to tell it to
flatten
our data into a single vector so we need
that because we're passing a one
dimensional vector
so now we just need to pass in the size
of it and if any of you have worked it
out on the side with this seven by seven
kernel size stride one
we're going to end up with a 22 by 22
image that is 10 channels deep so this
will be the actual size of the output
from this layer
and of course this is actually not the
last thing we need to do we also need to
change it up here
so it's going to need we need to change
its definition so that it is taking in
the proper size so
22 by 22 by 10. all right
so this is all set this network is valid
now it should be able to be run
we just need to run through each of
these but here we do actually have one
more thing we need to change give you a
second see if you can figure out what it
is
um so it is this right here so you
actually know what this does now we are
changing the view of the
images which is uh the input that we're
getting and we are making a significant
single dimension vector
we were doing this before because we
only had fully connected layers and they
of course
need a single input but now that we have
a convolution we actually want to have a
multi-dimensional input so we can get
rid of that
now all right so now this is all set so
we can start to train it
and let's see how it behaves so
off the bat nothing too spectacular it's
uh staying roughly around two which is
what the uh the rayleigh did but now we
see that it is dipping down
quite quickly um and it is going much
lower than either of the other two did
before
so even with this simple one
convolutional layer we got our loss all
the way down to 0.3
um like into the under one very quickly
and this is only with a little bit of
data mind you um so let's try
actually checking the accuracy again to
make this same change here
and now we can run it and we should get
pretty high that's 86 percent that's
pretty decent for
just three epochs and without doing any
tuning whatsoever
we didn't check for different type of
parameters we just won it
so now let's try something new we're
going to try
two convolutional layers so like i said
before we can
we can have as many convolutional layers
as we want um so let's try adding a new
one
um so if this one's going to be
convolutional layer 2 we're going to
have it go after confusion on error one
so of course its input channels will
actually be 10 because the output
channels of the one before it were 10.
um and it's a general um paradigm
account it comes from alexnet if you
want to go look up that paper but what
we tend to do is we have
the kernels across multiple convolutions
get
smaller but the number of filters get
bigger
this has sort of just been proven to
work empirically if you want to try to
convince yourself of why that's a good
idea
go for it but let's try upping the
number so let's say
55 kind of a random number but let's go
for it
and let's have the kernel size be
two two by two all right two by two
and we have stride one still let's say
okay
so that seems all well and good okay now
we do have a different size though so
i'll let you try to figure out what it
is on your own um and then i'm gonna
type it in in a second
so now we have a new size coming out of
here so i'm going to
i'm going to remove that then we're
going to have our output
is is now going to be self.com
2 taking the output so we're going to do
two convolutions on it now
and we're going to change the input size
with
the view so
hopefully you've got it by now with all
that typing
it's going to be a 21 by 21 by 55
so there are five channels and then you
get 21 by 21. we have
from this 7 we got 22 by 22
and then if we do you can just use the
equation if you'd like we get 21 by 21
out of this
all right so we need to make this same
change up here so we're going to take
the same value
this needs to be that all right so now
this should
all work out let's see if it does
and let's see so we run through these
and let's see how the training looks
all right so again this is just with
three epochs very
small amount of data um we see that it
starts converging
it seems to be converging very quickly
and in fact it is
um and we'll see that it will train very
well
actually so let's see that it goes all
the way down again to point three but it
tends to stay down there we have many
more parameters we've actually added a
lot of parameters
um which you know there is a trade-off
between adding more parameters there's
more things we're updating but you see
it doesn't slow it down that much
and we are getting much better
performance and let's see how the the
accuracy actually turns out
so we got 89 percent which is pretty
swell um so let's try
doing this except with more data
so instead of just three epochs let's do
10. i'm going to vamp a little bit more
but i believe in myself
all right so now with 10 epochs let's
see how this turns out
now again this is without us you know
messing around with the hyper parameters
at all
um did i change something wrong why is
it going up
all right that's a bit odd um hmm
interesting did i change the wrong thing
i might have changed the wrong thing
let me fox no 10 did
strange is it gonna go back down
huh well this is interesting um so
i'm guessing i'm i'm putting you a
little bit behind the curtain of uh
of training models and what it feels
like because there's a lot of debugging
that goes into it
um this is not this is this is not a
mistake this is on purpose
um easy actually it did go down pretty
low there um so i'm kind of curious how
this is going to turn out
um you can put your guesses in the
comments or whatever
um that's how this is gonna go it could
be that we are doing um
we're doing so that actually went down
very low
huh let's see how it turns out yeah i'm
curious myself
this is sort of the nature of playing
with machine learning is sort of just
figuring stuff out let's see how it
turned out
95 so pretty damn good um so yeah
these losses are a little bit um
not indicative of how well it's actually
doing we're going to talk about this
actually more in the next lecture that's
a pretty good segue about why these
losses can be deceptive and why we
actually don't necessarily want to
reduce these as
much as possible um so this actually
turned out pretty well
um this is pretty good accuracy i
am going to wager that you guys could
actually do better so i'm going to say
download this
see play around with the sizes of these
filters see if you can figure out some
filters that work
and see how good you can get the
accuracy i would expect that you should
be able to get
98 if you mess around with it but if you
can't that's totally fine just try to
try to figure out how it works
all right hope you enjoyed and i'll see
you in the next one to talk about uh
talk about all this nonsense all right
thanks for coming