HI, my name is  Abhilash Majumder.
I am a research scientist working for Morgan Stanley.
previously I used to work for HSBC holdings as a machine learning NLP engineer.
I have worked previously with Google research on the language models.
and I have mentoring professionals and students on machine learning,
AI and NLP from different organizations like a Udacity,Udemy, Upgrad.
And so in general, I have been working on this
mentorship opportunities and tasks for quite a long time.
And to find you can find the links in the comments section in the description below.
And so welcome to co-learning lounge, YouTube channel.
So today I will be explaining you the intricacies of RNN recurrent neural networks.
also make sure to subscribe to this channel because I will be uploading different interesting
videos on transformers, attention and other sophisticated things related to an NLP.
in general, you can command a, if you find something helpful and also feedbacks are welcome.
So let's get started with what recurrent neural networks are.
So recurrent neural networks generally refer to a class
of neural networks, which work on recurrence relations.
These set of neural networks are, are vastly used mainly due to memory retention.
And also it can capture lots of information.
from a particular classification tests or any tests in general, particularly
in the field of NLP RNNs have made the breakthrough from a long time.
So in the, in the context of sentiment classification the image
captioning everywhere, we find that our RNN are always there.
I'll meet in the present time.
These are present in the form of sophisticated architectures, but the basic
form of recurrent neural networks are still persistent even to this state.
Now, why do we need recurrent neural networks is because when we are talking about
particularly in the field of NLP, when we are talking about context of a particular
sentence or a particular word in a sentence, We generally need to refer to what words or
phrases are present for what that particular word and backward to that particular word.
That means we want to capture the context of a particular sentence.
Right.
And in that case Our recurrent neural networks perform the best.
They have this different activation units inside them.
They have a recurrence relations which are then time steps that
allow the Memory to capture all the sufficient information required.
For a classifier, generic Michel machine learning
classifier, or any NLP classifier to perform its tasks.
So sentiment classification is by far one of the most you know most applicable genres
of recurrent neural networks because they have been used extensively in this aspect.
And in, in other contexts, when we come to language translation where we want
to convert from one language to another language, let's say English to French.
French or vice versa, we can generally get to know more about recurrent
neural networks and how they can optimize by understanding different
contexts present in different languages and also analyze them.
So in this example, we see that there, we have a
French Corpus and then correspondingly English, Corpus.
So.
With the help of RNNs and all the, you know, sophisticated architectures, which are currently
in present we can generally translate from one language to another, and this has greatly
enabled us to build a scalable and highly like having a very high throughput of RNNs.
So RNNs are, can be used for mapping inputs to outputs of various
types of lengths and are fairly generalized in the application.
So.
Details of this recurrent neural networks.
Now, when we talk about recurrent neural networks we generally can think of
it as a very sophisticated multi-layered perceptron or a multi MLP in general.
So what happens in NLP is that we have an input which collects the input features, and
we apply some kind of non-linear activation units on it, on that particular inputs.
And we get the output of that, of those input features.
And these non-linear activation units can be.
Anything ranging from sigmoid softmax Relu, and this kinds of activation
units are present to allow some non-linearity in the input features.
Now, when we have a deep network, we design a deep network with just a basic MLP.
we there is effectively no memory retention or there is effectively no you know, memory.
present which can capture sufficient information from a particular text or a particular NLP Corpus.
so that is where the recurrent neural net comes into the picture.
Now, if we, if we were to unroll a recurrent neural network, we will
be able to see that a classic diagram, which is the word word, right.
And we apply certain activations in a series of steps, one after the other.
So if we have a particular word, let's say word one, as the input and activation comes
into the picture, which apples gets applied on w one that is the word vector input.
And the output of that particular activated Lear is the input to the next layer.
So in this way, there are lots of hidden layers in between and in
an unroll recurrent neural networks, but all these kinds of things
often happen because we are unrolling on recurrent neural networks.
But if we were to design an RNN from scratch, we would be thinking them as similar to
recurrence function, which can be viewed in this example over here, you can see that we
have an input sentence or an input feature vector, and we are passing it to a hidden layer.
Now that healer has a arrow loop, which is, which is a, which is a self loop.
And it is running back to itself.
Again, this implies that the intermediate parts that is the intermediate hidden layer.
So for recurrent neural networks affording some kinds of recurrence.
Now, recurrence is a general rule in computer science when we want to apply a function,
which, which is almost a similar as which, which ranges actually based on certain time.
So for instance, if  the function has a value of N.
The time equals to one you know, that same function with data value of N plus
some added features so that every, at every time stamp, some of the input
features of the previous timestamp will be, will be present as input features.
So recurrent neural networks applied this concept.
Now, if in a, in a general record and you will network since this is a neural
network topic, there are two broadly different kinds of things which are happening.
So one is a forward pass.
Which which computes the weights and the biases of the input features.
And then since we are performing supervised learning, then we compute that and drop it.
Then we compute the loss that we have either a categorical loss or a binary loss.
We compute the errors and we try to back propagate to the recurrent neural network.
And this is where the performance enhancement comes into the picture.
Now, in this case, we'll be talking about the forward pass in this mechanism.
Now, typically a recurrent neural network in detail appears like this.
You have an input feature, which is x recurrent neural network unit, which is a self loop on it.
And then it provides the output.
Now in this case, we have afforded or at work that is hello.
The first four letters that is H E L L.
And we will ask the network that is the RNN network in
the forward pass to predict what will be the next letter.
So here, the vocabulary of the task is just four letters.
That is H E L O no, in most of the language and NP situations.
This prediction is what gets output is, becomes the output in a general classification tasks.
Now, if we were to design a particular RNN, so that
would look pretty much similar to something like this.
If we consider the hallow example at time, step t if we, if we just pass the first four
letters that is H E L L, then we in the time step people, the one that is the next time
step, we will be passing E so at each time step, we are with the next character from it.
So if we write this in a record, his formula, it becomes Ht equal to F of Ht minus one, comma Ht.
When Ht is the new  state and Ht minus one is the previous state.
Well, Xt is the current input.
Now we have a previous input instead of the input itself because in recurrent neural networks,
the input neuron would have to be applied on the transformations of the previous input.
That means at the time step equal to T one.
What was the well, the outcome is dependent on the timestamp equal to t0.
That was the previous output.
So in this way, the recurrent neural networks try to apply this
in a sequential manner, in a sequence shell recurrence manner.
So if we were to take this simple example where we have Ht = F of Ht, minus
one comma Xt, and we will be applying some kind of nonlinear activation on it.
Now the design of this is very similar to what multi-layered perceptron.
We are applying linear activation, which has given me this equation over here.
Ht = tanh, each of this, this is a particular weight metrics
that is given by WHH times the Ht minus one, plus w XH.
This is another way where we had metrics with Xt.
So effectively we get up a couple of equation having a non-linear activation unit.
Called a Tanh and we are having some associated weights.
The weights are associated with the Ht minus one.
That is the previous state and also the Xt that is the input state.
So we have two different kinds of weight factors over here that the W HH under the
W XH, corresponding to Ht minus one, and corresponding to exterior, respectively.
Now, this is the internal layer of a particular recurrent neural network.
Now, now, if you want to compute the output, that is the Y in our
figure, this is why in our figures, we have to just apply the output.
That is the Ht.
We have to apply some weight on it.
So in many cases, this is the most simplistic output where we apply a way that is w H Y on top
of the output of the previous year that is Ht, or we can apply a non-linear activation on this.
So either it can be YT where to some non-linear activation times,
this is why I am so Ht, or it can be simply as wh wait I'm safety.
So if we were to summarize this and that step of how recurrent neural networks work.
So a single time step of the input is supplied for the network.
That is the input feature, which is in our case, the Xt, we then calculate the current state using
a combination of the input features the current input and the previous state in the previous state.
If it, if we have the first time step that the previous step will be zero.
So initially we calculate the Ht.
Now the current Ht becomes Ht minus one for the next time step.
So, this is how the recurrence pattern is followed in the current neural networks.
And we can go as many times steps as we want as our problems defined that.
And we can combine the information from all the previous States.
So in this way, we have our recurrent flow of inputs and recurrent flow
of weights and biases at each step of the recurrent neural network.
Now, once all the time steps are completed, the final step is.
It gives us the Yt.
That is the output.
Now the output is then compared with the, you know, the predictor that
is the actual output, just isn't the case of normal supervised learning.
Right?
And then we can do the backpropagation to calculate, to change the weights, to
update the weights, to make the difference on the error as much as possible.
Now, in this case, let us take an example to see how the forward proposition
are generally referred to as the forward pass take places in RNN.
So in this case, if we take the first four letters of the word, hello, H E L L.
So we see that this is, you know a tensor right, having zeros and ones effectively.
This is known as a one hot encoded tensor.
And in this case, you can also get to know the dimensions of this.
So it has only one column.
four different rows pertaining to the ones and zeros which are presented.
Now, One hot encoded vectors are effectively very they give very sparse
mattresses or very sparsed answers because only one element is one and the rest.
All the elements are zero.
And let us now initialize our two weights that is w H H and w X H.
If we remember in our equation that we have.
We have two weeks.
One is w H H and one is w X H.
Now we have to initialize those wings.
Now let us initialize them randomly as it has done over here.
So the W X H is defined by this tensor.
I mean, these weights corresponding to H E L & L.
Right.
And then we have.
for, for the letter H for and for the hidden state, we also need w X H right?
So by matrix multiplication, which is given by this equation,
w X H into XT bleak, it, we might do the W X H into this H.
That is the first letter.
And we get this as the output.
This decimal values out the, this decimal tensor as the output.
Now this completes the first step where we have calculated the forward pass for H.
Now, if we move to the recurrent neural network or the recurrent neural network,
we also have to calculate the w H H, which is another one plus one metrics.
Now we have to take some bias.
Now it is recommended to take some bias since most of the cases, but for our case, we if we
remove the bias, then our accordingly we'll network for the first step, we'll only output zeros.
Why this will be, is as follows because for the letter
H the previous is  because H is our first letter.
And if, and for the first set of the previous state,
that is the T minus one state is effectively zero.
Because H are what first that is t equal to one.
So for t equal to zero, they effectively, everything will be zero.
So when we calculate the weights, that is the w H H * H T minus one.
This is biased.
If it, this part has into Ht minus one are effectively multiplying.
This, this tensor that is 0.427 multiplied with this tensor
that is Ht minus one because Ht minus one is zero though.
W H Ht minus one also becomes Zero effectively.
What we are, what we are left with is just the bias.
So if we keep our biases zero, we can get to know that,
you know, for the first step, everything will be zero.
This particular part that is WHH into Ht minus one, this part will effectively be Zero.
So the output of the first one would be zero.
But if we were to keep some bias, in this case, we have a bias of 0.567.
So that bias will get added with zero to give some initial value status you'll 0.5, six, seven.
No, the step three is we have to add these two in the outcomes of these two mathematical equations.
That is this part, the tensor over here, and this tensor over here, because we
have computer WHH into Ht minus one, and we have also computed w XH into Xt, right?
And now we have to add them, which gives us these tensor of values to these floating point numbers.
And then we have to take some.
Non-linear activation on it in general, in record and neural networks, we are mostly
concerned with tanh because tanh has some important properties of memory restoration
and memory, and capturing a lot of member information from textual corpuses.
That is why banished is mostly suitable and there is another mathematical
importance of manage because the second derivative of tanh dies down very slowly.
Now, if we were to do a derivative of tanh of the function
X, the first derivative would give you one minus X squared.
And if you were to do the secondary of it is the secondary, but
it will not, would not be extinguished at a very faster date.
And that is where you can attain or to hold information for
a longer time period, as compared to other activation units.
Now tanh has almost similar features and it looks similar to a sigmoid.
it is almost, it almost has a chip, but it has different
limits and different bounces compared to Sigma.
And that is where the Tanh is more appropriately used.
And the step forward is we have calculated the Ht, bypassing it, the output
of these internal mathematical questions through the Tanh activation unit.
Now the next step is to compute the YT.
Now, if we were to compute the Yt, the Ytis pretty much
very, very simple because we just have to multiply a weight.
That is the H Y w H Y multiply.
That is the Ht.
Now w H Y is effectively the weight.
That is you can initialize randomly, which is in our case.
this has been initialized randomly, or we can initiate initialize them using some activation units.
Using some predefined formulas are we're going to initialize them as zeros or ones.
Anything can be done.
And we multiply it with the Ht that we have received from the previous step in our case.
So this gives you the output of the entire recurrent neural networks for a particular timestamp.
So we can see that for particular timestamps, we got effectively take the information from T minus
one, and we can also predict what will be the output or the next character in a particular sequence.
Now this steps four and five gives you an efficient of, you
know, the how the next step that comes into the picture.
If you're taking the next.
Letter that is E after H.
We can also see that in the computation of the word or the letter E we are taking into
consideration the details that we have covered while calculating the values for H so in
this case for each individual character, we are evaluating the characters, the details,
and the computations done on the character just before it, and also for all the timestamps.
Starting from zero.
So in this way,  try to kind of, you know, sequencial network, where you are
calculating a particular output and a particular timestamp T equal to t1.
This is on a certain time stamp that the t to in a one that is one timestamp before.
So in this way, The forward pass gets calculated.
Now, if we were to build we, when we get the yt, we
effectively get a series of probabilistic values.
We get the series of a tensor of decimal values.
Now, if you want to apply some sort of classification contexts, we generally refer
to some activation units on those or an activation function on those output labels.
Now that becomes a, in most of the cases in RNNs, we use softmax function for that,
where we transform the YT to a softmax variant, what a softmax transform the output.
And this gives you classified probabilistic values where you can have certain values, like
0.5, anything above 0.5 gets classified as one or anything below 0.5 gets classified as zero.
So in this case, you can have, probabilistic values of what the output.
So this can also be used for predicting what will be the next character, given a particular input.
So let's say in the word, hello, if you have seen that, H E L L.
It written, what would it be the next character that will, that will succeed.
And that is the last step.
So in most of the cases after sufficient training, we was seeing
that, Oh, the particular character, Oh, will, will succeed.
And so in this way, using the softmax activation and the output.
That is soft max of Yt.
We can effectively get all the range of possibilities for
them from the, which gives you the most playable word.
Next, next character.
I ended up this problem, next character.
And we can generally use this this thing as a classifier or,
or you can use this as a generative recurrent neural networks.
In this context, we have given the example of a character level
RNNs, where we have . We are applying this concept for recurrent
neural network concept on particular characters in a particular word.
But the same concept can be used in the case of a
words as well.
And next one step since this concept is generally considered a forward pass
of the first step, the next part will be going towards the back proposition
for this propagation, we will be moving towards the next tutorial.
But this is given in  W I L D ML blog.
So this has given really well over here, but then if it's, so
in this case, we will be seeing how backpropagation takes place.
Now we mentioned that neural networks generally have two kinds of process.
What is called the forward person.
One is the backward pass.
Now the backward pass generally takes place due to the
fact that we want the errors to be reduced and we want.
very clear and crystal outputs, which are almost very similar to the actual
or the predicted or predicted labels in most classification contexts.
So in this case, since we have a time, a time space in consideration, so we can also
consider, we can also label this as back propagation through time, because we'll be seeing
how recurrent neural networks actually actually applied gradient descent and gradient flow
through time which was not in the case of normal multi-layered perceptron or dense networks.
So if we connect, we can see that this is a variant of the same question
that we saw, where we have tanh of the input features the W HH into Ht
minus one plus  Xt into W Xh and then we apply a soft max of the output.
If we, if we collect in the previous blog, which we have,
we have, we have seen, now we can also define our loss.
So our loss can be binary loss, or it can be categorical loss.
So if we could, if we just consider our cross entropy loss, that is we can just frame it
as a very simple equation that is given by summation of yt in the log of Yt, like at T.
Well, like at T is the softmax activated variant of the output or in an output in the form pass.
Now, typically an RNN
for the in what you have easier as output as the, and this gets forwarded as X1.
Which takes us input as you know, that is the previous timestamp, right?
And it takes X one that is the input and the current step.
And it also gives you an output for the current step.
That is . And it's a part of the output is also fed to the next year.
That is the stew.
And since all the islands takes place, now, if we were to consider the backpropagation over
here, We want to do something called as input differentiation now chain rule differentiation
is the English and for using differentiation is because generally we are trying to optimize.
Generally, we are trying to optimize a curve in a high dimensional plane by finding the minimum.
Now, why do we need the minimum?
Because we want to reduce the amount of errors we are effectively using this loss
function that is given over here our cross entropy loss as our, effective loss function.
And we want to minimize the edit on this particular loss function.
So in this case, we want to find the minimum for the particular curve.
In general in calculus, if you want to find a minimum, we generally do differentiation.
And in this case, we want to do differentiation with respect to the weights,
because we want to update the weights for which are present in our loss functions.
So in this case we will be going through the gradient descent
algorithm because the gradient descent is the most basic algorithm.
And there is another very important stochastic gradient descent where we, some of the errors
for each of the time, you know each of the recent states and then we update the weights.
Either we increase the waste or decrease the waste depending upon upon our errors.
So generally the rule becomes D by DW.
Where W is the weight.
we have a Summation of the Dt for DWT.
Now we have mentioned that that backpropogation through time effectively takes place two times.
So in this case, we are doing all the Summation of the weights in the stochastic gradient descent.
So time.
So this is how the backpropagation algorithm works through time right now.
if we, if you consider the situation very closely, we want to calculate
the derivatives with respect to V because we, if we, if we see this
equation, we have the specs of V times the St where V is awake.
Now, if you were to apply this.
A gradient descent differentiation on with respect to V we have to do chain because
directly E of EFT is not a function of having V as an input or an input feature.
So we make the chain rule in this case, because we want
to first do the derivative with respect to y cap, y cap v.
And then we do the negative of y cap v with respect to V because we
it's just in case presenters, that input feature in white at three.
But EDD does not have that.
So in this case, this is why the intitution of chain rule comes into the picture.
We first do the derivative with respect to the y cap
then we do the derivative of y cap v  with respect to z and zt with respect to V.
Now, what does the tree?
The tree is nothing but V office three, right?
Because we, so if we are understanding the general concept that change is if a function
neighbor is not present in a particular equation, then we cannot do derivative with respect.
With respect to that equation.
And then we are going to decompose that equation into further
steps until the smallest part contains that particular label.
So that is what the inclusion comes into the picture.
So , and then we do this shingle we make the functions you know, having the same common part.
That is the V.
And then we back then we applied this general again with respect to D.
Is that three and DV so effectively.
If we, if we were to do this in our own notebooks, we
would be able to see and understand it in a more manner.
Similarly, in this case, we do the database for w if we
collect the W words, also we change and the W X stage.
So for these two hits also, we have to do partial derivatives that use the, to change.
So D by D gap.
Three.
And then  and then P a C followed by DW because in the, in our case, we D white cap fee
does not have any input feature with respect to w so in this case, we have to first do
the deliberative with respect to S3, and then only we can move forward with DSG and data.
But S3 is given by the 10.
Each of the input features that we saw earlier in the forward bus.
And this step of that propagation and gradient descent actually continues.
And this is where the Summation of the waste with respect
to the different timestamps, it comes into the picture.
So if we were to do with respect to DW, we can see that this
change will actually elongates in a very long, long chain.
So we have the feet.
Given by a white three and this chain actually goes on until we get, be escaped by DW.
So this is where one of the important drawbacks of on-demand comes into
the picture as well as one of the most important facts of having an RNN.
So you can see that if you, if you continue applying partial to rule on this
equations, the equation becomes very large and this is continued to backpropogate.
Look at it two time at for each time.
Step.
This is Pictorically represented in this case.
So you have, when we go from  to eat free, we see that first word with the derivatives,
with respect to DET, with respect to the S3, and then we are taking the outputs for that.
And we are back propagating it to a s2.
So we are effectively taking the database of se with respect to s2.
And then we are again taking the database and with respect to s2, with respect to a s1.
And then this process continues until we reach that is the first step.
That is the zero step.
So this process effectively use for all the other.
In regular neural networks, we just saw to summarize, we saw two things.
First is the recurrence pattern where we have an equation or Tanh activation activity
equation of with vectors multiple with H that is a time-step let's the input features Xt
might've played with some weight fitters, a w X, D, and then we applied to unassigned.
And after that, we have to get the output for that
which is given by the softmax activation of the V dot St.
So in this case, if you just go back to a previous equation, we will have the W H y cross y P Ht.
So in this case, we get that y D by having in the forward.
Now, in this case, we also want to do minimize the error.
So in this case, we first device the loss function in our case, that is
the cross entropy loss that is given by Summation of it into lockdown.
So I kept it and then we want to do partial elevators because we wanted
to perform minimization or gradient descent to minimize our errors.
Right.
And that is where the backpropagation would change through time, comes
into the picture, and this is the effective equation for backpropagation,
but we have D with respect to the rates with Summation overtime.
And in this case, if we expand this equation, that is the change or differentiation
equation, we will see that this equation of expression is getting really large.
And that is where the intuition for having these kinds of a
gradient descent for each time step comes into the picture.
So far in this, as we can see in this image first D three with the S3 is computed.
The output of that is computer is done derivatives with
respect to s2 to that is again with respect to a S1.
And this process actually continues.
Great.
And if we move forward, we have a vanishing gradient problem in RNN, which is a very hard problem
because if we, if we of using this equation where I mentioned that the chain differentiation
equation actually becomes a large, and this is effective, we've done the picture over here.
So if you have thousands of units of recurrent neural networks, neurons one after
the other, you can see that the gradient is computed at each and every step.
And when you have competing ingredients, the gradient actually becomes
very, very, very, very small at each and every differentiation step.
So it becomes literally very hard to know whether the
gradient, where did the gradient drop is there or not.
In most of the cases the drop becomes so, so small.
So, so minute that it becomes impossible for the wait update to take place.
So in that case, the weight update becomes really, really small and the learning is not improved.
Learning does not improve as the epoch go on.
So in that case, we are left with something called the vanishing gradient problem.
Without it, it's not capturing any information, any more information.
And there is something called, is a damping of the of the weight that
is taking place because the weight updates are not taking place because
the gradients are very, very small and negligible in in in numbers.
That is where, you know, some important features are like LSTM send GRU
was coming to the picture, which we will cover in the next few topics.
But in this case this is the drawback of the RNN because of the change.
It becomes really large because if you've got four to understand where the update is taking place
and effectively in, in the, in the concept of tensor, this is computed as a jacobian matrix.
Right.
And And this case, this jacobian matrix is effectively a mat fix done by differentiation
of all the individuals present in that particular Tensor on a particular metrics, right?
And this particular equation is a version of this particular integration where
we have a product DSJ given by DSJ minus one, which is effectively the loop.
As we increase the number of layers inside neurons, we can see that distance continues.
For a longer period of time.
And this is where this particular part actually tries to decompose the weights.
and the gradient is not properly attained.
The gradient change is not properly attained and there are several resources.
This paper also has provided in this link also has, a very mathematical detail
as to why this gradient vanishing gradient problem comes into the picture.
And that is all mostly what I wanted to cover about recurrent neural networks in general.
So to summarize, according to run, the trucks are highly sophisticated
nueral architectures, which which can be used for sequence classification,
sentiment, classification, any, and it'd be dust in general.
And they formed the base for all the advancements that have been there in the present instance.
So they use this reference relations mission from the previous time steps.
And there are two passes.
One is the forward pass where we compute the tanh activated input features.
Oh, coupled with the previous state in boots and we that are put
up the forward pass with a soft max activation of the inputs.
And then we designed the loss function, which in our case, the cross entropy loss.
And we tried to optimize that loss.
We tried to find a minima of that loss because we want to minimize the error.
And in that case, since we had been supervised learning.
We have to complete the back propagation in iron is the concept of back propogation.
So time comes into the picture where we are trying to design a neural network,
which can compress the gradients so time for each and the, in a timely manner.
So and that is where the vanishing gradient problem comes into the picture
where the effective gradient changed since the chain rule differentiation
is not observed and the weights are not unique.
I think.
The changing the way.
So I'm not . So in this case, that is all that I wanted to cover about recurrent neural networks.
for in the next sections, we will be covering about LSTM, GRU and
all our modification modified architectures and how they can solve.
They can solve this vanishing gradient problems.
And thank you.
And I'll be seeing you in the next video tutorial.