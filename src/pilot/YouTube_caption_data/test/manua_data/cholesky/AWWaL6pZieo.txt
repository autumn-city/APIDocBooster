Hi I'm Gilad from DataProphet and today
I'm going to talk to you about Conda
vs pip. Now in truth Conda and pip
do much of the same thing, you can create
virtual environments, install and remove
Python packages and import or export
environment definitions to another
production environment. There are some
differences for example Conda does make
it pretty easy to install a particular
Python version say python 3.6. Where pip can
create an environment only with what
python versions you have currently installed.
The part I want to highlight about
Conda is that many of the commonly used
data science packages are compiled with
Intel MKL libraries, as a result when
using an Intel CPU they can operate
significantly faster without you as the
user having to deal with painful
compilation of large code bases for
every package you install and then
having to ensure that all of them are
compatible.
Some of these packages includes NumPy,
psypy, scikit-learn, pandas, XG boost
tensorflow
and Keras, among others. As for the
performance I produce some benchmarks on
my own system, for simple matrix
operations, I've seen operations take half
a time for trigonometric NumPy
operations and my system got a 30-fold
increase when generating random numbers,
a six-fold increase, in DASK a popular
parallel processing library similar
to Pandas, I've seen performance
approach two times. So when it comes to
libraries I'm particularly interested in
such as Tensorflow and Keras I've seen
model training take about 20% less time
than it did before. Finally these results
I've not replicated myself but took
from Intel's own benchmarking tests, you
can see that many common algorithms in
scikit-learn are significantly improved
over their non and KL counterparts. Now
all these results were achieved without
writing more complicated code or a
particularly painful installation
process, but just by replacing pip install
with Conda install. So if you work
in the data science field it's
definitely worth exploring if Conda
meets your needs.