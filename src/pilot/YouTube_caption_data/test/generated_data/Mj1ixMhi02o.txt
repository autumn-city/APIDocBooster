all right so thanks everyone for joining
us
uh my name is eamon amer and i'm the
toronto
reactor program manager um i'd love to
know where
where in the world you're all joining
from um majaya is based in toronto as
well and we're really excited that
you're joining us today so
this live stream it's gonna be about 45
minutes and we'll leave the last
10 15 20 minutes or so um for any
questions that you might have
so our speaker today is jaya matthew
she's a senior data scientist at
microsoft and part of the azure global
ai team
her work focuses on the deployment of ai
nml
solutions to solve business problems for
customers in many different domains
before joining microsoft she used to
work with nokia
hp on various analytics and machine
learning use cases
she has an undergrad and graduate degree
from university of texas
at austin in maths and statistics so
thanks so much for joining us jaya um
we'd love to
learn more this is an awesome topic and
thank you for doing this
thanks eamonn for the introduction so uh
hopefully most of our audience can dial
in today i hope there are some issues
okay so let's get started with our topic
so it's kind of a
long title how do you get the most out
of your iot data
so we'll get started with some of the
basics of
any kind of data collection predictive
maintenance
and how to kind of use your data to
build
either traditional or deep learning uh
model
so let's go to the next slide
okay yeah there we go so this is the
quick outline of my talk
so we'll first get started with setting
the context for what a connected factory
is so that's how
a lot of data gets collected then we'll
define
what is manufacturing maintenance then
to get a basic
understanding of the rest of the talk
it's um important to define
what predictive maintenance is what is
it why do we need it
what are the different types of
maintenance models then we'll actually
get into
how to build a predictive maintenance
solution so
we'll go through the basic approach we
will actually work with some simulated
sample later so you kind of
uh get a feel for what feature
engineering looks like
then we'll do some basic modeling how do
you evaluate models
then we'll also do a comparison of
traditional models where you
actually manually do all the feature
engineering versus
deep learning modeling techniques so one
of the deep learning approaches that's
suitable for time series data that you
get from connected factories
is something known as lstm long short
term memory network
to wrap up i'll actually give you some
suggestions on
our python
code and you know where you can kind of
get some starter code
for you to kind of use for your data set
um i should ideally have about uh 10 to
15 minutes
towards the end for any questions uh
that
any of the audience might have so uh
would request all of you to keep the
questions to the end of the talk
okay so let's get started with what is a
connected factory
okay if we actually think of the various
phases in the industrial revolution in
the late 18th century was essentially
the first industrial revolution where
we had steam power coming and it kind of
made a lot of mechanical production
possible
then we essentially in the beginning of
the 20th century started
the second industrial revolution where
electric energy made mass production
possible in factories in the beginning
of the 1970s that's just about 50 years
ago
was essentially the third industrial
revolution where
i.t and computer technology allowed for
a lot more manufacturing automation
and now since the 21st century that's
just about the last
15 20 years you have a lot of internet
of things
uh making network manufacturing possible
so that's essentially coined as the
fourth
industrial revolution so our focus would
be on internet of things which is the
fourth industrial revolution so what is
this internet of things what can it do
so essentially if you think of it it uh
can enhance the customer experience it
can help
you innovate faster and it can also
transform operations
so about 83 of the manufacturers at west
survey
said that selling products has services
helped increase their profits
so that's where they kind of thought of
you know selling
add-on services for all the equipment
that they sell
then 40 of industrial manufacturers use
digital
technologies to monitor products sold to
customers so you might have an rfid tag
on some of the products that get sold or
you have an app that pings
the server etc then 79
of companies use iot iot is internet of
things
to become more efficient and more
responsive to customer needs
35 of the manufacturers collect
and use data generated by smart sensors
to enhance manufacturing so as opposed
to actually
going and assessing each and every
equipment if you have some smart sensors
which
sends data periodically back to the
server you can actually remotely
monitor the performance 80 percent of
the manufacturers also
expect to improve factory connectivity
uh
to transform their operations and 85
percent of the manufacturing executives
expect human machine centric
environments to become commonplace i
think it's already started to become
but they expect that to accelerate a bit
further
in the next few years okay so now
we do know that with this fourth
industrial revolution there's a lot of
data being collected in factories and
uh all that is collecting some data
center either on premise
or in the cloud but interestingly most
of this iot data is not
currently getting used so the data is
being collected
primarily for anomaly detection and
quality control charts
but it's not being actually used for
optimization or prediction
which is where the maximum value of the
data actually exists
okay so now that we know what data gets
collected let's actually define what is
manufacturing maintenance
so manufacturing maintenance uh the
couple of strategies
essentially you're trying to make some
strategic impact of predictive
maintenance where you're trying to
improve the overall equipment
effectiveness for mission critical
assets
where failure patterns are discernible
or you're trying to
make responsiveness to kind of prevent
any equipment shutdown so you want to
minimize production downtime and
associated variability
for monitored assets that exhibit some
sort of failure patterns
ahead of the failure actually
so now why would anyone want to do
manufacturing maintenance essentially
there are two kind of costs
one is the direct cost and the indirect
cost so let's kind of first look at the
direct cost
so typically maintenance related costs
are approximately 25 percent of the
overall operating cost so that is about
one-fourth which is
quite a big amount so if you can kind of
lower that your margins will
improve uh for your overall operations
they also estimate that 30 percent of
maintenance costs are related to
unnecessary expenditures associated with
bad planning
overtime spare parts inventory carrying
costs etc
there's also e loss which is where
variable costs associated with crap and
having to
kind of discard the entire line that was
produced
so there are also indirect costs so
those are the direct ones that can be
measured
indirect ones are essentially um you
know
based on equipment availability and
performance
it affects your quality and
eventually affects the brand and profit
margin
and on-time delivery affects customer
satisfaction and lifetime value so if a
customer goes to an atm machine and the
machine's down
well obviously the customer is not happy
with the service rendered to them
so there are indirect costs and this
cannot obviously be quantified at all
times but
it does affect the brand
okay so now that we know the basics
let's actually
get into what is predictive maintenance
okay so we've alluded to this in the
previous couple of slides and let's kind
of define this in
in a more formal manner so why do we
need predictive maintenance
so as we stated earlier unscheduled
equipment downtime
can be detrimental for any business so
it's essentially
very critical to keep field equipment
running
to maximum utilization and minimize
unscheduled downtime
and the goal of predictive maintenance
is to extend the useful
service life of any equipment and
prevent failures
so if you look at the diagram on the
right to essentially predictive
maintenance
can reduce operational risk reduce
unnecessary time based
maintenance operations control cost of
maintenance
improve overall brand image lower
inventory costs and discover
patterns connected to various
maintenance problems so
they have quite a few advantages that's
why a lot of companies are looking at
predictive maintenance and how to use
their
iot data okay
so in terms of predictive maintenance
the business problems
can be categorized into three main
buckets
so one set of questions is essentially
is trying to answer
what is the probability that an
equipment will fail soon so soon would
be in the next one week next one uh
next two months etc then um
some customers are interested in trying
to figure out what is the remaining
useful life of an equipment so that is
before
your next maintenance request by the
service team
and the other set of questions the third
category is
what are the causes of the failures and
what maintenance actions should be
performed to fix
these issues so if they know the cause
of a failure ahead of time maybe they
can do something to prevent the failure
which is good for the business
okay so in terms of maintenance models
there are
five types of maintenance models so the
current state that we are in
is usually stage one or two which is the
first one is a reactive which is a
traditional break fix so
something breaks and then the customer
requests for the fix so
for example your car breaks down on the
highway you call aaa
and then you say well i need my car
repair so that is
the reactive the equipment stops working
and you try and fix it
the second is the schedule maintenance
which is preventative maintenance where
repairs and services are rendered on a
fixed schedule regardless of the
condition
of the equipment so think of this as
taking your car
for a routine oil and gas
oil and filter change so that's every
six months or every year depending on
the
make and model of your car so that is
scheduled so that's usually the current
state
so the connected state with all the data
that's being collected
you can actually get into wave three
which is the condition based
monitoring so here what you're actually
trying to do is the condition of the
equipment
is monitored using sensors
to indicate the health and indicate
maintenance needs
via real-time alerts so you know
due to wear and tear when the equipment
actually needs
maintenance and this varies so think of
a vehicle
like your car some people drive it every
day some people only drive it on
weekends so
a car that's run more often tends to
have more wear and tear
then the wave four the one that we are
actually going to focus on in this talk
is essentially predictive maintenance so
that's essentially where you're trying
to
predict the remaining useful life for
critical components
and to determine the asset health
and usage patterns and repair history to
improve
maintenance planning and the futuristic
is
the cognitive which is intelligent
operation where you kind of
want the machine to do autonomous
actions
to ensure maximum asset utilization
efficiency
so we want to reach a stage where
maintenance is
automatically scheduled in consideration
of
the health of the machine so that's
more of the futuristic so we will focus
on
part four okay so you also want
to actually um align your different
failure modes by the maintenance
activity so like i said the reactive
which is what
we all do is typically you want it to be
small items that fail
non-critical it's and items that are
unlikely to fail so preventative is you
want to do
age exploration acceptance testing and
if we jump into what we are going to
look at which is predictive maintenance
we kind of look at
um equipment that is subjective wear out
consumable replacement and failure known
patterns
okay so now to kind of help consolidate
these concepts let's actually look at
some typical scenarios
across verticals so i've actually only
listed four verticals
which is aerospace utilities
manufacturing
transportation logistics however there
are many other
industries and verticals that you might
be aware of which also use predictive
maintenance
so in the aerospace domain so think of
an aircraft think of
a helicopter or anything so you might
be interested in trying to predict uh
what is the likelihood of delay
due to some mechanical issues in the
aircraft
or you might be uh trying to predict
when is an aircraft component likely to
fail next so if you can
accurately predict this hair ahead of
time you can prevent delays and
uh you know disgruntled customers in
terms of utility domain that is either
your
you know power energy wind farm
solar farms etc you might be interested
in trying to predict
um when is my solar panel or when
turbine going to fail next
or if you think of an atm machine
that any of our banks have td uh rbc
do they always want the atm um
dispensers to be up and running all the
time so that their customers are happy
every time they go there
so you might they might be interested in
trying to figure out
is the atm machine going to dispense the
next five to 10 notes without a failure
etc
in terms of manufacturing um like we
kind of
spoke about earlier you're kind of
interested in trying to figure out
what is the root cause of a test failure
and will the component
pass the next stage of quality testing
or do i need to rework the whole
lot of components that was manufactured
etc
in terms of transportation logistics
this is slightly
uh more easier for us to relate to on a
day-to-day
basis so think of uh yeah most of us
work from home these days because
they're covered but
when we used to go to offices we
typically are in buildings with a lot of
um you know elevators and you know you
obviously want the elevators up and
running during pika so you don't have to
endlessly wait
for one single elevator or take the
stairs
the other one is in terms of your car
vehicle you want to know should i
replace the brake discs on my car can i
wait for an additional month so maybe
i'm a user who doesn't
drive my vehicle as much so maybe my
brake this
or pads are not as used so maybe i can
use it for some more time before
i go to the service center
okay so these are some of the verticals
there are many more verticals but
yeah i've just given four of them in
here
okay so now that we know the basics
let's actually see
how do we get started with this whole
thing so essentially the first thing is
you want to start gathering data
so we've noticed a lot of uh companies
have data but they may not actually have
all the relevant data
so it might be a good idea to start
gathering data for a single machine
if the company doesn't have machine
machine related operating data
or before they gather for all the
machines and then realize they haven't
collected the
pivotal data needed for the analysis so
in terms of
data that needs to be collected you need
data in
five specific categories one is the
machine operating
specification data which is um
operational parameters like primary data
like
spindle uh speed flow rate etc then
secondary
measurements like temperature pressure
tertiary like energy consumption
then the manufacturer also might have
something like mean time between
failures etc
then typically if a machine has been in
use for a few years a few months you
might have actually some
maintenance history so you might want
the last
three to 12 months of records of
fast replays consumables labor events
etc
and you know a list of historical
unplanned and planned maintenance
requests for that machine in terms of
maintenance process and execution you
also want
the list of tasks work orders
maintenance resources
parts inventory lead time etc
and then you also should have a process
where you kind of schedule
and manage planned activity uh
as well as unplanned in in the event of
an unplanned
how do you quickly execute then you have
a bunch of manufacturing
uh kpis key performance indicators which
is essentially
capacity loss return on fixed assets
etcetera and then
you have a bunch of audit related like
what is that level one two three four
where you have the manual documentation
sensor scatter readings erp planning
data etc
now um in terms of tracking maintenance
so the thing is you need all this in
place because
there is no point building a model
for predicting when it equipment's going
to fail
if you don't have the entire process in
place to kind of plan
schedule order the uh you know spare
parts and have someone go and actually
do the repair and maintenance so in
if for that case you kind of need uh
to identify the work in terms of number
of
hours where you have some labor force
available to do the repairs and number
of work order requests etc
then you also need to think about work
planning and scheduling so there's a
percentage of schedule hours
over total number of manners that an
employee has then planned hours downtime
versus
total large down time so this will kind
of give you a bunch of
percentages and measurements so even in
terms of work execution so you might
have a
team of 10 12 people to go and
look at certain equipment you also need
to know
the percentage of work orders within a
certain due date percentage of work
orders assigned for rework and
number that's sitting in the backlog so
in terms of
maintenance you also need equipment
effectiveness
maintenance cost effectiveness safety
and environment so in terms of equipment
effectiveness you want to know about
number of unplanned maintenance
interventions that actually came down
the breakdown frequency
unscheduled maintenance downtime
availability number of shutdowns etc
so in terms of maintenance cost
effectiveness you want to think about
maintenance crossover replacement cost
maintenance cost per
a product unit etc so this all helps you
quantify
how expensive it is to do certain
actions based on what the model actually
helps you predict
and finally it's very important to
ensure that
um that i know uh what is that
environmental and uh safety related
incidents
within any of these environments when we
actually send people
for repairs okay so now
that we know the basics let's actually
get into the approach
so i would categorize this into a six
step process
where so over the next six slides we'll
get into each one of these steps in more
detail so the step one is to identify
your target outcome
step two would be to get an inventory of
all possible data sources
and then step three is you have all the
data you clean it you organize it and
make it ready
to use for your model step 4 is you
build
one or more models you test and
integrate step 5
is once the model is acceptable by the
business you want to validate it in a
live operational scenario
and then six is you want to integrate it
into operations so
until and unless you actually integrate
it into operations you're not
actually getting the full value of your
model
okay so like i said step one is to
identify
the target outcome so that's where
you're trying to determine
what outcome you ultimately want to
achieve
so assume that
the building has something called a
servomotor so you know that
the last time the servo motor failed it
cost thousands of dollars and operations
were down for days
so you want to prevent that downtime
for days so as a product manager you
might be like
i want to understand how much time each
servo motor has
before it needs maintenance so that we
can prevent
unplanned failures
step two would be to get an inventory of
all the data sources
so you want to identify all potential
sources of data
including the types of data and the
amount of data available
so in most cases you would be actually
surprised
how data is in different silos
throughout the organization
so you might have operating patterns
data somewhere failure logs sensor data
maintenance logs performance data
so when you're building the model you
actually want to get all the silo data
into some
centralized repository so that you can
use the goodness
from all this data for
your modeling process
the third is once you actually have a
list of all the data you want to
actually connect
all your data sources into a single
place and prepare for analysis
it's actually interesting to actually
build some power bi or some
visually interactive dashboards where
you can actually look at me and median
and some of the basic statistics this
also lays the groundwork for
a robust predictive maintenance model
step four is where you actually build
models so you might build
a couple of models model abc and then
um what is that
then you kind of see which model
actually works better and
in this case you might say well you know
what model b is better than model a so
maybe i'll put that into production so
your goal is to make your model
actionable by understanding how much
advanced notice the maintenance team
needs in order to respond
okay and then many a times you actually
say that model b
is the best you put into production and
you might get feedback saying no it's
not really good so you you need to go
back to the drawing board and make
changes
okay so assuming that i said model b is
the best and
the business team says well it seems to
do well with historic data now let's try
it with the latest data that's coming
from the server motor
so you want to apply that model b to
live streaming data and observe how it
actually works
and then you have to be willing to
refine the approach based on
the results from this live validation
because many
times the historic data may not be very
good indicator of what's actually
happening
and finally once you have the model
you're happy you've tested
it in a live scenario and you're happy
with it you want to actually integrate
it into operations so many
times what we've noticed is a very good
model is built
it's tested but they don't know how to
incorporate it into the entire process
and of operations do you want to
operationalize the model by adjusting
maintenance processes systems resources
to act in
near real time and so here here's where
you actually the model might say um
you know the servo motor is going to
fail
three weeks ahead of the failure so
that's when it gives you enough time
to order the replacement part and then
maybe two weeks ahead of failure maybe
one week ahead of failure
you want to send the repair team to
repair the servo motor so that it never
fails and you don't have any downtime
okay so now it's kind of
easier if you see this done with some
simulated data so we will
go back into step four where we actually
build the model so let's actually
think of a more specific use case so you
have a scenario where early sensor data
from a factory is being collected
and the customer has noticed that a lot
of components are failing and wants to
use
the iot data to build a model to predict
these failures so
essentially the goal is to predict um
component failures so this is a very
simplified scenario
it's more like a toy example where this
machine has just
four components one two three and four
and you're trying to address the
question
what is the probability that the machine
will fail
in the near future due to failure of a
certain component
so data like i said is in different
silos
so here you have telemetry data errors
maintenance machines and failure
and the task is essentially it could be
a prediction task a failure prediction a
maintenance
action recommendation etc
so these are the five tables of data
that you have
so in the next slide we look at some
sample data so that it's just
easier to understand the definition with
how the data looks like
so telemetry is essentially time series
data which consists of a bunch of
measurements from the machine
so it could be voltage rotation pressure
vibration
collected from machines in real time so
typically we
will average this data so maybe some
machines
have sensors that give the data every
minute every 30 seconds five minutes 10
minutes
but typically you want to average it so
that there is uh
there isn't too much of noise in the
data then in terms of error you have
non-breaking errors thrown while the
machine is still operational
and you also want to round the error
date and time to the closest top of the
hour so that
every table can be mapped maintenance
could be scheduled or unscheduled
maintenance records
the record is generated if a component
is replaced during
the schedule inspection or breakdown
machine
is the static table which has the model
make up the machine as well as age
depending on
the year of manufacture etc failure is
what we're trying to predict so a
failure table essentially has a record
of component
replacements due to failure so now let's
look at how the data looks
so if you look at the telemetry if you
look at
the first four tables there's telemetry
errors
failure and maintenance you'll see that
they all have date time
the date time is actually to the top of
the r so that is easy for
us to map these tables then all these
tables
the they have the machine id so that we
can identify the machine
in the telemetry you have a bunch of
sensor readings
this is the voltage rotation pressure
and vibration measurements
in the error table in addition to date
time and machine id you have the error
id
so you have about five types of error
you have four types of components
so in terms of failure table you have
again the date time
the machine id and then you have failure
four components because this is a very
simplified scenario where you only have
four components
and maintenance well if four components
fail one of the four components gets
replaced so you also have a record of
which component was replaced
machine table is a static table like i
said you have the machine id
model and age so the goal in here is to
try and get all these tables together
and generate some additional features
so now feature engineering tends to be
quite a tedious process sometimes and it
takes a lot of time in the entire model
building process
so you essentially could have static
features rolling tumbling features for
predictive maintenance cases
so static features essentially comes
from the model uh
the machines table where you have the
model
make of the machine as well as yours and
service
in terms of the telemetry data you
could actually have the data as is but
there's always quite a bit of noise in
the data so you might
want to create rolling or tumbling
attributes so maybe
if you look at voltage you may not want
to take the voltage
every hour you could do these rolling
windows where you see the
um you know if window size is three ws3
you take the last three data points and
you could either do the mean
minimum maximum mode whatever you know
value for that in terms of tumbling
you see that those green windows the
window size you see that the points
the windows are non-overlapping so
that's the difference so
rolling aggregates is something that's
very commonly used
and in terms of window size typically
the domain expert would
be the best to tell us what window size
actually works so you might have
if you don't have a domain expert you
might want to try different window sizes
and see
which feature has more of an importance
so like i said uh in terms of feature
engineering the raw telemetry data is
good
as shown in the table on the top where
you have daytime machine
and the four sensors which is voltage
rotation pressure and vibration
but you know doing some amount of um
feature engineering actually adds to the
predictive part of the machine learning
algorithm so in this case
let's assume that the domain expert kind
of told us that
we it makes sense to look
at the data at every three hours so we
assume that the window size of three is
good
and if you can see in the first table
you see
that all the date time is early six a.m
seven a.m eight am and then if you see
uh in the second table is every three
hours two pm five pm eight pm et cetera
so what you see is for each of the
sensors we've taken the mean and the
standard deviation in this case you
could also
take um the range and all the other
values whatever statistic that you want
to do
okay so like i said finally you want to
create this massive table
which has all the feature uh engineers
so you have your daytime machine id
then all your telemetry then you have
the machine related like model
age and then you have the failure table
so here is your final data set where
you're trying to i think we merge by
machine id and date time
as being the unique primary key in here
and the question that you're trying to
answer is what is the probability that a
machine will fail
in the near future due to a certain
component failure
so in this case it is a multi-class
classification problem
so if you look at this table in specific
it's this machine one which is model
uh so you see machine id is one and then
component one fails but it doesn't
really
make sense if i tell someone that a
machine is gonna fail
right now because i neither have the
company not the expertise
to have someone come and replace so
the team would like you to predict a
competent failure at least
a few hours ahead of time of your days
so in this case we're trying to predict
component one failure for machine one
at least 24 hours ahead of time so you
see that
um although the failure happens at 11 pm
i go back 24 hours and
i actually tag all those as impending
failure
okay so that's how you prepare the data
for the model
so once you've done all the hard work of
feature engineering and creating this
table the next thing you want to do is
you want to split the data into training
and test
so a time-based split is ideal for this
use case because
the timed component is used for feature
engineering in terms of rolling
aggregates and tumbling aggregates
and you don't want leakage of
information from the
training data into the testing data so
the ideal thing would be supposing you
have one years of data
2020 from jan to december so maybe you
want to take
jan to june for training
then you want to leave a few days
depending on your window size
and then maybe take from july to
maybe middle of july to october november
for
um testing now in terms of model
building there are
a bunch of multi-class classifiers that
are available you could actually
we have azure machine learning which is
very simple as drag and drop you can
click and it's very easy
in terms of metrics it is essentially a
business decision
if an overall accuracy is important or
recall precision or f1 score
so that's all uh what the business would
kind of help us decide
so the outline of the main steps was we
first had the data which is
early time stamp data for telemetry for
a thousand machines per year
and then we have all these different
tables of data which is errors
maintenance failure
and then you visualize you build all
those features
you create all those lag rolling um
measures for the sensors of telemetry
errors
etc and then you finally build and
evaluate your model
okay so now that we've actually gone
through so that was our traditional
modeling approach
where you essentially had to look at the
data
you know and then manually build all
these features
so it is a lot of manual construction
the right features in terms of
what window size do we do what features
do we keep
and etc so it is time consuming so this
also makes these models hard to reuse so
supposing i
collect one machine and it has a few
sensors
in this case it was voltage rotation etc
but maybe the other machine doesn't have
those features so it's very hard for me
to just
reuse all the code that i've written for
feature engineering
so this makes it hard to reuse the
entire traditional model so
that is when a lot of people got to
thinking
well is there any alternate approach
that we could try and use and then
over the last five years has been so
much a buzz around deep learning
so deep learning has proved uh to be
quite performant especially in image
related scenarios like
object recognition image classification
it's also kind of gained popularity in
domains but there's a lot of time
series data so now the thing about
predictive maintenance also is
the data is essentially time series
because you have a time stamp
and you're collecting various sensor
data um
over time so um we could try and use
deep learning
so i have to say that you know the
attractive part of applying deep
learning
is that the network can automatically
extract the right features from the data
so
we could eliminate this entire manual
feature engineering
however the caveat is if you have to
determine the topology
of the deep learning networks in terms
of number of layers
nodes hyper parameters that is also not
a trivial exercise and you do need
someone who
understands deep learning and the entire
architecture and etc
so let's actually think of define what a
deep learning model is
so in predictive maintenance like i said
earlier the data is collected over time
to monitor the state of the asset with
the goal of finding patterns so
you know maybe a deep learning model
would work in this scenario so
among all the deep learning networks
that we have
one specific network is very good for
time series data that's called lstm
long short term memory network and um
they're good at learning from sequences
you know so
we this is also a time series which is
like a sequence
so that's why we actually would try and
see if an lstm network works
in predictive maintenance
okay so uh lstm like i said is good at
capturing the distribution of
long term temporal dependency in time
series
so we could try and see if this works
this is how the lsem network each of the
layers looks so i mean this is the
overview we'll get into each one of the
specific layers and what happens within
each of these layers
in more detail in the next couple of
slides so think of
x t as a sensor reading at time
t and then x t plus one is the time
uh after you know t and then t minus one
so
you have this entire sequence of points
and all the h
uh refers to hidden layers uh you know
ht
is t minus one and each one of these
layers has a specific structure
so as you can see that this entire lstm
although the
uh manual feature engineering is taken
away and it's simplified you have to
understand the network
so i've actually given a link to a very
nice blog post which is
worth reading if you're interested in
learning more about
an lstm okay so the core idea
behind an lstm cell is
so they have something called a cell
state so if you see that ct minus one to
ct
so some information is going from one
cell to another
so gates within the cell are ways to
optionally let information through
as they pass from one cell to the other
so the lstm can remove or add
information
to the cell state and then you
essentially have
three what is that um there are three of
these gates to protect and control
what information gets added to this cell
so you have something called a forget
gate the input and the output
so now let's get into each one of these
gates and what it does
so forget as the name suggests the
forget gate
controls what is kept and forgotten from
the previous stage so that's the very
first thing that happens
so it essentially outputs a number
between
uh between zero and one so one
represents and
completely keep the information zero
means get rid of the information
so in a more nlp related scenario is
essentially is if it sees the word the
cat
it will know that it's singular and
it'll kind of say well
uh cat which ate was full but when if it
sees a plural will say well the cats
which it were for so if it were to
predict the next
word in the sentence then you know
obviously the
uh the mathematical equations are given
and it's then more detailed in the blog
post
okay so the next gate is the input gate
so which is
uh essentially it decides what new
information we're going to
store in the cell state and the input
gate controls
which part of the new cell content gets
written to the cell
then you obviously have a tennis layer
which computes a new cell content
so the combination of these two creates
an update to the
state the next gate is the output in the
hidden state
so you saw a bunch of h t h t minus one
h t plus one those are the hidden states
so the output gate which is essentially
a sigmoid layer controls
which part of the cell are output to the
hidden state so this is the hidden state
and
it kind of you try and put the cell
state through a tannis layer
to push the values to be values between
0 and 1
and then multiply it through a sigmoid
gate
so again the equation is given and if
you're interested in learning more about
the details and finally you've done
all these different uh gate operations
and you're ready to update the cell
state
so erase is like forget some content
from the
last cell and you try and write some new
content so it
passes the relevant content to the next
item in the sequence
it is scaled by outputs of forget and
input gate
and then you know essentially this cell
would pick up the relevant information
and pass it to the next one
so this is the recap of an lstm
cell so you you essentially have
uh you can forget some cell content here
write some new cell content
output some cell content to the hidden
state you compute the input
you compute the forget gate the new cell
content
and you have a bunch of these different
layers
stacked to create a quite a dense
lstm network so as you can see this is
not trivial but
it's kind of gained a little bit of
popularity
now implementing this is not as complex
as it looks
so essentially in python it's
it's kind of easy where you can kind of
define
the model as being sequential and you
essentially add layers so you kind of
just do
model.add and you say it's an lstm and
you give the
input shape the number of units and do
you want to return the sequence or not
to prevent overfitting you essentially
can
have a dropout rate of 20 then maybe you
want to actually add a second layer so
in this case there are only two
uh you know there's the first layer the
dropout layer the second layer which is
also an lstm
then again you say drop out to prevent
overfitting and then you finally have a
sigmoid output layer
then you say well you compile it and
this is the loss i'm interested in which
is the
binary cross entropy and the optimizer
i'm interested in using as adam
the metric that i'm interested in
accuracy and it'll kind of
uh build the model so you just need to
ensure that
your data is in the right format to
input into the first layer and then
it's kind of easy to build the model in
python
okay so in terms of uh tooling and code
before we just wrap up the whole thing
is
some people prefer to program an r some
prefer python
we have however seen that python is
gaining more importance than our
over the years and people prefer to use
python because it's
easier to operationalize the models in
um those production scenarios so for our
people have a bunch of options they
they could use our studio or vs code it
supports r
and python and even jupiter suppose r
and python for python specifically
there's pycharm
bunch of different tools that you could
use
and um here's some sample code for r
that you could run in a jupiter notebook
as well as this is some code in python
where you can
run this code in
jupyter notebook as well as these are
some
links to kind of get you started on
reading about
connected factory industrial automation
predictive maintenance and then we have
an ai guide for predictive maintenance
and
this is the block that i told you about
understanding lstm model
so yep so that is
all i had so we have about
nine to ten minutes and i'm open to
questions if there's anything
all right thanks a bunch jaya um i don't
see any questions
yet but if anyone has any questions
please feel free to add them
into the chat or the q a box um and you
can take them up
we'll give folks a couple minutes yeah
thank you
okay well it looks like no one has any
questions for
jaya now but if you do have them later
you can always feel free to reach out to
her on
twitter i think jaya you linked your
twitter there yes
yes so that's great um oh i just saw one
come in
oh there you go
well while you're answering that
question um i just posted the link to a
survey for today's session and if you
had any feedback
um we'd love to know how to make things
better or if things are great we'd love
to know that
things are great and to keep doing
things the way that they're going
um yeah so just any feedback is all good
feedback um
for us so if you wanted and if you had a
couple minutes it should only take about
30 seconds to a minute
um if you could take the survey that
always helps um
and beyond that i think there's a
question in the chat that you can answer
ah okay what what is the question so oh
yeah sorry the question is um
do people take into account slash model
for sensors themselves
deteriorating over time
model for just a sensor as opposed to
the entire equipment
i think that's what it is yeah
i think so so do people take into
account that those
sensors deteriorate over time
well that is an interesting thing
actually so we are assuming that
so then you'll have to build a
predictive maintenance model for the
sensor as is isn't it
so actually i think most of our cases
what happened is
the machines were not even instrumented
so we actually had
new sensors put in there so we're
assuming that the sensors were
high quality and didn't have any issues
but yeah that is an interesting thing so
we haven't actually addressed that
yeah okay um jay while you're answering
questions could you put your
last slide with your twitter on their
backup on the screen
yep yep thank you awesome
um and then while you're doing that
there's one more question
they asked are there any standard lstm
models that can be used as a starting
point
[Music]
well so i think the example notebook
that we have in here
is a good starting point so i think that
i don't know how many
layers it has now i haven't looked at it
but i think
that is the one that you want to look at
so there's a deep learning one
so again i actually know
more of standard models for custom
vision and nlp but
predictive maintenance no
[Music]
not really
okay perfect i think we have time for
one more question if folks have any
um but if not we can wrap up a little
bit early and give folks like
four minutes back of their time
all right yeah i don't see anything
coming in um so thanks so much jaya
thank you so much for your time for
those that are on the call
um with the recording for this session
will go up on our youtube in about
two days um and if jaya agrees will also
share her slides
in the description so you can just reach
out there i know there's a question
about that
um and thank you so much for joining us
thanks jaya
thank you very much
you