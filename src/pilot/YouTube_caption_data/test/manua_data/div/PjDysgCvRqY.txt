[music playing]
Hello.
Welcome to the second week
of re:Invent.
It has certainly been
an exciting event
so far with so many
groundbreaking launches,
a record breaking toast
to kick off the event
and tons of sessions
to attend so far.
And last week over 200,000 viewers
tuned in
to watch the first
ever virtual live races
during the AWS Deep Racer League
re:Invent championships on Twitch.
You will also have
the opportunity to hear
from our experts and many customers
such as NASCAR,
McDonald's, Mobileye, Intuit, and PwC
and more than 50 machine
learning sessions
taking place during the event.
I love seeing the enthusiasm
for machine
learning among our customers,
it is a testament to the technology's
potential to change businesses
and industries for the better.
Machine learning is one of
the most disruptive technologies
we will encounter
in our generation.
More than 100,000 customers
use AWS for machine learning today,
right from creating a more
personalized customer experience
to developing
personalized pharmaceuticals.
These tools are no longer
a niche investment,
our customers
are applying machine
learning to the core
of their business.
Now let's take a look
at some examples.
Domino's Pizza uses machine
learning for predictive
ordering to help meet its goal
of delivering hot fresh pizzas
in 10 minutes
or less following an order.
Roche, the second largest
pharmaceutical company in the world
uses Amazon SageMaker to accelerate
the delivery of treatments
and tailor medical experiences.
Kabbage an American Express company
apply machine learning
to their loan application process
and surpassed major US banks to become
the second largest business payment
protection program
lender in the country,
preserving an estimated
945,000 jobs across the US.
The BMW Group is using
Amazon SageMaker to process,
analyze and enrich more
than seven petabytes of data
in order to forecast
the demand of both model
mix and individual equipment
on a worldwide scale.
Using Amazon SageMaker,
Nike built a product
recommender on Nike.net
to deliver a more
relevant shopping experience
towards wholesale customers.
And finally in sports,
Formula One applies machine
learning to their car design process,
giving them new insights into more
than 550 million data points
collected through more than 5,000
single and multi-car simulations.
As you can see our customers
are innovating virtually
in every industry.
So why do our customers choose us?
They choose us because of our depth
and breadth of services
and the rapid pace
of innovation.
So now let's take a look
at our machine learning offerings.
At the bottom layer of the machine
learning stack we provide
ML capabilities for expert
machine learning practitioners.
These include optimized versions
of the most popular
deep learning frameworks,
including PyTorch MXNet
and TensorFlow.
And we provide choice
in infrastructure across GPUs, CPUs,
and our own silicon innovation
and training and inference as well.
At the middle layer of the stack
we have Amazon SageMaker,
which allows developers
and data scientists to build,
train and deploy machine
learning models at scale.
SageMaker includes a broad
set of capabilities,
many of which are both novel
and unique to AWS.
And these services are available
through an integrated development
environment for machine learning,
which we call
SageMaker Studio.
Many organizations
are standardizing on SageMaker
to remove the complexity
from each step
of the ML development workflow,
so that it's faster, more cost
effective and easier to do.
At the top layer are our AI services,
where we are helping
customers adopt machine
learning without having to build
their own models from scratch.
In vision we have Rekognition
and in speech
we provide text to speech in Polly
and speech to text with Transcribe
and customers can create
their own Chatbots with Amazon Lex.
For text we provide
natural language
processing with Comprehend,
Translate for translation,
and Textract to extract structured
text from documents and images.
We have also applied Amazon's
more than
20 years of experience in machine
learning to deliver services,
including Amazon Personalize
for personalized recommendation,
Amazon Forecast to automatically
create custom demand forecasts
and Amazon Fraud Detector
to identify online fraud.
We have also built end
to end solutions
including Contact Lens
for Amazon Connect
for contact centre analytics,
Amazon Kendra for Enterprise Search,
Amazon CodeGuru for automated
code review and DevOps Guru
to improve
application availability.
And last week we introduced
services
that are custom built
for the industrial sector.
As you can see we are
innovating really fast
and at a rapid clip to meet
the needs of our customers.
Four years ago at re:Invent 2016
we launched our first AI services,
Polly,
Lex and Rekognition.
Since then we have launched
hundreds of features
including Amazon SageMaker,
11 new AI services
with six more launched
just last week.
This year alone we have already
launched more than 250 features
and we have delivered
over 200 features each year
for the past three years.
That's a really big deal
for a new area of technology,
which is moving so rapidly.
As you can see, we are building
the most comprehensive
set of machine learning products
because giving our customers
the right tools to invent
with machine learning,
is necessary to unlock
the power of this technology.
15 years ago, when I was
making the transition
to my first job
out of grad school,
I noticed that builders were being
held back by their technology.
Instead of bringing their ideas
to fruition they were waiting on
IT departments to procure
the necessary hardware or software
to build their applications.
Shortly after I started at AWS,
I had the fortune to be part
of the launch of some amazing
technologies like Amazon S3,
RDS, Dynamo and saw how it
transformed every industry
as builders finally had
the right tools to do their jobs.
It's no exaggeration to say
that cloud computing
has enabled various startups
and businesses
to achieve
a new level of success.
Today, machine learning
has reached a similar moment.
Until recently
it was only accessible
to the big tech firms
and cool startups
that had the resources
needed to hire experts
to build sophisticated ML models.
But freedom to invent requires
that builders of all skill levels
can reap the benefits
of revolutionary technologies.
And the technologies themselves
allow for experimentation,
failures and limitless possibilities.
So today, we are enabling
all builders,
irrespective of the size
of their company or their skill level
to unlock the power
of machine learning.
And through feedback
from our customers
and our own experience implementing
machine learning at Amazon,
we have learnt a lot
about what it takes
to create an environment
that promotes boundless innovation.
At Amazon we often use tenets
or principles to follow
as guides for teams or projects.
Today, I'm going to talk
through some of the tenets
that enable freedom to invent.
We will also share more
about the work
we are doing to give builders
the power to harness machine
learning along the way.
So let's start with the very first
thing you will need firm foundations.
To enable more builders
to build and deploy machine
learning we are focused
on optimizing the very foundations
that these models are built
upon frameworks and infrastructure
that is used to speed up
the process of training
and deploying these models
and reducing costs,
firm from foundations
are essential to giving builders
the freedom to invent.
With the abundance of compute power
and data available today machine
learning is doing
some incredible things,
things that we never thought
were possible before like self-
driving cars, autonomous systems
or machines
that understand
what we are saying.
Often these more advanced
applications of machine
learning use deep learning
which consume massive amount
of inputs to achieve
their high accuracy.
The complexity of the model
and the size of training data
set means that building a deep
learning model
can be resource intensive
and can take days
or even months to train.
Moreover, there is not a single
framework that is universally used
by all expert machine
learning practitioners.
They typically build
on three primary frameworks
for deep learning,
TensorFlow, PyTorch, and MXNet.
We know that choice is important
to our customers
that is why we invest
in making AWS
the best place to run all of
the major deep learning frameworks.
Through our deep learning containers
and deep learning
AMIs
we ensure customers always have
the latest versions
of the major frameworks
optimized to run on AWS.
Today, 92% of cloud based TensorFlow
and 91% of cloud
based PyTorch runs on AWS
and we actively participate
in the community
to add new functionality
to these frameworks, for example,
TorchServe now the default model
serving library on PyTorch was built
and is maintained by AWS
in partnership with Facebook.
We are also expanding the usage
of deep learning to new audiences
and widening the available
talent pool
with projects like Deep Java library,
an open source toolkit
for performing deep learning in Java.
In addition to optimizing frameworks
a critical part
of being able to efficiently deploy
all machine learning models,
such as deep learning is
the underlying infrastructure.
Now, every machine learning project
is different
with different compute needs
and we have built the broadest
and deepest choice of compute,
networking and storage infrastructure
to help our customers
meet their unique performance
and budget needs.
We are rapidly investing
in this area
to keep up with the growth of machine
learning sophistication,
introducing new chips and instances
that help our customers keep the cost
of training and inference down
while speeding up
their innovation.
The latest addition to our portfolio
to help builder train faster
and more cost effectively
is the P4d instances,
which provide the highest performance
for ML training in the cloud.
They feature the latest
NVIDIA A100 GPUs
and first in the cloud 400
gigabit per second networking.
For Inference we launched AWS
Inferentia based EC2 Inf1instances.
They provide the lowest cost
per inference in the cloud,
up to 45%
lower cost or 30%
higher throughput than
comparable GPU based instances.
After migrating the vast
majority of inferences
to Inf1 the Amazon Alexa team
saw 25% lower end to end latency
for the text to speech workloads.
And customers such as Snap,
Finra, Autodesk and Conde Nast
use Inf1 instances
to get high performance
and low cost ML inference.
Conde Nast, for instance,
observed a 72% reduction in cost
than the previously
deployed GPU instances.
Together this powerful hardware
and optimized frameworks
provide firm foundations for
innovation in machine learning.
For training last week,
Andy announced two new efforts.
The first is Habana
based Amazon EC2 instances,
Habana Gaudi accelerators from Intel
offer 40%
better price performance
over current GPU
based EC2 instances for training
deep learning workloads,
they will be available
the first half of 2021.
The second is AWS Trainium,
a machine
learning training chip custom
designed by AWS for the most
cost effective training in the cloud.
Coming in 2021.
We are building Trainium
specifically to provide
the best price performance
for training machine
learning workloads in the cloud.
Now, our customers tell us they need
more than just the best hardware
to train large models.
For example, let's take a look
at two deep learning models
that are highly popular.
Mask-RCNN is a state of the art
computer vision model
used by our customers for things
like autonomous driving,
it requires a significant
amount of training data.
Similarly, T5 is a state of the art
natural language model
with 3 billion parameters.
To speed up training for both of
these we can use distributed training.
To speed our training times
for models
with large training data sets,
like Mask-RCNN,
you can split your data
sets across multiple GPUs,
commonly known as data parallelism.
When training large models like T5,
which are too big for even
the biggest, most powerful GPUs,
you can write code
to split it across multiple GPUs,
commonly known as model parallelism.
But doing this is difficult
and requires
a high level of expertise
and experimentation,
which can even take weeks
even for expert practitioners.
So we asked ourselves, how can we
make it easier for our customer
to do distributed training?
Do it well and do it really fast?
Today, I'm excited to announce
with only a few lines
of additional code in your PyTorch
and TensorFlow training scripts,
Amazon SageMaker will automatically
apply data parallelism
or model parallelism for you,
allowing you to train models faster.
[applause]
Data parallelism
with Amazon SageMaker
allows you to train 40% faster.
Similarly, with model parallelism,
what used to take a dedicated
research lab weeks of effort
and hand tuning training code
now takes only a few hours.
So what does this mean
for our customers?
Using these engines
we challenged our teams
that work on TensorFlow and PyTorch
to train Mask-RCNN
and T5 as fast as possible.
Here is what happened.
Last year we shared that AWS had
the fastest training for Mask-RCNN,
at 28 minutes on TensorFlow
and 27 minutes on PyTorch.
With our optimization
we cut that training time
by approximately 75% to six minutes
and 13 seconds for TensorFlow
and six minutes
and 45 seconds for PyTorch.
Our TensorFlow training time
is 23%
faster than the previous fastest
published record
training time held
by our friends in Mountain View.
And with our optimizations
such as model parallelism on T5
we went from development
to fully trained model on PyTorch
in less than six days,
it is the fastest published
training time for this model.
Previously, this should have
taken weeks of developer time
to find the optimal way
to split the model.
We are very excited
about the innovations
we are bringing
to builders in this area
but deep learning is still
the domain of expert practitioners
and is simply too hard
for most people to do.
That leads to my second tenet.
For any technology to have
significant impact, builders
need to be given the shortest
possible path to success.
Having the tools for your builders
to be able to satisfy
and explore their ideas
quickly without barriers
is a significant accelerator
to your business.
Historically, machine
learning development
was a complex and costly process.
There are barriers to adoption
at each step of the ML
development workflow,
right from collecting
and preparing data,
which is time consuming
and undifferentiated.
Then choosing the right algorithm,
which is often done
by trial and error,
leading to lengthy training times
which leads to higher costs.
Then there is model tuning,
which can be a very long cycle
and require adjusting 1000s
of different combinations.
Once you have deployed a model
you must monitor it
and then scale
and manage it in production.
To make things more complicated
many of the tools
developers take for granted
when building traditional
software such as debuggers,
project management,
collaboration and so forth,
are disconnected when it comes
to machine learning development.
To address these barriers in 2017
we launched Amazon SageMaker.
We built Amazon SageMaker
from the ground
up to provide every developer
and data scientist
with the ability to build,
train and deploy ML models quickly
and at lower costs
by providing the tools
required for every step
of the ML development lifecycle
in one integrated
fully managed service.
In fact, we have launched more than
50 SageMaker capabilities
in the past year alone,
all aimed at making this process
easier for our customers.
The customer response to what
we are building
has been incredible
making Amazon SageMaker
one of the fastest
growing services in AWS history.
And tens of thousands of customers
are using Amazon SageMaker today.
It’s customers from virtually
every industry
including financial services,
healthcare, media, sports,
retail, automotive
and manufacturing.
These customers are seeing
significant results
from standardizing
their ML workloads on SageMaker.
Let's take a look at some of them.
Lyft autonomous vehicle division
Level
five reduced model
training time from days to hours.
T-Mobile saved data
scientists significant time
labeling thousands upon
thousands of customer messages
to improve customer service
by using SageMaker Ground Truth.
Vanguard deploys workloads up
to 20 times faster using SageMaker.
iFood, the leader in online food
delivery in Latin America,
uses Amazon SageMaker
to optimize delivery routes
to decrease their distance
travelled by their delivery
partners by 12 person.
The scale at which iFood
operates 12% is a big deal.
And ADP reduced time to deploy machine
learning models from two weeks
to just one day.
As you can see so many customers
are able to innovate more quickly
by using SageMaker.
Another customer that has done
some really fascinating things
with machine learning is NFL.
We started working with NFL
to create Next Gen Stats
as a new way to engage fans.
And we have expanded that work
recently to the Player
Health and Safety initiative.
To talk more about this
and how the NFL is expanding its use
of machine learning with SageMaker,
I'd like to introduce
Jennifer Langton of the NFL.
[applause]
My name is Jennifer Langton.
I'm Senior Vice President
of Health and Innovation
for the National Football League.
While sports is my profession,
it's always been
a central part of my life.
In my second year as a college
athlete a knee injury
took me off the field
and what was at that time
one of the greatest challenges I had
ever faced
became inspiration for my career.
I know personally the impact
an injury
can make on an athlete's life
and also what an impact technology
and innovation
can have in treating injuries and
preventing them before they happen.
In our work at the NFL
our highest priority
is the health
and safety of our players.
We leverage data and innovation
in order to protect our players
and make our game safer.
The NFL has used AWS as its
official cloud computing and machine
learning provider for the NFL
Next Gen Stats platform since 2017.
Next Gen Stats provides real time
location data speed and acceleration
for every player during every play
on every inch of our fields.
Powered by AWS, Next Gen Stats
enhances the fan experience.
At re:Invent last year we built
on that successful platform
with the announcement
of a new expanded partnership,
a partnership that will pursue
an audacious goal,
making the sport of football
and ultimately all sports safer
for athletes who play them.
We will combine unique data
sets of human performance
and football information
including hours of video with AWS’s
strong culture
of technology innovation,
to develop a more profound
understanding of our game
and human performance
than has ever been done before.
Our goal is to improve
player safety
by eventually being able to predict
and therefore prevent injury.
AWS’s AI and machine
learning services
combined with the NFL’s data
will speed an entire generation
of new insights into player injuries,
game roles, equipment,
rehabilitation and recovery.
But before we talk more about
where we're going together,
let me first share where we've been
in our innovation journey
as a league,
showing just how much
we've accomplished
in a short amount of time.
Over the past six years,
biomechanical engineers
jointly appointed by the NFL
and the NFL Players Association
have analyzed on field injuries
and developed laboratory
tests for helmets
that represent the impacts
which caused those
injuries on the field.
This work has been central
in informing
everything from our rules changes
to improve protective equipment,
to centre pieces of our efforts
to reduce injuries,
specifically concussions.
Using video of head impacts,
our biomechanical engineers
developed a test that accounts for
hundreds of different variables,
speed direction,
who makes contact with who, play type
and impact among others.
We use it to test the performance
of the helmets NFL players wear
and then we create
a simple color coded chart
with the best performing helmets
in the darkest green
and the worst which
are prohibited in red.
This has led to
a tremendous behavioral change
among NFL players
over the last five seasons,
we've gone from having about
one third of players
in top performing helmets
to nearly 100%.
Moving players into better
performing equipment,
encouraging safer
tackling techniques and rules changes.
All three underpinned
by data and innovation
together have led
to significant progress
in keeping our players
safe on the field.
As a result of this
three pronged injury reduction
plan we saw a 24%
drop in reported concussions
during the 2018 season
and the 2019 season.
So our reported concussions
remain at that lower rate.
This validated our intervention.
That's what we mean when we talk
about our key drivers,
data and innovation,
that have evolved the game
and will continue to evolve the game,
and AWS is helping us to do that.
As a part of our work together we
are developing the digital athlete,
a computer simulation model
of a football player
that can be used to replicate
infinite scenarios
within our game environment,
including variations by position
and even environmental factors.
By simulating different situations
within a game environment our goal
is to better foster
an understanding
of how to treat
and rehabilitate injuries
in the near term
and eventually predict
and prevent injuries
in the future.
Leveraging video
and Next Gen Stats data
we together are doing something
that has never been done in football
Before, developing
computer vision models
that identify the forces that cause
concussions among other injuries.
Using Amazon SageMaker
we are in the early phases
of training deep learning models
to identify
and track a player on the field,
an important first step as we train
the system to detect,
classify and identify injury
significant events and collisions.
In the case of our helmet
example
the volume of new data
the system generates
and the speed with which
we can incorporate
that new data into our helmet
testing and analysis
could exponentially expand
our ability to rank, develop
and ultimately
encourage player adoption
of better performing helmets.
And over time the techniques
developed to detect
and prevent concussions
will also be extended
to reduce a wide range of injuries
including foot ankle
and knee injuries.
This technology is giving us
a deeper understanding of the game
than ever before allowing us
to reimagine the future of football.
We’ve just launched a challenge
to pressure test the solutions
that the NFL and AWS
are creating together.
The crowd source computer vision
challenge is currently underway
and allows anyone
with the interest and capability
to be a part
of our important work.
The data and insights
collected through this project
have the potential not only
to revolutionize football
but also to help address
injury prevention
and detection beyond the football
field to society more broadly.
Last year the NFL
celebrated its 100th season
and we look forward
to the next 100 years of football.
We remained committed to innovating
on behalf of our players
and those that come after them.
I'm so proud of the work
we are doing together to that end,
the future of football together
with AWS is very bright.
[applause]
Thanks, Jennifer.
It really amazes me to see the impact
that SageMaker can have in helping
our customers to embrace machine
learning as a core part
of their strategy.
And as it becomes easier
for our customers to build,
train and deploy one model they are
inevitably going to do more of it.
Take Intuit for example,
Intuit was one of our very first
SageMaker customers,
they started with the machine
learning model to help customers
make the most of their tax deduction.
And today ML has become
a core part of the business
touching everything
from fraud detection
to customer service
to personalization
to the development of new features
within their products.
Just in the last year alone they have
increased the number of models
deployed across the platform
by over 50%.
This increased use of AI and ML
drove a variety of customer benefits,
including saving customers
25,000 hours with self-help
and cutting
expert review time in half,
improving customer confidence.
And it's not just Intuit, we see
this across many of our customers.
Many of them today
are looking to scale to hundreds
or even thousands of models
in production
and at this scale bottlenecks
in ML development
whether it's data prep training
and many more they become more
amplified and new challenges arise.
So we needed to build new tools
across the entirety of the machine
learning workflow to help with
not just one model
but with hundreds
or even thousands of models.
So I'm going to walk
through these tools today,
some of which we launched last week
and some that are new today.
Let's start with data prep, the first
step of building a machine
learning model. It is a time consuming
and involved process
that is largely undifferentiated,
and we hear from our customers
that it constitutes up to 80% of
their time spent in ML development.
Last week, we announced
Amazon SageMaker
Data Wrangler,
a game changing way to do
ML data prep much faster
through a visual interface
in SageMaker Studio.
Typically, to get data
ready for a machine
learning model you need
to collect data
in various formats
from different sources,
which may require you
to create complex queries.
With Data Wrangler
you can quickly select data
from multiple data sources,
such as Athena, Redshift,
Lake Formation, S3
and SageMaker Feature Store.
Previously, you would then need
to write code to transform your data.
But with Data Wrangler we provide 300
plus pre-configured data
transformations,
so you can transform your data
without writing a single line of code.
Next, once the data is transformed
it's easy to clean
and explore the data, through data
visualizations in SageMaker Studio.
These visuals allow you to quickly
identify inconsistencies
in the data prep workflow
and diagnose issues before models
are deployed in production.
Finally, rather than having to engage
an IT ops team to get your data
ready for production,
you simply export your data
prep workflow to a notebook
or a code script with a single click.
Now, not only will SageMaker
Data Wrangler integrate
with AWS data sources,
but coming soon,
you will be able to quickly select
and import data directly into
SageMaker from Snowflake,
Databricks Delta Lake
and MongoDB Atlas.
[applause]
Using SageMaker Data Wrangler
with just a few clicks
you can complete each step
of the data prep workflow
and easily transform
your raw data into features.
Talking about features in machine
Learning, features represent
relevant attributes or properties
that your model uses for training
or for inference
where you make your predictions.
Now to explain it a little bit more
let's take a look at
Intuit, for example, in their
TurboTax contextual help model,
which tries to provide
the most relevant
possible tax guidance to a tax filer.
The features the model might use
can include information
like what step you're on in the tax
filing process
or your prior year's tax returns.
Intuit uses features in large batches
to train its model and at inference
so they need to be available in
real time to make fast predictions.
Previously, Intuit was
storing features for batch training
in one data store
and the real time features in another.
This means it required months
of coding and deep expertise
to keep these features consistent, so
Intuit came to us with this challenge
and together we worked backwards from
the problem to build a feature store
which served as a training repository
for features
where latency isn't as important
and also provide access
to the exact same features at runtime
where latency is important.
It also enabled
feature discoverability
and reuse accelerating
the model development lifecycle
and improving data
worker productivity.
To solve this problem for all of our
SageMaker customers, last week
we launched SageMaker Feature
Store so you can securely store,
discover and share features,
so you don't need to recreate
the same features for different
ML applications.
This saves months
of development effort.
Now Features Store serves features
in large batches for training
and also serves features
with single digit
millisecond latency for inference.
And it does all the hard work
of keeping these features
in sync and consistent.
You can use visuals to search your
features and share and collaborate
with other members
in your organization.
Now, as you can see, SageMaker Data
Wrangler and Features Store
make it easier to aggregate data
and prepare and store features.
This is an important part
of the machine learning process
because your model’s predictions
are only as good as the data
and features that use this,
that's also why we need
to better understand
the bias in the data our models use
and why our models
make a certain prediction.
But today, it's very hard
to get this visibility.
It requires a lot of manual effort
and stitching together
a bunch of open source solutions.
So our customers asked us
to make this process easy for them.
Today, we are launching
Amazon SageMaker
Clarify, which helps improve
your ML models
by detecting potential bias
across the machine learning workflow.
[applause]
To talk more about the work
we are doing here
I'd like to welcome Dr. Nashlie
Sephus, one of our leaders at AWS
focused on algorithmic bias
and fairness.
[applause]
Thank you, Swami.
I have been immersed in machine
learning technologies
as both a scientist and a consumer
and I have developed
a personal passion
for mitigating bias in technology
and identifying potential blind spots.
As one of the scientists working
on bias and fairness at Amazon,
I see firsthand the challenges
in doing this
and the increasing need for us
to get it right.
Mitigating model bias
and understanding
why a model is making a prediction
helps data
scientists create better machine
learning models.
And it helps the consumers of machine
learning predictions
make better decisions
based on that information.
Bias can show up at every stage
of the machine learning workflow
so even with the best
possible intentions
and a whole lot of expertise,
removing bias in machine
learning models is difficult.
Bias could come in at the very
beginning from the training data
itself when it's not representative.
For example, not having enough dramas
in your training data for a TV
show recommendation model
may bias the outcome.
You could also introduce bias through
an imbalance in training data labels
and by selecting a subset
of that training data.
And then you can also have bias
through model drift,
where your model is
making predictions using data
which is sufficiently different
from the data on which it is trained.
For example, a substantial change
in mortgage rates
could cause a home loan model
to become bias.
Today, the process to get insights
into data bias across the machine
learning workflow is tedious
for both data scientists
and machine learning developers.
I have spent my career working on
this problem, and it's hard to do.
I'm excited to present a product
feature that I've been a part of
from day one of its inception,
SageMaker Clarify.
SageMaker Clarify provides
an end to end solution
to help you mitigate bias in machine
learning and provide transparency
across the entire machine
learning workflow.
And it all works within SageMaker
Studio and integrates
with other SageMaker tools throughout
the process of building a model.
Let's take a look at how it works.
To start, during your initial data
preparation in SageMaker
Data Wrangler, SageMaker
Clarify enables you to specify
attributes of interest,
such as location or occupation
and then it runs a set of algorithms
to detect the presence of bias.
SageMaker Clarify then provides
a visual report
with a description of the sources
and severity of possible bias
so that you can take steps
to mitigate.
After you've trained
the model on this data,
Clarify will check the trained models
for imbalances,
such as more frequent
denial of services
to one group over another
and provide you with a visual report
on the different
types of bias for each attribute.
With this information you can then
go back and relabel data
to correct any imbalances.
Once your model is deployed
you can get a detailed report
showing the importance of each model
input for a specific prediction.
This can help the consumers
of your machine
learning model better understand
why a model is making
a certain prediction.
For instance, a business analyst
wanting to understand
what is driving
a demand forecast prediction.
Lastly, why your initial data
or model may not have been
Biased, changes in the real world
may cause bias to develop over time.
SageMaker Clarify is packaged
with SageMaker Model Monitor
so that you can get alerts to notify
you
if your model begins to develop bias
or if changes in real world data
can cause your model to give
different weights to model inputs.
This way, you can retrain your model
on a new data set.
Reducing bias will continue
to be a challenge in machine
Learning,
but SageMaker Clarify provides tools
to assist in these efforts.
Thank you.
[applause]
Thank you, Nashlie.
We are really excited to bring this
important feature to our customers.
As customers scale machine
Learning, managing time
and cost is critical.
And while data prep consumes
a large part of the time
to build machine
learning models, training a machine
learning model on the data
can be a costly process at scale.
So data scientists and machine
learning practitioners
want to naturally maximize
their resources.
Now if you look at training itself
it has different phases like data
pre-processing,
training and finalization.
And one potential bottleneck
in optimizing
your resources can be
when your data pre-processing
ends up being compute intensive
and your CPU core is busy,
while the GPU,
which is used for training phase
and is the most expensive resource
in your system,
sits there idling, underutilized.
But today, there isn't a standard way
to identify these bottlenecks
like there is in
software development with profilers.
So customers today need to cobble
together a diverse set of open tools,
many of them are unique
to their ML framework they're using.
To address this, last year we started
with introducing SageMaker
Debugger, which automatically
identifies complex issues
developing in ML training jobs.
Now customers wanted to use Debugger
to get more
detailed profile information
to optimize their resources.
Today, we are adding a new capability
to SageMaker Debugger
to provide deep profiling
for neural network
training to help identify bottlenecks
and maximize resource
utilization for training.
[applause]
With deep profiling for debugger
you can visualize
different system resources
including GPU, CPU, network and IO
memory within SageMaker Studio.
With this information you can analyze
your utilization and make changes
based on the recommendations
from the profiler or on your own.
You can profile your training runs
at any point in the training workflow.
SageMaker Debugger saves developers
valuable time while reducing costs.
Now, as you can see,
ML comprises multiple steps,
some which take place in sequence
and others in parallel.
And there is a lot that goes on in
stitching these workflows together.
In traditional software development
continuous integration
and continuous deployment
CICD pipelines
are used to automate
the deployment of workflows
and keep them up to date,
but in machine
Learning, CICD style tools
are rarely used
because where they do exist,
they are super hard to set up,
configure and manage.
To address this, last week we
launched Amazon SageMaker Pipelines,
the first purpose built easy
to use ML CICD service accessible
to every developer
and data scientists.
With just a few clicks
in SageMaker Pipelines
you can create
an automated ML workflow
that reduces months
of coding to just a few hours.
SageMaker Pipelines takes care
of the heavy lifting involved
by managing dependencies and
tracking each step of the workflow.
Now, pretty much anything you can do
in SageMaker
you can add
to your workflow in Pipelines.
Moreover, these workflows
can be shared
and re-used within
your organization as well.
Templates for model building
and model deployment pipelines
help you get started quickly.
And once created, these workflows
can be easily visualized
and managed in SageMaker Studio
so you can even compare
your model performance.
Now, to show you how all of these
new features work together,
I'd like to invite Dr. Matt Wood
to the stage for a demo.
[music playing - applause]
Thank you, Swami, and good morning.
With capabilities like Data Wrangler,
Feature Store, Clarify,
Pipelines and new debugging
and profiling features,
it's never been easier to build,
train and deploy machine
learning models in Amazon SageMaker.
By working together,
these capabilities provide a way
for developers and data
scientists to focus on what really
matters, building accurate,
high quality machine learning models
which improve over time
without all of
the undifferentiated heavy lifting.
SageMaker removes the muck
of building machine learning models
and leaves only the diamonds.
So, what goes into a great model?
Let's take a look at building a model
which uses track
and artist information
to create the perfect musical
play list.
First, you need data, lots of data,
and lots of different types of data.
The more, the merrier.
SageMaker lets you connect
and load your data
from sources such as S3 and Redshift
in just a few clicks
from SageMaker Studio.
SageMaker can then use this data
to train a model.
Models learn complex
and often subtle patterns
to let you map inputs
to predicted outputs.
So, we will need tons of metadata
about the songs in our library,
length,
beats per minute, genre, ratings
and more to use as our inputs.
Next, we will need
a strong set of features.
Data in its raw form
usually it doesn't provide
enough or optimal information
to train a great model.
So, to maximize the signal
and reduce the noise and the data,
we need to convert and transform it
into features through a process
known as "feature engineering".
For instance, beat and genre could be
combined into a more abstract
or super-feature called danceability.
Now, creating features
can take a ton of time.
Some customers estimate
that it is about 80% of the time
spent building machine
learning models.
Instead, we can use
Data Wrangler to convert,
transform or combine raw tabular data
into features
in a fraction of the time
without writing
a single line of code.
With a single click,
we can then save these features
to the SageMaker Feature Store
which lets us check in
and check out features
in a very similar way as you would
a source code repository.
The service lets us create
multiple versions of features
and we can add descriptions
and search our features
which helps teams understand
and reuse them for other models.
You can retrieve an entire data
set for training,
or, once your model is deployed,
retrieve individual features
used in making low
latency predictions.
Such as predicting that I want
to listen to more songs
with high danceability
like ABBA’s Dancing Queen.
All with single digit
millisecond latency.
There is no need to try
to recompute these features
on the fly over and over again.
You can just do it once
in Data Wrangler
and use them again and again
from the Feature Store.
Next, great models can be used
in many different situations
if they are trained on a balanced
set of features and data.
We are going to use SageMaker Clarify
to ensure that our training data
is well balanced.
That means that it has the possible
values of features and labels
are well represented
across the data.
And that the accuracy
of our training model
is roughly the same across
different subsets of the data,
such as different musical genres.
For example, if we had
a preponderance of blues music
in our training set,
our model would probably create
a lot of blues play lists.
That is fine if all you want to do
is listen to the blues.
But our model will be
even more useful
if we use an evenly balanced
set of features
representing dozens
of different genres for training.
So here we can make sure
that that is the case
and that our model makes
good predictions with good coverage
across a wide range
of musical genres.
We can also use Clarify to inspect
every single prediction
to understand how each feature
plays a role in that prediction.
This allows us to check that
our model isn't overly reliant
on features which we know
to be underrepresented in our data.
Now, one of the great things
about machine learning
is that models can improve over time,
not just based on new data
as it becomes available,
but also by incorporating
the learnings
we see from tools like Clarify
and the new debugging
and profile features
to systematically
identify sources of error or slowness
and remove them from our model.
With this approach,
we can condense hundreds of thousands
of hours of real word experience
into just a few re-training iterations
and our models can improve
far more quickly.
And since we often want
to continually improve our model
by rebuilding it over
and over again,
we can take advantage
of the automation in Pipelines,
the new continuous integration
and continuous
deployment capability in SageMaker,
which lets us automate
the entire end-to-end machine
learning build process and replay
it perfectly with a single click.
This not only accelerates the time
to our first model,
but it decreases the time
between model improvements
and gets us to better models
more quickly.
So, in SageMaker, we have made
the tools which every developer
is familiar with, visual editors,
debuggers, profilers and CI/CD,
all wrapped into an integrated
development environment
available for machine
learning.
And we can't wait to see
what you'll use SageMaker for next.
With that, I'll hand it back
to Swami. Thanks a lot.
[music playing - applause]
Thanks, Dr. Wood.
Another place where we are seeing
a lot more machine
learning happening is the edge.
More and more applications
such as industrial robots,
autonomous vehicles,
and automated checkouts,
require machine-learning models
that run on smart cameras,
robots, equipment and more.
However, operating ML models
on Edge devices is challenging.
This is because of limited
compute memory and connectivity.
It also takes months of hand-tuning
each model to optimize performance.
In addition,
many ML applications
require multiple models
to run on a single device.
For example,
a self-navigating robot
needs an object detection model
to detect obstacles,
a classification model
to recognize them
and a planning model
to legitimize the appropriate actions.
Now, once a model
is deployed in production,
your model quality may decay
because real world data
used to make predictions
often differs from the data
used to train the model, which leads
to inaccurate predictions.
In 2018, we announce
Amazon SageMaker Neo
to make it easier
to deploy models on Edge devices.
While Neo addresses model deployment
for a single model,
developers still had to deal
with managing models
across fleets of edge devices
and also build mechanisms to monitor
their performance and accuracy.
This became harder for our customers
as their ML edge adoption grew,
and that is why we are
investing more in this area
to bring the full power
of SageMaker to edge devices.
Today we are excited to announce
Amazon SageMaker Edge Manager.
It provides model management
for edge devices
so you can prepare,
run, monitor, and update machine
learning models across fleets
of edge devices.
[applause]
SageMaker Edge Manager applies
specific performance optimizations
that can make your model
run up to 25 times faster
compared to hand-tuning.
You can easily integrate Edge Manager
to your existing
edge apps through APIs
and common programming languages.
And you can understand
the performance of models
running on each device
across your fleet
through a single dashboard.
Finally, Edge Manager
continuously monitors
each model instance
across your device fleet
to detect
when model quality declines.
With these services,
we are delivering the most complete
end-to-end solution
for ML development
with Amazon SageMaker,
all integrated in one pane
of glass with SageMaker Studio.
While tools like SageMaker
make machine learning model building
and scaling more accessible
to data scientists
and developers
with machine learning skills,
there are many more people
who either lack the skills
or the time to build models,
but they can benefit
from the insights
that running machine
learning can provide.
As you all know, good ideas can come
from anywhere in the organization,
so we need to invest
in making machine
learning more available
to more builders.
And one of the ways we do this today
is through SageMaker Autopilot.
Building machine
learning models historically
has traditionally required
a binary choice.
On one hand, you can manually
prepare the features,
select the algorithm,
and optimize model parameters
and have full control
of your model design and understand
all the thought
that went into creating it.
But this requires deep machine
learning expertise.
On the other hand,
if you don't have that expertise,
you could use an automated approach
to model generation with AutoML.
But that provides
very little visibility
into how the model was created.
Last year we launched
SageMaker Autopilot
to address
this trade off.
It automatically trains
and tunes the best machine
learning models for classification
or regression based on your data
while giving you full
control and visibility
so you can create
your first model in minutes.
With Autopilot, you just need
to upload the training data,
it automatically transforms the data
in correct format for ML training.
It then selects the best
algorithm for the prediction
you’re trying to make,
trains up to 50 different models
and then ranks them in a model
leader board in SageMaker Studio
so you can choose
which model to use.
Then you can deploy the model
into production with a single click.
No longer are developers left
in the dark about how an AutoML model
was built or the process
in which it was created.
Now, over the past
year we have invested
in making Autopilot even more useful,
increasing its accuracy by over 20%
and reducing training time by 40%.
While SageMaker Autopilot
makes machine
learning more accessible
to ML builders and developers,
there is a large group of database
developers and data analysts
who work in databases
and data warehouses
that still find it too difficult
and involved to extract
meaningful insights from that data.
While they are SQL experts,
they may not know Python
and are reliant on data scientists
to build the models for them
so that they can add intelligence
to their applications
to derive insights.
And even when they have
a model in hand,
there is a long
and involved process
to move data
from the data source to the model
and back to the application
so that they can actually
add intelligence to their apps.
The result is that machine learning
isn't being used
as much as it could be.
So, we ask ourselves how can
we bring machine
learning to this large
and growing group of database
developers and data analysts.
We are bringing Amazon SageMaker
and other ML services
directly into the tools
that database developers,
data analysts and business
analysts use every day.
These are databases, data warehouses,
data lakes and BI tools.
Our customers use different
types of data stores,
relational, non-relational,
data warehouses and analytic services,
for different use cases.
So, we are providing
a range of integrations
to give customers options
for training their models
on the data and adding inference
results right from the data store
without having to export
and process that data.
Now, let's start
with relational databases.
Our customers use Amazon Aurora
as an efficient relational database
for enterprise apps,
SaaS, and web and mobile apps.
Historically, adding machine
learning from Aurora
to an application
was very complicated.
It involved the data scientists
building and training a model,
next you had to write app code
to read data from the database,
then you had to call an ML service
to run the model,
then the output must be then
reformatted to your application,
and finally you had to load
the results into the app.
This process is bad enough
with a single database
but if you are using
multiple data services
like a customer database
and an order management,
then there is even more work
and integration to be done.
So, to make it easier for customers
to integrate machine
learning into
Aurora-powered apps,
we launched Aurora ML
which makes it super-easy to apply ML
to apps right from the database
just by using a SQL query.
Let's say you wanted
to conduct sentiment analysis
of customer product reviews
to identify negative feedback.
No longer do you have to do
all this multi-step process.
You can simply run a SQL query
and then under the
covers Aurora passes the data
to Amazon Comprehend
and then the results are then
returned to Aurora ready to be used.
This integration makes it
so much easier
for relational database
developers to apply ML.
Now let's talk about data analysts.
They often use Amazon Athena,
an interaction serverless
query service
to easily analyze data
in Amazon S3 using standard SQL.
And they want to apply ML to this
data to generate deeper insights.
To address this,
we launched Amazon Athena ML.
Customers can now use more than
a dozen built-in ML algorithms
provided by SageMaker
directly in Athena
to get an ML-based prediction
for their data sitting on S3.
Within seconds analysts can run
inferences to forecast sales,
detect suspicious logins,
or sort users into customer cohorts
by invoking pre-trained ML models
with simple SQL queries.
So, we have shown you
how you can use pre-trained models
in Amazon Aurora and Athena,
but what if you didn't need to fuss
with selecting a model at all?
Every day our customers
use Amazon Redshift
to process exabytes of data
to power their analytics workloads.
And customers want their analysts
to leverage machine
learning with their data in Redshift
without having to deal
with having the skills
or the time to use machine learning.
So, we asked ourselves,
how can we make this easy
for our Redshift customers?
Today, I am really excited
to announce Amazon Redshift ML,
an integration of Amazon SageMaker
Autopilot into Amazon Redshift
to make it easy for data
warehouse users
to apply machine
learning on their data.
[applause]
Let's see how it works.
It starts with the simple SQL
statement for creating a model.
And once this SQL has run,
the selected data is securely
exported from Redshift to Amazon S3
and SageMaker Autopilot
takes it from there.
It performs the data cleansing,
and preprocessing,
then creating a model
and applying the best algorithm.
All of the interaction
between Amazon Redshift,
Amazon S3, and Amazon SageMaker
are completely abstracted away
and automatically occur.
Now once a model is trained,
it becomes available
as a SQL function
right in the customer’s
Redshift data warehouse.
Customers can then
use the function
to apply the ML model to their data
in queries, reports, and dashboards.
So, for instance,
in our customer churn example,
they can run the customer
churn SQL function
on new customer data in the data
warehouse regularly to identify
which customers are more at risk
and then feed this information
to sales and marketing.
Now, in addition to making ML
more accessible to data analysts,
it turns out
that combining machine
learning with certain types
of data models
can also lead to better predictions.
For example, graph databases
are often used
to store complex relationships
between data and a graph model.
These include things like knowledge
graphs used by search engines,
graphs of models of disease
and gene interactions,
and the relationship between
financial and purchase transactions
to aid in fraud detection and product
graphs for recommendation engines.
Amazon Neptune is a fast, reliable,
fully managed graph database service
that makes it easy to build
and run applications
that work
with these kind of graphs.
Our customers tell us that they
would like to apply machine
learning to applications
that use graph data
to build things like
better recommendation engines
and generate more accurate
predictions for fraud detection.
But again, they lack the time
or the skills.
So, today, we are announcing
Amazon Neptune ML,
enabling easy, fast, and accurate
predictions for graph applications.
[applause]
Neptune ML does the hard work for you
by selecting the graph data
needed for training.
It automatically chooses
the best ML model for selected data,
exposing ML capabilities
via simple graph queries
and providing templates
to allow developers
to customize ML models
for advanced scenarios.
And with machine-learning algorithms
That are purpose built for graph data
using SageMaker
and the Deep Graph Library,
developers can improve
prediction accuracy by over 50%
compared to that of traditional
ML techniques.
We are very excited about this one.
We are not only integrating
the power of machine
learning into our own products,
but we are integrating SageMaker
into partners’ products
as well.
We have integrated
SageMaker Autopilot into Domo,
Sisense and Qlik, with Tableau
and Snowflake coming early next year.
[applause]
In May of this year,
we also added machine
learning to Amazon QuickSight,
the scalable, embeddable BI service
built for the Cloud.
QuickSight ML Insights integrates
with Amazon SageMaker Autopilot
to enable business analysts
to do things like anomaly detection
and forecasting
without any heavy lifting.
Customers like Expedia Group,
Tata Consultancy Services,
[PH] Ricoh Company,
are already benefiting from ML
out-of-the-box experience
with QuickSight.
And it has a really great
feature called ‘auto-narratives.’
It uses machine learning insights
to tell customers
the story of their dashboard
using plain language narratives.
Customers love these
human readable narratives.
And they told us that they want
to interact
with their dashboards
in a similar way,
ask new business questions
in plain written language
when the answers are not
easily found in the data
displays in their existing
dashboards.
Last week Andy announced
Amazon QuickSight Q
to solve just this problem.
Q is a deep-learning powered
capability in Amazon QuickSight
that empowers business users
to ask questions in natural language
and get answers instantly.
To tell us more, I would like
to invite Dorothy Li
to give a look
at how Q works.
[applause]
Hi everyone!
Amazon QuickSight Q
is a deep-learning
based capability in QuickSight
that is built using
state-of-the-art machine
learning and natural language
processing techniques
allowing business users to ask
data questions in plain language
and get answers instantly.
Let's dive into
the capabilities of Q.
Let's look at the scenario
of a sales leader
who is trying to look
at the insights from her dashboard
to inform next year’s planning.
Now my dashboard shows
a summary of the data.
Sales per state, sales per product
and some yearly trends.
But what if I wanted
to understand
something not in the dashboard
like the specific sales
for the top two performing states,
California, and New York?
Typically to do that I would need
to cut a ticket
or send an email to the BI Team
and wait for an answer.
And since most BI teams
are thinly staffed,
that answer could
come in days or weeks.
Now with Q, I can simply
type my questions in QuickSight
and get answers.
‘Show me last year's weekly
sales in California,’
and, Q provides an answer
in just a few seconds.
‘Now let's see how it
compares to New York,’
and now, Q shows a nice comparison
of the two trend lines.
It's interesting to see
that in March,
California sales
had a huge spike
and that most likely got them
to the top spot in sales last year.
Since Q uses advanced
natural language
understanding you can ask the same
question in multiple ways.
For the same question,
let's try asking a different way.
‘Weekly revenue for California
versus New York in 2019.’
And I get
the same answer.
Typically, users in different
functions of the business
from sales, marketing, to finance,
often have
their own specific language.
To understand everyday phrases
in these different functions
of the enterprise, we partnered
with hundreds of teams in Amazon
to collect a large volume
of real-world data
and train Q’s models
to understand these phrases,
so there's no need for users
to learn anything new.
They ask questions in the natural way
that they already do and get answers.
Let's continue from
our sales example.
I know that California was
our best-performing territory.
I want to drill
a little bit deeper
and find the best-selling product
categories in California.
All I need to do is ask Q,
what are the best-selling categories
in California this year?
Ah, it's kitchenware and outdoor,
but it's a bit hard
to see who the laggards are.
How about we change the visual
to show a bar chart?
In the bar chart, I noticed
that gaming is underperforming.
Look how easy it was
to get these insights.
Getting started with Q
is incredibly easy.
Once you have connected Q
with your existing data,
Q automatically generates
a knowledge layer
that captures the meaning
and relationship of your data.
Allowing you to start
asking questions in natural language
in a matter of minutes.
From all your data, not just
specific data set or dashboard.
And getting started
is just the beginning.
Q uses machine learning models
to continuously
improve with no machine
learning expertise required.
It's incredibly exciting
to be able to reinvent
BI using machine learning
with Amazon QuickSight Q.
Thank you.
[applause]
Thanks, Dorothy.
For technology to be really impactful
it has to solve
real business problems
end-to-end and Amazon QuickSight
Q is one example
of the impact machine
learning can have when applied
to a real business need.
And the most successful customers
are those in which domain experts
and technical experts
come together to move from idea
to implementation to do just that.
What makes a good machine
learning problem?
When we think about
good machine learning problems,
these are typically areas
that are rich in data,
impactful to the business
but that you haven't been able
to solve sufficiently
using traditional methods.
Examples where our customers
find these synergies are areas
like product recommendations,
improving code reviews,
bringing more efficiency
to manual processes,
faster and more accurate
forecasting and fraud detection.
When we identify
these common use cases
we build AI services
that enable companies
to quickly add intelligence
to these areas
without needing any machine
learning expertise.
Some customers also ask us
instead of us having
to stitch together
these point-products ourselves
by writing code
on top of your AI services,
could you just solve the problem
for us end-to-end?
That's why we have launched
several things that do just this.
Amazon Connect is one example.
A contact center in the cloud
where we provide automatic
voice transcription,
sentiment analysis and analytics
using ML through Contact Lens.
Amazon Kendra is an end-to-end
intelligent search solution
which can connect to multiple
internal data silos
and uses machine learning
to create an accurate index
which can be searched with
simple natural language queries.
Again, no ML experience required.
Customers can build
and customize their index
and search interface
without writing a line of code.
And today we are expanding
the support
for more than
40 more data sources
via the Amazon Kendra
connector library
including Atlassian,
Jira GitLab, Slack, and Box.
Plus, we are releasing
incremental learning
which is a capability
that learns from user behavior
to improve your results
on an individual level.
We also launched Amazon CodeGuru
that allows developers to use machine
learning to provide
automated code review
providing guidance
and recommendations
on how to fix
some truly hard to find bugs
and to locate the most expensive
line of code
by automatically
profiling applications
as they are running
and making recommendations
for how to dramatically
reduce latency,
CPU contention and so on.
And we just launched
DevOps Guru to easily improve
an application’s operational
performance and availability.
Another area where
our customers are asking us
to do the heavy
lifting for them
to solve a business problem
is anomaly detection.
It turns out machine
learning is really good
at identifying subtle signals
against a lot of noisy data.
And there is data across
a broad spectrum of industries
where machine learning
can be applied to help understand
and catch anomalies
before it's too late.
Organizations of all sizes
use data to monitor trends
and changes
in their business metrics
in an attempt to find
unexpected anomalies
from the norm such as a dip
in a product sales
or a sudden increase
in qualified sales leads.
Now, traditional methods
for detecting these anomalies
such as setting fixed thresholds are
error prone leading to false alarms,
undetected anomalies and results
that are not always actionable.
The cost of not finding
these anomalies
in a timely manner
can be really high.
For instance,
if a retailer prices
something incorrectly
on an e-commerce site,
that product could be
completely sold out
before someone even realizes that
there is a certain spike in sales.
So, our customers asked,
how can we make this process
of anomaly detection
for business detection easier?
To solve this problem,
I'm excited to announce
that we are launching
Amazon Lookout for Metrics.
[applause]
It uses machine learning
to detect anomalies
in virtually
any timeseries-driven
business and operational metrics
such as revenue performance,
purchase transactions and customer
acquisition and retention rates.
Lookout for Metrics
detects unexpected changes
in your metrics
with high accuracy
by applying the right
algorithm to the right data.
It's very easy to get up
and running with Lookout for Metrics
because it has 25 built-in
connectors for data analysis.
It not only identifies
the anomaly
but it also helps you find the root
cause of these anomalies
so that you can take quick action
to remediate an issue
or to react to an opportunity.
And it continues to improve over time
with the feedback as well.
Retail customers can gain
insights into category-
level revenue by monitoring
point-of-sale or to clickstream data,
or an adtech company
can optimize spend
by detecting spikes or dips
in metrics like reach,
impressions,
views and ad clicks.
Now, let's take a look
at how it works.
It automatically retrieves
the data you want to monitor
from your selected data source
from sources
including various popular
AWS services such as S3, Redshift,
RDS, CloudWatch,
and many other popular Saas
applications such as Salesforce,
Marketo, Amplitude,
Zendesk and others.
The service inspects
the data and trains
ML models to find anomalies
using the best algorithm.
It automatically scores
and ranks anomalies
based on their severity
and helps you find potential root
causes of the detected anomalies.
Finally, it also prepares
an impact analysis
and sends you a real time alert
via your preferred alert channel.
You can also automatically
trigger a custom Lambda function
whenever an anomaly
is detected.
So, for instance, if something
is selling out quickly on your site
due to pricing inaccuracy,
you could trigger an action
to pull the product off the site
until further inspection is done.
Lookout for Metrics
uses your feedback
to continuously
optimize its algorithm
and improve its accuracy
over time.
You can visualize
and review the details
of these anomalies in the AWS consul
or retrieve them through an API.
Amazon Lookout for Metrics has use
cases that apply across industries,
but we also hear from our customers
that they want more solutions
that are tailored and specific
to their industries.
To share more, I would like
to invite again, Dr. Matt Wood.
[music playing - applause]
Thanks, Swami.
Machine learning is driving
extraordinary levels of reinvention
across virtually
every industry.
Take for example, iHeartMedia
which uses machine learning on AWS
to give its listeners
real-time music recommendations
across all of their media
and entertainment platforms.
Or, in the auto space,
Lyft is gathering petabytes of data
and analyzing it
with Amazon SageMaker
to improve
self-driving systems.
In finance, J.P. Morgan
is improving its banking experience
by adding personalization
to its client interactions
including real-time coaching
and recommendations
for contact center agents
so they can better
serve their customers.
And we see reinvention happening
in industrial manufacturing,
where they are using data
in the Cloud
and in nodes at the edge
to rethink virtually
all of their design
processes on the production line
from supply chain
to finished product.
At their simplest, industrial
processes are a series of steps
but, unlike most software,
industrial processes are monolithic.
They are very,
very tightly coupled
which means that in equipment
or process problem
anywhere on the line can have a very,
very large blast radius.
As a result, maintaining throughput
and cost goals in manufacturing
and other industrial processes
is a high wire tight rope
balancing act.
It's critical that these
systems are monitored
and that early warnings
are given when something if off.
Today, much of this is managed
by process control
with fixed thresholds.
But these are brittle
and don't take it advantage
of the vast amount of data
available from industrial systems.
Now last week, we announced
new industrial focused services
that enable customers
to apply machine
learning to find and maintain balance
in industrial processes
making it easier, safer,
and faster to monitor and evaluate
everything from manufacturing
to power generation,
to agriculture.
Together, these services
help lower and widen
that tight rope significantly.
So, let me walk you
through them briefly
and then I will show you
how they all worked together.
So, there are a lot of industrial
companies who know that
if they could use this data to do
better predictive maintenance,
they could save a lot
of time and money.
But some customers either
don't have sensors installed
or they are sensors that are not
modern or not sensitive enough.
And they don’t know how to take
that data from the centers
and send it to the Cloud,
or to build the machine
learning models
that detect a problem
before it occurs.
To help last week
we launched Amazon Monitron,
an end-to-end solution
for equipment monitoring.
Monitron comes with three things.
A set of sensors,
I have one here with me right here.
A network gateway device
and a mobile app to track
and resolve machine failures detected
by Monitron on the shop floor.
They work right out of the box.
These are wireless sensors
and they are designed to have
a three-year battery life.
They measure vibration in three
directions as well as temperature
and they can easily be mounted
to equipment with epoxy.
You easily mount sensors to any
piece of equipment like motors,
gear boxes, compressors,
turbines, fans, and pumps,
and they start taking vibration
and temperature measurements
straight away.
The vibration
and temperature data
is sent automatically from
the sensors to the network gateway,
which then transfers
the measurements to the Cloud.
You can view the sensor readings
right away directly
on the mobile app.
Monitron will also start building
an ML model using the sensor data
and use it to determine the normal
baseline operating performance.
If there is an anomaly
in the machine-sensor data,
Monitron alerts technicians via
push notifications to the app.
It’s a simple end-to-end solution
for predictive maintenance
with no machine
learning expertise required.
And that’s a big deal.
It makes it much, much easier
for companies
to do predictive maintenance
on their equipment.
Now there are other companies
that we talk to that say,
“Look, I have modern sensors
that I am fine with
and I don’t want to build
the machine-learning models
based on their data.
I just want to send you
the data, use your models,
and have the predictions
come back to me through the API
so that I can integrate it
with my existing systems.”
So, we have something for this
group of customers too called
‘Amazon Lookout for Equipment.’
A new anomaly detection service
for industrial machinery.
With Lookout for Equipment,
you send the data to AWS.
It gets stored in S3.
The service can analyze data
from up to 300 sensors
per industrial machine,
and uses machine-learning models
to identify early warning signs
that could be a sign
of impending machine failures.
The service pinpoints
the sensor or sensors
indicating anomalies
letting you respond
even more quickly
before the line is impacted.
And if finds anomalies, the service
will send them to you via API
so that you can do
your predictive maintenance.
The anomaly is detected
by Lookout for Equipment.
It can be integrated with your
existing monitoring software,
IoT SiteWise or industrial
data systems such as OSISoft,
and you can also set up
automated actions to take
when anomalies are detected
such as filling in a trouble ticket
or sending an automated alarm
that notifies you immediately
of any issues.
Customers are also
asking for help
with using Computer Vision
to improve industrial processes.
Industrial manufacturing
processes, they move fast
and often require constant vigilance
to maintain quality control.
Determining if a part has been
manufactured correctly
or if it is damaged,
can significantly impact
product quality
and operational safety.
You can try and do it manually,
but it’s super-hard
to do this accurately,
and to scale this
on fast moving line.
So last week we launched
Lookout for Vision,
a new service that spots visual
defects and anomalies in images
using Computer Vision.
You start by providing
as few as 30 images
to establish a baseline good state
for machine parts
or manufactured products.
Then you can start sending images
for cameras on the line
straight away
to identify anomalies.
Lookout for Vision
will spot differences
between the known good state
and any differences
it detects like dents
on a manufactured part,
a crack in a machine part,
irregular shapes,
or inconsistent colors
in a product.
If anomalies are detected
you can get alerts
in the Lookout for Vision dashboard
where it will highlight
the portion of the image
that differs from the baseline.
Now, Lookout for Vision’s
machine-learning models
are sophisticated enough to handle
variances in camera angle,
pose, and lighting from changes
in the work environment.
In an industrial line,
there are also lots of
split-second decisions to make.
We just don't have the time to send
that information to the Cloud
and get the answer back.
So, many industrial companies
try to use smart cameras
that allow them to process
video on-site at the edge.
But the problem is that most of
the smart cameras out there today,
they're just not powerful enough
to run sophisticated
computer vision models.
And most companies
that we talked to,
they don't want to rip out
all of their cameras
that they have just installed
and put in a different one.
That's why we built
the AWS Panorama Appliance,
a new hardware appliance
that allows organizations
to add computer vision to existing
on-premises smart cameras.
Here's how it works.
You simply plug
in the Panorama Appliance
and connect it
to the network.
Panorama starts to recognize
and pick-up video streams
from your existing cameras
in the facility.
The appliance can then
process streams
of up
to 20 concurrent cameras
and operate Computer Vision
models on those streams.
And if you need to have
more concurrently,
you can just buy more
Panorama Appliances.
We have prebuilt models
inside Panorama
that do Computer Vision
for you
and that we have optimized
by industry.
So, we have got them
for manufacturing,
construction, retail, safety,
and a host of others.
And of course, you can also
build your own models in SageMaker
and then just deploy
those to Panorama,
and Panorama also integrates
seamlessly with the rest of AWS
and IoT
machine-learning services.
The appliance itself is small but
perfectly formed for industrial use.
I have one here with me.
It's IP62 rated which means
that it is dust and water resistant.
It's not as rugged
as a Snowboard Edge device,
but you also don't have
to treat this with white gloves.
That said, it's a one unit tall
and half a rack wide
with chassis points,
so if you did want to mount it
in the cabinet, you can.
It has multiple GigE networking
ports for redundancy
or to connect cameras
from multiple subnets.
People are pretty excited
about the possibility
of having real
Computer Vision at the edge,
but they have also told us that,
“Look, we’re going to buy
the next generation of smart cameras
and those smart camera
manufactures have told us,
that we want to actually
embed something
that allows us to run more powerful
Computer Vision models
right on those devices.”
So, we’re also providing
a brand new AWS Panorama SDK
which enables hardware vendors
to build new cameras
that run more sophisticated
Computer Vision models at the edge.
This SDK and the API’s
associated with it
can be used to add a lot more
Computer Vision power to cameras.
We have done the work to optimize
models for memory and latency
so that you can fit
more powerful models
into what is often
a very constrained space.
The Panorama SDK devices will
integrate with other AWS services.
You can build and train models
in SageMaker
and then deploy them with a single
click to all of your devices.
Those devices will also integrate
with SageMaker Edge Monitor
and IoT services
such as SiteWise for integration
with existing systems.
And we are already seeing
a ton of excitement
with partners across
system integrators,
devices, independent software vendors
and silicon providers
working with us on this
next generation of cameras.
It's really exciting.
So, all these new capabilities
are designed
to help customers
in industrial manufacturing
to improve their processes
from start to finish.
So, let's see how they all
work together
looking at a manufacturing line.
Building a product which is
manufactured in its billions of year
that many of us
always carry in our pockets
and has famously changed the way that
most of us create and communicate.
The humble number two pencil.
Like many industrial processes,
pencil manufacturing is a high volume
low-margin game
which is automated in part
but still requires several
manual steps to keep moving.
So, let's look at our pencil
manufacturing line.
Large compressors create
the pencil wafers
and large-scale machines high
throughput machines insert graphite,
paint ,and then sharpen the pencil.
Industrial machines like these
include dozens of individual sensors.
Using Amazon Lookout for Equipment,
the sensor data from this equipment
is aggregated and analyzed
using machine learning models
which are trained using your own data
but require no machine
learning experience to apply.
The ML models are trained
to identify early warning signs
of future operational issues
by monitoring behavior
such as how many reps per minute
is considered normal for a machine.
These are the proverbial needle
in the haystack problems
that if found early,
could help avoid expensive downtime.
When the ML model detects
a potential issue,
such as a sudden drop
in the rate of repetitions
of this pencil wafer machine,
the service will send text alerts
so you can send engineers to take
a look or preemptively inspect
the equipment for issues way
before disaster strikes
and the entire line is impacted
and has to come down.
Even with this sensor data,
in lines like this,
there is often bound
to be blind spots.
Equipment which either
doesn’t have sensors installed
or rotating equipment such as
conveyor belts which move products
between equipment and provide
a potential point of failure.
Monitron allows you to completely
remove these blind spots
by expanding
the coverage of the sensors
with an end-to-end machine
monitoring solution.
Process engineers can install
Monitron sensors onto machines
to start closing these
blind spots in minutes.
Like on this pencil
sharpening machine.
Once the sensors are installed,
you can start collecting data
such as vibration and temperature
which is then analyzed automatically
and any early warning signals
that deviate from the norm
are flagged to staff onsite
through a mobile app,
providing a completely closed loop
for monitoring and remediation
which requires no machine learning
or even AWS skills to set up
and operate.
Now, quality at every step
is critical in lines like this.
Even small imperfections
at each step can compound
and they get more expensive
to correct as they move down the line.
Amazon Lookout for Vision
uses machine
learning to automatically evaluate
quality at every step on the line.
Using its view
as thirty reference images,
Lookout for Vision can identify even
subtle defects such as misalignments,
dents and scratches,
sending alerts and notifications
as soon as defects are identified,
before they move down the line
and impact entire
batches of products.
Amazon Lookout for Vision
processes the pencils’ images
from the cameras along the belt
and the model analyzes them
for defects in real time.
Each time it spots a lead
that is out of alignment,
it will record it and report the rate
of defect via an online dashboard
so that you can take actions
such as maintenance
or the switching off of a line
to stop more defects
from occurring quickly.
Now, of course, these lines
don’t exist in isolation.
They are surrounded
by entire teams of people,
stacks of inventory, other lines,
and dozens of other pieces
of equipment and moving vehicles.
In addition to monitoring
each process,
many customers have installed cameras
to help monitor
the environment as a whole.
With the AWS Panorama Appliance,
these cameras just got
a whole lot more useful.
Now you can process video onsite
with low latency.
So, for example, you can count
and monitor inventory and analyze
its movement through the site
or monitor the impact
or process changes for improvements.
Panorama can help
transform your existing
on premises cameras
into computer vision enabled devices
so that you can monitor
all of these processes,
remove bottlenecks,
and make improvements
to the overall supply chain.
So, with services such as Lookout
for Equipment, Monitron,
Lookout for Vision, and Panorama,
you can use machine learning to add
end-to-end monitoring and analysis
to your industrial processes,
whether you’re manufacturing cars,
mobile phones, producing
and packing food,
collecting harvests,
generating power,
or yes, even building
billions of pencils.
We can’t wait to see
how our industrial customers
reinvent their processes
through machine
learning using these services.
So, industrial manufacturing
is transforming in a very rapid way.
And the same thing
is happening with healthcare.
A good example is to look at what
Moderna has done in the last year
or so, in really just
the last nine months.
They built an entire digital
manufacturing suite on top of AWS
to sequence their most recent
COVID-19 candidate
that they just submitted,
that has a 94% effectiveness.
And they did it on AWS
in forty-two days
instead of the typical
twenty months that it takes.
Novartis uses natural language
processing to improve its ability
to detect adverse events,
a crucial part of delivering
drugs safely to market.
Cerner is using SageMaker to query
large anonymized patient data sets
and build complex
deep learning models
to predict the onset
of congestive heart failure
up to fifteen months
before clinical manifestation.
But even with
all of this innovation,
piecing together data
that lives in silos
and different formats to create this
three-hundred-and-sixty-degree
view of patients
or trial participants
is really hard.
And this is really the Holy Grail
for healthcare companies.
And they’re just not there yet.
This data is often spread out
across various systems
such as electronic
medical records, lab systems,
and exists in dozens
of incompatible formats.
It often includes
unstructured information
contained in medical records
like clinical notes,
documents like PDF laboratory
reports,
forms such as insurance claims,
or medical images,
and it all needs to be organized
and normalized
before you can start
to analyze it.
And gathering and preparing
all of this data
for analysis takes healthcare
organizations weeks or even months.
This often involves manually going
through individual health records
to identify and extract key
clinical information
like diagnoses or medications,
procedures from notes,
documents, images, recordings,
forms, before normalizing it
so that it can be searched.
It's expensive
and time-consuming to do well,
which means analysis like
this effectively remains out of reach
for almost all healthcare
and life sciences companies.
Every healthcare provider,
payer, and life science company
is trying to solve the problem
of analyzing this data.
Because if you do, you can make
better patient support decisions,
operate more efficiently, and better
understand population health trends.
So, today, I'm excited to announce
the launch of Amazon HealthLake.
A new service that enables
healthcare organizations to store,
transform and analyze
petabytes of health
and life sciences data
in the cloud.
HealthLake transforms data seamlessly
to automatically understand
and extract meaningful
medical information
from raw disparate data
such as prescriptions,
procedures and diagnoses.
Reinventing a process
that was traditionally manual,
error prone and costly.
HealthLake organizes data
in chronological order
so that you can look at trends
like disease progression over time,
giving healthcare organizations
new tools
to improve care
and intervene earlier.
Healthcare organizations
can query and search data
and build machine learning models
with Amazon SageMaker
to find patterns, identify anomalies
and forecast trends.
HealthLake also supports
interoperability standards like FHIR,
the Fast Healthcare
Interoperability Resource,
a standard format to enable data
sharing across health systems
in a consistent
compatible format.
So, let's take a look at an example
of how HealthLake can be applied
to one of the most common
chronic medical conditions, diabetes.
Now, early detection
and control of diabetes
is critical to prevent
the disease from getting worse
and can lead to tangible improvements
in the quality of life for patients.
Data can help
with earlier diagnosis
and more fine-grained
control over treatment.
Healthcare organizations receive
a lot of data for diabetic patients.
For just one patient, there are
hundreds of thousands of health data
points from doctors’ notes
to prescriptions to blood sugar levels.
And it is all stored
in different silos,
in dozens of different formats
and file types.
It is a Herculean effort
for healthcare organizations
to organize all of
this information for each patient
and to normalize it
for analysis.
But with HealthLake, we can bring
together all of this data
in minutes with natural language
understanding,
ontology mapping,
and medical comprehension.
HealthLake can load
prescriptions and identify
if a patient has been prescribed
a drug like metformin,
accurately identifying
and pulling out the medication’s
name, dosage and frequency.
Here, the information
from a patient’s blood
glucose monitoring system
can be added.
HealthLake can load this structured
data on an ongoing basis.
And HealthLake also
extracts information important
from forms like physicians’ notes,
insurance forms and lab reports,
and then adds it
to the data lake
so that it can be queried
using a standard nomenclature.
Separately, these are all
just pieces of the puzzle,
scattered around different silos.
But when combined, we can start to get
a much clearer picture of health.
With HealthLake,
you can bring together
hundreds of millions of data
points across millions of patients
to paint a picture of the entire
diabetic patient population.
So, now that this data is collected
and normalized in HealthLake,
it is immensely more useful.
Let's see what we can do
with this data
to start to unlock new insights
about this population.
First, we can identify
a subset of patients
with uncontrolled diabetes
with high blood sugar levels
so as a provider
we can adjust the treatment
and avoid severe complication
by better managing the disease.
To do this, we can query the data
directly from the HealthLake console
to identify these high-risk patients
using standard medical terms
such as medications, diagnoses,
or blood sugar levels.
Next, we can use Amazon QuickSight
to build a dashboard
to visualize this data
to get a more complete picture.
We can compare
this group of patients
against others in a similar situation
to identify trends.
And monitor patients
to better understand
how their risk factors
change over time
based on interventions
or public health initiatives.
We can also build
predictive models which look forward.
We can use SageMaker
to forecast the number
of new diabetic cases
year-over-year informed
by millions of points
of health data,
providing a quick easy way
to identify health trends
in patient populations.
What was once just a pile
of disparate and unstructured data
is now structured,
easily read and searched.
And for every healthcare provider,
payer and life sciences company,
HealthLake helps them get more value
out of their health data
by removing the undifferentiated
heavy lifting
associated with storing,
normalizing, organizing
and understanding their data
so that they can answer
important questions
which help their patients and improve
the quality of their care.
So, to talk more about
how they’re applying machine
learning to reduce this complexity
and provide better care,
I would like to invite
Elad Benjamin,
the General Manager
of Radiology Informatics at Philips
to talk more about his work.
Thanks a lot.
[applause]
Hi, everyone.
My name is Elad Benjamin.
I'm the General Manager
of the Radiology Informatics
Business at Philips.
When you envision how you
would like healthcare to be,
what do you think of?
For me and many others
what comes to mind is quality.
And what is quality
in the context of healthcare?
It’s the optimal meeting
point of speed, accuracy and cost.
The holy grail of medicine
is to reach diagnosis
and deliver treatment
in the least time possible
with no mistakes
at the lowest cost.
We have the opportunity to get
closer to the Holy Grail
by synthesizing data
in new ways.
And today, I will talk specifically
about data analytics,
machine learning
and computer vision.
Part of the difficulty
in healthcare today
is the abundance of data
being generated,
quantity diversity and multi-source,
imaging, monitoring, genomics.
Physicians need to work
through those data silos
and it's getting harder for them
to diagnose and treat.
At Philips, we are trying to help
tackle these challenges
in a number of ways.
One is HealthSuite.
HealthSuite is a foundational layer,
a cloud-based data platform
that consolidates patient records,
data from wearable or home-based
remote medical monitoring equipment,
information from insurance companies
or healthcare organizations.
The HealthSuite clinical data
lake runs on AWS
and brings high volume
clinical data together
while meeting
regulatory requirements.
HealthSuite includes
dozens of AWS services
from the edge to the cloud,
providing the cloud foundation
for IoT and remote connectivity
for smart diagnostic systems,
operational analytics
for optimizing workflows,
scalable tele-diagnostics for remote
and emerging points of care,
and cloud PACS
for integrated diagnostics.
A specific example
within HealthSuite,
we just announced
the availability
of the new Analyze AI
training service.
It’s a multi-tenant service
that provides functionality to submit
and manage CPU or GPU-based AI,
machine learning,
and deep learning
training jobs.
It uses Amazon SageMaker as
the execution engine in the background.
The training service
offers users the ability
to configure the custom
compute environments
and permitted
compute targets.
It helps users submit and manage
the long running training jobs
connecting to an existing repository
and associating its execution
with required compute
environment and targets.
Within radiology, in order
to advance precision diagnosis,
Philips is applying machine
learning and AI tools
to improve diagnostic systems,
realizing first time
right diagnosis
through clinically relevant
and intelligent diagnostics,
optimized workflows,
connecting and integrating workflows
to drive operational efficiency,
integrating insights from imaging,
monitoring, laboratory, genomics,
and longitudinal data
to help create clear
care pathways assisting with decision
making at pivotal moments
of the patient’s journey.
We build machine learning models
using Amazon SageMaker
to draw insights from the data.
And in the future, we may use
Amazon Transcribe Medical
and Amazon Comprehend Medical
to integrate additional data sources
and store them
in a data lake built on AWS.
Using AWS machine learning and AI
services to streamline building,
training and deploying
our models makes sense.
AWS builds these services
to run at scale
and cost efficiently,
freeing our data scientists
to focus on higher value activities.
Philips and AWS share a common goal,
to demystify data science
and artificial intelligence methods
and accelerate their use
to extract new knowledge
from health data
to improve healthcare delivery.
At Philips,
we are disrupting healthcare
by bringing together
the right information,
the right tools, to make
the right decisions for patients
and have providers really
do what they signed up for.
Taking care of those patients.
We expect to see AWS machine
learning and AI services
continue to be further embedded
throughout the broader
Philips organization.
There are a number
of business areas
that will benefit
from accelerated AI adoption,
from image guided therapy
to sleep and respiratory care,
remote patient monitoring.
The unlocking of data
using ML and AI tools
will support the fundamental shift
from volume to value-based care
and to a precise diagnosis
for each patient.
Thank you very much.
[applause]
Thank you, Elad.
Finally, the last tenet
that I’m going to talk about
is giving builders the ability
to learn continuously.
Training and education,
especially in emerging areas
like machine learning,
enables teams to keep up
with new technologies
and fosters innovation
throughout an organization.
At Amazon, one of our
leadership principles
and my favorite one,
is learn and be curious.
We encourage everyone,
including our builders,
to try new things,
learn new technologies,
and stay curious
about the world around us.
This is one of the reasons
why Amazon has been at the forefront
in adopting disruptive technologies
like machine
learning before they were
even mainstream.
In fact, early on in our adoption
journey of machine learning,
we developed the machine
learning university
that we have used for over six years
to train our engineers on ML.
Now, to help others benefit
from this content,
we've made it available
for free for anyone to learn
and launched a certification
for machine learning on AWS.
And developers cannot
get enough of it.
Based on this demand, we also develop
content from massive open online
courses such as Udacity, Coursera,
and edX to bring practical
applications of machine
learning to more people.
Also, to make more
complex machine
learning concepts
like reinforcement learning,
deep learning,
and GANs more accessible,
we created
our educational devices
like DeepRacer, DeepLens,
and DeepComposer.
Over the years,
programs like DeepRacer,
our fully autonomous
one eighteenth scale race car
driven by reinforcement
learning, have built a loyal fan base
and the teams continue
to bring new experience
to our DeepRacer
leagues.
And over one hundred
and fifty customers
globally have trained
thousands of developers.
These include Capital One,
Moody’s, Accenture,
DBS Bank, JP Morgan
Chase, BMW, and Toyota.
They have held events
for their workforce.
Now, let's take a look at the fun
we had with DeepRacer last year
and a look ahead at what's next
with DeepRacer this year.
[applause]
[revving engines]
[revving engines and techno music playing]
What am I getting myself into?
[techno music playing]
Welcome to another
AWS DeepRacer Underground.
[techno music playing]
Oh, wow. OMG.
[techno music playing]
[revving engines]
Go. Go. Go. Go.
[revving engines - techno music playing]
[applause]
Some exciting stuff
coming from DeepRacer.
Over the past few years,
machine learning has come
an incredibly long way.
The barriers to entry
have been significantly lowered,
enabling builders
to quickly apply machine
learning to their most pressing
challenges and biggest opportunities.
This was never more apparent
than in the wake of the pandemic.
Our customers needed
to move faster
than ever to respond
to the changing world.
They applied machine
learning to create new ways
to interact with customers,
reimagine the way we work and learn,
and automate business processes
to react faster to customer needs.
They applied machine learning
to tracking the disease,
finding new ways
to care for patients,
and to speed up
vaccine discovery.
They were able to do all this
because their builders were free
to harness the potential
of machine learning.
Free to build remarkable
technology on top of it.
Enabling this freedom is what
our team is passionate about.
It is what drives
our own innovation
and it is why we push out
new features nearly every single day.
In fact, we have so many things
launching during re:Invent that,
even between myself and Andy,
we are not able to announce them all.
So, be sure to check out
the more than 50 ML sessions
that we have available
throughout the event.
Thank you and have a great rest
of your re:Invent.
[music playing]