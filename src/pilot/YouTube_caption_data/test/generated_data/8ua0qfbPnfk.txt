hello everyone and welcome to my youtube
channel in today's video we are going to
build a pie torch
trainer from scratch there is a lot of
code floating around on the internet and
most of the time you don't need
all that you need something which is
customizable
and still pythonic if some trainer or
rapper
is making your code ugly and
non-pythonic you must stop using it
as you can see in the background there
is a github repo
and it's called tase which means sharp
or active
and this is a trainer that i have built
the idea comes from one of my old
repositories
called wtf ml and a lot of ideas have
been borrowed from the most amazing
machine learning library scikit-learn
and the
most amazing most famous deep learning
library called
keras in this video you will learn how
to build a python trainer
specifically these you can also go
around
and you can do a pip install
phase if you want and you can start
using the library
so the idea around what i have built
here is very simple i have to keep
things as simple as possible there is no
need to complicate stuff
where when it's not required make it as
customizable as possible
clean code it's very important and it
can be used for
faster prototyping and it's always
production ready you are not leaving the
pi touch ecosystem at all
there are no dependencies so
it's as close to python as close to pi
charge as it can be
so um to get started let's
go to our code server environment and
uh start coding it and then only you
will learn how
it is built so let's get started
so now we are in our code server
environment
and now we can start building the
trainer so uh the only things that you
need to remember
is what are you simplifying so
uh pie torch has a lot of things
floating around so
you have to simplify a lot of things one
of one of the major things is
the loop the training loop
so let's say the training loop let's
write down a few things
then you also have you can have
different types of optimizers you can
have different type of
sketch scheduler so you need to take
care of that
and what you want to do is you want to
put everything in the model
so like if you have seen how keras
trains the model
it just calls model dot fit so we don't
we don't have to
call another class or another function
and another function after that
to just train the model we can do it in
one go
and that's that's what our goal is so we
need to take care of the model
so uh one of the most basic things in
python
not basic but advanced is class
inheritance
so what what it does is you inherit from
some other class
and then this class will have all
properties of the other class
the parent class and its own properties
so let's import an n dot module
so we can do import
starch.n as n
and here we can write an n dot module
okay and let's write the init function
in it and here we have self
we can also write some arguments
some arguments need to be provided so
args or
keyword arguments
if required you can also skip this step
um so so we got these
and now what we do is we write super
and then we do dot underscore and score
in it
and then provide these arguments and
keyword arguments to the
parent in it in case you want to do that
so this is
the way i would do um
but you can totally skip this if you
want to
so now there are a few more things um
so we had optimizer so let's define
a simple optimizer
variable and set it to none
similarly we can have a scheduler
set a tune on um so we got the
optimizer we got the scheduler um
maybe we will have few more things maybe
uh training train loader
so that is a data loader that you have
set it to none
we can also get
valid loader for your validation stuff
set it none and then
go to the next step so what does the
next step do
so there are many many things that you
can do uh
we will break it down into different
parts so that's
much easy to understand so we do
fit and self
so this is the function that you will
call model.fit and
um here
what do you want to provide so
what we are doing is we we are building
a trainer
that requires only two things
your data set
class the pi dodge dataset class
and model class that's it
so when you're when you're saying model
okay
then dot fit it should take
train underscore data set
so i will leave the validation as an
exercise for you guys
let's just do train so train underscore
data set then it will probably need some
bad size um
[Music]
what what else what else do you think it
might need
let's let's keep it like this and
a box obviously that's important
epochs so
we got a few variables in and now we can
uh write our loop so
here you see i have taken train data set
you can also take train loader if you
want but
what i'm going to do is i'm going to
create the loader inside the fit
function
so you don't have to go and
create the train loader so you can just
you can just do
from the data set and it simplifies your
code so
i will say um i had already defined uh
train under dot train loader
self.trainloader so it's defined here
so what i'm going to say if
self.trainloader is none
then um create the train loader
then self.train underscore loader is
equal to
so what was it let me import torch
import dodge and here we have
torch dot and dot util start
data order dot dot nn dot
utils no sorry trust.youtube.com
[Music]
dot data loader um but
it was a class okay
so we got a data loader that data loader
takes
train data set it can also take a batch
size
which you have um batch size
and what else
i i think that's it right a shuffle
probably
shuffle to true because it's our
training set so uh
we did that and then um
what we do is we write the
training loop so i would say for
underscore and range
epochs
do some training so train underscore
loss
is equal to self dot
train one epoch
and train one epoch takes the train
underscore loader
as an argument what you can also add
here
is device and you can do
you can check which device is the more
is the model on
so if next self.parameters
and then dot device
so this will give you what device the
model is on if this is not equal to
device that you have provided then
self.device
device self.2
device um so so
you must have seen that so you always do
some model.2 device
so now we are doing just self.2 device
because we have
inherited from an n dot module
so we have everything that it has and
model is a part of it
so we can just do dot 2 self.2.
so we got a
self.train one epoch that takes the data
loader
it doesn't need to take anything else
now it's totally
up to us maybe we can provide device
here
or we if we have provided device here
then we need to
create uh another variable called
self.device
and um we we need to make sure that
certain device and this device is the
same but for simplicity what i'm going
to do is i'm just going to say device
okay so now um our fit function
is done except for the fact that it's
not going to work
and this should not be train loader
should be self dot drain loader
okay um
and now
we write another function train
one epoch itself
and this takes itself and data set and
a device
now it has taken these three things and
you write the
training loop so the first thing that
you do is you put your model
in the train mode and that is nothing
but
self.train
and then you go over all the
items in your data set let's not call it
data set let's call it data
loader so
i can just say for data in
data loader
do the training
so um there are a few things now so
let's say
our model returns
the forward function of the model
doesn't just return output but it
returns output and loss and some other
things
so you can make it written whatever you
want so make
right now um let's say it returns
um output and
loss so now i create another function
train one step
okay why am i creating those functions i
will tell you soon
awesome so now we got
our data loader and using this data
loader we have
um our loss coming from
train one step and train one step should
again
take some arguments so it takes
data and device so data is like
one uh sample
sorry uh not one sample but one batch
one step
uh okay so so we got that and now we do
lost dot backward
and everything else that you want to do
we also have the scheduler so
you you also need to take care of that
um or let's let's not do the backward
here we will do it inside train one
step so it returns some loss and you can
say
okay temp epoch loss
equal to zero
and here if i can risk a loss
plus equal to loss
okay and then you return uh
epoch loss divided by
length of data loader
okay so uh you return average loss
so i'm not sure if uh it can be done
like this
or maybe uh data loader
dot um so whatever the number of batches
and data loader are
so you just need to take care of that i
think you can figure that out
i don't remember um so
so we got that and then you return this
so now you got your
train one epoch function so but you can
see that we define one train one step
function so we take this and
we write our one batch of training
here so def
train one step so now what it does
is first of all it will zero grab the
optimizer so self.optimizer
dot zero grab
and see we have we still have to define
optimizer and scheduler so let's wait
for it
and then what you can do is very simple
you can do for
k comma v key and value in data dot
items and you can put all the items
on device so you can say data okay
equal to v dot to device
so you don't have to take care of um
putting them on the same device
individually
so we got that now we calculate loss
and let's say our model forward
returns something and loss something is
output and loss
and we just do self to asterix
and data so we just do a forward pass
and then what we can do is we can do
lost or backward
like we usually do
and self.optimizer dot
step
so now one one thing here that you need
to keep in mind
we can also parameterize that is you can
also
step the scheduler after one batch of
training or after one epoch of training
so here we are just going to hardcore it
but we can also make it a parameter
and then you return loss
okay so i think everything is
done uh so you got one step
and now you need optimizer and scheduler
so
we are not going to do anything about it
like
[Music]
very simple let's write a function fetch
optimizer
self args
and keyword arguments
and return so this is just this is a
function that can be
replaced by you um
scheduler okay
one more thing that we forgot and that's
very important is the forward function
itself
so the same forward function that you
have
so what i'm going to do is you have to
provide
some arcs keyword arguments
and just call super
it's the same function forward from
your parent
arcs and cure arguments
okay hmm looks good
so now now you got everything so you got
your new model class
which has a forward function it has a
fetch optimizer which scheduler
train one step train one epoch the fit
function
so it has everything so now we
we can write let's say we create this
file
and we we just import it so we
write our new model my model
and now it inherits from the model class
that you have written so you just do
super dot in it so you call the init
function
of your parent
and here you do the same thing that you
would
always do
[Music]
so here you can have anything let's say
you have number of classes
and here you define your
network define uh
network layers
and then whatever self dot
out is nn.linear if you have
and something i don't know 128
let's say n number of classes
so this is also your fully fully
flexible
as it used to be and you define
forward function so now when you define
forward function
it should take a few more arguments than
normal
so it should take
inputs or features let's say let's say
features
and it should also take target targets
and we can always make it none uh
by default and then you run your network
you say okay
this is dot something that you have
defined
inside the layers forward
and then again x do something whatever
you want you would want to do
and then you calculate a loss so you can
calculate loss
by just writing a function here
loss takes self output
features sorry targets
outputs and targets and you say
if targets is none
return none and uh
otherwise return and then dot
any any loss that you want you can
customize it as you like
output targets
okay so now you you have any kind of
loss you want and why we did this
let's say you're running your model for
prediction you don't have the targets
but you don't have to change any code
and
it's not going to crash so
you calculate the loss self dot loss
and uh here we had let's say we had
output out equal to something something
something
so you do out comma targets
and you return out
and loss and that's how you do it
so uh but we still haven't defined a few
things
like scheduler so you can define fetch
scheduler
if you want to have any and uh
this takes self
let's say scheduler
torch dot optim.lr
scheduler and uh
anything you want uh step either
let's say and it takes a optimizer
parameter so you know
like your optimizer is nothing but
self dot optimizer
and return sketch
scheduler let's change the name a ch
and similarly you have fetch optimizer
itself now optimizer take can take some
model params or
all model parameters so all your
parameters are
defined by paragraphs equal to self dot
parameters
so you used to do model dot parameters
model.name parameters things like this
you can just do self.parameters
and define here
optimizer here let's say it's uh
i don't know torch dot optim dot
optimizer
uh sorry
atom let's say and you say
self dot parameters
return opt
so now we have our optimizer using the
fetch optimizer function
scheduler using the fetch scheduler
function and we have our forward
function
so now what we do is we are missing one
more thing
in fit so
we say self dot optimizer
is self dot
fetch optimizer and similarly we say
self dot scheduler
[Music]
is self dot
fetch scheduler so the this thing you
need to take care of
other than that we i think we are
probably done and now we have defined
our model here
which inherits from our own class the
model trainer class
and then you you do whatever you want
like
m is my model
and whatever whatever whatever and you
also need to define the data set class
that i have not shown you here but you
can define it easily
uh so you have then you can do m dot fit
train underscore data set and batch size
uh whatever
16 device equal to cuda
and it will train your model and it's as
simple as that it cannot be simpler
um there are a few more things here
uh that that you have to know about
and i have not explained them in this
video
and i'm not going to do that um i'm
going to
go through uh phase
and i'm going to show you the model
class
intakes and what it has
so i'm just going to go inside model and
model dot py
and it has a lot of things but it's
super simple nothing complicated
lightweight still customizable
one more thing that i forgot to tell you
let's say you are
not happy with train one step
or train one epoch you want to add
something there
so what you can do is in your model
you can just write
train one epoch
what was it data set or data loader
data loader and uh
train one data loader and device device
self and you can write however you want
to
handle it doesn't matter and it will
replace
the train one epoch function so you
write one generic one that works for 95
99
cases and then you just
replace it for for the cases it doesn't
work you can also include keyword
keyword arguments in here
so now i have a lot of links here i have
the train loader i have the valid loader
optimizer scheduler step scheduler after
so this is
something that i have added like i want
to step scheduler after a batch or after
epoch
uh so i also keep track of current epoch
what is the current training step valid
step
some state about the model the state
about
uh training and i also have a callback
runner
so i define a property i say this is a
model state and then using uh the setter
i say okay i'm setting the
value of model state using uh to
something else
you you can also do something like okay
after you set the value and if the value
changes you can run some code
and that's how callbacks are made i'm
not going to going into
details of that in this video
um so i also have something very
customizable which is called monitor
metrics
so you can add as many metrics as you
want and after every epoch or after
even after every step it will give you
the metrics and you will be able to see
them
and most most of the things remain the
same i have predict one step
for testing purposes so let me show you
a code code example using this
let me show you multi-class
classification
text classification
so um
let's go down here so in this data set
the bbc text data set i
have a category column
and a column with text
and our job is to build a model to
predict the category given the text
so what i do is uh i i
convert them using label encoder convert
the categories to
integers and uh using label encoder from
scikit learn
and i split them
straight in a stratified manner so
then after that i have created dftrain
and df
valid and i have a dataset class
bird dataset so let me go there
so bird data that takes text and target
it tokenizes it it has a tokenizer
and it has some other parameters i don't
care about that
and then it returns the total
length of the data set and the simple
get item function
so now this is important because you get
item function
should just return a dictionary with
data types because that's what
is not handled in the
in the trainer class
and then i define a model so here i just
import
from uh taste.model
i just inherit from tase.model and
here i have uh the birth model
i added some dropout i have linear
whatever i have
number of training steps uh as another
argument
i have number of classes so i can change
the model
depending on the number of classes and i
just say okay
step the scheduler after a batch
i have a fetch optimizer function
that returns item w optimizer fetch
scheduler function
that returns get lean linear scheduler
with warm-up takes self.optimizer
self tottenham train steps i have a loss
function for cross entropy loss and my
metrics monitor monitors accuracy so it
will always monitor loss
but you can also make it monitor
anything you want
and then the same old forward function
now the forward function here
must return three things output
loss and the dictionary of metrics
if you do it this way you don't have to
do a lot and this is not a lot of code
and this is still the same kind of code
you would write
for if you were just using pytorch
without any kind of
helper trainer so and you can see
this code is pythonic it doesn't look
ugly
um so you have the trained data set you
have the valid data set you define the
number of training steps you create the
model here
so i've created the model here and then
uh i told you i added some callbacks you
can create your own callback it's so
supe
it's super easy and all that inspiration
comes from
cameras and
uh then i just fit the model so i
provide training data set i provide
valid data set blah blah blah blah blah
and i also added if i want to use fp16
for training
and if i when i save the model it saves
the model
as usual and then i have the prick
function
which um which is a generator
so you can do all kinds of post
processing as
as you like
and like i have early stopping so if you
remember this from keras you can do
train underscore accuracy or train
underscore loss or valid underscore
accuracy valid underscore loss or
whatever
you want so whatever you have to find
so um yeah go go through
go through this code uh if you like it
don't forget to start
and uh if you have any questions let me
know i'm i'm still
developing this it's in very early stage
but i'm
i'm i'm telling you one thing i'm going
to be using this
for all my future videos which are not
building
complicated models just to save me time
i have already shown you
how to design a simple trainer and i've
designed a very simple trainer
and i hope you design your own trainer
too
so thank you very much for joining me
today if you like the video
do click on the like button if you have
any comments let me know in the comment
section
um if you want to request tutorials for
future let me know
and we will see each other soon bye