 Alright, so at the end of the previous video, I promised you
 to show you Alex net now. But before we do that, let me show
 you one more thing how we save and load models. And then in the
 next video, I will show you Alex net. So I explained to you how
 that works in an earlier lecture. But yeah, it's really
 good to just recap that because I think it might be very useful
 for your class projects. So here, I have a subfolder, I just
 called it safe and Lord. So all of that is on GitHub, I will add
 the links. So this safe and Lord subfolder, and let's do the
 Alex net first with only training it for like one or two
 epochs. So here, I'm showing you how we can save a model. So same
 thing as before. Notice that I'm having now this path dot insert
 dot dot. That's because all my helper files are one level
 higher than this folder where I'm executing this notebook. So
 it's basically going back one folder, and this is where my
 helper files is. So this is essentially just adding this
 path, so that Python knows where to find these helper files. Of
 course, you can also make this a Python a Python package and
 then import this as a package by different by a setup file,
 maybe even, but this might be overkill here. So here, for
 experimental purposes, it's just sufficient to just add the path
 and it will find this and run this or import everything. So
 everything here is the same as before. So now let's train only
 for three epochs or something to and it's all the same stuff. So
 I don't have to explain all of that again. So this is
 essentially not training for two epochs instead of five. So let's
 briefly wait until this finishes, it shouldn't take that
 long, maybe a minute or something. Half a minute. All
 right. So here, maybe we might think, okay, it might be good to
 train a bit longer. So actually, I also added an another. So I
 have this show example function. So here, everything looks
 correct, all looks fine. But I also added another functional
 confusion matrix, students who took 451 last semester may know
 what the confusion matrix is. But yeah, essentially, for those
 who are not familiar with that, it's essentially a matrix
 showing the predicted labels versus the true labels. So how
 many, let's say how many nines were predicted as zero, right?
 So you can see where the model makes the most mistakes, what
 you want is you want the highest number here in the diagonal, you
 can see, for instance, the model mistakes, a lot of the nines as
 a five, or mistakes, a lot of can we see here, twos as seven,
 I mean, they are quite similar, right? A two and a seven are not
 that different. So it's kind of interesting to look at that and
 see where the model makes the most mistakes. But this is just
 as a side note. So the main part I wanted to talk about is the
 model saving here. So here, what we do is we save the model
 parameters, that's the state dict. So take a dictionary
 consisting of the state or the weights and everything, all the
 parameters, and we are saving it to file called model dot PT. So
 PT just for pytorch, but you can choose any name that you prefer,
 you can also spell it out, like pytorch, oops, doesn't really
 matter. Okay, and then let's do that. So then it will all but we
 also do is we save the optimizer state because we use on s SGD
 with momentum. So there's also a momentum state that we save, if
 we want to continue using that optimizer. And we also have the
 scheduler. So we also say the scheduler state, I mean, you
 don't have to do that. You can start from scratch with a new
 optimizer and scheduler. But if we really wanted to just
 continue training, like if the run here got interrupted, for
 example, then this would be the proper way to do it in ways that
 we save all of them and then load all of these states. So now
 we have these here in this safe and load folder. And can we see
 this? I'm not sure we can see that the file size is also quite
 it's also quite interesting. Sometimes these are pretty large
 the model because there are lots of weights. Anyways. Now, assume
 we have saved the model. Let's now load the model. So you have
 a prepared another notebook. Actually, it's all the same
 stuff. So everything is the same. It's kind of required
 because what we do is we first have to initialize the model. So
 that is what creates the class. And then once we have initialized
 it, this is really only the new part. That's how we load the
 model. So now we have torch law load, and then the model dot pt
 file, the same thing for the optimizer and scheduler. And then
 we are loading this state dict here into the model. But
 notice that we have to initialize the model. As before,
 that's the same thing as before, but we have to do that. Because
 otherwise, it wouldn't know where yet where to put the
 parameters, right? So okay, if we've done that, we can then
 train the model further here for 10 epochs, it might take quite
 a while. But yeah, we would then continue training that model. So
 that's how you save and load models. Next in the next video.
 Next in the next video. Now let's get finally to the Alex net.