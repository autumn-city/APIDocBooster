hey guys welcome to the scholar online youtube 
channel the channel that is all about learning  
okay so if you're new to this channel make sure 
that you don't forget to subscribe to us so  
that you'll get notified every time we have a new 
video on the channel we typically have new videos  
every week and we talk about everything from 
python development to artificial intelligence  
development to web development to like wordpress 
i mean anything that's got to do with coding and  
programming you're probably gonna find it on this 
channel okay we are a learning channel we here to  
teach you guys so you can learn to be able to 
build some of these applications yourself all  
right so uh again remember to like this video 
smash that like button smash that subscribe  
button um go underneath the description box of 
this always check out the description box because  
inside of the description box you're going to find 
all the links that i'm going to be talking about  
so if i say to you that i'm going to link it in 
the description below you're going to find that  
in the description box okay and then also there 
will be video time stamps or videos are quite long  
you do not have to watch the entire video you 
can go into the timestamps and you can just  
jump to the section that you like if you want 
to jump to that section of the day just click  
it there and it will take you to that section 
and you can just watch what you want if you  
come back in future again you can just always use 
the description box okay and then we've got links  
to all our social media publications everything 
just check it out and then let's get learning okay  
in this video here today i'm going to be showing 
you an alternative to gpt3 that you can access  
right now um open source uh for free no api keys 
and you can just get it done to and you can use  
it for text generation okay it is called gpt neo 
and it is sort of like a clone or a sort of like  
a cheap ripoff of gpt3 but it is also i'm quite 
effective in certain things and it really depends  
on the use case that you want to use the text 
generation for and if you have a use case  
that you cannot afford for example an approval 
and you um you know you want to just like you know  
not have limitations and not have to pay 
for it you might want to consider gpt  
neo okay and um so um i'll take you through all 
the steps but i wanted to show you quickly what  
we're gonna be building at the end of the day all 
right so over here you'll see i've got my command  
line that um i've already done all right and i'm 
gonna take you through this whole process of how i  
got here in this video we're gonna be running 
this on a virtual private machine that is running  
us on digital ocean um uh you know uh you know a 
platform okay so what we have built is this okay  
so once you've done everything you'll be able to 
run this code um import transformers generate text  
and this is a model that we're gonna use to 
generate text and then we're gonna give it a  
prompt an apple iphone as a prompt and then 
we're gonna ask you to generate text that's  
hundred characters long and print out the output 
okay so if you list um this uh you know where we  
are right now you'll see there's a there's 
a file called gpt2.py if you open that file  
um like that you will see everything that i'm 
showing you i've already pasted it inside of  
that file okay and then i'm gonna close that 
file and then i'm going to run um that file  
it takes quite a bit of time so i'm going to 
fast forward to the end of me running that file
okay so we have a response the response is it 
gave us is an apple iphone 7 ios 11 is the most  
powerful for nowaday which makes it the best phone 
ever and that also makes it the most expensive  
um one out there the best phone since it comes 
with a huge battery and an incredible performance  
but when you look at the price you'll find out 
that apple is now trying to push you to spend more  
here are all the best gadgets that are compatible 
with an apple iphone all right so this is i mean  
this is reasonable takes generation i mean if you 
wanted to depending on the use case um you know  
this is what you know you can get out of the gp2 
it does take quite a bit of time though and this  
is what we're going to build and of course if 
you just copy and paste this code you can take a  
screenshot and copy and paste this code and run it 
it's not going to run it um just but because you  
have to install a couple of things you have to 
install pycharm you have to set up your virtual  
server to run python in virtual environment so 
that is actually what we're going to spend 40  
minutes doing and then once we've done that then 
you can run these four lines of code and get the  
outcome that i show you okay so that's what we're 
going to cover in the video and let's get started
so basically gpt stands for generative pre-trained 
transformer so it is a transformer model if you're  
familiar with that in python all right and um it 
it they provide you with models that they have  
already trained um sitting in their servers 
that you just access via an api and this has  
really simplified and accelerated um the use 
of um artificial intelligence uh you know use  
cases within um the industry you can just see the 
boom in in that has happened in the last couple of  
years with respect to what we call you know text 
generators you know copywriters blog generators  
all of these are all based on gpt models all right 
i got a question this week from one of my clients  
uh not clients really but like students here on 
school online but like can we develop our own  
uh they wanted to develop their own gpt model 
thinking that oh you know that they can't get  
the results that they want out of them available 
online gpt3 and i think i had to say to them i  
sounded a bit i might have sounded a bit rude but 
you know gpt3 the current one he's been trained  
on over 150 75 billion parameters all right 
it has been trained over um almost all the  
information that's available on the internet is on 
the internet trillions and trillions of data over  
years a cost billions of dollars to do right so 
it's not something that you can wake up tomorrow  
and think you know what i think i'm gonna just 
build my own gpt model because i don't like the  
one that's been provided by by open air yes you 
can but it's going to take you as much time and  
as much money to you to build your own all 
right so this is why people were not doing  
it before because it is it's an expensive process 
and open ai has taken the initiative to do it and  
then provide it to the industry at a fee hence we 
access it via the api and we pay for the right to  
access it so that's their business model but that 
has opened up you know a lot of use cases and  
allowed many people that would not have otherwise 
been able to build and train their own models to  
find already trained models that they can just 
customize for their specific use cases so trust me  
when i say this you're not going to build your own 
gpt model overnight you can do it but it'll cost  
you a couple of years and a couple of billions 
of us dollars to do all right so it is easier but  
the good news is there is alternative models 
um that have been built by other people  
perhaps trained on less data that can perform 
some of the functions uh probably not to to the  
quality to the level of the gpt3 models but 
perhaps towards a reasonable standard or a  
reasonable level that you can still get something 
out of it without going via open air all right so  
you might not be able to train your own or build 
your own but you can find open source models  
out there that have been pre-trained that you can 
actually use without going through the process of  
applying for an api key and and your app maybe not 
getting approved in terms of the use case that you  
have because i find that's a bit of a challenge 
there are certain use cases like in my case  
i wanted to build a a tweet generator you know 
something that would generate automatic tweets  
based on your industry so you don't have to like 
tweet every day you can just have the a i generate  
tweets for you and then you can decide to tweet 
those things on um for example the twitter api all  
right a use case like that for example will never 
be approved by openai openair will never approve  
an automated twitch generator that just generates 
tweets and posts to your twitter via by an api  
because their specific state on their website 
they wouldn't approve something like that so  
if i wanted to build that i might have to get my 
own model or perhaps use another model that can do  
that all right so that there are cases situations 
where you might want to uh consider using a  
different model so today we're going to discuss 
gpt neo and other available text generation models  
that are that that you can use out there right 
so what i wanted to the reason why i've got this  
slide over here what i wanted to show you here is 
the difference in parameters you know just to give  
you an indication of the size of the model right 
if you look at gpt2 it was way smaller than gpt3  
gpt2 i think had about 1.5 billion parameters and 
this is from the internet i don't know for sure  
this is what wikipedia says all right if you look 
at gpt3 today the carry the latest one has been  
trained on over 175 a billion parameters okay so 
it is by order of magnitude way larger right even  
compared to gpt neo so gpt neo was almost in the 
same ballpark as gpt2 but gpt3 was abounds and  
bounds ahead and nowadays with the gpt models you 
even have the instruct series which is even better  
than the original gpt2 um that was initially 
released last year which was the gp23 um you  
know like the da vinci dpc the original one was 
more like gpd2 where you had to give it a prompt  
for it to continue and and generate text for you 
nowadays you with the instruct series actually  
you can tell it what you want it to do so you can 
say generate for me a tweet all right that is not  
necessarily a completion right it's it's it you 
tell it what you want it to do with an instruction  
and it will listen to that instruction and give 
you the the content that you want and that is like  
a huge improvement and you don't get that with 
gpt neo you can't give it specific instructions  
you have to like start writing something and then 
it completed for you um based on you know what it  
will read and understand what it is you're 
writing okay so there's a huge difference  
and definitely if you want the most advanced 
definitely gpt 3 is but today let us discuss gpt  
neo okay so gpt neo basically i've got some 
notes that i've written here that i'm going to  
make available i'll put a link in the description 
of this video and you can go through these notes  
and these notes are going to cover all the steps 
you're going to follow in this tutorial all right  
and um then you can refer to them later on even 
in your own time okay so the first thing that you  
need to to understand we've got some prerequisites 
for this tutorial okay we're going to be working  
off a digital ocean a droplet because i want to 
show you how to actually run this model yourself  
in like a cloud environment and then if you wanted 
to build an application on top of it once you've  
run the model you can then attach an application 
like a flask application for example to it  
and then you can then for example load that 
application and you know and get it google  
live so i'm gonna i'm not i'm gonna show you um 
all the steps to set up a um you know a virtual  
server where you can run this because you would 
not wanna run this on your own computer on your  
personal computer this is not gonna be possible 
if you look at some of the models they like the  
gp2 model the neo one if you look at this 1.3 
billion parameters in 2.7 it takes about 10 gigs  
of memory okay so it's gonna be very difficult 
to run this on your own uh private computer  
um you're gonna need a cloud server to do this all 
right so um i'll show you how to set that up with  
digitalocean and then after that there's a couple 
of things we need to install the prerequisites for  
um being able to run the pipeline you need to 
have a pie torch all right so i'll show you how  
to do that and obviously the transformers model um 
that we need to to get running then after that you  
know we're gonna be using um um these these models 
are we're gonna be using hugging face because uh  
you know um online um api um repository or you 
know whether you know a lot of companies sort of  
upload their models over here and you can you can 
have a look over there all the available models  
that you can work with so when i was talking about 
a text classification for example um there is tons  
and tons of text classification models here that 
you can actually use all right that you can have a  
look over there and see how many times they've 
been downloaded so if you like sort based on  
most downloads you can see the most popular ones 
obviously will be the ones that are downloaded the  
most and then you know you might want to use that 
for example so when it comes to text generation  
which is what we're interested in you can see 
all the text generation models available here  
um and you can see this is the most um downloaded 
one with over 20 million downloads and the next  
one is gpt2 with um on 12.5 and you can use 
whatever model you want you can figure out  
which one works better in all these models and you 
can use it so the one that i was telling you about  
um the the the 1.3 gpt neo models is this one 
over there so this is the 1.3 uh billion um  
parameter model it takes quite a bit of space 
you know and actually tried running it on  
on a droplet and it you know the memory ran 
out and i couldn't you know you have to get a  
bigger droplet to get a bigger memory you know so 
sometimes the model when you try to run it you'll  
see another and i'll show you and i'll demonstrate 
it to you when we get to that point that um the  
model is actually too big and the moment it 
runs out and the process just gets killed  
and you can't complete it so um you know if you 
wanna more complex tasks then i'll go for the 2.7  
billion um um you know model but then for this one 
you might want to um you know get a bigger droplet  
with with more memory maybe because you need 
like about 10 gigs of of memory to be able to run  
this um on it so you're gonna need a much bigger 
machine this is why you can't run this on your own  
machine but the good news is hacking face does 
provide an api as well all right so this is an  
alternative api to the open ai api all right so 
you can use um the hacking face api to access any  
of these models this means that you don't have 
to install the models in your personal computer  
i'll show you how to do that you can have a 
look at their pricing page and their pricing  
page is definitely less and cheaper than the 
open ai price you can see here you're only  
paying like nine dollars a month up and then 
you have like sort of like i think unlimited  
one million input characters i think over there 
and i don't know one million is quite a lot and  
um you can try this out and compare it but i mean 
it depends on your on your spec on the kind of  
app you want to build what i like about this api 
here even though you got to pay 9 million a dollar  
nine million dollars a month there isn't a lot of 
you know oversight management controls of what you  
can use the model for which is the challenge 
sometimes with open ai is that you're quite  
they police you quite a lot with what it is 
they allow you to use the model for so you  
have to fit within their use cases or else they 
don't allow your application to go live all right  
so over here you might have a little bit more 
freedom of what you can use the models for  
you know but of course the open ai models are 
much more advanced okay so um i must mention now  
that this can only be done on python obviously 
so um so the javascript guys sorry um you can't  
run a lot of these um you know um watching my 
code you can't run a lot of these um you know  
ai you know machine learning type functionalities 
on on on anything i mean you can run it on like  
java for example but like python is definitely 
um one of the best ones and and and it just works  
okay so at some point if you want to get into ai 
and data science you might have to really learn  
python i'm saying this because i'm going to get 
the comments of can we do this and can you please  
do the tutorial of this in javascript okay so no 
um this is this is going to be have to be done  
on on python all right so let's get started 
i've talked a lot given you a bit of background  
let's get started with our tutorial okay so the 
first step like in our in my notes over here is  
the prerequisites so i'm going to take you through 
the process of getting your or your server running  
so that you can be able to run these models okay 
so i've got a link in the description i'm going  
to put this link in the description but i've got 
the link in the notes as well you can just click  
on this link it'll take you to digitalocean and 
then you can um create a droplet over there right  
so i've got my digital ocean open already um here 
and um once you create an account um you can then  
um just go ahead and create a droplet okay so you 
click at the top of a day and you decide that you  
want a droplet so let's let's go there and see 
available droplets what i like about this ocean is  
they're very flexible you know so when you create 
a droplet you don't get charged immediately for  
the whole month like other service providers if i 
created a droplet and i and i decided that within  
10 days i don't want it anymore i can delete it 
and i'll only get charged for 10 days all right  
so they charge you per you know they charge you 
after you've used to the service and then they  
charge you for only how much you have used all 
right so um i'm gonna go for that and ubuntu  
um you can see over here you can select the 
different types of ubuntu that you want all right  
so i wanted the 20.04 the latest version you can 
choose any other operating system that you like  
but let's work with ubuntu 20.04 make sure that's 
selected and there's your cpus all right so memory  
optimize is obviously the better one if you wanted 
to work with the the 16 billion um gpt model so  
what i would do here um i think i showed you the 
sizes over there so let's see so if you wanted to  
work with this for example the the luther um gp2 
neo 2.7 billion which will give you better outputs  
and better results all right depending on what 
your use case is closed even better than all the  
old gpt2 but not as good as the latest gpt3 but 
it's probably the best available model out there  
that's open source all right so if you want for 
text generation specifically and if you wanted to  
automate text generation um this one would be the 
one that i want to go for and if you wanted to do  
that model you would want to go for something 
that's memory optimized and the cheapest one  
is is 80 a month um that you can select okay 
and you can see over there it's got two cpus  
and um it's got a 50 gigs ssd um whatever 
and um and it's got a memory of um of you  
know of of 16 gigs i think right so this 
will cover the 10 gig memory that you need  
for this model all right so i'm going to i'm going 
to use this okay i'm going to select this one  
because i'm going to delete the drop letters in 
some time but um let me let me let me select this  
one because the last time i used the basic one 
and i could not download the model and didn't work  
all right so so let's use the memory optimizer 
one and see and see what happens over there right  
and then once you once you've selected that um 
you go down here you're going to then select  
the location where the data is going to be saved 
this is just only important if you know for legal  
issues based on your you know whatever you're 
if you're going to be doing this for clients  
and stuff like that i always like to go for um you 
know a location that's closest to me with respect  
to time zones because then when they do their 
maintenance perhaps they'll be doing it at night  
even in my time zone okay so um then you can 
select whether you want a password login or an ssh  
key login all right so what we can do uh because 
i'm not going to go through the whole process of  
getting ssh keys for you uh perhaps we'll go for 
a password login because then i'll have to teach  
you how to do ssh keys if you're not sure how to 
do it but i must stress this right now very very  
important this is a very bad practice very very 
bad practice okay when you create a virtual server  
you do not want to access it via a password you 
want to access it via ssh keys that is the best  
way to do it okay and i always do it that way uh 
but because i can't take you through a process of  
getting ssh keys right now i'm going to just keep 
it with a password and you can see over there that  
they're already giving you a warning about this 
but because i'm going to delete this this this  
thing right now i'm just going to use a password 
and then i'm going to leave it at that all right
all right so what's the problem
must contain one number must contain 
a special character okay let's see
okay let's see cannot end with 
a number or a special character
all right so i'm going to write my password 
as i don't forget what i selected okay
okay let me enter it again just to 
make sure it's the correct one okay
what is wrong now
oh man that's not the one
there you go that's the password  
all right so once you've done that um enable 
backups that's recommended i don't mind monitoring
um collection monetary alerting i don't 
know i want to delete this right now so  
i don't mind about that and then over here just 
remember you want to give it a a different name  
so that you can um you know access it and if you 
have if you had a domain for example you might  
want to give it the same name as the domain that 
you're gonna be working with all right so once  
you've done that you're gonna select a project 
that you're gonna work with so i'm just gonna go  
through everything and make sure that everything 
is okay i'm using password um it's gonna be in  
amsterdam i'm selecting this eighty dollars um all 
right droplet which is memory optimized because  
we're doing ai functions and then you just go and 
create a droplet and um when you do that it is  
pretty it's gonna um all right go ahead and create 
a droplet for you so let me just close that and
where is my droplet now
okay there you go took a bit of time to create 
but just refresh the page i just moved from there  
to another one and i came back and you'll 
see your droplet appears over there right  
so once you've created your droplet the first then 
you can log into your droplet so i'm just going to  
copy the ip address and then i need to just find 
like a command line and then you can log into your  
into your droplet okay so um to log 
into your droplet the first time  
you are going to use if you are working from a mac 
you're going to just say ssh you need to log in as  
root because root is obviously the first root what 
user that's created on the on the droplet and then  
you just say root edge and you put in your droplet 
ip and then this will allow you to log in of  
course you'll have to enter your password in this 
case because you didn't actually input ssh keys  
but if you had input ssh key then you had them 
on your computer this would just be a seamless  
process and i've got a video in this channel that 
shows you how to get ssh keys and set up a droplet  
properly so watch that video to do things properly 
but if you want to use passwords then you can  
continue with with what i've got here all right so 
once you do that it will you can enter it it will  
ask this is a new droplet you're logging into this 
thing for the first time do you trust this this  
machine the reason why it's asking you this is 
because it's very dangerous if you don't know the  
the the thing that you're gonna the you know the 
ip that you're connecting to it'll um make your  
computer vulnerable to a text via that ip so i do 
trust the source i'm okay um and then i have to  
enter my password now because i'm using a password 
login um instead of of an ssh so let's do that
all right enter and then um 
password what did i do now
they entered the password wrong oh no oh no 
please don't tell me that i didn't get the  
password right because that's all it 
takes and i can't log into my droplet  
oh my gosh i'm here okay let's try again
oh no yes
oh okay got it all right so i've got the password 
the last time jesus bit scared because if if you  
got the password wrong then you might have to go 
through the process of trying to change that but  
anyway now i've logged into the droplet as user 
root okay so the next thing that you need to do  
is you need to create a different user all right 
so if you're doing this for the first time like  
oh why you have root can user no it's just how 
you can't run commands and do uh you know work  
on your droplet is root because route has got 
like sort of automated super user privileges  
and um you don't want to work on that um on that 
account you use that account basically to sort  
of like administrate and manage your droplet but 
everything else that you do in terms of creating  
applications um you know running code and things 
like that you have to create a different user for  
that and this would allow you as well if you're 
an organization you had like three different  
developers you'd be able to know who's doing what 
okay so you would create a specific user account  
for each and every of your developer and then 
give them access right and access permissions  
based on their role and the thing that they do and 
then all the files will also be saved under that  
user okay so this is the same with your machine 
when you have a macbook and you log into your  
macbook for the first time it asks you to create 
an actual user all right you can still call the  
user admin all right but you have to create a 
user so we need to we're doing the same thing  
as well on this droplet consider think a drop 
think of a droplet like a like a computer okay so  
the first thing that we're going to do now is to 
create a new user all right so inside of my notes  
that i've got over there i've got uh clear 
directions how to do that okay so the first  
thing that we're going to do to create a new user 
we're going to say add user and then we're going  
to put in the name of the user that we want to 
add all right so ed user scholar i'm going to call  
my user scholar all right and then we'll create a 
new user it will ask you for a password all right  
i've entered the password there and 
i'm going to enter the password again  
and then all of that is fine i'm just going to 
just click enter and say yes everything is correct  
and then just like that you've got a new 
user called uh scholar now the user will be  
created as default just a normal user they don't 
always have a root or super user permissions so  
you you gotta give them that if you want to be 
able to write pseudo commands on this machine  
with that user so we just modify the user um and 
add them into the sudo group okay so you just run  
that command because your route everything you 
run on root doesn't even ask you for a password  
every time because you are already a super user 
as root okay that is why you don't want to run  
functions um you don't want to um to do to run 
code the all right if you had a an ssh key created  
you would want to run this command what this would 
do was it would copy the ssh key from your um you  
know root account and co and and paste it into 
the scholar account so that you can log into  
scholar account as a um you know with the ssh 
keys okay so we didn't use ssh keys in this case  
we use the password arrive so all of you know 
what's required here is done we can just exit  
from this um from this machine and you'll see that 
it has taken me back to my macbook i've now logged  
out of that root it's called online which was the 
virtual server right because i want to work as a  
scholar so i need to ssh again all right so i need 
to now connect again but now connect as a user  
the new user that i've just created okay so i'm 
not going to ssh as a scholar at that vps all  
right so let's get that vps number again from 
here let's just copy that so now we are logging  
in as a new user that we've just created and um 
it's going to ask for the password now this is  
not the root password this is now the password 
i created when i created that new user and you  
can just enter it there and it's going to log me 
in and you'll see now i am now scholar at school  
online i have now logged in as a scholar user into 
school online virtual server pricing which i just  
created now data ocean so this is all you have to 
do to create and set up your vps or your virtual  
server now we're going to be able to now continue 
and run our code from this server all right so i  
like to always um create a a um mkdir i like to 
just create sort of like a folder to work from  
you know so i don't run on the root of the machine 
so i'm going to create a folder called development  
all right and i'm going to immediately um cd 
into that folder okay so i'm now in inside of  
the development folder and then here maybe i'll 
have multiple projects so i'm gonna have my first  
project i'm gonna call it gpt2 okay so i'm gonna 
create another directory that i'm gonna call gpt2  
all right and i'm gonna cd into that directory 
okay gpt2 and then um then this is where i'm gonna  
work from okay so i've created now you can see 
now i've got a folder gpu development lgbt tool  
right and before i do this you must know python 3 
is already pre-installed inside of digitalocean um  
virtual servers i don't know if you buy a 
server from someone else because what i've  
shown you here with digitalocean you can buy a 
virtual server from any any service provider okay  
but i i can't confirm that the other guys um you 
know what what what you know sort of operating  
system you're gonna get and if some of these 
things already pre-installed okay so i know  
that with a digital ocean for sure when you create 
a virtual server there um it does have python  
three already pre-installed okay to prove that i 
can just run python3 command from the command line  
and you'll see it will take me into the python um 
i'm now inside of the python 3 sort of like you  
know shell and i can actually then um you know 
run anything here you know i can say print my  
name whatever you know um scolo online all right 
this is a python command you know and it'll print  
it whatever you know so this is inside a python 
shell so you can see that so i'm going to exit  
out of the that python 3 is already pre-installed 
inside of i didn't do anything to install it but  
there's a couple of setup steps that you need 
to get done um to continue and i'm going to um  
now take you through to through a digital ocean 
tutorial because i actually still follow them  
all right even though i know exactly what i 
need to do some of the steps um they change very  
depending on the version of operating system that 
you're on okay so um if you go to digitalocean  
i'll also link this in the description below there 
is a tutorial for serving flask applications okay  
and um this tutorial is really good for setting 
up your python environment as well all right  
so i actually use this tutorial all the time all 
you've got to do at the top there is to change the  
operating system that you're on okay so depending 
on which ubuntu system you're on you just change  
that there because the steps sometimes are 
a bit different depending on the operating  
system that you're on okay and this is created 
specifically for digital ocean so because i'm on  
um ubuntu 20.04 that's the one i select and i'm 
just going to go through these steps and um and  
and follow them until i get done okay so the first 
one is obviously update um that one so let's um  
put in our password okay and then we'll go ahead 
and update um the packages and then you need to  
then run this one installs for you python 3peb 
and a whole lot of other things that you need  
to um to run python code all right and be 
able to create a virtual environment so  
um and then you can just say yes that's okay and 
then it will go ahead and install all of that for  
you so while it's busy doing that um we're gonna 
have to also install the virtual environment  
okay so this is a package that's gonna allow 
us to create virtual environment okay so that's  
still running a little bit let's give it like 
a second and then um we're gonna install that
okay so let's paste that in there python 
3 virtual environment i'm okay with that  
yes take up the space i bought quite 
a bit of a machine this time all right  
and then once we've done that let us um now create 
our project directory okay so i'm already inside  
of my project directory actually so i'm just going 
to run this command that allows me to create an  
actual virtual env all right so python 3.8 uh 
virtual env i wanna create i wanna call it gpt2  
all right env all right so let's call it gpt2 env 
and then we'll go ahead and create it you'll see  
if you list the directory you have this gpt to 
env over there right so to activate it as usual  
it's just source gpt to inv bin activate all right 
so let's activate that and now our environment is  
activated and we can get started okay so it took 
quite a bit of steps to get this running okay and  
you'll see a lot of tutorials online where they're 
just showing you once you're already on some  
server that's already created how to get started 
but if you really we're starting from scratch  
these are the steps you would need to follow just 
to be able to run those four lines of code okay  
so now that we've got our environment running we 
um we've installed python and all the tools we've  
got pip we've got everything going now you can 
actually run these lines of code okay so we're  
going to move from then i'm going to take it back 
to my nodes and you'll see the lines of code are  
actually very simple okay you just basically 
install pytorch you install transformers and  
then immediately you can start running your models 
okay this is very simple but before you can do all  
of these things you gotta be in the environment 
that you gotta be in the right environment okay  
so to install python i've got a link over there 
in the notes you can go to the link and it'll  
take you to a page like this and then um you can 
then um just um run this command over there right  
and this command actually you you know if you're 
inside of the virtual environment you don't need  
to use pip3 you'll see instead of pi torch um they 
say pip3 but this is if you're not installing this  
inside of the virtual environment i always like to 
work inside of a virtual environment so that i can  
separate my projects okay so because i'm inside 
of the original environment i need to just run pip  
not pip three okay so pip run all of that that 
it gives you and by the way um instead of the a  
pie torch website you need to select like which 
build you like which machine you're on and whether  
you're using paper what you're using to do the 
installation and whether you're on python or or  
java okay so you've gotta do all of those things 
and whether you're on a cpu so you gotta select  
you gotta do these pre-selections like if you 
were on you're working with conda for example  
you'll see that the command is different okay 
if you're installing from source you'll see  
that the command is different so we're gonna 
work with pip and when we and if you were on a  
windows you would select windows okay and 
then it will show you how to do it on window  
if you're on mac you would select mac and it will 
give you a different command okay so because we  
are on linux because now we are on the virtual 
private server that is why our command looks  
like this all right so just to clarify that okay 
so we are on linux and this is the command that  
we need to run inside of the virtual server so the 
command they gave you just have to make a bit of  
a change instead of pip3 you're just gonna say 
pip because you're inside of the virtual server  
and then you're gonna run it okay it's gonna 
take some time because it's gonna go and install  
a whole lot of libraries um uh you know to allow 
you to be able to work with pytorch um so that  
you can be able to run transformers okay so um 
just wait for it while it does the installation
so while it's doing that i'm going to go back 
to my notes the next um thing that you got to  
install is transformers all right so um you 
just run keep transfer install transformers  
and then i'm gonna paste that in there and it's 
gonna go and install transformers and i think  
that's a little bit faster to install transformers 
and that's um i think almost done all right  
so that's it that's done um we're good to go 
so inside of here i'm gonna create a python  
file all right so my python file is um um is 
gonna look like this all right so this is what  
the python file is to look like you're going to 
say from transformers import pipeline all right  
then you're going to say generate a text pipeline 
and then generator you know then you're going to  
run a pipeline and pick what model you wanna run 
with okay so we are using text generation but  
there are definitely different options and inside 
of my notes i've um sort of illustrate you know  
i've put notes for other things that you might 
wanna do okay but for today's tutorial we want to  
just do the text generation so you could want you 
could maybe they would there's there's models for  
uh you know uh you know classification there's 
models for language you know being able to do  
download language translation there's models for 
a lot of things okay and um you're gonna pick  
that the model that you want to use and to get an 
idea of the models that they've got i'll put this  
in the description below as well you know these 
are all the models that they've got you can use  
any one of these models and you can see you know 
anything from film mask because filmas now helps  
you to fill in like feeling the missing word that 
is those type of models questions and answering  
model summarization if you had a long text 
that you wanted to summarize you want to build  
on a web app for specific summarization you got 
models for that uh questions and answering text  
classification text classification is actually 
quite cool if you wanna like classify tweets  
i had a question they maybe will do a tutorial 
on this for a text classification all right um  
a token classification translation that's also 
very interesting if you wanted to build an online  
translator and i've seen a lot of guys 
building this kind of applications here okay  
and this is something you might not even need to 
use gpt-34 you know you might be able to get a  
free open source um sort of model over here the 
helsinki one works really well for uh you know  
trans for text you know for for text translation 
if you had you know maybe and you wanna do maybe  
translate your application you know and you 
could run it with a model in the background  
and you know you have your translation being shown 
in different languages i mean your application  
uh shown in different languages for anything you 
can build an online translator for example you can  
do a lot of with with the translation engine here 
so but today we are going to focus only on text  
generation okay and i wanted to show you the top 
model that appears for text generation is this one  
okay is the digital gpt2 and i can i you know 
just from uh playing around with these models  
i'm assuming the reason why it's the most commonly 
used or the one that appears the most is probably  
the most um effective that is the smallest okay 
because it's a small module you can like run it  
even on a small um you know vps the last vps that 
i tested this on was the basic six dollar gpu  
virtual server and you could run this model on it 
without issues okay the the really the best model  
is the gpt neo 2.7 bytes but this is quite huge 
and this one is the next best thing from there  
okay so i'm going to open this in a new window 
so i can copy this nicely this um 1.3 let me  
copy that day so in our models we're gonna try all 
of these all right so um let's put that in there  
all right and then let's copy the generator code 
all right and then at the end for text generation  
if you want to use that model not 
the 2.71 model you're gonna um
uh paste that okay so i'm gonna try the neo 1.3 
because i've installed a bigger machine this time  
and i'm going to try and see if this one works 
okay if it doesn't we'll go back to the disto gpt2  
because i'm assuming this will do a better job 
all right so um so what we're going to do is let's  
just start a python shell over here so you just 
say python it'll open a python shell over there  
and then um let's say from transformers let's 
import pipeline all right gonna go and import  
the model i mean the pipeline um uh library then 
from there we're gonna um load our model okay so  
when you run this command to load the model what 
happens it happens automatically in the background  
is that the you know the python code then 
downloads the model into your machine all right  
because you are going to now install the module in 
your machine and then you can use the model to run  
okay it will only download it once the first time 
you run it the next time you run it it does not  
download it every time okay so um i'm going to now 
download this model the 1.3 byte model um you'll  
see it takes a bit and you can see the download 
process happening in the background we've got a  
bigger virtual server this time so let's hope that 
we'll be able to run this um on memory because  
it's a smaller engine as well but um what's 
happening in the background is that it's it's  
downloading the model and this is the difference 
between use between doing something like this  
which is open source and downloading the 
model yourself and going and using an api  
uh for open ai the open ai api you don't download 
the model when you're using it you basically use  
a model that is sitting inside of their um 
virtual instead of their servers and you  
do an api call to that model and then that model 
is already sitting there and then it gives you a  
response what we're doing here although the 
module is pre-trained we are downloading it  
into our machine so every time we run a command 
now it's going to actually just run the command  
with the model downloaded on our machine this 
is why now we don't need any api keys we don't  
need to pay we don't need to even justify what 
we're using the thing for we don't have to have  
anywhere anybody check our application you know so 
that's the benefits of using an open source model  
is that you can basically you know do pretty much 
anything you want with it all right but obviously  
the downside like i've already mentioned is the 
limitations that yes um you can do anything you  
want but the model is not as great as the open 
as the gpt3 which is already trained on like way  
more parameters you can see 175 compared to you 
know 1.3 billion all right so you can read more  
on this model over here you can see the limitation 
the training data it tells you that this was 1.3  
billion um the training procedures it shows 
you the the intended use case and limitations  
okay um this model whatever you can read there and 
you can even read then how to go about using it so  
there is like you know um you know like like like 
like ideas on how you can go about using the model  
you can see the code and you can see you know 
some stuff in the and the intended use case i want  
to read this internet use case again because i 
didn't read it the last time preaching i mentioned  
a prompt okay so it generates text from 
a prompt okay so let's see okay so it's  
finished downloading good i'm happy with that 
um unless then um you know let's actually just  
copy this from over there right so then you 
gotta also the pipeline we've already done that  
so let's run the generator okay so this is 
the next line over there so after you've  
done the pipeline okay so i'm going to highlight 
that out because you don't need to run both of  
these if you're running that you don't need to run 
the other one okay so um let's do the the pipeline
um okay let's enter a prompt first okay so 
the prompt is crm software is also known as  
it can be used to do that okay so let's enter the 
prompt all right so we entered the prompt over  
there so once we've entered the prompt then we can 
um you know get the response from the generator  
okay generator uh get a response with the prompt 
and the maximum length i did must whatever in the  
sample and the temperature and all of that all 
right so let's let's run that line of code then  
and then um it's going to get the response and if 
you get if you get to this point with your virtual  
server without it uh bombing out and like killing 
the process you must know that the cpu that you  
selected is sufficient okay so the last time i 
ran this model um i tried to run this model on  
the cheaper virtual server um i didn't get this 
far i got it downloaded the first bit and then it  
killed the process because the model was just too 
big for the server to manage all right so this is  
why sometimes you end up using an api right if 
you don't use an api the you know the cost is  
that you're gonna have to get a much more powerful 
machine to run the model yourself on the machine  
okay and it takes also some time to to to do that 
generation you saw it was a couple of seconds  
while i was keeping you busy with the talking and 
but now you can actually get the response out okay  
so um so the response actually recorded 
under that variable so i'm just going to  
print it out so you can see what response 
we got from the from the machine all right  
um crm software is one is so here so here's 
here's what i gave you the prompt i gave it  
was crm software it's also known as customer 
relationship management software it can be used  
to manage and track all the customer interactions 
either in the form of an online database  
offline database the crm software is one of the 
best data for customer service it is a great tool  
for managing customer relations and you can 
improve your customer service and other time  
you can use human to track all your customer 
services and all the interactions in it okay so  
you can see that this definitely works much better 
i'm going to try and and get the same um i'm gonna  
try and run the same so let's actually clear 
this let's exit first okay let's exit out of this  
all right let's clear so that i can put everything 
in the top and you can see i'm gonna run the same  
prompt with this other model and show you how 
much better the the 1.3 billion models you can see  
the text i got from that made much more sense 
all right but if you try to to run it with  
this other one which is a smaller model for 
example if you've got a smaller virtual server  
you'll see that the response you get is not that 
great okay so i'm going to say um python again  
all right this time i'm gonna install uh from 
pipeline i'm gonna import that but then this time  
instead of running that model i'm gonna run this 
one okay i'm gonna generate around this one all  
right run uh the digital gpt2 this this model is 
the one that is mostly downloaded over here it's  
the most popular one because it's smaller okay 
it's a smaller model so let's run that one and  
you'll see it downloads much much faster because 
it's a smaller model right so let's download let's  
download then once we finish downloading that 
model we're gonna run the exact same prompt okay  
we're gonna run the exact same prompt and 
from the prompt we're gonna run the response
all right that's the response and it also 
works a little bit faster as well you'll see  
um it's already gotten the response back okay 
and if we print you'll see it just prints a lot  
of empty space okay um it just gave me back what i 
said crm software is also known it can be used to  
ensure customer information is being processed 
upgraded vendor customer relationships often  
sources of stress to customers most customers who 
receive marketing communication like you choose  
customers in order to you can see some of you some 
of the takes doesn't even make sense all right  
like i don't even understand how this is connected 
but the gp but the 1.3 billion one was much much  
better all right so i'm going to exit out of 
this all right i'm going to clear that all right  
and let's let's play with this a little bit all 
right let's get it let's get like an apple iphone
apple iphone let's use that prompt okay 
so let's let's then run this as an actual  
um python file all right so i'm going to say 
nano uh python no no not nano gpt2 dot py gpt
nano gpt2.p1 so it's gonna open a text 
editor and i'm actually gonna just copy  
all of this in there all right so 
i want to run the 1.3 billion one  
so let's delete the other one so we don't get 
confused all right so we import the pipeline we  
get the generator we get the prompt this prompt is 
the one that goes in there inside of the generator  
and then we print the generated text all right 
let's do that let's paste all of that in here  
and then let's close and then let's just run 
python gpt2.p1 i just wanted to show you that we  
we did only download this one so the next time 
it runs this code on the same virtual server  
it's not going to try and download the model again 
because it already downloaded it the last time  
it's just running it off the downloaded model 
it takes time because it's such a huge model  
it's 1.3 billion um sort of like you know um 
variables or you know that was trained on so  
it takes a bit of time to get the result 
out so let's just wait for it there you go
when you see this it means it's 
generating the stuff it's working
she's just taking quite a bit of time
okie dokie finally okay that took quite a bit 
of time and if you wanted to build an online  
application this amount of waiting period would 
not be acceptable i can tell you that already okay  
so if you wanted to run this in your like if you 
wanted to run your own application and use gpt2  
or using or use a neo i suppose this is 
why they've got the api available all right  
so instead of hugging face you can um you 
know go into their api so if you go into their  
um you know a login you can log in and create an 
account you can have a look at their pricing i  
think i opened that pricing page earlier on and i 
think you can actually access this for free okay  
you can get it for free for up to like 30k input 
characters and some support so there is some free  
version available for limited use okay and then 
if you want to get more use and you especially  
if you want to get the inference api all right 
you're gonna have to pay this nine dollars a month  
so this api will allow you to do this without 
having to download the morrow and and wait you  
know so this api is like 10 times faster and it 
gives maybe a response time of closer to what you  
get with open ai all right but um it's cheaper and 
again the only reason you want to use this over  
open ai in my opinion is if i've got a use case 
that i know would never be approved by open ai all  
right but if the pricing is not that much cheaper 
to be honest um if you go to use use case that was  
approved by open ai i would just rather use that 
but if i've got my own use case like i want to do  
automated tweeting for example then i'd rather pay 
this nine dollars a month and use the open source  
api okay so let's read what it gave us okay the 
apple iphone was the first smartphone manufactured  
by apple ink it was released in september 
nine iphone was one of the upper first devices  
i mean this is amazing like this is actually not 
so bad you know depending on the use case this  
is not so bad really and if you didn't have a 
problem with lagging times and you could like  
run this in the background and this was not 
a real-time application you know and you were  
generating tweets for example if you're generating 
tweets on autumn an automated tweet generator  
you wouldn't worry about response time because it 
would be running like maybe on like a scheduler  
okay so you could like wait the little one minute 
that it takes to get the tweet back this would be  
a perfect use case for that and perhaps in the 
future i'll do a tutorial on that where you can  
generate automated tweets um from gpt2 and then um 
you can run it with a you know twitter api version  
two and just you know tweet automatically but i 
think twitter will also not approve that use case  
if it gets to an approval stage because um twitter 
would not want you to be generating automated  
tweets as well on their platform with a bot 
anyway thank you guys for watching this tutorial  
the next steps for you to do which i'm not going 
to cover in this video and please don't ask me in  
the comments to cover it because i'm telling you 
now that i will not cover it but i'm going to show  
you how to do that okay you might want to then 
build an application around this thing all right  
because what's the point of generating content 
on the command line okay so what you want maybe  
is to have a front end where somebody can input 
um the prompt and then when they finish inputting  
the prompt it returns the response okay and i've 
done a lot of these tutorials guys on my youtube  
channel where i've built in a flask application um 
and within the flask application you can see the  
input and the output so just watch that tutorial 
it's in this um video series with um gpt 3 where  
um you know you can get the prompt via a form 
from the flask application and then you can get  
the form submitting um the data directly to a um 
you know to the to the view function and then from  
the view function you then include a so you can 
put all of this inside of a um you know generate
all right you can put this inside of a function 
like that and then you enter the prompt from  
there all right and then instead of now um 
entering the prompt manually you enter it  
from the function and then you return this all 
right okay you return that so this returns the  
response generated text okay so you could do that 
then you don't have to put it inside of brackets  
you can just say return response at zero generator 
takes and then this function over here you would  
run it inside of a python flask application 
so if you go into the python flask application  
you would have a root that says this okay so 
you'd have a form or something like that and  
then you would run that function with the prompt 
you know so um have a look at the previous um  
tutorials i've done showing you how to do that 
then somebody can submit a form then from the  
form the post information you get the prompt you 
run that and then you return you know um answer is  
equals to this and then you then show this to 
the front end and then you display the answer  
um that way all right so i'm not going to cover 
that because running out of time i wanted this  
to be less than an hour this time and i'm already 
on 50 minutes you can do something like that so  
watch our previous tutorial especially the 
one where i show you how to do an automated  
content generator but that's using gpt2 model 
i mean gpt3 model apis instead now that place  
where you had the gpt3 model api you just replace 
that function with this function okay that part  
of the tutorial and just like that you're using 
gpt2 instead and it's a free um you know gpt neo  
um you know a function where you don't have to 
go through all the approvals and all the stuff  
that goes with using the other api all right so 
thank you guys for watching i think i'm going to  
end this tutorial here please feel free to ask 
questions in the description below i will link  
all of the stuff that i've demonstrated here on 
the description specifically this written tutorial  
where you can go and follow the steps that i have 
shown to you here see you guys again next week