I found [this page (hyper-link)], and the suggestion is that the naming in the bmm file might not be matching what you have in your design hierarchy.
Updating your bmm file with the correct naming would resolve the issue!
The inner query counts the number of reported/not reported per user and BMM, BYYYY, DMM, DYYYY.
There is no (single) source for bmm per se.
bmm is declared in [aten\src\ATen\native\native_functions.yaml (hyper-link)]:
The implementations (like bmm_cpu) are to be found in aten\src\ATen\native\LinearAlgebra.cpp.
Notice in function declaration of function contains(), there uses bmm object, which should be undefined at the time this function body is being parsed.
It's just a free variable with the name bmm.
Why can we use bmm and its method treeLookup before they are defined?
Also: If this is your BMM layer then one suggestion: Use correct business names and designations!
Thus, we need torch.bmm on these two tensors.
while @wasiahmad is right about the general implementation of seq2seq, in the mentioned tutorial there's no batch (B=1), and the bmm is just over-engineering and can be safely replaced with matmul with the exact same model quality and performance.
The trace of the first element would return the lowest difference in time, which in this case would be bmm.
This code will not work as you expect because you are redefining the changeColor function (and colors array) 3 times, so the last function declaration will overwrite the first ones: this is why your code only works well for the last cell (the one whose id is bmm-03).
