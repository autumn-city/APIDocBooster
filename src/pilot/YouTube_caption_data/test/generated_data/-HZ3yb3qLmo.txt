[Music]
it really is my pleasure today to be
talking
about this uh this very interesting
field and it's
at least that's that's what many are
thinking nowadays
about learning and differential
equations
so to preface this i'd like to say that
learning machine learning and
differential equations have a very long
history together
in many aspects modeling optimization
today we're going to be taking a
specific perspective a a very new
perspective
indeed and that's what is being called
continuous depth
learning for a specific reason that
we'll see
what was already introduced before so
the schedule for today
is as follows um it will be a
multi-multi-step
kind of presentation um
i will give you a little bit of
background on what continuous depth uh
learning means what the objectives are
uh and why we should care as a community
um a lot of a lot of this content will
be
relying on will be focused on neural
ordinary differential equations
which are not everything they're a core
component of the field
and they're good instructive first step
into the field
since it's a very clean very simple way
to
say a way without too many assumptions
to merge
differential equations and neural
networks
in particular merging a very specific
type of differential equation which is
arguably
the simplest one the most well-behaved
ones the ordinary differential equation
we'll then take a look at some of the
more recent works including
some of our papers um going beyond all
these maybe to other classical
differential equations
all this would be taking around 35 to 40
minutes
um hopefully and then we look at
torstein library that i know
who developed with some collaborators
all dedicated
to neural differential equations and
continue step learning uh we'll show you
what is uh with what is possible
in around 10 minutes and how you can
change some of the templates for your
own applications
and then we'll finish with uh with the q
a so i'd like to say that um
you won't see aside from the code the
live code walkthrough you won't see as
many
discussions of results and applications
and trying to give you
as broad an overview as possible with
enough technical content
that with the help of torch dying
tutorials as well as
one or two references you'll be able to
then uh go on your own
and really focus on the specific
applications that you care about be it
finance control
or what have you okay so continuous step
framework
um we are somewhere around the
intersection between many fields
deep learning machine learning dynamical
systems and thus differential equations
what is the what is the object the final
objective
we'd like to have the same type of types
of successes that we've had
in other traditional machine learning
fields such as computer vision and
natural language processing
but that haven't had the same type of
widespread use yet
so something like physics the broader
sciences
medicine finance that have been you know
where some of the other methods
classical methods have been applied but
they haven't
yet reached mainstream usage or
deployment
to do this we need to go beyond what we
what we know
deep learning models to be and some of
the people in this field often refer to
this
symbiotic relationship between deep
learning and dynamical systems
indeed some people are working on on one
direction
they're working on injecting more deep
learning and machine learning
into methods to help dynamical system
research differential equation
research scientific machine learning
stuff like improving
numerical methods with neural networks
for example
some other people are working on the
other interaction importing some of the
the mathematical tools and knowledge
which have been developed for the
the past two centuries almost longer
dynamical systems optimal control to
help in more traditional
machine learning tasks so to start
um let's dive a little bit more into the
details
and let's see how we can justify the
formulation of neurology
what the object is and how we can get
there so there's there's several ways to
get to the neural d formulation we'll
take the
say the original path uh of the seminal
paper
that uh i'm sure many of you have heard
of by chain at all
one best paper was one of the four best
papers at
eureps 2018 and the argument was as
follows
so let's say let's suppose to have a
discrete dynamical system of this type
which is indeed a residual network so
the layer to layer dynamics of the
residual network where you have
the so-called skip connection where you
pass through
a parameterized nonlinear function your
residual block and then you add it back
to your input
now if you squint at this um you
introduce
a sort of a phantom term here that has
been simplified away equal to one
uh if you squinted this rearrange some
of the terms you see that it
looks like a forward euler
discretization for those of you that
have a little bit of background in
numerical methods or
you remember calculus uh it's sort of
the definition of a forward derivative
right but we're missing the limit here
so it's sort of a
rough approximation very rough
approximation of the derivative
uh in s now if you take this this
quantity here
you put it here um
we're almost almost there in the sense
that we need to make some some
considerations
first off s here um i'm using us for a
very specific reason
uh more traditional you you do something
like k
uh to index uh ak integer two to index
your
your layer layer one layer two layer
three now here s becomes a continuous
a real scalar value
and that's why it's called continuous
step learning so you're still
sort of indexing your layers but you're
doing it
an infinite amount of times potentially
so that's the first difference
second uh second thing that's missing is
an interface with the data so we're
trying to do to do learning trying to
achieve some tasks
to to solve some tasks so we need an
interface with the external data
and the data for neologis is nothing
more than the initial condition
of this whole thing which is nothing
more than
an initial value problem so it's a
problem that needs to be solved
and this is where the numerical methods
come in right um
if you add some more bells and whistles
this is the generalized formulation that
you see
in our wallpaper at
new rips you may see some other things
that help relieve some of the
limitations that we'll briefly
see later something
that's very useful for example is having
parameters
varying in depth
now this is where having the the s
depth variable as a real really comes
into play right
even in your residual networks you could
think of the parameter tensors
for each residual block as being a
function
taking the layer index and spitting out
your parameter tensor
you could think of it this way and
indeed you can think of this
let me open the chat the other one okay
you can think of it here even here in
the same
same way um indeed here you have a
complication
that you have you would have infinitely
many layers and so if you have
non-constant parameters that's a problem
that we'll see how to tackle
something else you can you could have is
a variable amount of depth a variable
amount of layers in some sense so a
learnable integration bound
for the initial value problem you could
have some embedding
encoding and decoding steps to go from
your data space to your
space where f lives yeah you can have
some
additional conditioning on the vector
field
so the point here is f f is everything
f is where your d um interfaces with
neural networks f is often a neural
network parameterized by theta
it doesn't have to be a neural network
it can be anything
regarding process that has been done
even non-non-parametric
function approximators can really be
anything the point here is that
um by taking this view
we're um we're transforming learning
into
um a different type of problem instead
of learning the map
directly that shapes the data in some
way the morphs
the data in some way we're learning an
underlying vector field that lives in in
some space
and i'll give you some more intuition
later on this is a good point to to stop
and really
develop an intuition uh which will then
help
pretty much everywhere in this field so
the solution of an ivp
simply takes this this form
you have your input data you map it to
your initial condition
for example here now the problem is
indeed here
solving for the integral of the vector
in the vector field
which will draw this uh this squiggly
line
then taking the final point here you you
can map it back
with another neural network and you have
your solution
of the of the ivp now
um this is i think another very useful
um thing to look at
so what we are learning is a vector
field that is
a vector valued function which takes
so we're living in some space of fixed
dimension we can change our
dimension um so there's no
you know and then linear going from 10
to 15 to 10 to
four across the neural d has to be fixed
sort of like a residual
network the vector field
has to be shaped so the vector field is
parameterized you see
it evolves both across training
iterations as well as
for depth varying parameters also varies
across
integration and it's it will learn to be
shaped to pull data in certain ways that
help for the task attend in this case
you're looking at the binary
classification problem we're trying to
separate
inner and outer circle and you see that
the vector field
pulls the the inner points apart even
learns to to flip it
to flip some of the the the vector field
uh vectors
to to to better help downstream layers
achieve their task
so this is uh all the intuition that's
really required to understand what is
different about
neurologists i'd like to say that
there's like
i mentioned before there's a long
history between differential equations
and machine learning
even the idea of neurology itself some
some would say the idea was in the air
already indeed if you check some of the
work by mathematician y and e
and some others you see that you find um
some of these formalizations
available as well as the idea of
normalizing flow continuous thermalizing
flow as a link to optimal transport for
those of you that
are familiar with the normalizing flows
and there's also
an even older line of work on continuous
time so the concept of depth and time is
interesting to
to keep in mind there's a difference the
reason why
we use depth is that for example in a
classification task
where we're fixed in time there's no
time evolving
depth takes more of a space connotation
so evolving through
the depth the space of the network you
can view time
if you have a time series like none then
you can have the data
time as time the data dimensionless time
or
some other references you'll see the
training iterations this time
so the vector field evolves in time but
solving on the vector field
will be a propagation through depth of
the network
okay so why should we why should we
bother with this there's many ways
there's many aspects
uh many reasons for this i'm gonna be
giving you some
um maybe some some others will come up
in the q a
so we'll start with um say that the
reason that
many think was mined
in neural d paper getting really popular
with this idea of having
constant memory gradients parameter
gradients
to to optimize in standard deep learning
fashion
and constant in depth so in number of
layers on integration depth
we don't have any any overhead
you have advantages in learning and
control it's a good prior
knowledge to to insert if you know
you're controlling the robot
you know you want to use an od you even
know a specific form of that you might
want to use you might want to use an
euler logarithm formulation
you might want to use a second order
system if it's mechanical
etc similarly for forecasting if you
want to do a stock price for casting
you might want to use a neural sd you
might have some prior knowledge on
on on all kinds of parameters that you
can you can include
you can do cheap density estimation you
can do other other things
now there's also disadvantages that are
important to keep in mind
so neural these are less expressive
unless you you're careful about how you
design your model
than equivalent or analog discrete
models they have more computer
requirements
because it's no longer but only about
the model but it's about the model and
the solver
we see this later with the hypersolder
idea
it's new so there's there's different
techniques and mathematical
tools to develop to use in order to
to fully understand and implement even
implement
on a practical level these models and
and thus it's less accessible
although i hope that the talk today will
be
a small remedy for the last the last
disadvantage
so we start with the perhaps this is the
most technically involved section
i don't expect all of you to understand
all the details unless you have prior
background on either optimal control or
really excellent background on on ods
i'm going to be giving you a proof
sketch of some of the intuitions
hopefully
at least you have an idea of how
training is performed
for these models so
let's suppose to have a loss function of
this type that has two terms
a terminal a loss term or for those of
you from control
terminal cost um we assume to have
um maybe some downstream layers right so
this is the solution of the od
we assume to have the neural d
so now if you if you look at this this
is and if you're also familiar with
optimal control this is
the type of loss that you see in control
and if you want to minimize this
what you're ending up with is
an optimal control problem
of this type right so the problem now i
said
the dod itself becomes a constraint
of of the problem trying to minimize
this across a mini batch
of size k where k indexes the
the samples in the of data and then we
have our
other conditions or other boundary
constraints right here so
we solve this in some situations we can
indeed solve this analytically
but we need some assumptions on on f the
dynamics and the constraint
and in this case where the vector field
itself is is
a neural network a really complicated
function it's it's impossible to find an
analytic solution
which means we're going to approximate a
solution
uh as good a solution as we can find so
it will be a non-global
optimum solution with k indescent an
iterative procedure
and the parameters so our task is
finding these
gradients with respect to the parameters
as with
any other learning task we have two
options
two umbrella options one is by
propagating through the discretization
of
dod the solution of the initial value
problem
which would be doable right no no
problem we will choose a numerical
solver like
the euler scheme that we saw before
which approximates this continuous
solution with a limited number of steps
uh this is what you will often do in
implementation but it's not the actual
gradient
uh with respect through the solution of
the audi
second option is you have to find a way
to to do this
in closed form analytically for the
gradients
with respect to theta of the loss with
respect to theta
and the problem of using uh your
traditional chain rule
is this integral right here that poses
problems
so here comes the the joint method comes
to the rescue
and um so the way it works
is the intuition is we introduce an
additional
set of variables echo state a vector of
lagrangian multipliers
so we're applying some ideas from the
calculus of variations
and we're solving another od by solving
a final value problem
because we have a boundary condition at
the end of the network the final depth
and we're running it backward in such a
way
so that the a's will be defined in such
a way that we have a specific
relationship
that defines our gradients in particular
this is what
it looks like so for the simplest case
where parameters are fixed in depth
um you have your optimal control problem
uh this is your final value problem a is
your vector your cost state vector your
vector of lagrangian multipliers
depending on
what your say perspective is on this
type of approach
this is what it is and you you're
essentially saying
if my a starts so the initial the final
value but
the initial value for the backward d is
the gradient of this
terminal loss with respect to the
solution and
it evolves according to this
relationship here then i have this
i have this closed form expression for
the gradients
so the proof sketch now um
fully diving deep into into this i will
require another
20 30 minutes um
i will give you a proof sketch to give
to get it and get you thinking about
maybe you have some other perspectives
that you can connect to this some other
proofs some other ideas that you've seen
if you're really serious into
um doing research in this field or
you're just
interested you know getting your hands
dirty
i suggest uh walking through this proof
uh yourself it's
maybe ten lines to mostly rearranging
terms um
we have a good reference i think in our
new rips paper in the appendix
very compact proof and the proof goes as
follows
um it's a few steps conceptual steps
first you introduce
lagander multipliers so
um you you have to introduce a perturbed
version of the loss right in in in this
way as in traditional uh
calculus of variation your lagrange
multipliers will be
weighting um your um
uh the um the amount
uh that you're not respecting your your
condition your constraint this is the if
you put an equal here
you recall this is the dynamics
constraint of the optimal control
problem
l is your total loss so you're
introducing a perturbed version
of l uh then you're computing the
derivative of l
with respect to the parameters as a
function of a right you you flip this to
the left side and then
you'll do some a little bit of
integration by parts and there's a
couple of steps
um you get you got a function of a of
this um
laganja multiplier vector and then you
pause it
you say if a satisfies the final final
value problem
and that we saw before then you can
simplify a lot of terms away and you get
this this uh
so what you calculated in the second
step simplifies in several ways and you
get this this
form here which is easy to compute easy
enough to compute in
in your preferred deep learning
frameworks
so this is the exact gradients what do
we do we don't need to store anything
for this what do we do in case the
parameters are
a function of s itself so they're not
they're not constants
well in that case uh you need to go a
little bit beyond
what you saw before this is one of um
also in the appendix of
one of our newest papers um
you need to make some assumptions to
simplify the proof a couple of key
points
in that the function theta of s needs to
belong to
needs to be an square integral
integrable function
that comes into play we are simplifying
with the dirac delta if you're
interested in the details but you see
that this is exactly the same you just
change here you have a derivative in
function space it's called that
derivative function space which is
impossible or very difficult to compute
i should say
so you need to introduce another
discretization another approximation of
the problem
to compute this to actually compute this
and implement this
there's two ways two main ways to do
this you can discretize
in depth so in s
that means you have parameters that are
piecewise constant
and in that in that case we saw before
you have just many of the same problem
so before so you know exactly how to
compute the gradients
or you can discretize in function space
meaning
you don't consider all square integrable
functions you
you choose a subset of them that can be
expressed as a linear combination
the alpha j's of
some eigen functions you choose an eigen
basis a function that's that's uh
could be fourier harmonics could be
polynomials chebyshev polynomials and
then you you
you turn this into the learning of these
alphas that combine
your your eigenfunctions and this is
what it looks like for a binary
classification problem you have
a piecewise constant parameter so you
might have a polynomial
discretization so again this doesn't
look discrete it's discrete in the space
of
functions so it's less expressing the
space of functions
but it's it's continuous in in depth
right here
and if you if you use vanilla neural ds
you would have constant
functions here okay
so let's move along a little bit
um i think to here
um so there's a lot more to say about
nero these
it's arguably one of the hottest
subfields now in
deep learning at least in some key
conferences and for good reason
like there's um many applications are
pretty much every week there's a new
paper exploring a new application and
you know it's it's an attractive way to
to impose your prior knowledge of a
model
why should we do reinforcement learning
with rnn
uh surrogate models when we can we know
we know we're controlling a pendulum for
example we know exactly what
shape the od has even if we don't know
every parameter we know more or less you
know
might know it's conservative we might
know so it's
in that sense it's good what are the
downsides
to downsides it's there's many that we
saw before the greatest one that's
currently
slowing the field down is the fact that
these are slow slow
for inference and um for training um
the problem is is related to to their
influence speed
uh in terms of training iterations um
they're often better than
corresponding analog discrete models
it's just that to do one
inference pass it takes longer if you
need to choose a solver you need to
choose the correct solver
you need to ensure that the solution is
close enough and
it can be difficult something that
people um
start thinking about is regularization
techniques for the vector field
and it's a it's a strange regularization
uh
perspective and that we're trying to
make the vector field easier to solve
for usually adaptive step solvers so
we're trying to make the vector field
less nonlinear less um say
um more well-behaved
so that it's easier to solve but that in
some in some perspective it's also
making
us putting some constraints on the
expressivity of the model itself
similar to you know your l2 l1
regularization
but more in indirect traps now what the
problem is
with with these approaches is that you
can't always regularize the
vector field so if you're doing control
and you have a partial model
of your uh robotic arm there's nothing
you can do to regularize the dynamics
of your uh of your robot you know
they're what they are and often ugly
um so this is not the answer going
forward probably won't be the answer for
all applications it's pretty good for
purely machine learning applications
where you don't have any any any other
prior uh component of the od or the st
or what have you so what we
would like then is to explore the
connection with solvers
like instead of taking solvers as
another
black box component we're just importing
into into
our field we want to to look at them as
as design
components as well so how to make this
interplay better how to understand it
better
so very quick primer because we don't
have a lot of time on
od solvers explicit of these solvers so
we saw the euler
forward method um you're just iterating
uh through
the integral to approximate it as well
as you can right so you're choosing some
points on your on your continuous
solution
um your design choices are your your
step size
um your map fee so for euler
um of psi should say um
for euler it's simply the vector field
evaluated at the other point for other
solvers such as methods which are really
popular
it's a combination of
various things the the quickest way the
most complete way you can characterize
the method
is by their butcher tableau coefficients
these are coefficients that are
collected in a certain way displayed in
a certain way
there's a matrix a and there's two
vector
of coefficients and these tell you how
you you
combine certain stage evaluations of the
solver
they're found in very specific ways so
the field of numerical analysis
is often this is what
a lot of it is trying to improve trying
to find better coefficients
by solving different optimization
problems putting different constraints
on the type of solver you want
you want to get better coefficients and
different solvers
have different properties of course this
is only a very small fraction there's
multi multi-step solver there's a
predictor character schemes adaptive
step
in place it etc but this is this is uh
this will do for the
the discussion so the upper solder idea
what we would like to shine light on is
the fact that you can discretize in your
od
uh you you need to discretize your id to
solve solve it
we'd like to have a faster neural d in
that
the number of discretization steps for
an accurate solution
needs to be minimized so
how should we or should we do this a way
is to take the solver
a p p order solver which means
we're doing p roughly speaking there's
some technicalities involved you're
doing p evaluations of the vector field
so if the vector field is a
10 layer in your network you want to
minimize that
as much as possible for one step of of
your approximation your discretization
you're doing
many evaluations many forward passes of
the
vector field the neural network so you
want to take a base solver pith order
and you want to make it better by
introducing a learning component
and hypersolver network so we can
collect our solver this
whole uh combination the app resolver is
trained on on local truncation residuals
so you're you're looking at your
discretization
of the base solver and then at each
point you're comparing the step
that would be taken by the solver and
one taken by
a really accurate solver or the actual
ground truth solution if you have it
available
if you do this so you solve this this
supervised learning problem for g
and you have this better bound
on the local truncation error which is
better than
um your your this is the step size by
the way
you would have an epsilon to the p for
the pith order solve when instead you
have a delta
epsilon to the p plus one where delta if
delta is the
say the approximation capability like
your hypersolver network
uh if you train it correctly will be an
absolute will be a delta approximator
where delta is hopefully much smaller
than one so you have a better um
a better uh bound here um
this is a good reference if you'd like
to have a clearer picture of how
you can do this with your ods and
you compare this with other solvers even
higher order servers
so say we have an ipad euler
variant so it's a it's a first order
method with a learning
component to approximate second order
residuals you are more competitive than
your your base solver but also higher
order methods and here you're looking at
first row you're looking at amnesty
results for a new lod image
classification
cipher 10 you're looking at the solution
error average percentage error on the
actual solution you don't care about
about the task
and here you're looking at test
classification accuracy right
so you're training with an adaptive step
solver that's really accurate
and then you you're evaluating how much
you're losing by then
speeding up for inference later on like
deployment or
or your your needs later on once it's
trained
i'd like to stress this is once it it's
trained we're looking at how you you
could use this also for for a training
so there's more
technicalities involved but you like to
have a discretization that preserves as
much as possible of
solution accuracy and task accuracy
something also interesting um i quickly
mentioned is that you can
generalize across base solvers without
fine tuning
so you if you if you consider a second
order
second order family of solver explicit
solvers
uh it turns out there's a there's such a
thing as a planetarized
um family of solvers so you can tune
this scalar value to get
potentially an infinite number of
solvers if you if you train your wrapper
solver
with alpha 0.5 as it's it's it's base
solver
and then you evaluate without fine
tuning against the equivalent solver you
you see that it doesn't really need
any fine tuning to preserve on the same
pareto efficiency
there's more to say that there's more
results we hope
[Music]
this is just the beginning but something
that's really exciting
is that we see this as
as a link or as a as a similar
way in which nlp models natural language
processing models
have been successfully pre-trained
on large corpuses of data for better
performance
we see this as something similar for
neologies in that you you
you might have a general hyper solver
that's pre-trained on a large corpus of
dynamics
or fixed dimension for example and then
you you can use this to train and
inferno all these neural sds so sort of
a pre-trained uh
large numerical methods not too large
though because there's uh
there's another head all right so
very quickly some uh something to white
your appetite if you
want to go beyond neurods you don't
think these are interesting
i know many of you are into finance um i
also had a little bit of experience in
finance
and this is one of the questions we get
the most
are neural sd is used in finance
can you expand your support in your sds
so universities you can already play
with them in turnstine or library
and pretty much everything i've said so
far applies to them as well
in terms of training their joint
training holds
also for them as well pretty much the
same
the same formulation
[Music]
we have this is a very active field of
research
and we expect a fairly large impact on
finance as more
uh experts in domain experts will uh
start exploring with these
graphs so data as graphs is pretty much
ubiquitous
you can you can have neural d's and
graphs it's called neuralgids
where you have now a vector field that's
on a graph so you can use your graph
neural network layers as
the underlying vector field
where you can evolve for example your
your node feature matrix
see if you if you have a sequence of
graphs
you might want to have something like an
rnn
make a mix of another and the neural d
where you evolve your node features in
between observation times and then
you incorporate with an rnm cell the
equivalent of a graph and an m
you incorporate your graph information
into a different space and then you flow
from then on this is also a new new
field of research there is already
attempts with
stochastic so neural graph stochastic
differential equations
um if you want a true continuous version
of rnns
you can have a full solve so if your
your data
is not just an initial condition but
it's a time series for example and you
don't want to have an hybrid between
you can add an n cell little stm cell
and a neural d
in between if you want to solve
everything with one
od solve for example you can look at
control differential equations where you
can for example interpolate your data
and you can you can condition the
vector field on this interpolation you
have different values here
affecting the vector field this roughly
the theory of control differential
equations and also rough differential
equations if you're familiar
that extends to the stochastic case is
um really fantastic
as um it's a way to to tie your
intuitions together
once you start playing with these
objects
so what you have um
you know you you have a you would have
an
integration on on time or depth but you
also have other driving signals
so for nst you you'd have your brand in
motion but here you can have other
objects like an interpolation of data or
you might have a
also a stochastic driving signal that's
nothing like
a brand-new motion really opens up your
creativity okay so i think we're um
reaching the end so we'll look um
i think i'll be really quick with the
code but i'll be happy to to
answer on slack so we have a really
active sort of active slack but i really
encourage you to join we have around 40
people right now
a lot of researchers in this space that
you might know
are present if you have any
implementation problems or any ideas
feel free to join so this is what some
of the code will see
now looks like these are some of the
other ideas um
that are still working progress there's
a lot more it's really opening up
and i expect a bigger and bigger
percentage of ai conferences next year
to be
about continuous depth learning this is
our open research group
again feel free to contact me
anywhere but also on slack
these again some some references uh i
maintain a repo with
a lot of the latest papers on your lods
and your differential equations
uh this is our link to thursday
um maybe i'll share the slides later and
uh our hooks can uh
or i can share some of these things
later on
all right so now one moment uh
we'll take a look at the code and then
we'll do some q a
okay this is the fun part i know for
many of you so i hope
we can do it justice
okay so i'll be a bit brief because i
really i really want to hear your
questions and
talk to you about this um okay
so there won't be any live coding
because we don't have time
i want to show you a few things you can
do so
we talked about neural ds for a while
let's see how it's like to train one on
a binary classification task
uh this is just a training loop um we're
using python's lightning which i
greatly um recommend it's a way to
reduce your boilerplate
but this is just a training loop um so
again i'm assuming you're familiar with
uh
by torch or at least tensorflow um to
follow
otherwise it's gonna be confusing for
five minutes i apologize
okay let's say we have a vector field um
that's just a very simple
[Music]
just a very simple
mlp of this type right very shallow
you can define a neural d or a neural d
object
under both okay as follows you have a
bunch of
options to to choose this is one of the
core
classes of torstein but we have one for
sds as well which we'll see later
and there's going to be more so what
you do then you can choose between a
joint and an autograd to back propagate
through
you can you can simply uh train right
there's nothing
uh there's nothing mystifying about this
i want to show you how the flows look
and then i also want to show you
um the difference if we use a depth
varying
version both in convergence as well as
the actual flows okay
so with the neural d object you can uh
construct the flow at a certain
set of points right so
span is simply collection of points in
depth where you want to evaluate your
flow and this is what the two dimensions
look because this is a two-dimensional
classification problem and this is what
it looks like in the state space so the
two dimensions against each other right
so this is the initial condition we're
trying to pull them apart as you saw
before
now what if you want to use um depth
laying parameters well it's really
simple here
we have a variety of um
eigen eigen bases you can choose
chebyshev polynomials
rbf radial basis functions etc
it looks exactly the same this is also
very useful a trick
where you you can include a dependency
on the depth variable
itself an explicit dependency what this
will do it will concatenate along
this dimension here so this is an mlp so
we'll just be
using linear layers with the first
dimension being a batch size
we'll be concatenating s along the the
first dimension
to to feed it into the layer spill
so if you want to use this you can also
have um
you can have an exp like only
concatenation dependency
on the adapt variable so you see it's
converging a little bit
faster although it's taking longer to
evaluate because these flows are more
a little bit more crazier more dynamic
what if you want to do something else
sds for the finance guys
uh you can specify your drift and
diffusion you can have stratanovic
ito the noise type
bunch of solvers uh it's the same api so
scan link space
again a joint versus autograph
so you can you could solve the same
problem here with uh
with nusd if you want to do stock price
forecasting with this you might have to
put it into an hybrid module where
you're doing jumps as we discussed with
the neural graph differential equations
you will have a for loop as you step
through your your time series
you will have a jump like an rnn cell
lstm cell
to incorporate information into latent
space and then you will flow
you will have a continuous depth
integration between
your timestamps which can be an dnsd scd
anything you you you want with this
you can for example extrapolate uh
building a forecasting model in finance
something else that will almost always
get asked
is uh there's a lot of it we have a lot
of tutorials that you can step through
but a lot of them use this type of
example where we are using
uh uh n sequential uh modules
to define our vector fields
and something that people ask us is what
if if i have prior knowledge of
the vector fields uh some of the
components of the equations i know some
others i want to to learn i want to do
control
you can do it no problem so you want to
do control of
an acrobat double pendulum you have your
dynamics equations
they're not very pretty but you have
them you can you can say
i know my control enters the the system
this way i want my controller to be
parametrized by neural network
like this right then you create your
this is your your od system this is your
vector field that goes inside
the neural d then you have access to the
same api
right so you're solving the system the
control system
in in batch and gpu um
and you can solve an optimal control
problem you can say i want to stabilize
the system
around this this point you have your
cost function that's maybe the norm
of the state and the the endpoint of
of the solution of dod and then you can
you can iterate uh and optimize the the
parameters
of the controller right so you can do
model based control
you can go beyond you can do model 3
control so you know you're controlling
this type of system you don't know the
dynamics equations but you know for
example
maybe it's a conservative system you
know it's a mechanical system
you can you can put your knowledge here
you can
have maybe a newtonian neural network
specific type of neural network that
preserves energy
you can have a second order a type of
dynamic
and that's all uh model three in the
sense that there's a neural network
that's approximating everything
and this will give you better this is
what we we mean by better sample
efficiency for our control
this is not so in uh we have a lot of um
tutorials so um feel free to check
our um our github there there's there's
one more
indeed um coming uh we're inactive
development we're working on a better
solar suite
we're working with python's lightning
closely
to allow training at scale of neural
differential equations so if you want to
have a huge batch of systems
that you're simulating and you're
simulating a stock price time series and
you want to to
solve an optimal control problem there
you can do it at scale
and um a lot more but indeed uh
feel free to reach out and uh and follow
us and you'll see
i think that that's that's all i have
we're a bit late i don't know i'm happy
to take all the questions that
we have time for but otherwise this is
uh
this is the end of the presentation
thank you all for uh
for listening