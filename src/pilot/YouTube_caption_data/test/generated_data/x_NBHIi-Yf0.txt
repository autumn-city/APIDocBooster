okay welcome back everybody um
hope you've had a great afternoon so far
this session up here
is a two hour tutorial you've got yep um
so just letting you know that the
session down in the main hall is
scheduled to be a longer one so like
when we break from here you might not
find some people outside you probably
shouldn't go traipsing through the main
hall just because they might still be
underway so with that said um
it gives me great pleasure to introduce
adam green um and adam will be giving us
a tutorial in distributed computation in
python in a bunch of technologies that
i've actually i mean i've heard of those
ones but there's a couple in here that
i've never heard of and i can't wait to
hear about them so
let's make him feel welcome
[Applause]
hello everyone thank you everyone for
coming i really didn't think this many
people would show up so yeah thank you
for your time
uh so the
notes for today the materials for today
are in this repo here
i appreciate because of the wi-fi here
it might be a little bit difficult to
clone that you have to use you can't use
ssh which most developers do
um and also the wi-fi here apparently
isn't great so yeah if you can clone
this um you know you'll be able to run
the notebooks
the
sessions are based around three separate
notebooks
the first one is kind of an introductory
uh warm-up session about functional
programming
the reason we introduced this and of
course about distributed computation is
because a lot of distributed computation
leans heavily on functional programming
concepts map in particular so the real
important thing about this section is
you know how to run a map in python
that's kind of the big thing um so yeah
20 minutes of kind of theory of me
talking and 20 minutes of you guys you
know having a chance to have a go with
some exercises
which is obviously conditional on on
being able to clean the code
the second notebook
single machine this is all about
distributing computation on on one
machine
we'll only use the python standard
library there so it's everything should
hopefully run pretty easily
there's no clusters or anything kind of
to set up
and in that section we're talking about
solving two types of problems i o bound
problems and cpu bound problems uh two
solutions for those async i o and uh
multi-processing also go into a bit of
lightweight threads and processes icbu
cores and stuff um
this is an introductory focused course
and what i mean by that is that what i'm
trying to do is bring everyone along uh
for the journey um so some things might
seem a bit basic you know but hopefully
uh you know once we get going we can end
up in a
interesting place
uh and then the final
notebook which is running on many
machines
which is kind of the inverse of the
second notebook this is a whole bunch of
external accounts
um you know i think two or three
external accounts especially include aws
um
a bunch of different random packages
that you know people won't have heard
from so that's kind of the exact
opposite of the second notebook
um and i'll be giving a demonstration of
running a dash cluster in the cloud
using coiled and prefect as well
um
don't know whether you guys will be able
to get that running yourself because you
have to sign up for this account and
that accounts and all these kind of
things but i'll be here to kind of give
you guys a hand if you want to
um this third notebook
you can read it in binder if you want to
sorry
this here is is an example of the
notebook running in binder
um
this third notebook
you won't be able to run in binder
because i don't install dusk onto binder
because dust doesn't like uh
binder doesn't really like dusk or
condor in particular
um yep and so you can see there's kind
of two requirements files in here coiled
and crimes.txt
that's because we're targeting two
different environments here the coiled
ec2 environment which is in notebook 3
and the binder environment if you just
want to run notebooks 1 and 2 on on
those um
on binder
cool this uh console is not returned
which is as interesting
um anyway so we can start it with the
first section does anyone have any
questions or
did everyone kind of get a
sorry
sorry what was that
you can't find the link
where is it oh it's on github right if
you just uh if you go to
i mean
i would just copy and paste this in
google right
um
but is there a way for me to share text
with people here no there's no slack
channel or anything
okay
so the way that i would find this i
would look for my own github profile adg
efficiency
[Music]
github
and of course it will come up for me
because uh
i'm me uh and yeah hopefully be able to
find
some of the other random stuff i've done
on github
then go to my profile
uh and then repost and it'll be the top
one um
does anyone want me to go over that
again
sorry
oh yeah sure
[Music]
okay
and
all right sorry i need to do something
can't use you to lab without them
bindings unfortunately um
okay link is here
how can i let you guys uh
take a second to get there working
i suggest can everyone see that okay
hopefully
there's three vertical bars are
interesting um i'm just going to get
going uh
if if anyone uh has any problems what i
suggest is we'll take a break after this
notebook you know uh when we did the
practical session just come up and i'll
give you a hand you know running through
your machine and stuff
um
cool so first section on functional
programming uh
so outcomes of the course uh this
notebook this is the big one right so as
long as you know what a map is and
you're comfortable with a map and you
can do maps we're kind of all good
the genesis of this course is another
course i gave in 2020 march 2020
before the world ended and uh in that
course which was a lot longer we covered
mapreduce so it kind of you know rarely
justified the functional programming
stuff but for the context of this if you
take away i can do a map you'll be good
for the second notebook
um
right and this is kind of the motivating
example right uh here we do a star map
but kind of just understanding the
syntax of mapping over a you know a
function and a circle to apply so
functions or applies to that answerable
is kind of uh where i want to get to
so let's talk a bit about uh functional
can i
probably not uh what is functional
programming there's kind of three ideas
one is this idea of no side effects
right or essentially um
not depending on or mutating uh state in
the outside world external to your
function uh variables that don't vary
this idea of immutable data right not uh
not taking data and mutating it but
instead writing it to disk and and
reading it would be the more functional
way to uh to deal with that the other
one is sort of first class functions
that we can pass around
and uh and using python
um
functional programming i think uh
one of the big benefits of this justin
encourages good functional decomposition
it just encourages you to write
functions uh which is almost always a
good thing
um
right i kind of leave you guys to read
this a lot of the notes in here i kind
of won't go over it and talk over it's
kind of extra detail for you guys to
read
um as you want to but this idea of
imperative versus declarative functional
programming is all about just saying
kind of what you want
and often the mechanics of uh so for
example if you look at this map
here
the mechanics of how this map is done
you know whether it's done over a
cluster or over a process and stuff like
that it doesn't really appear at this
stage right that kind of uh complexity
is hidden um
in inside that function call whereas you
know imperatives type programming you
have a class and it's very kind of
you're telling the computer exactly how
to do it whereas uh here we're more kind
of saying this is what we want this
function
um and then this kind of map will take
take care of
where and how to run it
uh yeah no side effects
not depending on state not depending on
the outside world kind of um
becomes this you know computer science
term of item potency which a lot of
people say to sound clever that's what
i'm doing here
the idea basically is that uh
when you run a function it should always
run the same way right there should
never be anything that can happen you
know in a database or an s3 or you know
in in some other parts of the program
that will cause that function to run
differently right same inputs same
outputs right it's really course this
idea of
functional programming
so some examples of this this kind of a
very simple somewhat trivial example i
just need a little bit more space here
we have a door right we want to close
that door one way to do that would be to
implement a toggle right which looks at
the position of the door and just takes
the inverse right um
this way of closing a door is not item
potent right the behavior of this toggle
or door closing functionality that we
want uh changes each time we run it the
reason it changes each time we run it is
because we depend on the state of the
door right
that's essentially not being item posted
as seen as
sort of not adhering to these functional
programming practices
a way to do this in an item potent ways
essentially just always close the door
right the concept of uh fail safe in uh
in engineering um
there's a bunch of different kind of
ways the stuff uh this stuff comes up
um variables don't wear it very
very very
so
this is a a bit of an interesting
concept because variable itself you know
suggests something that should change
um this idea of variables that don't
vary is essentially relying on
immutable data as the input and output
to your function
so
here we have a you know simple
dictionary it gets passed into a data
pipeline here you know i just changed
the stage to processed
um
this way of do of implementing this
mutates this raw dictionary right and we
can see now our raw dictionary has been
lost right this is an example of not
immutable data right
instead the correct way to do this where
we both maintain our raw dictionary data
right that that data doesn't change uh
is essentially just make a new
dictionary write take the data that we
want you know return that
but again the key idea here is that uh
this variable raw it's always raw right
we never change it if we do work on it
we'll create something new right a new
variable that will never
change
and first class functions uh this is
kind of people that
are kind of introduced to programming
through python like me kind of take for
granted it's just this ability kind of
to kind of throw around functions as if
they're variables to throw functions
into
other functions again for python
programmers we kind of take this for
granted there are other programming
languages where you can't do this kind
of stuff
so just to summarize these three things
these kind of like
you know ideals or goals of functional
programming
no side effects not appending not
depending on state item potency this
first one second variables that don't
vary you know my data is always there
even if i work on it i can still go back
to it and first class functions
any questions at the stage
cool
um right so i kind of mentioned that map
is like the big motivating uh idea or um
function of this whole section right um
you need to take away how to do a map
a map essentially exactly the same as a
for loop functionally or applying you
know a a function to each element of a
data frame
i have a data science background so a
lot of these notes will be kind of data
leaning
um
so
the first example of uh
using a for loop which most people will
hopefully be familiar with
we just operate on each element of this
list and we call this function on each
element this function just lowers the
striking right just takes that
first capital letter and lowers it
um we can achieve this exact same
functionality using a map right
obviously we need the the function uh
here and the data as well
um
and this map syntax
the first thing we put in is the
function that we want right so this
lower here whatever function that we
want to apply to each element of this
input right is our first input and the
second element is just the thing that
it's writing over right in this case
just a list of cities
one of the things that's a little bit uh
is a bit of a gotcha or you need to
learn about a map is that a map
evaluates lazily it doesn't actually run
that for loop when you create this map
object
and just calling lists on it will just
actually run that map computation it's
just kind of an additional uh you know i
need to call a list on a map thing uh
which you need to remember with maps but
by and large it's roughly the same you
know it still
can still easily be a single line like
uh you know a list
comprehension um right so that's map so
really important to understand this to
kind of understand that okay it's just a
for loop and a different uh syntax uh
you know if you get that um we'll be all
good
um
right lambda functions lambda functions
is another one that that kind of becomes
important in functional programming
because
quite often we just want to dump a
function in here
very quickly that does something very
simple like for example this is a very
simple function it can easily be a
lambda function because just uh one line
um so uh an example of doing the same
uh exact same thing we did above with a
lambda function this lambda syntax um
just declaring this anonymous function
this is what's going in and this is
what's coming out right
and one of the things to understand
about lambda functions that we have some
flexibility over what we do here
and what we do here right so i can input
a tuple you can take the sum of that
tuple right you have complete
flexibility of what you do on the input
uh and what you do on the output i can
see some people struggling to see is
this big enough i can
i'll go
one more actually that's maybe too much
um
yeah so complete flexibility on input
and output you're kind of limited to a
single line return you're actually doing
multiple lines here as it would be a bit
inconvenient you would just write a
normal function
um
yeah and you see this kind of returns a
function object right we could assign
this lambda function to a variable then
essentially we've done the same as you
know if i did something like lower
lower
equals
sorry i use a different
keyboard layout at home so you'll see me
struggle to type some things this is
exactly exactly the same functionally
except for the you know the things
obviously different as doing def
you know def name
def lower you know some function
uh
okay filter right we're almost at the
end of me talking guys uh not too long
uh filter very simple just kind of doing
an if statement you know a conditional
on each element that we're iterating
over
um so you kind of get a map
for free with a filter it's kind of
doing uh you know a map and then an if
statement the same way we can kind of
see with this list comprehension
so list comprehension you know for city
and cities we just have a conditional
that will determine whether we include
that thing and what we get back
exactly the same as what's going on in
the filter
right we have this lambda function
defined here which just does that
conditional right just use a lambda
function to do it it's just kind of
easier keeps things on a single line
population is the thing that we're
iterating over um
yeah you can obviously do the same thing
with uh
with a for loop
right last one
[Music]
yeah i need to do
i'll do that
um
last one so we've had map which is like
a for loop with a filter which is like a
for loop you know with a conditional uh
reduce is slightly different so
with a map well with a map you always
get the same amount of objects out that
you get in
uh with the filter you might get the
same but you'll probably get less
uh with a reduce depending on how you're
doing the aggregation uh you might get
one or you might get you know an object
with keys which which we'll see
so um
if we want to do something like just sum
all the population in uh in each city um
actually this uh
populations thing i didn't really talk
about that too much just a simple uh
list of
tuples first one
name second one uh you know just a float
yeah apologies that people have got uh
have gotten lost there
um
so here i just iterate over this list of
tuples it's actually a name tuple just
for convenience
so for each city in these populations i
just pull out the population i take the
sum of it right super simple and easy
now understanding kind of how
the reduce
function works in python the one that
we'll kind of see down here
it's actually really good to have a
mental model of
a for loop with some sort of internal
state that's being passed on to next bit
of the loop right you kind of think
about how you would do a reduce
using a for loop this is you know maybe
how you would do it
the reduce function from isotools if you
look
look at below it's the same thing you
kind of pass in this
you know initial
state that's going to be passed across
each elements of the esterable that
state gets mutated as you kind of move
across exactly the same way as the
reduce is working
you don't really see that here right so
this is actually probably a better
mental model
for thinking about how we reduce work
works uh in functional programming
uh i'm right i will
so
for whatever reason um
reduce is not a built-in and python
that's uh hidden away in functors
but we can kind of see it's uh
roughly similar um to what we had uh
with a map
function first then the thing that we
want to iterate over we just have this
initial this additional
uh concept of like an additional value
right this this initial value is the
same as total here right
you you can think about it we kind of
need the reduce to give the reduce a
place to start right an empty dictionary
or a you know a um
zero is usually a natural place to start
but you can kind of change that if you
wanted to
um
right so how would we do
uh how would we use reduce
um to
do this kind of summing over a list
thing which is which is quite easy to do
in a for loop
so this reduced syntax reduce
function
thing we want to iterate over right
populations and then initial value right
so we have initialized to zero
this is exactly the same as total
and then using reduce uh
here uh yeah
two ways one using the function you know
defining a separate function and this
here i'm just defining using a lambda
function to do it
which perhaps would would take a bit of
time to understand i'll just go through
super quickly so lambda function lambda
syntax to you know define the function
again we have some flexibility of input
here right so i have both my accumulated
value of total uh and my kind of new
element and the essential which is pop
right pop is would maybe be better
called city here that's maybe slightly
confusing
um and then
i i say how do you want to do the
aggregation here i'm just doing a sum
right so i take the previous value i you
know increments it uh and move on to the
next one here's what i'm measuring over
here's the initial value
um
right you can do more complex things so
here i'm actually doing a group by right
uh i have
you can see that what i'm passing in as
my initial uh value is no longer just a
float it's actually a dictionary right
uh because these are the aggregations
that i want to do
um
yeah
definitely things you could change about
this code but roughly it's uh you know
it obviously works fine
um
cool right now your turn
um so
there's a couple of exercises
i have about 20 minutes
for
exercises um but i think i might cut
that to 10
just just for the sake of time because
i'm a little bit further ahead than
where i thought it would be although
actually we started at 20 past didn't we
sorry i think we're good
um
cool so yeah i'll give you guys about 20
minutes or so you know
to work through these there's three
exercises i'll just go through them
quickly uh the answers are already here
as well
if if i was in this tutorial i would
just go straight here and look at this
right don't you know feel like there's
anything wrong with doing that
um other people like to kind of you know
give it a go and and see if they're
clever enough i kind of know that i'm
not
um so
three examples first exercise here's
some code right you can kind of see some
of the things we've been doing
as you know alternatives to functional
programming for loops if statements all
these kind of things right here we have
some aggregation
and the you know here's the result you
get
um
and the idea is uh to just do this in a
functional way you know using map filter
and reduce uh you know you can use all
three to solve these problems
the second exercise you know again i
appreciate you might not get through
these
creating a pipeline there's no starter
code to get going here
selecting the cities that have
populations greater than the average of
all cities so it's a little bit of a
nasty or annoying question because
you kind of need to know the average
before you do that filter
right um there is a way to do it in a
single
reduced step which i show in the in the
answers
um but one of the things that's really
important i kind of don't write it here
but i should have
is uh you know whenever you have a task
like this and maybe you're thinking i
want to do this in a functional
programming way
uh just first write something like this
you know use for loops just do it in the
way that you're kind of familiar with
and then take that program and try and
make it into a functional program i
think that's a much better way to start
out because kind of understanding where
to put a map and where to put a reduce
and and stuff ahead of time without any
code to work is difficult
that's why i've made this question like
that so it is a bit more difficult um
but definitely in general you want to
think about you know first doing in a
way you're comfortable with and then
kind of swapping things out
and then yeah another sort of group by
average population for both continents
um yeah that this is very similar to it
to a map produce
uh example
um
cool so yes what i suggest maybe we go
just until the hour on the hour
and uh
yeah is it common to do practical
exercise in these tutorials i kind of
thought it would be it is okay cool good
cool
um yeah and i think if anyone has any
questions if you can just come up and do
them up here because i don't think i can
get back to to everyone
although it's quite difficult for people
to get out through
and i'll show the repo again
is
there we go
crazy
okay good cool
uh
nice
thank you very much
who in here is also
looking at venus and looking at the
online chat
is there anyone else like david has the
chat window open does anyone else have
it open
no oh sam are you hanging out for the
tutorial
the reason the reason i ask is i'm kind
of looking for someone to
maybe act as an interface between the
live room if there's like questions in
the chat you could maybe relay them up
then i will not i will not
yeah cool
if while
you're while your battery's okay
if you can be in the chat with the live
stream off
if you turn the live stream off your
battery and the wi-fi will be happier
there's a no there's um
yep
uh
jesus
thank you
hey
yes
i don't know if i okay here's my mic
back
okay guys i'm just going to run through
the
answers now i appreciate the exercise of
that engaging that uh
everyone's ignoring me now
um
so i'll just run through this super
quickly uh so the answer to the first
question
um which is about uh
yeah summing total population for a
consonant
we can do this in a single step so this
lambda function here is our sum function
right
uh
whether whether you call this a single
step or not is uh yeah it's maybe two
steps because this is yeah i would say
this is two steps uh the sum function
right we have this uh you know
accumulator valuable that we're sort of
passing around the that's real
and then this filter you know just
filtering on a you know a certain um
continent you know pacific in this case
uh
okay
is that me
ah
oh yeah you can still see it down there
as well
you
you
cool all right i think we're back guys
thanks for that um
go i just run through these answers
super quickly uh a second one
uh this is this one we're calculating
the average right and when you kind of
initially look at it you think oh we
need to calculate the average first
right which is what we do here
and then do a reduce
um and then you know calculate the
average you know sum over the count
you can actually do it in a single step
i won't kind of go and explain this
but you can see we kind of take
advantage of uh
you know some complexity in the
the um thing that we're iterating over
this kind of initial thing uh
tracking these two values and you can
kind of calculate the mean as you go
that way um not that important lots of
people would probably just prefer this
for uh you know ease of understanding
um
right and then the last one for this
uh notebook
was just finding uh essentially doing
a
group by population
um
yeah which i think is very similar to uh
to one of the examples that we showed
you can see there's some horrible
monstrosity here which attempts to do it
in one line
but uh yeah these are much easier to
understand and work with
um
cool
let's move on to the second notebook
uh
so this is kind of the mate of the
tutorial um this is the thing that
probably will be the most useful to you
if you haven't done any multi-processing
or uh async or before
[Music]
working on a single machine is uh
is is really nice for a lot of reasons
um and you should definitely be
trying to distribute compute over your
you know cpu cores or you know use the
single thread a bit more intelligently
uh with async io before you think about
i want to spin up a thousand cores on
aws um type stuff
um which we'll look at in the last
notebook
uh
yeah so so we'll kind of talk about some
computer science stuff i'm not a
computer scientist so i have this kind
of uh
um
always try to kind of explain these
things for people like me who didn't
have that education we also talk about
some basics around how you know cpu what
a cpu does threads and processes
again very simple concepts that a lot of
people understand but it's really
important to bring everyone along
together uh especially an introductory
talk
and then we talk about basically these
two things
multi-processing and async io uh
threading is just kind of something that
um you should probably shouldn't do uh
you can just use synco
um
yeah and we're kind of solving these two
problems right cpu bound problems and
and io bound problems i'm going to talk
a little bit about what those are
um
so a couple of background concepts that
are kind of useful for
understanding you know how to think
about working in you know across many
machines or many cores should you do it
right there's a couple of concepts that
are really useful
one is this idea of horizontal versus
vertical scaling right horizontal
scaling is scaling wide right i
take my job and i use many workers to to
do that job right usually many small
workers right it's like um distributing
that way
a second way of kind of scaling uh is
just to get one very big machine right
and that will be the idea of kind of
vertical scaling right we're taking uh
taking this one job you know this big
job that we have and we just get a one
real real big thing we kind of you know
scale into it rather than horizontally
scaling where we can let's get many
things in and scale wide
really useful concepts for kind of
talking and thinking about
distribute computation the other one
that's really useful is fixed versus
variable
i didn't draw a picture here
um
i probably should have because it
communicates really well as a pitcher
you can basically just think about a
line the slope is the variable cost the
intercept is your fixed cost right
any type of more complex things whether
it's multi-processing async io i guess
has some overhead but not much
certainly if you're speaking thinking
about spending up clusters
you end up hitting a lot of fixed costs
start-up times of clusters you know run
times of of clusters and all these kind
of things processes and multi-processing
which is kind of relevant to this uh
section
um so this balance between fix and
variable cost is kind of always
something you need to consider right if
it's going to take you 10 minutes to
start up cluster probably not worth
paralyzing something that takes a couple
of seconds right this kind of logic is
really important and you'll kind of see
especially when you work on your own
machine sometimes you might multi
process something and it's actually
slower than just doing it in a for loop
just because of that fixed cost to start
up processes
and run them you might also run into
memory problems uh you know with
multi-processing depending on what
you're doing
um
right
so
why distribute why distribute
computation uh one reason is just to do
things fast right we don't care about
cpu time we care about real world time
uh
especially nowadays
the last few companies that i've worked
at have not been so concerned about uh
cloud costs but they have been very
concerned about developer time so
distributing computation kind of gives
you a way to you know save some
developer time uh but you know maybe pay
a bit more uh on the cloud or have to do
some kind of slightly more complex
things
um
yep and and these two
uh these two problems are kind of the
focus what we're going to talk about cpu
bound io bound and here are kind of the
two solutions here and there's kind of
two solutions to these problems to
you know two kind of tools that we have
to do things quicker one is to use more
hardware right we do things in parallel
we use cpu cores that are just sitting
unused on our machine or we do things
more intelligent
intelligently just by waiting handing
off execution and stuff like that
those are for i o bound problems these
messages i'll be repeating again and
again uh because they are kind of the
core
core messages of this notebook
sometimes you want to use more memory
right it's not necessarily that you want
to do something fast but you might just
want to work on a really big data set
right uh and that data set kind of needs
to be held in memory for some reason you
need to do a calculation across the
whole data set
we've kind of seen at the end of the
last notebook that even something that
intuitively you think that you need to
do
you know all at once like taking an
average you can actually do
incrementally
and this is this kind of idea of
batching data das data frame does this
we don't talk about das data frame but
you know we do talk about dusk
but these two solutions here are
essentially the same as above either
using more hardware or just being a bit
more intelligent about how we do things
right this is kind of these two two ways
uh to solve problems just throwing more
computer or actually just thinking a
little bit about what we're doing um
cool yeah and why or just on a single
machine i think it's easier
it's really great to not have to rely on
anything third party um
you'll kind of see when we get to the
cluster the next notebook i'll show you
some of the stuff i was doing last night
trying to get things working
um
yeah so this notebook's great things
just run python standard library
not paying anyone any money for anything
don't have to have an account for
anything don't have to worry about
credentials for anything
which we you know usually just worry
about all day
um
cool so hardware and software uh this
will be for some people very basic but
it's worth going on
here's kind of a mental model of how a
computer works
uh we have multiple processes running on
our computer
your music player maybe you're doing
some stuff in python you know this
browser right all individual processes
and inside these processes this is kind
of a good mental model it's not
necessarily 100 correct but i think it's
very good
inside these processes you have process
is a software thing a thread is a
software thing and it's just kind of
like a path of execution right if i want
to run
a process to completion i just kind of
need to think about running all the
threads to completion right these
threads kind of exist in the program
the kind of simplest way and this is how
python will run
we get one of our cpu cores you can
think about we kind of attach it to a
process where we kind of okay this core
is running this process
and kind of at the same time
this core is running that thread in that
process right
so one core one thread one core on
process
this is how python works most of the
time
there's this thing called the gill which
i think most people will have heard of
basically means you can only work on one
thread at a time in python that's just
kind of how it is
it is possible to do other things right
it's possible to run multiple threads in
one process using you know multiple
cores right you'll see that we still
have this kind of map between one core
runs one thread and i think that's a
useful thing to stick with i talk a
little bit about multi-threading and
hyper threading and stuff
um but i think just having a mental
model of i have eight cpu cores
i can run eight processors and because
it's python i can run eight threads
right that's kind of where you end up
there are opportunities for
multi-processing and python um
i think i've mostly just said most of
this out loud
i'll come back up a little bit
uh you know multi-threading and hyper
threading um
you can kind of read through if you want
but i think it's good to kind of stick
with the especially when you're writing
normal python
i can't use multiple threads at once i
have one core i won't run one thread and
one process and that's kind of kind of
where we are
um
right to see if i didn't say anything
uh
yes so that we kind of have these two
units these two software concepts
threads and processes process kind of
wraps around threads
um
the big difference between these two is
uh let's say i want to run you know two
units of compute if i can do both
threads in one process that means i
don't have to incur a huge amount of
fixed costs spinning up another process
each process has its own space and
memory but if i'm multi-threading right
doing something like this these threads
are sharing the same
memory space you can see it's kind of
separated from you know this other
process that's both good and bad
it's good because it means we use less
memory but it's bad because this thread
can get in the way of the other thread
right there kind of a you know classic
trade off there
yep so threads are kind of lightweight
easy fast but we can't really do it in
python not you know kind of what we want
to do which is i have one python process
and i have eight threads running in
there
you know in normal python that's hard to
do
uh processors talk about the memory
things um
yeah the one kind of uh sort of uh
exception to this role is and is very
common in data world in particular
is uh using low level libraries like c
or c plus from python you're kind of uh
you're able to do these things here
because when you're calling say numpy
and c c is uh
will happily multi-thread you can
multi-thread safely so we can kind of we
are doing multi-processing in python but
not really sorry multi-threading in
python but not really
that's kind of the one got you that you
can kind of do something like this
um in
in python uh
right so that's kind of computer
hardware and software stuff
um the important one is important things
are threads unit of computation process
this thing that kind of wraps around
threads
that these are software things and then
cpu cores one core runs one thread you
know at once
and yeah again like i've said using
python that means uh
one process one thread
right so we have these ideas of these
kind of computer science ideas
concurrency parallelism and asynchrony
which i'm going to struggle to say most
of the talk
and to kind of explain these things i
have these three examples right one is
growing a tree
the second one is mowing a lawn and the
third one is playing many games of chess
at once and we'll kind of use these
examples to explain these uh you know
computer science things
uh so concurrency
concurrency is this idea of uh
doing uh we're not necessarily doing but
managing many things at once right so
concurrency is like a sort of like a
parent property to both parallelism and
asynchronous i should have drawn a
picture of that
um but it's kind of this general idea of
i'm not only doing this thing but i'm
doing that thing i'm not necessarily
doing both at the same time
but i'm kind of aware of both them i'm
managing both of them you know that can
be doing both at the same time which is
uh parallelism
um
right i'll kind of yeah scroll through
that you can kind of read through that
at your own time so we have this idea of
concurrency managing doing many things
at once
parallelism is a special form or kind of
a
um
yeah a special type of concurrency and
this is actually doing many things at
once right so i'm doing this thing at
exactly the same point in time i'm doing
something else right usually the same
thing on a different input or different
kind of data
so parallelism fundamentally requires
many workers right you can't do anything
in parallel with one cpu core right
because that one core runs one thread
right you're kind of stuck to doing one
thing
if we introduce more hardware additional
cores now i can start to use those cores
to run you know threads and additional
processes because we're in python
and do many things at exactly the same
time um
yep and you can kind of think about
paralyzing it kind of multiple different
levels right
um
but we'll kind of be sticking to yeah
these three
uh in uh this notebook and uh the next
one
um
right so we have concurrency this kind
of idea of doing managing many things at
once parallelism a special form of
concurrency when we're doing many things
exactly the same time
asynchrony synchrony which might not
even be a word i might have just made
that up um is this idea asynchronous
programming doesn't really map exactly
to parallelism because it kind of has
this programming context but it's fine
the basic idea is just that when we're
waiting for something right and the
things that we wait for in computers are
reading writing to disk or you know
waiting for an api call you know
essentially reading and writing to the
network
um
while we're waiting for that other thing
to happen we can instead of waiting just
take the cpu and let it do something
else that that's all that kind of this
asynchronous idea is
so it's not parallelism because when
we're well it can be looked at
parallelism it depends whether you look
at that waiting thing as a thing or not
because you're waiting for it but you're
not actually doing anything
so it gives you a form of parallelism
where
my
main thread can keep going doing
something else in python while i'm
waiting for the network right whether
you call that parallelism it's kind of
up to you you can see it as both ways
um but it's a form of parallelism but
not
the same as this kind of parallelism
where i'm kind of
it's not just something i'm waiting for
unless any computation i'm doing
in parallel
um
yes but the cool thing about this idea
of asynchronous we get this form of
parallelism with a single cpu right so
we're not throwing more hardware at the
problem here all we're doing is being a
little bit more intelligent we're
pointing out these places in our program
oh okay you can wait here right you can
go do something else while you wait here
sorry is the way to think about it um
cool so these three ideas concurrency
parallelism uh asynchronous asynchrony
um so let's think about these three kind
of motivating examples uh growing a tree
mowing a lawn and playing many games of
chess at once
um this first example growing a tree
you just can't really do it quicker
right there's no opportunity to do
anything in parallel with growing in the
tree there's no opportunity to kind of
wait for one part of the tree you know
and grow the other part of the tree
while you're waiting it's just a tree
right there are some some
things you want to do there's just no
opportunity to do anything concurrently
right and it it's important to kind of
understand and remember that
a second kind of uh
our second example is mowing a lawn so
let's imagine i have a lawn right and i
want to mow it quicker what i can do is
i can get more mowers essentially throw
more hardware at the problem right and i
can mow those different bits of lawn at
the same time in parallel right
this is you know parallelism
this is multi-processing right i'm not
being more intelligent about how i mow
i'm just mowing more at the same time i
need more mowers to do it
the final example is this idea of one
chess ground master playing many games
of chess at once right how does this
kind of relate to what we're talking
about
um
so
when our grandmaster gets to you know
his next game if we weren't doing this
in an asynchronous way
that grand master would let's say the
grand master takes two minutes to decide
an action
you know regular joe takes 20 minutes if
we're doing this in a synchronous way in
an unasynchronous way our grandmaster
decides to move in two minutes and then
sits there and waits for the other
person to make a move for 20 minutes
right that's a synchronous way to do it
these two things are in sync and
essentially the grand master even though
the grand master is just waiting right
his cpu is is kind of not doing anything
because we're in sync in that game
there's no opportunity to do anything
quicker and we kind of do things slower
where instead if we do this in an
asynchronous way
while we're waiting for the next move
our chest ground master can move on to
the next game
take an action there etc etc and he can
move the whole way around the board
and kind of get back resync restart that
thread so we have this kind of idea of
handing off execution while we wait and
then restarting right there's kind of
two things there both being able to hand
off and being able to restart
but if we can do that then essentially
we can just while we're waiting go do
something else come back you know and
then we kind of save uh you know clock
time
any questions at this stage
sorry
yes it is yeah it is bobby fischer yeah
i should probably have a caption here
it's a better yeah um
yes this is hank hill by the way yeah
yeah that's right
um
cool
right i kind of talked a little bit
about this should probably be in
background a little bit because i've
mentioned this this cpu-bound io bound
heaps um but i think it's a good a good
way to think
what the one thing that's been really
useful for me to think about computers
is just narrowing it down to three
things you do computation you talk to
people or you remember things right
that's kind of all computers do for us
these three
these three functionalities can be
mapped directly onto problems we have
those with those functionalities
cpu bound problems right i want to do
compute but you know almost my one cpu
is going as hard as it can right it's
vertically scaling as much as it can
um and i'm now bound by that cpu
io bound
you know my thread is set there waiting
for a long network call right as an
example being io bound i o read write
memory problems we don't get into here i
can have a conversation i have a list of
a bunch of ways to solve these problems
if you will never talk about them
these can actually be quite nasty
for some people but we're really talking
about these two things cpu bound
and
and io bound
cool um
threading i'm not going to talk much
about much about this there's some
content here but basically
the way to think about threading and
when i'm talking about threading here
i'm talking about a specific module in
the standard library right from you know
import threading
uh
there's just really no
because of async io which came out in
python 3.4 i think
there's really no space or room for
threading in your tool kit in my opinion
obviously
i wouldn't suggest looking at it
you kind of get the impression with
threading that oh we can do
multi-threading but you still can't do
multi-threading you're still limited to
a single thread
exactly the same as async io so i would
kind of really just forget about
threading as a thing
there's some links to some talks here
this is a great talk this guy's a great
guy
talking about how to do multi-threading
code he's a very good programmer and it
looks very difficult so i would suggest
just just don't worry about it threading
is kind of uh we don't need it because
we kind of have these three i think i'll
show them here
these three things threading
multi-processing async i o but we only
have two problems right io bound and cpu
bound so we can throw one away we throw
away threading um
yeah so just something not to worry
about
right talk a little about c surprise c
plus plus thing multiprocessing
um
so because i'm a data person most of the
problems that i have are cpu bound
problems multi-processing is an amazing
fantastic tool that should be in your
toolkit
async i o is worth learning and
definitely you know a valuable part of
this course but you can actually just
multi-process everything if you want to
right and just have multiple calls you
know waiting for the network in parallel
if you want to it's totally fine you
just incur the memory overhead of using
multiple processes but multi-processing
is if you just take away one tool this
is the one tool to take away
i i think it's easy to program
personally
it just ends up being something like
a map right
this is why
this was the motivating example of why
we went through all the functional
programming stuff just so you understand
and you're comfortable exactly what's
happening in this map call
here's a function
here's an iterable that i throw into it
right that's all that's happening so you
can this is this uh
example of uh
this functional style of programming
allow you to not really worry too much
about whether you're multi-processing or
just normal map right i just write a map
and then i do it in multi-processing i
do it in
normal python you know i can do it on a
cluster right
this kind of hiding away all this detail
is
is one of the reasons why maps are used
to do these things um
right multi-processing uh yeah for loops
and maps these kind of things
uh yes this is the big thing to remember
multi-processing it's great but it has a
memory sorry to remember it has a memory
uh overhead
uh which can be a problem
uh you can also get some problems
sometimes it's difficult to get standard
out coming back
into the main process
you know
yeah
you kind of deal with those problems
when you come to it
um
right so let's kind of walk through this
code i appreciate i've gone to the end
very quickly
uh
this compute intent task i think it just
guesses a
creates a random string of so many
letters he says it's a lot of letters
just so we make it you know a
cpu bound problem
um so we start out with a for loop right
again as i mentioned
it's very okay to just start out writing
a for loop if that's what you're
comfortable with just write a for loop
uh then convert that into a map right so
this is the map we call list here
because that's how things work
i i wouldn't pay much attention to these
things here we kind of don't really care
at this point
um well yeah maybe the average of these
two versus this one but what i'm trying
to say is don't think a map is quicker
or faster than a four lip is basically
the same right functionally the same
you're not saving any speed by just
using list map
you are saving speed by doing pull.map
um here i'm
creating a you know multi-processing of
a 2 cpu course
right
and each time that i go
so when i go through this essential of
you know number of words you know
a thousand you know
this is a list worth a thousand like
eight times or something like that
each time i run this function i spin up
a new process or i use an existing
process and it will happen a lot uh you
know i run that compute task when i
return right and it's quicker it's not
kind of exactly twice as quick but kind
of thereabouts
and that's kind of it um
there are some kind of nice
tools or or things that are useful
multi-processing like funktools.partial
star maps and stuff but you'll kind of
come across that as you need them
the big thing to understand is if you
can get a map then you can just
multi-process without really thinking
about anything
and
yeah
hopefully for at least some of you this
will be a useful thing because this is
really the you know okay you can do
things a bit quicker now on a single
machine
um
right so that's how we solve cpu bound
problems if you want to do a bunch of
things
obviously these things need to be i need
to be able to do them in parallel right
here we're just creating random words so
i don't need to wait on you know the
last one if you did then you can't do
things in parallel this idea of
independence i didn't really stress this
that much
is is really important when thinking
about can i parallelize a task
okay i think we're getting there
um
right async io
so as i mentioned async io is kind of a
light comma to python that's why you
know threading in async io they
basically fill the same space of single
threaded um single threaded computation
single threaded concurrent computation
or asynchronous computation as a way to
think about it so unlike multiprocessing
i just still use one core one thread
right i'm not throwing any more hardware
at the problem when i do async io
um
i find it a bit harder to program uh
async await keywords are fine right
the thing that's a little bit hard
when you use
examples of this
yes this is a good example
this is the equivalence of requests.get
in an asynchronous way right i'm having
to use uh
yeah i said we didn't have to use other
libraries here um
with that async io essentially you need
to introduce because we have to be more
intelligent right we have to think we
have to write different code uh you kind
of have to introduce non-blocking
versions of everything that you already
use right
so sleep becomes async io dot sleep
right
um and all this kind of stuff so it ends
up having this kind of weird effect of
both uh maybe i can open a script so you
guys know what i'm talking about
um both
now all my code
has async in front
right which is fine i mean it's not that
big a deal um
i now have to use special kinds of
things that i already do i have to sleep
in a certain way i have to make network
requests in a certain way i have to read
and write to the disk in a certain way
that's this is us being a bit more
intelligent
and then some
you know
you actually have to run the program a
little bit differently this kind of
isn't too big a deal you can kind of get
used to it but this is the real annoying
one uh having to rely on another library
to do this having to make the decision
on what to do
you obviously get a benefit from it it's
not that it's um
you know not
not worth it but compared with
multi-processing which is just like okay
if it's a map it's already done
uh asynchronous program requires a
little bit more
uh things to uh think about
um
a final challenge
that kind of destroys us being able to
do these examples of jupiter is asyncho
is already running in a jupiter notebook
so you have to use a script
uh which i think i can do
here
um
so that kind of happened reasonably
quickly
but
essentially what's happening
is
we have these long running tasks these
are like our i o bound tasks this is me
waiting for the network waiting to read
and write from disk
and essentially these three tasks
instead of running sequentially
they run at the same time right so
that's why i get one one one two to two
right i don't get one two one two one
two right and this is why the whole
thing uh runs in a single second right
so
all those three sleeps that i did i kind
of did them in parallel right
on a single thread and that's kind of
the benefit or the use case of async io
i don't want to you know throw more
cause at it i'm actually just waiting
let's just be a bit more intelligent and
kind of uh do things this way
um
cool
yeah so exercises again i'll kind of run
through them super quickly there are
answers to these ones as well
um
yeah i
have to think a little bit about how
long to do this maybe 20 minutes as well
i think
and the examples are there's some cpu
bank call code
in
here
it's just doing i just tried to think of
some things that will take cpu a
reasonably long time
uh and the task is just to take this and
and multi-process it
you can see there's kind of this nesting
of loops i'm actually not sure what the
best way is to do that uh whether they
should be nested or not or you can kind
of flatten them out into a single thing
and run in parallel
i'll kind of let you guys take a go out
of it as you want
and then the last one is
uh i o bound problem
which is just downloading some high
resolution images from the internet
you can see here i use request.get
right
because we're doing this in an
asynchronous name we need to think about
replacing this right with a non-blocking
right get because this gets blocks at
the moment right the thread sits here
and waits for the request to come back
whereas what we want to do is
essentially do this asynchronously
send out the network request and just go
do something else while we're waiting
this is this asynchronous programming
um
yeah and then i think the final example
is kind of the motivating example for
the next section
so
uh
the exercises to use both
multi-processing and or async io kind of
as you like
um on kind of a you know completely
malformed problem where things are kind
of you know there's a whole bunch of
stuff happening
this example is the one we will take
through into the next section which is
running stuff on many machines and on a
cluster and stuff like that
um
cool so i think i can give you guys till
maybe five two or so i think that's good
um
ah yes true yes so what i would suggest
if you if you want to make these
problems a little bit easier just uh
yeah just delete a bunch of days
you know
it's fine if you find it it's taking a
while and vice versa if things are
running too quickly
uh you know if you're finding that
multi-processing actually isn't worth it
because it just runs quicker without it
you can just kind of do more things in
your multi process essentially um
yeah so this is this idea of fixed
versus variable cost you might not be
quite hessing the the trade-off uh
it's possible that's kind of why there's
lots of downloads here
any other questions or
but yeah i think just to summarize the
whole lecture it's cpu bound problem
multi-processing io bound problem async
oh and that's a
if you take that away i think you're
good
so
um
foreign
you
going
nice
spot on navy guy
um
what i'll do is
i'll just run through two of the answers
um
there are no books just weird
uh
yeah just run through two of the answers
uh just so everyone's on the same page
um
this cpu bound problem we had
which
was kind of ended up being these
multiple
for loops oh actually no sorry it's uh
apologies for the structure of this code
um
yes this is our cpu problem
uh you know we have a bunch of images we
want to do some stuff on here we do
things on each channel of the image
that's just to make it slower
um you could obviously vectorize that
um
yeah so if i was to think about kind of
rewriting this uh to use just use
multi-processing uh this is kind of what
i did i kind of made a big long list of
all the um images in the integer
channels and then just multiplies across
that
you kind of have to do two loops right
you loop here and then you loop here but
i kind of figured that this probably
isn't that hard to do um you know it's
just making a list but you know list of
tuples um and you still kind of get the
ability to you know parallelize across
that really difficult
uh bit
um
yep and then
uh the i o bound problem uh which is
just waiting for these images
i bet no one got
any of these
because they're they're
big images
uh the naive way to do it you know i
just look over the images you know i do
a synchronous
request
you know to get the data and then just
write it to disk
uh the
if you wanted to do this asynchronously
um you can see you end up having to do
quite a bit of stuff right so we have to
introduce this asynchio.run right we
have to run the code differently um we
have to define
well i think we make two
methods
yes so this is kind of like my main
method you see that it's just called
main in other
i think at the other async example
and here i just gather you know all the
things that i want to do right so you
can see already we're having to do a
bunch of stuff right uh that's kind of
annoying
um you know where to define multiple
functions here you know when we just had
kind of one before
uh and i've also introduced this httpx
uh to do an asynchronous request rather
than a synchronous request
um which i did with uh request.4
um
yeah
so that's how you would uh kind of
change that it does run quicker too that
the problem is it's just difficult to
run anything um
so now we can move on to the last uh
notebook
um which i think for some of you will be
the interesting one
um for me it's the difficult one
and just to kind of give you guys
uh an understanding of some of the
challenges that i had
last night um with this when this loads
up if it does
um
cool so uh third network final notebook
i want to give you guys kind of a brief
overview of other ways to do this in
2022 there's a bunch of ways to do it
one of the reasons is that distributed
compute is a very general thing
and
lots of things can be looked at as
distributed compute
so yeah i'm just going to talk about
some of kind of my opinions or you know
understanding of some of the things that
people use
and then we'll look at a very specific
stack
of four things
which isn't great
three of them require an account
so i don't know whether anyone else will
be able to get this working i'm happy to
help people uh you know understand how
to get stuff working if you want to sit
here and do it um totally fine also
happy to you know have a chat afterwards
about things but this is just one way to
do things uh and it's kind of an easy
way to do things too um
[Music]
so
why distribute computers over many
machines
uh
fundamentally there's only so much you
can do on a single machine right uh and
essentially what we're saying there is
there's a limited ability to vertically
scale right
the largest instance you can get on aws
you can't get bigger than it right um so
if you're kind of
pushing up against the limit of either a
you know a cpu bound thing or you know
you need more memory on a single you
know a single job at once
right
you are fundamentally limited there
whereas if you can distribute compute
over many machines
then you can use many many small
machines right this is horizontal
scaling
can also be cheaper you know maybe
and you get this fault tolerance because
essentially most of the distributed
compute things that we'll talk about
um
already have to deal with okay one
worker dies right so you kind of get
nice fault tolerance for free whereas if
you're just running one big ec2 instance
and it you know fails it kind of you
would need to engineer that fault
tolerance and
uh yourself so you kind of get a bit
more resilience
you should hopefully get more resilience
with
a cluster
um
right so ecosystems are doing this
historically spark has kind of been the
way to go
um spark wrestling in scala you can
accept with with access it with python
pi spark
uh lots of data scientists are using
data bricks to do this now aws glue i
think is also running spark
um or something spark-like
uh
yeah
a lot of people don't like spark i don't
like it personally because i don't
really know scala i don't want to deal
with java um and yeah all the times i've
had the spark have have not been
particularly fun
um
ray and dusk are kind of more python
focused
uh ray is written in c plus
technically but very much feels like a
python library
to ask i think i don't know if it's
written in python at some point you you
have to kind of let go of python it kind
of depends on where uh but ray and ask
are kind of two ways to do the same
thing
um you can kind of create these uh dags
you're essentially creating decks
directly acyclic graphs which i actually
don't talk about
but these are kind of two ways to do it
they kind of do roughly the same thing
ray i think will run on dusk uh as well
you know so they have a good
relationship um you can kind of have a
look at the two i went with dusk just
because dark plays nice with coiled and
prefix
but ray ray is a fine tool as well rey's
kind of differentiation is a
it kind of introduces idea i don't know
introduced it but really emphasizes say
actors or stateful um
distributed compute
um whereas task is kind of more
functional you know just running
functions but there is actually ways to
do state and dusk
uh tensorflow and pytorch
you know you can look at uh
obviously a gpu is massively parallel
already tensorflow and python will do
multi-gpu stuff i'm sure it's pretty
hard fundamentally there you're you know
running c plus plus again python
bindings
uh and then there's probably a bunch of
other things heaps of things i don't
know about
you know just running lots of lots of
lambdas and parallels you know you're
distributing compute that way
um you know a bunch of different ways to
do things
the stack that i'm going to try to
demonstrate here we'll kind of see how
it goes uh is
dark coiled prefect and ec2 and i'll
kind of introduce what these things are
so dark is kind of like the core
uh execution framework right so
dasc will you obviously have to write
your
program in a certain way
we're not going to write any dusk we're
just going to write prefix and ask we'll
get dusk for free
but low level dash code is uh
is
not something i've written and not
something i you know i would
ideally you're never right you're using
dusk but you're not having to write dusk
is kind of what i'm trying to do here so
it's a fundamental part of the stack
but we will never ever talk about any of
the stuff right it's all kind of hidden
uh inside the way we're using dusk with
prefect um but the way to think about
dark is kind of like the core of the
stack
it's responsible for creating the graph
executing the graph managing the cluster
and all these kind of things
but we will never really see it that
much
coiled
is
essentially only exists because aws is
hard
so all that coil well not all called
coil does for us
essentially takes your aws account and
will set it up to be able to run das
clusters so all the aws permission stuff
internet gateways vpcs
um you know to build a docker image for
you from your requirements file and
stuff like that
it really tries to take away
all of the sort of
yaml hacking cloudformationy type stuff
that you need to do a lot of to get most
things to work on aws
we could not use coiled you can
you know essentially build everything
from scratch yourself in aws
in my experience that takes around a
week or two um so
uh
whether you want to go through that week
or whether you want to introduce a
dependency on a third party
tool an account is kind of up to you
right but uh we're using it here just
because it makes things a lot easier but
essentially it's just doing uh
infrastructure management for us that's
all right if aws didn't exist called
wouldn't exist right it's very kind of
tied it does gcp as well google's um
thing
uh
prefect so
prefect is a
interesting tool it's kind of uh
more for it's kind of a bread and butter
i would say is a batch etl kind of
classic data engineering work
um you know it's it's a data
orchestration
workflow management pipeline uh tool
uh scheduling monitoring all this kind
of stuff
is kind of what it does well
um
we i'll give you a look at kind of some
of the scheduling in the monitoring but
you don't really
we won't be using that at all
essentially we're just kind of using
prefect as a wrapper around desk and
i'll show you that now uh what's
happening
so
this is uh
i will try to run this on a cluster and
just kind of see
what happens
where is my underscore
um
i'm just going to let that sit in the
background and see
i've been trying to run
trying to run things when we've been
here and getting some errors i haven't
seen before i'm also struggling to sign
into
pretty much everything
so that in in the background is just uh
please sign in one thing that's really
interesting i can't get access to ec2 at
all here which is a little bit worrying
so if the cluster kind of stays around i
won't know about it
um
[Music]
let's
start out i'll find out when i get home
uh let's
go through all the stuff
all right we haven't gone through it
did i have the latest cell
i think i deleted us uh
hold on
sorry i just lost uh some stuff that i
should have
um
[Music]
two minutes ago
quilt here we go i think i yeah deleted
this somehow uh and this is actually run
which is good
okay i'm not going to run these again
i'm just going to show
you the results and the code
so
we're introducing a bunch of tools here
so um
it is a bit difficult to kind of
understand everything that's happening i
usually wouldn't
teach at all this way you try to
introduce things slowly and blah blah
blah but you know we don't really have
the time
okay
this script here uh source.naive right
i'm just running it from the notebook
you know but essentially i'm just
running a shell command here
this is the naive way to do the task
that we want to do this is the task from
the end of the last exercise right
uh i have some urls that i want to get
data from it's a big zip file of
electricity prices
um
so i go and download that url
i save it to disk
and then you know my next step i read up
that data and i do some work on it right
sort of very generic data pipeline i get
some raw data and i do some work on it
and stuff like that all right so that's
a naive way to do it this is just normal
python it takes about 15 seconds
if we look at let's convert this code to
what is it called naive dice prefect
to just use prefect and ask right so
we're not using coiled we're not using
aws we're still just running on a local
machine right right we're essentially
setting up a das cluster on our local
machine
um
and to kind of do this
uh we need to introduce prefect and we
need to introduce that this das task
runner this is as much task as you'll
see right
we'll show a little bit more detail when
we actually show the cluster but
basically this is you using dusk
the majority of the work that you have
to do as a programmer here is
introducing prefect um and essentially
prefect we have this idea of flow which
is kind of like the global job you know
there's one flow with many tasks
so i have a flow here i have a task here
and i have a task here so my previous
program is now two separate tasks
uh it now lives in a single flow this is
just in main
there's some slight difference in kind
of how we run things we need to do dot
submits rather than dot run
but by and large the way that i kind of
see this at least is you take your main
flow
your main function that becomes your
flow and any kind of sub functions that
you're calling just become prefect tasks
right
hopefully that makes sense i appreciate
this is a lot to introduce and i've kind
of only just started
but essentially all that we've done
there is uh just introduced prefect okay
let's run it on a das cluster
and i think
we do get
i don't know if we get any performance
improvement 15 seconds
15 seconds essentially no performance
improvement
we can then uh if we want to stick with
prefect on a single machine uh start to
introduce some asynchronous stuff
right
so um the asynchronous stuff i think you
need to introduce specifically
in terms of parallelism my expectation
and understanding experience with dusk
is that it'll find that parallelism
naturally right so hopefully i'll be
able to show you some stuff running you
can kind of see
but we kind of need to engineer in the
um
the asynchronous stuff especially inside
the function but you can think about at
this level
right when we're kind of telling dark
and prefect this is like a thing in the
graph right
uh it can actually find parallelism
around these kind of things
which is really cool um
right so it's kind of all running on a
single machine i think this one does run
quicker but you know i'm kind of not too
worried about that
um the main thing i'm trying to
introduce here is just this idea of
prefect and dusk so now we're running
prefixing the dusk on one machine
and and that's great
um
let me now try
to run it on a cluster i think we
started on before don't
um
okay this one actually ran
which is good
um
okay so
let me go through the script first
so that's running prefix and ask on a
single machine right that's great you
can do that you know it'll it'll save
you some time you can do things
asynchronously uh you can maybe do
monitoring through prefect and stuff
um but the real thing that we want to do
here we're still working on a single
machine then let's try to distribute
compute across many machines
i apologize for these this is literally
stuff i was doing last night and i just
haven't cleaned it up a lot of these
things aren't needed
but
now that we're working on
a remote cluster we kind of need to
introduce coiled right
remember coiled is doing this kind of
management of aws infrastructure for us
um
rather than just running on our machine
so i've logged into coiled at this stage
right you can see in the
there's a lot more detail in these notes
about how to kind of get things set up
but i've essentially logged in an auth
with coiled here
and if you notice when we ran
uh
our das cluster locally just with
prefect we essentially said use this
task task runner we're saying hey
prefectus
when we go and run on the cluster
we use something very similar except now
we kind of say just go run uncoiled
right so coil then and dusk
here are kind of uh reasonably tightly
integrated or at least integrated
um
and
it does because this is also in the
cluster
so we can have a look at
that script that i'm running is starting
a cluster
uh this is coiled by the way um so here
eight workers i thought you guys were
gonna be able to see this
eight workers
um
so desk has a scheduler and then a bunch
of workers so these are all uh instances
on aws right in t3 mediums
um that are running the compute
this is the the long kind of start-up
time of the cluster blah blah blah
unfortunately i can't show you the
instances here which is kind of the sort
of proof that things are working
um
we can see
if i get access to
it you can get access to the
desk itself kind of has a ui that will
show you uh
what's going on what cpus are doing uh
this might not connect this has kind of
been a little bit okay here we go
it's also possible it connects after the
thing is done which looks like it's
happened so
here are eight workers right eight cpu
cores
um
these tasks here so download uh if you
remember
is this one here
right we have four urls so we kind of do
that four times
um
yeah and then process four so this is
kind of already run and worked
um
which is good to be honest um
right
sorry i'm getting lost
and that's kind of it i mean that that
is uh now our
code running on a separate machine i'll
kind of go through the
encoders second what do we have to do to
get this to work right coiled account
aws account you don't need a prefix
account technically to do this
um
we have to set up the coils and stuff
the coil cluster and stuff like this
uh and introduce prefect and then you're
kind of done
and whether you kind of think that's
easy or not is kind of up to you
but
yeah that's roughly the stack i think
there's another example i can run
which i think is uh
is just the
an example but it kind of largely looks
the same
unfortunately because you can't see the
instances on ec2 it's uh
yeah that's the thing that's um i think
i have a picture of it
yeah essentially you'll see something
like this
your scheduler worker and then just a
bunch of instances uh you know running
in parallel on site running your compute
you know doing whatever it can on your
uh
on your prefix program
and i think uh
yeah there's a bunch of stuff here about
how to kind of do things and how to run
through all the accounts and stuff
the last thing that i will show just
quickly
maybe not
[Music]
if you have prefect and prefix cloud on
top of this and obviously logged in all
these things
um
then
you can see some good understanding of
uh
it's working
okay so now you guys can see what i was
doing last night
um
so uh
to get this kind of uh visibility
or um
this kind of visibility of these jobs
obviously i've been kicking off jobs
just running a script here right
because i have a prefect account and
i've logged in using the shell just like
prefect login or whatever it is
um i'm getting some visibility of what's
been happening
so i'll show you guys my day yesterday
this was my day yesterday
um yeah it goes a little bit later where
was my success somewhere here
um
yeah yesterday was was tough but uh this
is kind of not necessary right this is
just kind of an additional layer of uh
of um
visibility and you know you can look at
the
things and kind of see what's
uh been happening
you know um
yeah here i'm just
downloading two urls so i process
download you know download process
all these kind of things
um
[Music]
yeah
one thing to point out about
prefect
is that it's this is prefix 2. um
they've introduced this new kind of way
to look at the task which i just don't
understand at all
yeah it used to be much better but
anyway that's kind of the stack right uh
computer running on ec2
we're using coil to kind of set up and
manage the cluster right we need an
account and all these kind of things
uh once we have that
uh we can
then you know use something like this
right
we have to be logged in an author coiled
and then just kind of using prefect
almost here as just like a convenience
to let us run dusk and that's it you
know
and that's kind of the stack
and i don't really have anything else to
say
and it's time just about up too
so
any questions or anything i appreciate
that might have been a bit sort of
chaotic uh certainly felt like that to
me
um
but uh
yeah i think that the key message is
just uh
uh
yeah if you wanna do this from scratch
and you don't want to fall around with
aws too much coil to help you out a lot
and yeah prefix is a good way to
get access to the desk i think
cool
awesome do you have any other questions
in the theater
i'll repeat your question once you say
it
ah yeah testing what is what is a good
way to write a unit test for the
infrastructure
uh well i mean uh
i guess something like this ah where do
i have one with um
i mean this could be unit tested i think
this kind of this is almost like
business logicky right
but like
and i guess you can test the download
but if you're talking about
uh those obviously unit tests if you're
talking about testing you know is prefix
running can i spin up a cluster and
stuff like that
uh it becomes more monitoring i think
you know like what do you have running
automatically to try to get stuff to
work i don't know if you can really unit
test that too much because the problem
is you if you have integration with
system tests they just take ages
to run you know spin up clusters and
stuff
does that answer your question
yep
yeah the question is um how would you
compare this with concurrent futures
yeah i'm actually not familiar with it
what is that
third party or no it's in standard
library oh really okay yeah i haven't
heard of it yeah have a look
what was that nick
hang on i'll pass you the microphone
because nick will probably know the
answers to these questions
i actually filed the bug against the c
python docks during this tutorial we do
not cross-promote concurrent.futures
from the threading or multi-processing
docks at all
so yeah i'll look at that this weekend
so the recommendation is um
don't mix don't cross the streams
so nick is saying that for most of that
sort of
threading stuff you're much better off
going with concurrent
you two should chat yeah well i just
said not to do it eh so
yeah
um any other questions
um
this tutorial will remain online won't
it so like because i had to definitely
notice i can kind of yeah yeah yeah
myself yeah yeah sure yeah yeah like i
said i'm happy to give people a hand
feel free to reach out on email and
stuff like that
um yeah and this this last section i
appreciate it's chaotic and people are
probably like what's to ask and prefect
and stuff but uh yeah that's all we can
do in the time
cool
thank you very much everyone
[Applause]
you