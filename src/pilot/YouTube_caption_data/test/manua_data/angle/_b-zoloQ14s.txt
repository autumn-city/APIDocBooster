These are machine learning books, and most
of them have something in common.
This is where we are when we
start our careers in machine learning.
This here is our goal.
This is where we want to get.
And the gap between these two points is
made up by a bunch of different skills.
The problem with most of these books is that they
teach you one particular skill to close that gap.
They're very heavy on theory
and very light on experiences.
And that's where this book, the Kaggle Book, comes in.
This is a book full of practical advice.
I even wrote this here.
So I decided to reach out to the authors of the book.
Here are the authors, Konrad and Luca, and asked
them to share with me their two favorite lessons.
I heard them out, added my own thoughts
to the list, and came up with my
five favorite lessons from The Kaggle Book.
And we're going to be talking about them right now.
And let's start with lesson number one.
Data makes the difference, not the model.
In real world applications, usually the difference between
a model that works and one that doesn't
is the data, not the model itself. Now listen, here
I'm not talking about more data;
I'm talking about better data.
Every single model out there has the ability to
start with features and turn them into predictions.
And of course, there are differences between models.
And you can pick a good model or a bad
model, but generally speaking, better data will have a much
stronger impact on your results than a better model.
I want you to keep this in mind whenever you're deciding
how to split your time or where to focus next.
Of course, every problem is different.
And there are no silver bullets in this business.
This is a bullet.
It's just not a silver bullet.
But most times, you should be able to squeeze
a lot more value by improving your data, not
necessarily by focusing more time on your model.
And I'm going to take this one one step further:
When you bring many people together, when you put
together teams and give all of them the same
data and ask them to create the best possible
solution, something comes up to the top.
Something becomes clear.
The key, the differentiating factor among all
of those people, is what you do
with the data, how you handle it.
And that brings us to lesson number two: Improve—
keep working on—your feature engineering skills.
This is something that many data
scientists ignore for too long. And I get it.
Feature engineering is hard.
It requires a ton of practice and a ton of creativity.
But if there is something that will make
a difference, it's your ability to start with
raw features and turn them into signal, turn
them into valuable information for your model.
Guess what?
The real world is messy. Companies, right now, they're
capturing data or planning to, or they already did.
But none of that data is stored
and transformed in the way you need it.
So the first day on your job is
your responsibility to transform that data and create,
extract from that data valuable information so you
can actually solve useful problems.
And that's related to something the book
mentions, a common mistake newcomers make:
They immediately jump trying to build a new
model when they in fact should put their
time trying to understand and improve the data,
the raw materials, they have access to.
So, yes, data is key.
Better data is better than better models.
And the way to get to
better data is through feature engineering.
With those two out of the way,
let's make a moment of silence
for those of you watching this video
that haven't subscribed yet. Now is the
perfect time to click that subscribe button
before we go straight into lesson number
three: Set up a solid evaluation process.
I talk to a lot of people, and I always
give them the same recommendation: Don't start until you understand
how to evaluate the success of your project.
There's always a specific criteria to
evaluate the work you do.
It doesn't matter what the problem is.
You need a process to
understand and optimize your work.
So even before you start, ask
yourself, what does success look like?
What's that metric I need to optimize?
Now, keep in mind, every time I say this,
people immediately think about a technical way to evaluate
a model, like their accuracy, or precision, or recall.
That's important.
It's just not what I'm talking about right now.
I'm going beyond that.
I'm thinking about a way to evaluate your
solution from a general point of view.
Like is your work any valuable?
Is your work better than the existing manual
process the company already has in place?
Or are you solving something
that hasn't been solved before?
And these are not questions that you ask only one time.
You need to keep asking them.
And that's why you need a process
to constantly evaluate where you're at.
And this, of course, is the
perfect segway to lesson number four:
Systematic experimentation is key.
So you already have a good evaluation process.
Now you need to start experimenting.
It's very unlikely you'll find the best solution for
a problem the first time you try, or the
second time, not even the fifth time.
You need to experiment relentlessly.
The more you experiment, the more
likely you are to crack the problem.
I come from a software engineering background, and
something that I've always found interesting is that
when building software, you constantly find problems where
you can go from zero to solved.
There is a line that when you cross
your problem is done. Here in machine learning
you don't find those problems too frequently.
It's all about continuous progress.
It's all about "good enough" solutions.
And the way you improve, the way you move from
where you are to a better solution is constant experimentation.
But keep in mind, it's not only about
the quantity of the experiments you run.
You just don't want to throw spaghetti
to a wall and see what sticks.
You need to fail fast.
And more important, you need to learn from it.
So before you design experiment number two, you
need to think long and hard and learn
from your previous failures and your previous successes.
And that brings me to the final lesson.
Lesson number five, the one nobody taught you before:
And that's Ensembling gives your model superpowers.
Here is my conversation with Luca, one
of the authors of the book.
And it's funny because he mentioned two things, and the
first one was about data, and the importance of data
over model, and the importance of feature engineering,
and number two was Stacking and Blending.
And he used the word,
he's the one saying they give your model superpowers.
And that's true!
This is something that took me
a long time to understand,
but one of the most effective strategies in
machine learning is using not one, but many
models in order to make one prediction.
So instead of trusting the results of one model
or another model, we're going to put them together
and we're going to use their combined power.
The main idea here is that as long as
these models tackle the problem from different angles, their
combined results is going to be better than the
result of any of the individual models.
So when you're designing your solution, instead
of thinking about this or that, start
thinking about this and that.
And of course, these lessons are
just the tip of the iceberg.
You see, I had a great machine learning
professor that taught me way before I knew
any of this, how to interpret learning curves.
This here is a video you don't want to miss.
It's been years, and I still use learning curves every
single day to understand how my models are doing.
I'll leave you with that.
Go nuts, build something cool, and I'll
see you in the next one.