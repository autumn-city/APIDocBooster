what's going on everybody and welcome to
part 4 of the deep learning with PI
torch and Python tutorials in this
tutorial what we're gonna do is
basically continue on with what we've
got here so we've we've talked about
getting some data which we I think kind
of cheated a little bit but we've got
data we built our neural network we had
passed some data through that neural
networking got a response but now what
we want to talk about is actually how do
we pass through you know labelled data
and actually train the model to
hopefully be able to recognize whatever
it is we're passing so in this case it's
handwritten digits so the idea is to get
this model to the point where we can
show it at digits it's never seen before
and hopefully it can predict and
recognize hey that's a seven or a three
or whatever it is so yeah let's get
started so in order to do that there's
two new concepts that we have to talk
about one is loss and the other one is
an optimizer so when it comes to loss
this is uh this is just a measure of how
wrong is the model so our goal over time
is to have loss to crease so even if a
model predicts correctly you know in in
terms of org max or whatever the output
is even if that's correct
chances are the model was at least wrong
in some way it was it wasn't perfect it
wasn't a hundred percent confident in
any of its predictions and maybe it was
sixty percent confident it was the thing
that it did correctly predict but it was
also twenty percent confident was
something else that's still not totally
correct there's some degree of error
there because we want it to be a hundred
percent confident so that's what losses
and then the optimizer what its job is
is to go through and adjust the weights
based on the loss based on these
gradients it it wants to optimize and
adjust all of the possible weights that
it can adjust in such a way so as to
lower the loss slowly over time and that
slowly over time is based on the
learning rate that we use so so let's go
ahead and make some imports and then I'm
gonna briefly show some awesome imagery
of
learning rate so import torch optim as
optim and now we're going to say the
optimizer equals optimum and then Adam
is going to take for now two parameters
the first is going to be net dot
parameters what's this this corresponds
to everything that is adjustable in our
model so there are things that don't
necessarily have to be adjustable so
there might be layers and your neural
network and this is going to be true
especially if you do transfer learning
where maybe you've got a model that's
been trained on millions of images to
detect classification or whatever those
first few layers are going to be very
good at very small and general types of
image recognition tasks and then the
later layers are going to be very
specific to the exact tasks that you
trained it on well what you could do is
use transfer learning and freeze those
first few layers and then only let the
model or the optimizer adjust weights in
like the last layers and we'll talk a
little bit more about transfer learning
later on but just know that that's a
thing you can do you can actually tell
them Network hey don't calculate
gradients here don't adjust these
weights and and then only adjust you
know certain weights in them in the in
the model but for now we just basically
it's everything because we haven't we've
baited Eve alt is to be adjustable but
I'll like I said we'll talk about later
how you can actually freeze them and why
you might want to do that but anyway so
the first parameter is what what is
adjustable by this optimizer and then we
specify the learning rate we're gonna go
as 0.001 you'll often see this one a
negative 3 as well just means the same
thing so what does that mean what is
this learning rate how does it
correspond to training times and how
well the models are actually going to
learn for that I've drawn this really
beautiful this let's just call this the
optimization curve so the goal is to get
here now in order for your model to
learn and actually get to this point
we're in order for your model to learn
it doesn't necessarily have to get
to that point it could probably get to
you know this point and still do pretty
good still be pretty accurate at
predicting things but the goal is to get
to this point the learning rate in part
dictates the size of the step that your
optimizer will take to get to the best
place
so anytime you pass data through this
normal Network you get a loss it is
entirely calculable to determine what
weights do we need for loss to be zero
right to get perfect accuracy on the
data we just sent that is a simple
mathematical operation we could
definitely do that we don't want to do
that because then or if we did that that
would be 100% we just we're gonna over
fit to this to each batch that passes
through and we're going to just keep
basically overfitting everything that
comes through so we use learning rate to
tell the optimizer optimize to lower the
loss but only take certain size steps
and then over time as you take those
those steps the the part of the steps
that were taken are the the changes that
were made that we're just basically
based on just the data passed will kind
of get overwritten and won't when we
remain as we go batch after batch after
batch what remains for us is the actual
general principles but anyway I digress
let's talk about the learning rate and
step size so let's say you've got this
optimizer and you're telling it hey
learn really fast just go as quick as
you can take huge steps well the problem
is is gonna take steps like you know
this big right and then it gets here
here here and then it just keeps it
can't get any lower than that right so
if you have a learning rate that's too
quick too big it's gonna take these
gigantic steps and it's never actually
going to get to the point we want to get
conversely if you have too small of a
step that you're taking you're just
gonna go bloop and you're stuck here you
never got anywhere so what you really
need is something that's going to take
just the right size step so let's say it
takes steps like this it just slowly
gets down where it needs to get it gets
over all these humps per
Fix but there's really no way to have a
priori knowledge of what is the perfect
size step to get to this point so what
we do generally on more complicated
tasks is we do what's called a decaying
learning rate and the way this works and
it starts off with these gigantic steps
right but over time the learning rate
slowly gets smaller and smaller so it
starts off taking these huge steps might
get stuck in this local minimum area but
then it gets smaller right and then it
gets smaller and smaller and then so
basically the idea is that'll help you
to send this kind of mountain I suppose
and get to where you want to go now for
a lot of problems like I said if you
wound up here even though you could get
to this point you'll be fine if you wind
up here and in the in the tasks that
we're gonna do right now we are not
going to decay the learning rate it just
adds more and more complexity eventually
we will be decaying learning rate
because it's something you're going to
have to do on most real problems in a
problem like this it's pretty easy to
solve problem for the models so we just
don't need to but we will talk about
that and that's what that means I won't
have to draw any more pictures this
might be the last picture I have to draw
for you guys so you're welcome so anyway
we have our optimizer now and again all
that we're gonna do is we're gonna
calculate loss based on the output so
you get the models output you get the
targeted output the desired output and
you calculate how wrong is that and then
we apply that back to the entire network
we adjust the weights based on the loss
and then we just keep doing this we just
keep passing data and then hopefully
overtime loss Falls and as loss Falls
the expectation is that accuracy will
also improve but the model actually does
not we don't optimize for accuracy we
optimize for loss it just so happens
that accuracy follows so mmm let's get
to it so what we want to do is we want
to iterate over all of our data pass it
through the model but we also generally
want to iterate at least a few times
through our data a full pass through our
data is what's called an epoch and we're
gonna say epochs equals three so we're
going to make three whole
passes through our entire data set so
then what I'm gonna do is make some
space here cool what we want to say is
four epoch in range of however many
epochs we have what do we want to do
well we're gonna say fort data in train
set and again data is a batch data is a
batch of features and labels right or
feature sets is probably the better
thing to call that a feature set has
features so you've got your features and
your labels or your targets basically
your classifications so what we're gonna
say is capital X comma lowercase Y
equals data so we're just going to
unpack because data basically is a it's
it's a I think it'll be a tuple I'm not
really sure I think I guess it would be
a tuple someone even corrected me on
this is it a list maybe someone said I
think it was a list I don't know I don't
really use this for data I'm only using
it here because it simplifies it for
tutorial purposes
initially anyways it's a container that
contains ten feature sets and the
feature sets are just picks greyscale
pixel values and then ten targets labels
whatever you wanna call them they're the
class that basically says hey this is a
three this is a seven this is a nine and
so on so XY data so in fact let me just
print Y break print Y oh so these are
batches unfortunately so let's say Y
zero and then hey let's just print X
capital X zero as well cool so as you
can see this is your image these are
just rows of pixels basically that we're
gonna need to flatten and then we come
down here and then you get you get the
tensor hey that this is if we were to
graph this it would look like a four and
so on cool so let me clear that XY data
awesome okay
mmm so every time we calculate or every
time every time
we run this kind of every time we
calculate loss and optimize the model we
want to start with kind of a so every
time we actually calculate and make
these little gradients so pretty much
every time before you pass data through
your neural network what you want to do
is NetZero underscore gradient now there
it could be the case so for example
there's two reasons we batch our data
one is it increases or decreases
training time so it goes faster right if
we train in batches but we don't want to
pass the entire data set for reasons I
brought up before already but we also
like batches because it at there is a
law of diminishing returns here but
somewhere between usually 32 and maybe
128 of a batch size also helps to
generalize it's kind of - two things
going for us so there could be times
where you hat you're on a very weak GPU
or laptop or maybe you're on a Raspberry
Pi or something you're trying to train a
model for who knows why and you can only
pass through one set of features and
labels at a time well this is going to
be it makes it very hard for the neural
network to learn so in theory you could
go around and you could for every 10
samples or 10 things you pass through
the model then 0 the gradient and then
calculate everything all over again
because if you don't zero the gradient
they will just continue getting added
together so I guess PI torch leaves this
in your hands for I suppose niche cases
like where you can only actually pass
one set of features and labels through
your model at a time because you're on a
small GPU or something or CPU but you
want to still get the benefit of batch
training I'm not really sure but anyways
just know we want to start at zero with
these gradients and again these
gradients are basically they're going to
kind of contain your loss like how wrong
were you and then your optimizer goes
through and uses those gradients to try
to optimize these weights so net zero
grab the next thing we're going to do is
actually
past data through the network so output
is equal to net and then we pass X dot
view negative one you could also make
this you could just say hey it's my
whatever my batch size is but in this
case negative one is fine and then it's
28 by 28 so 784 again these are the
dimensions of your image cool I think
that should all make pretty good sense
to everybody
so once we once we've got output what
can we do well we can now we calculate
okay how wrong were we so what we're
going to say is loss equals and we'll
use the functional and then NLL loss and
we're going to say output and Y and
later in the series we can talk about
loss metrics and functions for now at
least as a newcomer that I'm assuming
many people are just know there are kind
of two major ways to calculate loss one
is based on one-hot vectors so the
output of our neural network is actually
a 1 hunt vector right it comes out and
you've got this vector which it's
actually not a one-hot vector but the
hope the goal would be that it was it's
just not but a one-hot vector is
literally just like this array where one
value is on right one is hot one is on
so like something like this
this is a one hot vector and if our
input data or input targets so the
actual ground truth targets if those
were one hot we would probably use mean
squared error that's generally the one I
use and then for regression you would
use probably something else and then for
in this case our metrics aren't one hot
right it's a singular value it's just a
scalar value so when your data is just a
scalar value you have to use a different
loss metric you couldn't use mean
squared error so just know going into it
just assume like for now again we'll
talk more but if you're going if you've
got if your data set is a scalar value
like this it's not a vector right with
just one hot just use an ll loss okay if
your data is a one
hot vector use mean squared error cool
like I said we will talk more on that
and for sure we can get much more into
that like when we do the neural network
from scratch but for now
I don't want to belabor loss metrics too
much all you really need to know is
which loss is applicable to which
environment and what is lost doing
that's it so loss equal okay cool so
we've got our loss now what we want to
do is back propagate the loss so we're
gonna say loss literally dot backward
done this is magical luckily this is one
of the things that PI torch does just do
for us we don't actually have to do it
but you could and again that's one of
the cool things about pi torch is you
could not only can you do it it would be
pretty simple you would just iterate
over net dot parameters and and then you
could do at least stochastic gradient
descent is pretty simple to do I don't
think I've ever I've never hand coded
atom so I'm not really sure the atom
optimizer functionality there but you
could do anything you wanted so you
would just literally iterate over net
dot parameters and you can distribute it
however you want it but for now we'll
just use lost out backward because we
can then we're gonna say optimizer dot
step and this is what actually will
adjust the weights for us and that's
basically it
so what I'm gonna say is for data and
trace it cool we'll just come down here
and let's at the end of this let's just
print loss and this will give us the app
plus print loss this will actually give
us the the lost value I know this is not
what everybody wants to see at the
moment we will talk about doing accuracy
but the goal is to see loss decline so
I'll just go ahead and get that to start
running again we are still running on
the CPU so things might not be super
fast I will be showing how to get on the
GPU and I will eventually be doing
everything on the GPU but just trying to
introduce only a few things at a time so
yeah this is actually taking
surprisingly long I kind of would have
expected at least one output by now
why are you taking so long not too sure
okay so we actually we finally got a
value I don't know that took so long
but anyway this is our actual lost value
for now so the next thing that we're
gonna do while we wait on this to Train
we can actually start coding the next
stuff as this pops out there's really no
reason why we can't do it I'm just kind
of surprised at how slow that is I
really thought this would go faster but
I'm I've done this on the CPU it
normally isn't this slow anyway so let's
say we want to actually calculate I'm
just I'm just trying to think of my head
like did I do something wrong I don't
know but it loss is going down so that's
a good sign so anyway well that's going
let's see how correct were we so we're
gonna say correct equals zero total
equals zero and I know there's probably
way better way to do what I'm about to
do but anyway whatever and then we're
gonna say is with torch dot no
underscore grad what do we want to do so
there's there's two things that we can
do one like I said you can for the
layers in your neural network you could
say hey do not count gradients on these
layers but you also can say with torch
no grad or no gradients do something so
in this case when we act when we're
trying to validate our data we actually
don't want gradients to be calculated
this is supposed to be out of sample
data this is testing data we just want
to see how right or wrong is the model
we don't actually want to optimize based
on this data so we're saying with torch
no grad because we don't want to count
gradients here we just want to know how
good is the network at this point so
we're gonna say with oh and again I'm
not a PI torch expert so just take this
with a grain of salt but I'm pretty sure
historically there's been like whatever
your model is called so in our case it
would be like net dot train I think and
then there was also like net dot eval I
think and what this did was based on
your parent class here I think is where
it was pulling from this would dictate
whether your model was in training mode
or eval mode or
you wait basically to do validation i
Italy I never saw this in the actual PI
torch documentation that I went through
I think that's old like I don't think
that's a thing you need to do anymore I
could be wrong but if you're looking at
people's code historically that's where
I was seeing it in other people's github
code and stuff like that I was seeing
this dot train and it was usually in the
forward method I think I could be
mistaken I forget where I was seeing it
but I was like what's that so I tried to
look into it and see what what was going
on there and I think this has basically
just replaced these two calls I could be
mistaken I'm sure somebody will tell me
if I'm right or wrong there but anyway
just take note that that was also a
thing ooh and at least in in my findings
I haven't found that it matters if I
don't use these so I think it was just
part of old PI torch but you'll still
find it in people's code anyway
continuing along so with proportional
gradient what do we want to do well we
want to say for data in Train Set what
do we want to do so we're gonna say
again XY equals data and then we'll say
output is our network and then it's X
dot view and again negative one 784 or
28 by 28 whatever anyway the size of our
images so we have our output and then
what we want to do is we want to compare
is the Arg max because again our targets
are scalar values but the neural network
outputs an Arg max so what we want to
say is for we'll say I D X I in and
numerate and we'll just enumerate over
the output again there's probably way
better way to do this but we're just
going to do this for now if torch Arg
max I is equal to the index value that
we're on so Y index whoops if that's the
case we'll say correct plus equals 1
regardless we're gonna say total plus
equals 1 and then we'll just print
accuracy and then we
will do correct out of total and let's
say let's do a round here round correct
out of total three then okay so that'll
give us a decimal accuracy so basically
what we're doing is this is this was a
batch of information so then what we're
gonna do is we're going to compare there
probably is a way to compare these two
things I can think of better ways to do
it if like if both were one hot or
scalar values I can think of some
quicker ways but anyways all we're doing
is we're just gonna say hey for every
prediction that we made does it match
the actual target value if it does hey
we got it correct
either way we total so what do we do so
let's go ahead and run this this is also
slow we need to be on the GPU
while we wait on that shout out to a
long term channel members Igor Malan all
faust florian Lynch feed Werther's
original Allen Wang Daniel kooky yellow
Magali drummer wheatgrass njr 1762 in
misc and of course the ogia STUV all the
members the longest term member stou
nose co thank you everybody for your
support fifteen months is basically
forever you guys are amazing
okay we got accuracy of ninety seven
point five percent so we did really well
okay unless we somehow cheated I don't
think we did but one thing I will tell
you is it's really really easy to cheat
with neural networks and I don't mean
actually cheap but to miss something
little so there's lots of ways you can
sneak in little biases without realizing
what you're doing and again the neural
network doesn't understand oh I
shouldn't actually be using this
information if it's useful to figuring
out what the accuracy is whether it
has some had some direct relationship
with the target or it could be something
way more obscure than that like an
imbalance issue or whatever just know
that normally seeing an accuracy this
high should be a major red flag this is
valid for this task but for most real
life tasks you will never see an
accuracy this high especially if the
distribution is like 10 classes or
something like that this is very
difficult to get in this case it
probably is legitimate but be wary be
very wary so so for example as we
iterated the the last batch will still
be stored as X's and Y's so if we just
print X out like I said before there it
is so what if we did import mat plot Lib
dot pipe lot as PLT and then we'll just
say PL TM show and we'll say X 0 and
then we'll say dot view as a 28 by 28 so
we'll get it back to be an image
hopefully hmm and then we'll do a peel T
dot show run it one more time I know
there's a way to do a matplotlib in line
but hey what about ok that's a zero
that's actually a pretty hard that's
like a very slanty zero it'll be
interesting if we actually got this
right but we'll say is now print torch
dot argh
max and in fact we actually could say it
would be the zero with prediction so
output zero I guess but we could also
pass it through so we can say torch shot
argh max of net and then we'll pass into
the network X 0 dot view we need to
reshape it again to be a negative one
784 and then remember we we input a list
we get a list back so we need to say the
zeroeth element cool it's a 0 so it
actually got the prediction right let's
try
x1 and one so let's look at it what the
heck that could be a six or a zero I I
would say it's a zero but that's a
really hard one I've seen some crazy
stuff and he's an image image net or
image 10m Nastasia sets anyway
I would I would be happy if it said six
or zero to be honest with you guys
let's check the UH two here let's see
what this one is let's hopefully it's a
better one one these are like these are
crazy hard but again it got it right
let's do the third index here okay
that's clearly a six clearly a six and
so on we go on like this forever I think
we should move on to the next model it's
very tempting to like open paint and
hand draw digit and load it in and see
if the model gets it right maybe down
the line we can do that like a lot of
people have historically requested
please show us how to actually run a
model on a server so I think maybe I'll
save that maybe we'll have like a little
GUI or something where people can hand
draw a digit and then we output the
prediction or something like that and
that would mean the models running in
the cloud and then it makes the
prediction and so on so I think we'll do
that I know some of you guys really want
to see it it's so just know that
maybe I'll incorporate it that way and
what we'll actually host this model but
anyway I think we've learned a lot of
basic stuff but the problem is with your
knowledge up to this point this was
really cool but you can't quite apply it
yet because we would kind of cheated we
used our own data set also it was like
everything was just done for us
including things like balance issues and
normalization issues like again these
images were already for example scaled
for us so it was the images were
automatically gray scaled and scaled
between zero and one for every pixel
value and so on there's a lot of stuff
that was just done for us that if you
tried to take what you know right now
and apply it to some other use case
especially with imagery but even other
of tasks that you might want to do
chances are you'd have a really hard
time so what we're gonna do is leave em
nest and leave cheating behind and we're
gonna grab we're still gonna grab a
premade data set because building your
own data set is absurd
so we're still gonna grab a premade data
set but its raw images and we're gonna
build a new type of model which is a
convolutional neural network which is
traditionally used for imagery but
actually convolutional neural networks
are kind of taking over in fact I'm not
even sure I'm going to teach recurrent
neural networks in this series because
the things were current neural networks
were being used for like sequences of
data we're actually kind of finding
convolutional neural networks are doing
better so so we'll see what I decide to
do there I really haven't made up my
mind so anyway that's all for now if
you've got questions comments concerns
whatever feel free to leave them below
hopefully you guys are enjoying the
series I'm enjoying working with PI
George I think it's a pretty cool
library it can get tedious to do some of
these things the other thing I'll bring
up if I forget to mention it I probably
will also cover this in this series
there is a library called ignite which I
guess makes the training loop easier
it's that's the most tedious thing with
Pi torch is the whole training loop that
you've got a code all this it's highly
likely you'll make a mistake somewhere
so there is a package for that the other
thing is like there's so much stuff that
we've we've not taught yet because I
just trying to do a little bit at a time
but some of the things that we have to
pay attention to or like as you train
the you know comparing validation
accuracy to in sample accuracies really
important also we probably like to graph
loss over time as we learn there's so
much to learn so much more to go
anyway I think I'm gonna stop it here
questions comments concerns leaving
below you can also join us in the
discord discord GG slash centex
otherwise I will see you guys in the
next video where we have so much more to
learn