As per the documentation we need to specify num_features parameter which is the input size of tensor. 
Batch normalization works when batch size is greater than 1, so an input of shape (1, 32) won't work. 
In most cases you should be safe with the default setting. 
If you pass torch.Tensor(2,50,70) into nn.Linear(70,20), you get output of shape (2, 50, 20) and when you use BatchNorm1d it calculates running mean for first non-batch dimension, so it would be 50. 
