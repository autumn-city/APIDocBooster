welcome back to the second tutorial on the deep 
learning with keras in this video we will try to  
improve the accuracy of our previous model if you 
haven't watched yet the previous video I highly  
recommend you to start first by this one in the 
previous video we used the mnist dataset which  
contains grayscale images of handwriting digits 
and their correct labels from zero to nine we have  
trained our model using two dense layers which are 
densely connected or fully connected and we got 98  
percent of accuracy which means that we were able 
to classify correctly 98 images from 100 images  
in order to improve our accuracy we 
will use the convolutional neural  
network and i will show you how to 
implement this technique quickly with
keras
first it's important to know the difference 
between densely connected layer and convolutional  
layer the dense layers can only learn from 
the global patterns of all pixels but the  
convolutional layer can learn from the local 
patterns for example he can look to the shape  
of the edges to the vertical and or horizontal 
lines and then he can recognize it anywhere  
so let's import the mnist from keras.dataset then 
from the mnist we can load the train images train  
labels test images and test labels in order 
to make sure that keras is able to read our  
images and use them effectively we need to reshape 
our input then we need also to scale the values  
in the 0 ,1 interval another transformation that 
needs to be done before starting our training  
is to categorically encode the labels the 
easiest way is to use keras api which provide  
a two categorical method that can be used to 
one-hot encode integer data let's now build our  
architecture of our convolutional network first 
we need to import models and layers from keras  
our model is a sequential model which is 
appropriate for our example where each layer  
has exactly one input answer and one output answer 
the conv layers consist of a set of filters and  
each filter can detect a specific pattern in our 
example we will use 3x3 filter in the first layer  
we will use 32 different filters of 3x3 and the 
output will be 26 by 26 pixels and not 28 by 28  
due to the border effect of course if you 
want to get an output with the same dimensions  
as the input you can set the padding argument to 
"same" then we use the max pooling method in order  
to reduce the size of our input and also because 
the neighboring pixels in images tend to have  
similar values the max pooling which is a simple 
max operation that select the maximum value from  
a block of tensor in our example we will apply 
the max pooling 2 by 2 which means selecting the  
maximum value from each block of 2 by 2 so the 
output will be 13 by 13 which is the half of our  
input 26 by 26 then we use the second conv layer 
and this time we will use 64 different filters and  
the output will be 11 by 11. again we will use 
the max pooling 2x2 and the output will be 5x5  
and for the last conv layer we will use 64 filters  
in order to use our first architecture 
model with two dense layers we need to  
flatten the output three by three times 64 which 
can be done easily by keras method and finally we  
can use the same architecture of our first model 
with two dense layers the first layer contains  
64 units and the second one contains 10 units 
which represent the 10 digit classes from 0 to 9.
the next step is the compilation phase 
where we need to specify the optimizer  
which define how the model will update itself 
we will use the rmsprop algorithm the loss  
function which measures the performance on 
the training data and we will use the cross  
entropy and the metrics in order to monitor 
during the training and the testing in our  
case we will only focus on the accuracy which 
is the number of the correctly labeled images  
finally we let our model learning from the 
training data using the method fit the argument  
needed are the train images train labels number 
of epochs and the number of batch size one epoch  
is one forward pass and one backward pass of all 
the training images in our case we'll do it five  
times and the batch size is the number of training 
examples in one forward backward pass the higher  
the batch size the more memory space you will need 
so in our example we will select a batch of 64.  
let's check now if our new model performs also 
well on the test images the test data is used to  
see how well the machine can predict new answers 
based on its training as you can see we reached  
99% of accuracy by adding the conv layer in this 
example we have seen how to improve the accuracy  
by using the convolutional neural network but 
let's continue in the next videos and explore more  
functionalities and techniques on deep learning 
thanks a lot for watching and see you soon