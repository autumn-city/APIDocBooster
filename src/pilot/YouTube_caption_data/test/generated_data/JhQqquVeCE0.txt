hey guys you're watching python
tutorials on my youtube channel python
for microscopys
in the last tutorial we had a quick look
at loss functions and again
for regression mean squared error is
quite common and for classification
cross entropy is the most common one
that you use in deep learning
now in this tutorial let's talk about
optimizers
so where do you define an optimizer
again model.compile
loss binary cross entropy in this
example optimizer i'm using adam
okay so what does that mean well
first of all an optimizer updates the
model
in response to the output of loss
function
for example for linear regression we are
trying to minimize the mean squared
error
by actually placing this line
equidistant from all the data points
right so an optimizer updates the model
okay in response to this loss function
so the line is moved
and then the mean squared error is
calculated and then the optimizer is
like hey that's going in the wrong
direction let's move in this direction
so it moves it slightly and then
calculates the mean squared error
and then it's like oh that's that's good
you're going in the right direction
keep going so update move it further
move it further and so on
until it finds the minimum so the
optimizer's job is to assist in
minimizing this loss function how does
it do that
the easiest way to understand this is by
looking at gradient descent i think this
is the granddaddy of all
optimizers this is what how everything
revolutionized the deep learning
uh in general okay so what is gradient
descent so first of all if you look at
the loss as a function of weights again
the weights and biases are the ones that
are adjusted
after every epoch to make sure we are
heading in the right direction
now this is a simplistic case uh showing
very nice
curve here so you start with uh
so let me explain this curve initially
you start somewhere
with certain weights okay that's not
optimal
if you are very close to the optimal
then it takes fewer iterations to get
there typically
but if you're farther away let's assume
and then it calculates some loss
well this is pretty high let me change
this initially this data point
the next step may be on in this
direction we don't know the next step
may be in this direction right
and then it calculates the loss and it's
like oh that's pretty high
compared to the last one so let's go the
other direction other way and then it
goes in this direction
and then it calculates hey loss is
getting better go further
next step and the steps here are called
uh
the learning rate in general okay but
this is it and typically your space
here when you map out the loss versus
the weights
it may not be this uniform you may have
like a hair uh you know
like uh a valley but then a small hill
and valley and so on
so gradient descent is a way of actually
finding this minimum and think about
actually
if i want to find an analogy i'm not
sure how many of you are
hikers out there but think of
hiking a hill uh blindfolded
well you go in one direction you know
that you're going up the hill but your
goal is to let's say find
your way down the hill so you kind of
turn
around because you know what the slope
is you feel it in your feet
and here you calculate what the slope is
okay and then you go in the direction
that actually gives you
towards the minimum that's all this is
now
how big of a step do you take you can
take very big steps
but then sometimes you can feel the
terrain if you have smaller steps
right so that's these steps are actually
uh called the learning rates now if you
look at these two scenarios on the left
hand side if the learning rate is very
high
you'll get to the minimum very fast if
the learning rate is very high
you see from here to here to here it's
probably like just three epochs or
something to get here
but then if the learning rate is very
high you'll never reach the true minimum
because the learning rate is you know
too high you'll never reach this bottom
point
on the other hand if your learning rate
is too small
then you it will take more epochs but
you'll definitely find
you know a very much closer uh
minima compared to a larger learning
rate but the problem is
if this is how your terrain looks like
and then you're blindfolded and you're
coming down
then you end up in this valley and you
think that you're at a minimum
but in reality the global minimum is
down here so you may
end up at a false minimum which means
your accuracy is not good
okay this is not the right answer there
now
there are certain terms again i don't
want to get deep into this but for
example
what if think of this as a rolling ball
that's actually coming down the hill but
then as it comes down it goes
here and comes back and then comes back
and then settles down at this point and
you're like okay that's my minimum
but what if this ball has higher mass
meaning more momentum so if this ball
has more momentum it comes down here but
then it pushes over this
and then it goes up here it goes up here
because it has more momentum and
eventually it settles down here
so in deep learning again i'm not going
to talk about this much
because this is a hyper parameter we are
not going to tune much but
momentum is something that you can
define which exactly does
uh what i just mentioned it speeds up
first of all
the uh this process this learning
process and moreover
it ensures that you're not at these
false minima
or pseudominima okay so this is your
optimizer now gradient descent is
an older version but a new version again
there are many of these i'm going to
talk about only one atom
because this is the one that is very
common nowadays okay
so atom optimizer here is the link to
the original paper
very insightful if you can read this
whole thing okay there's a lot about
this
i'll just summarize a few things first
of all atom stands for adaptive
moment estimation okay and
i should actually go back one thing i
should highlight here
you see this learning rate for gradient
descent that learning rate
is constant okay for adam it's not
constant and i believe the uh
it's it's part of the summary that the
authors actually put together first of
all adam is computationally efficient
apparently compared to the other uh
approaches
uh little memory requirements and uh
well suited for problems that are large
okay for large data sets in terms of
data or the number of parameters that
you are
that you that need tuning and it's
appropriate for
problems with noisy or sparse gradients
and hyper parameters have intuitive and
i just copied and pasted these things if
they don't make sense that's okay noisy
and sparse gradients is
as the name suggests you know you look
at the gradients and they're kind of not
noisy or very sparse
uh the best thing i like about adam let
me put it this way
is i do not have to adjust any of these
hyper parameters
like uh you know these learning rates
and a few other things
and i'll show you the default values
almost everyone uses default values the
tensorflow
when i say everyone all libraries like
uh keras for example
they all use whatever got published in
the original paper so this makes your
life easy you don't have to play with a
whole bunch of things someone else
did the work kind of for you okay so uh
here is the graph out of the original
training paper where they kind of
compared this with a few of the other
ones and you can kind of see
the training cost for adam
you know as a function of iterations is
minimum compared to all the other
approaches
okay so i trust this and i
from almost all the time i actually use
adam for
most applications now like i mentioned
most
popular libraries use the default hyper
parameters
i keep doing this sorry default hyper
parameters
from the original paper and here is uh
are the hyper parameters that we use
meaning
when you select adam these are all the
default
parameters that get actually used okay
so
this is optimizer and again in the next
tutorial i am going to talk about
metrics and uh
so that should finish at least our
understanding of model.compile and let's
also see if there are any parameters
under model.fit
that need a bit more explanation and
then let's also cover that in one of the
upcoming tutorials
so thank you very much for your
attention and let's actually meet again
in the next tutorial to talk about
metrics