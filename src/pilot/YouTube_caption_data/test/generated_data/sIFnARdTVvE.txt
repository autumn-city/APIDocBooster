okay uh let's get started this
is the last class of the semester
um i'd like to congratulate everybody
for following i mean
keeping along uh doing the best you can
and doing
all the practice sessions every week and
the two projects as well
so i hope everybody had a good time the
last
topic is neural ordinary differential
equations or neural ode
in short so let's get to it then
so uh in order to understand your od we
have to first understand what odes are
so
uh a lot of people probably had gone
through
uh mathematics for engineering or uh
in korean kung fu so we did learn
some ordinary different differential
equations
uh in that class uh but still like
for some some of you who might have not
gone through that class or
do not have the background knowledge we
will go through od
uh preliminary knowledge first and then
move on to neural od so in ode
we'll first talk about uh first order
ods because there can be like
you know like high order ods as well so
first order only we'll talk about that
and then we'll
define initial value problem or short
ivp
and then we're going to move on to how
to solve a forced
first order ode or how to solve a
initial value problem ivp
and then after that we'll move on to
real od so it's uh the entire class
today is gonna be a bit mathematical but
uh it's all very
like simple stuff to be honest so uh
hope you guys follow along
so od right so uh
first order first order differential
equations d e it's
uh any problem it is defined as any
problem formula any problem formulation
that follows
this form so it means that the so d y d
t s is y prime so
y prime equals some function of y and
t so t is is the one that is uh
doing the differentiation with respect
to so usually it's time because
differential equations were
first uh or i'm not really sure about
history but it's usually
uh very heavily used in like classical
mechanics
like you know shooting a cannon or
dropping something in
in in the air or something like that so
t is usually time and y is could be a
velocity or it could be
like a position uh some something that
changes over time
so the change over time which is y prime
or the rate of change over time
is defined by some function of y and t
so that's
first order differentiate differential
equations and of course second-order
differential equations will
involve y double prime and third order
will involve y triple prime
such and such right so
what this means is this what this this
equation means is that we don't know how
to calculate
y directly so for example if we are to
uh for example let's say that we are
trying to measure the velocity
of a of a ball like we drop a ball
in midair so it's a free falling object
and we'd like to calculate the velocity
of the ball at certain time t but we
don't know how to do that so we don't
know the is
the solution but we what we do know is
we know how to calculate the change of y
so this is the change of y
over time so what we know is we don't
know what we don't know
is the velocity at time t but what we do
know is how
velocity changes over time or the rate
of change
of velocity over time so this is what
this so yeah that's what what this
uh first order differential equation
means so
there are a lot of types of first order
differential equations uh
this is like linear differential
equations usually take the form like
this
so y prime plus uh some some function of
time
pt multiplied by y equals gt some other
function
over time so that's usually what we call
a linear differential equations there's
also
something called separable differential
equations which looks like this
so all functions that relate all
functions related to
y the one that we're interested in is
multiplied to the y prime the the rate
of change
and all the functions uh with uh
regarding time t is all in the other
side
so it's separated and bernoulli
differential equations looks like this
so there's a high order y variable
y like to the power of n something like
that
but they are all like they're all like
special special cases
of of this equation
so yeah like this so so what we
have here is uh because you can simply
you can simply take this and move it
over to the right hand side and we get
this
so y prime equals some function of
y and t which which is exactly this uh
same deal with here separable de
you put you take this and move it over
here you get this which is also another
sum function of t and y again bernoulli
this
bernoulli differential equation you put
you take this
put it over here and you get this which
is again again a sum function of y and t
so it's all
special k three differential three
different special cases
so yeah uh so example so just
like you know when we talk about
abstract abstract concepts
like different eq differential equations
so i to me it always helps to think
about
like concrete examples so we're going to
talk about free falling objects so
we drop something in mid-air and
and we want to know the velocity we want
to know the velocity of a falling object
at time t
so uh we don't know as i said we don't
know how to calculate velocity at time t
so we don't know how to calc we don't
know what
vt the what we don't know the function
vt
but what we do know is we do know v
prime
uh t which is dv dt
so we do know this we don't know we
don't know this but we do know this
so how do we how do we do this so
oh actually yeah that was a question
sorry about that
so we don't know this but do we know how
the velocity changes over time so do we
know
this because in order to solve this in a
differential equation
paradigm or frame we even if we don't
know this we still need to know know
this right so that's whole idea behind
differentiate equation and in fact
it turns out that we do know how
velocity changes over time
because we do have access to newton's
law of motion
or specifically second law of motion
which is f equals m a
so we're going to use that to derive how
to solve
for v t
right so f equals m a and a can be
rewritten as a uh a which is an
acceleration is a rate of change
of v or time so it's
instantaneous change of of the velocity
and so we can plug plug this
here like this and then we get this so f
m
a and which is equal to the force and
the force
can be written as a function of velocity
and time
so force is something that could change
over time and the velocity of the object
so let's uh if
we are so yeah we're continuing on the
newton's law of motion so we have this
if we do not take into account the air
friction which is
so if we do not take and take that into
account then this is simply
f is simply a constant it doesn't change
over time doesn't change
depending on the velocity it's just the
gravity the gravity constant which is
9.8 meter per second squared
multiplied by the mass m so it's a
constant so
f is a constant but if we do take
take into account the air friction then
let's just say that the
air friction so if air friction is a
force that applies
uh on the up uh in the opposite
direction so the if the
if the ball is falling this way then the
air friction is applied this way
and the force of the air friction is
here it's gamma v v being the velocity
and gamma is
a some friction some friction constant
for some
friction constant
so it's like so the minus is to account
for the uh the opposite direction
and gamma is the friction constant v is
the velocity so it
semantically means that the faster you
the faster something falls
the four the the higher the more
powerful the force
will be or the more powerful the
friction will be
actually there's typo here it should be
friction so the more
the powerful more the more powerful the
friction will be and it'll
slow down the object or it will up
it'll work in a manner that slows down
the object's velocity
so all right so we have we have
have we have this this equation and we
can rewrite this
in this format uh we just divide both
both sides with n and then
so and this is a constant this is a
constant this
well let's just say this is also a
constant so everything is a constant
so besides besides v except for v
everything is constant on the right hand
side so
g equals 9.8 and let's say that gamma is
like let's say that m
is just one so it's one kilogram one
kilo and gamma is
some some some constant like this so the
final
differential equation of the free
falling object with our friction
accounted for is this
so we have and so it is
like the differential equation is some
function of v
and t and here there's no so there's a t
here but there is v
here the v is here so
uh before we actually start to solve
this for so
given this we want to solve this
eventually right so we want to be able
to
tell the velocity of the object at
certain time like
maybe five seconds later or 10 seconds
later 15 seconds later something like
that
but what so let's let's
kind of work backwards actually so what
what if at certain point certain time t
the velocity was 50 meter per second so
we plug in 50 meter per second here
then what would happen then we would
obtain
the rate of the the gradient basically
the tangent or the rate of change of the
velocity at time
at that that instant the instant being
when the object object's velocity is 50
meter per second
so uh it turns out that if you plug in
50 here then it's exactly zero so that
means
when the object's velocity is
50 meter per second there's no change to
velocity so
here it's uh so this is time axis
this is time axis and this is uh
this is a velocity axis and it means
that as time
time goes by when you start
when you're when your velocity is 50
meter per second
it won't change it'll just stick to the
same velocity over time so this red
arrow
the red arrow represents the red the red
arrow
each red arrow represents dv dt
at that time step so it's like this is
the let's say here so here
dv dt when t equals
one so but when v equals 50
they're all zero anyway so it means that
v
probably 50 meter per second is the
equilibrium it's where
it's uh it's when
when the the gravitational force and the
air friction
cancels each other out so there's no
more like change to the change in the
velocity
so it you can generalize this so
if you're if your velocity is 80 meter
per second then that means that
ever like if for example let's say i
mean going back so
50 meter per second is equilibrium
velocity then everything else
will so if you if your velocity is like
higher than 50 meter per second then
it'll
con it'll converge on to 50 meter per
second if
if your velocity is like below 15 per
second then it'll increase towards 50
meter seconds
right so that's why the gradients will
always work towards
like like this it'll work towards 50
meter per second
like this so this is called
the vector field so it's a vector field
of this particular differential equation
so it's just simply what you're doing is
you're just evaluating
this this value at each time step
or but the time step actually doesn't
matter because this this value doesn't
change over time
only changes depending on the velocity
so you just
have the same same
you just have the same gradient
or the same slope across
all time step as long as it's 80 it's
all the same as long as it's 20
it's all the same it doesn't change over
time it only depends your your gradient
or your slope
only depends on the velocity so anyway
that's how you draw
the the vector field so
we can just follow the velo so we once
you have the vector field you can just
follow the trends
to see how the velocity changes over
time so if
your initial if your initial condition
which is
your starting velocity like even if you
drop something in mid air like even if
you drop something in midair
its initial velocity could be you know
it could be
like 20 meter per second like you can
throw your object
downwards to the ground or actually
maybe you can throw your
object upwards to the sky and then it'll
some
at some point reach zero and then come
back down to the ground like something
like that so the initial
initial uh velocity actually matters and
depending on where you start then if you
start at 80 meter per second then it'll
slowly work towards this way when it
until it reaches
50 and it's if you if you actually
just you know just softly release your
object release the object towards
to to to to the ground like starting
your starting initial condition
you're starting initial velocity being
zero then it'll start increasing the
velocity and
slowly until it converges to 50.
so that's how you actually use the
vector field
all right moving on so actually so once
we have this
we can actually analytically solve this
which
you can obtain this particular value so
this
differential equation which is which is
obviously a linear differential equation
first order
it's actually relatively easy so that
you can analytically solve this
so like intuition being that if your dv
dt equals some sum v
then that means that you know uh
your the the derivative of some val
of some variable takes the same form
that
basically so that means that your true
your
your variable would look like actually
uh look like something like like this
basically
actually not t so it would
oh yeah actually it does look like yeah
it is t
so i mean think about it like if you
if you differentiate your function and
you still
obtain the same form like that this is
what what is happening here there is
some constant over here but
the the variable still stays here so you
you differentiate your variable with
respect to time and you still get some
the same form the same variable form
which mean which indicates that it's
probably
some you know exponentially
exponentiated form basically
so you can take that intuition and then
work work it work your way backwards and
then how that's this is how what you get
actually
so you can analytical solve this
differential equation which looks like
which looks like this and there is a
unknown constant c
so there's c here which is unknown
because we didn't specify the initial
condition
so we need an initial condition so like
whether your
v 0 is 20 v0 is 80.
you need to know this and then plug that
in and then work your way
work your way towards defining the
specific value of c
so this this set of problem diff where
you have a differential equation
an initial condition this combination is
called initial value problem
ivp so you need to have this and you
also need to have
v0 defined to some value and that's how
you get ivp and that's how you
end up with a specific solution not a
general solution this
this this form is a general solution
because it has an unknown constant c
right so that was the the primer for a
first order differential equation and
yeah so if if you specify your initial
condition initial velocity to be 48
meter per second then you can
work your way towards getting c to be
two right so that's your final solution
so if this means that if your initial
value
initial velocity is 48 meter per second
then
at certain point at certain time t t
could be like five seconds later
10 seconds later 15 seconds later you
can just plug this value in
to calculate the exact velocity at that
time
so that's your your solution
so we're going to move on to the
numerical solution now
this was analytical solution this was
analytical solution
but assume that what if we can solve
this analytically
so we have to solve it numerically like
for example if your
differential equation first order
differential equation is not linear
it's not separable it's not bernoulli
it's just some weird form that's
hard for you to analytically
analytically solve then what you can
what you have to do is just solving it
numerically
so you have some some
differential equation that has a very
complex form function
on this side then the only the only
thing you can do is numerically solve it
or or you can actually
approximate it to a to a like a more
manageable form but that's
just whole other another like you know
other
topic so this this is all you know this
is computer science basically so it's
it's mathematics it's machine learning
so numerical solution is what we are
actually interested in
so let's just assume that this is no
longer analytically
solvable so we're going to turn to
numerical solution
so we have what we call what let's call
the euler's method
euler's method is the
the oldest numerical solution numerical
algorithm to solve
for solving of odes basically so we have
an ivp
and we have an so iv we have an initial
value problem we have the differential
equation the the derivative
and we have the first uh the initial
condition of y
and the slope of the solution at t 0
which is
the initial point would be this
so we have a initial at
this we actually know we do know this
value this value is a ground truth value
this would
this value was given to us and at time t
0 we can evaluate the slope
at time t 0 which would which you can
simply do by plugging
this value and this value here and here
right so here so that's your your
slope or your gradient at t zero and you
can actually draw a tangent line
to the solution at t zero which is
simply just
this so this is a tangent line you have
y
zero you have uh you have the slope and
you have the uh the t
zero here so this is all you need to
have so
if you have like this is your y and this
is about
this this is your y this is your t and
all you need to do is you just need to
have the slope in order to draw a
tangent line
which will look like this basically so
let's say that your the red line the red
line is the true
trajectory of your y which is your your
target variable like velocity
like y is your velocity so it changes
over time
but what you are interested in now is
that you don't exactly you can't exactly
calculate yt so you don't
have the analytical solution you don't
have the analytical solution of yts but
so you're trying to numerically
approximate it
and what you and your first step towards
that
is calculating the tangent line
at t zero so this is your t zero
this is your t zero and you have the
slope
so you have the slope
is f t 0 y 0
and this is your tangent line
all right this is your tangent line like
this is your tangent line
and obviously you can
assume what i'm gonna do next so this is
exactly what gradient is in
so you take some small step so i'm gonna
erase all this
i'm gonna erase all this
and let's just use red so you're going
to take
some small step towards your tangent
line
and then that becomes your next
solution or your approximated y
one or so here actually
this in this figure they moved all the
way until
all the way to here
so they took a pretty big step towards
this tangent line along this tangent
line
which is t1 t1
so it's a pretty big delta
which is not a good idea by the way so
anyway so you took
a pretty big pretty big step like delta
t worth step uh delta t delta t amount
of step
toward along the tangent line and so you
are here now
so your approximated y one plus y one
hat
and the true y one it has some error
here so there's
there's certain there's a certain error
here this is
this is the error so this is the error
and then what you do is next you
calculate
why what what you would do is you take
f t 1 y 1 head which is approximated
which is the approximate solution and
then take another
take another tangent line which would
probably look like this
which would probably look like this oh
actually tangent line i should
oops sorry tangent line i should draw it
in blue line so this is your
next step would be like another tangent
line like this
so this this slope
this slope is what it's t1
y1 hat and then you take tangent line
and then you move on to t2
you take another big step t2 and this
becomes your
new solution this becomes your new
solution at
t2 t2 y2 head
and this becomes your error now this
becomes your error now
and so you can see that the error has
increased so
apparently a numerical solution will
always
involve some amount of error so the the
key is
the key is to actually minimize the air
and you can obviously
think of a way to do it is simply using
smaller time step
smaller steps so delta t you you you
want to use like as small delta t as
possible in order to minimize your error
so yeah so this is the algorithm for
using
a fixed step now so euler's method is a
fixed step algorithm you need to
define the delta t first so you need to
define
delta t is defined or is fixed and the d
is fixed and you need to fix it actually
yes user given delta d is fixed
so it's simply you just take some step
towards this guy and then take this guy
take another step take another step and
as you can see the error increases over
time
so the at t like the last time step t
the true y t is here but your
approximated y
t is here is here so there's
some error there so yeah you just repeat
this process over and over and over
again
so if you put it put this into a more
like
succinct form then it looks like
succinct form it looks like this so your
final solution at time step t
or like times that large capital t is
your initial condition plus the
integration over time
using your dynamics function or the
derivative function
because this this is also given to you
this is given to you because it's a
differential equation
so you have access to this you have
access to this so you just need to
numerically solve it
the integration is numerically solving
it basically
if you have analytical solution you can
just analytically solve it like in the
free falling object
free falling object example but since
you don't have
analytical solution you need to program
programmatically solve it using od
solver
so od solve being euler's method in this
case euler's method
and the argument for this program is
your initial condition
your derivative function dv dui dt
in your
starting time step or starting time
point and the ending time point
and also actually i forgot but you need
to define delta t as well
because it's a fixed this is euler's
method so you need to
define your delta t like how how like
how fine grain stem you want you want to
take
as i said if you take like small smaller
delta smaller delta t
means higher precision higher precision
all right so this is where uh the things
get interesting because we're now using
computers
machines power to do this integration
for you
so uh yeah so in theory uh
if you just have vector field and an
initial condition vector field being
just
dy dt then you can solve any
differential equation
uh with the power of the computer
actually so you can we can numerically
solve the problem with a computer
there's some so there are a lot of
methods other than just euler's method
euler's method is
is like the uh the oldest the oldest the
simplest
most naive method for solving
numerically solving differential
equation but there's something called
the runge-kutta
could method met it i'm not really sure
how to pronounce this but i'm just going
to call this rk method so it's an arcane
method
and it has better it provides better
procedure better
better precision uh the knowledge method
because what it does is
uh so you have ivp initial value problem
you have the
y prime and the initial condition so
euler's method is just simply
doing a for loop over this just
repeating this over and over again which
is
your next predicted solution is your
current predicted solution
plus h being the delta t some small time
step
multiplied by the uh the dynamics or or
the gradient or the slope
uh but runge coda especially in the
fourth order form
it's not not as simple as this so you
have this
here compared compared to this this guy
it has way more complicated so
taking a step taking a small step is
more complicated than just
euler's method and it consists of four
different
parts so k1 is just simply euler's
method
so you just take this function here you
just take it and plug it in
but the k2 is now the k2
depends on k1 k2 depends on k1 as you
can see here
right here and then k3 depends on k2
right here and k4 depends on k3
so it is iteratively uh like
kind of recursively going a bit further
and further and further based on its own
prediction
and then and then averaging them out you
can see it's averaging
like one it's the the ratio the average
is
one two two one one two
two one and that's why you divide by six
so that's uh
basically how you do a runge-kutta and
uh graphically so graphically it's uh
this is k1 and then this is k2
this is k3 and this is k4 and then you
uh average them out by you averaging
about
by uh dividing it with six and then
that's how you get
uh this part this particular this that
is how you reach from here
to here and you can see that
it is has a very low error actually so
let me just erase some of this
so the blue line is the ground truth
line so blue line
here is your true y
t one and the green line is your
predicted
your predicted y one based on
runge-kutta fourth order and you can see
that
the star here is has very small error
very very small error
like almost minuscule error so that's
the power of rooney but obviously it'll
take more time than simply
euler's method because it is it is doing
euler's method basically four times in a
single step so there's
k1 to k4 so that each involves
the similar form of euler's method so
it's four times as slow as
euler's method actually but it's but
it's way more
precise so there's a trade-off so if you
have a power
powerful computer you can use rk for if
you have a slow computer you can just
use euler's method actually
uh yeah this is the comparison between
uh
rk4 and euler's method and your d y dt
your
your derivative derivative function is y
sine t
squared basically all right it's y sine
squared which is or the orange line so
the orange line is
right
right here right yeah
so that's the orange line and euler's
method
euler's method is the pink line which is
doing pretty bad so initially the error
is like this much
this much this much and and the in the
end the area is like like this much
this is the error which is doing a bad
job but uh
runge-kutta here which is which is
uh the gold line which is the gold line
yeah ringakoda here is doing a very good
job so at
even even at the last time step the
error is only like this much
this is rk for error this is euler
oops this is euler's euler error
there are some other missiles there's
like hinds method and euler's method
with i'm not sure the this is actually
all
german so i'm not really sure what they
mean but at least i know that this is
rooney caught in the zoiler and this is
exact solution
right yeah so that's the power of
runge-kutta so rk-4 so if you
in most cases you should use rk4 instead
of using euler's method
all right moving on so there's a long
history of
ode solvers so there's a lot of ods
holders actually and it has a long
history in mathematics both in
mathematics and physics because as i
said
uh ordinary differential equation
differential equations are
used not in not just in classical
classical mechanics but also in uh in
electric
electric electronic circuits like rlc
circus
you know the rsc rlc circuits can be
uh formulated in second order
differential equations right
so a long standing history and it means
that
there's a lot of like advanced methods
out there and they guarantee
some some you know some guarantee they
guarantee some level of performance
so the in in in short there are
two big categories which is fixed step
size solvers and which another is
adaptive adaptive step size offers so
these are the uh the
some some of the well-known fixed step
size solvers and these are the
uh well-known adaptive step size solvers
we have already take we've already
looked at euler's and runge-kutta uh so
midpoint is somewhere
in between older a dormant prince is
what we what a lot of people use in your
loadings
so that's basically the difference
between two is that
in fixed step size solvers as i said
user needs to decide
when to evaluate f when to evaluate the
derivative function and taking a step
the next step right you know like y1 to
y2 y2 to y3
which means that you need to explicitly
tell the ode solver program
the delta t like how how like how small
how small you want the steps to be like
can like if you want your time step to
be like 0.1
or 0 like delta t to be 0.1 or 0.01 or
0.001
it depends on how much time you got and
how much accurate you want your
solutions to be
compared to that adaptive step size
solvers uh
the algorithms decide when to evaluate f
and take a step so
instead of u giving delta t algorithm
will decide
and basically the high level idea is
that if at some region there is smooth
dynamics for example
like if your solution looks like
looks like this then it then
at this region there is very barely any
dynamics there's
barely any change so in this region
you'll take large steps you'll go like
boom boom boom and then but in regions
like like this
it has very it's a very fast changing
dynamic so in this case
you don't want to go like like like this
and this and this right so that that
would be a bad idea so you want to take
very small steps like like this like
very small steps small steps small step
like like
doing a gradient system basically right
so that's that's basically that's the
idea so
uh internally i'm not sure how they
actually work because i haven't
like you know taken take a look at the
uh the source code but probably
it has a it has some like if and else is
uh so it
uh it internally checks its solution and
if it
is not satisfied with the solution then
it will go back
and then take another step or something
like that basically so it's a bit more
complicated than
uh than the than the fixed step size
solvers but
they internally they use like either
this or this like
dorman prints will certainly use like
rk-4 to take some step and then if it's
not satisfied it'll roll back and then
take
smaller step and you know compare and
compare and compare basically
all right so yeah uh before we end uh
before we end uh the differential
equation
primer there's also like second order
differential equation and just
just short introduction so the general
form of second order differentiate
equation would look like this
so some something
actually this should be all like p y t
q y t r y t and g y t
yeah i'm sorry about that but yeah this
is yeah but
this is okay rather general form and
usually we don't deal with this because
this is already too hard to deal with
it's just hard to solve this
analytically or
so this the only thing we can do is
probably just say numerical solution
so usually what we deal what we see in
physics
problem is is this things these things
so either it's homogeneous or it's not
homogeneous or there's some
non-constant term on the right-hand side
and yeah of course second-order
differential equations can be solved
numerically as well
all right so moving on to neural od now
so we'll first take a look at the
resonant because resonant
is kind of the motivation for coming up
with neurology or
at least it was written that way in the
paper so just a refresher so resnet
the current the next hidden state or the
next
latent latent state will is
determined by some value uh some some
non-linear activation function and uh on
the weight matrix the bias
and then the residual connection here so
this is this is
typical your typical nonlinear layer
actually let me erase that
so this is your linear layer this is
your linear layer
this is your non-linear function non
nonlinear activation activation function
and this is your your residual
connection
right so this is your resonance so hope
this is
pretty much clear to everybody and we're
gonna abstract this
abstractify i'm not sure yeah we're
gonna
yeah we're gonna abstract this away into
this form
so it's just some function basically
it's just some functions and
we still need your your the current
latent state
at time time t or or layer t
and you still need this weight which is
just your weight matrix and the bias
we still need the parameters and this is
some function representing it could be a
linear function it could be nonlinear
function whatever
some function basically and you still
have the residual connection so what
we're going to do is
we're going to rewrite this in a couple
steps so first of all we take this
move it over here so we get this guy and
this
can be written as as this this is re
divided by one so it doesn't make
doesn't make any difference right
dividing by one doesn't make any
difference and we take a look at this
guy
so take a look at this this and then
change this to delta
delta and delta equals one so nothing
still changes
it's the same same same here and same
here and now what we do
is we take delta and push it to the
limit
zero and you take you see this guy
and what what what is this guy what is
this this guy is exactly the different
derivative it's the differentiation of
uh of the uh the function h or or the
latent state h so h is written as a
function now
because we're doing a derivative so this
is your your your final
uh this is like rewriting resonant
as a a for some other form basically
some in like continuous form because
resonant is a discrete it has a lot of
layers so it has
discrete discrete layers but by pushing
the uh the
the the the gap between layer
into infinitesimally small value to zero
you can actually make it into a
continuous
neural network basically so that's what
what this means so
you can you want to compare between you
want to compare between
this guy and this guy
so here you also you can also see that a
theta t
is now just theta because what you're
saying is the rate of change of your
latent state
is dictated by some non-linear function
and the function doesn't change and the
function i mean the function
the theta is is fixed and now the
function receives t
now so it's a bit more like in the ode
format so let's take a look let's
compare between the two so this guy
versus this guy
so this guy has l discrete layers like
resonance 50 has 50 layers whereas 100
has 100 layers
this guy doesn't have a discrete layer
there's infinite number of layers it's a
continuous
continuous architecture so it's a
different different paradigm
and the latent state changes discretely
which means that
once you move from one layer to another
it'll change
it'll make a sudden like change like it
it'll look like like the
if you the state will change in a
discrete manner over
over different layers but this guy the
latent state changes continuously
because
what you have is a rate of change of the
latent state over time and you just
simply need to
integrate it to get the change right
right so the latent state dynamics the
in state time how the latent state
changes is controlled by
l different number of functions which
means that there's
layer number one layer number two layer
number three so this is
l1 l2 l3 all the way to
l50 if we're talking about risen f50 so
50 different functions
so latent state dynamics controlled by
50 different functions but here
latent state dynamics controlled by it's
just one function this this function
this function
which is the uh ode dynamics function
right so this you can see the clear
distinction
the the comparison between the two so we
all all all your own neural network
models follow this format but actually
now we can generalize it or
not sure if this is generalizing it this
is because it is in a way
a bit more limiting uh but we'll talk
about that later but anyway so this is a
different paradigm different way of
viewing
uh your neural networks
so this is interpreting resonant and
into or viewing resonant as a ode
uh yeah and we talked about vector field
so this is the vector field in resonance
so this is uh
depth one depth two depth three that's
four depth five and
your vector field only is discrete
so at each layer it has its own vector
field or the chain
how it changes the latent state but here
in the continuous format that has
it has it has a continuous vector field
basically
so yeah moving on so we can actually
change we can actually apply the same
logic to recurrent neural networks as
well not not just
resonant but also neural net recurrent
neural networks rnn so we're good we're
just going to look the vanilla rna
not touch the gru so just the rna so r
in rnn the next time step hidden layer
is dictated by
this formula here so this is the
equation so there's
nonlinear function activation function
such as 10h and then there's
u for changing linearly transforming the
current the previous hidden layer and w
for linearly transforming the current
current input and the bias and the bias
vector
you can actually uh assuming that
u is identity function and f is just
a vector of ones then you can
rewrite this function into this equation
to this equation
so here so u is u is gone
f is gone so you have this and then you
can put this guy into the back
to the back so this is this guy you can
rewrite this like this and now you
have differential equation here
like this so this guy is now this guy
so your next next time step hidden layer
is
current times the hidden layer plus some
change
which is dictated by this function here
and this function consists of inputs
the current time set and the current uh
new input
the t the time step and the theta which
is the
the weight matrix and the and the bias
right so you can view you can use
neural these to actually deal with you
know time series data as well or
sequence data actually and when it comes
to continuous time
handling continuous time neurology
does it better than recurrent neural
networks because as you know rnns
are inherently a discrete discrete
sequence
processor or discrete sequence encoder
as opposed to continuous
uh continuous time series uh processor
which is neural ob
all right so uh yeah neural so yeah this
is the for
formulation of neural v so you have the
function
you have you have some derivative
function or the rate of change
of your hidden layer or latent state
and this is now a neural network
before before in if you if you can
remember in free falling object f y
t was what it was mg minus
gamma v right but
in neural od what we're what we're
saying is we don't know
this what we do know is we're just gonna
model the differential the the
derivative function
with neural network that's why it's
called neural oda so
we are not we're no longer given a
analytical
form of the derivative function we're
just going to use
urlody to model this so what is the
meaning of this in terms of od
that means that we have an od we know
that some problem
for example image classification or time
series classification or
translation whatever whatever we know
that that problem can be viewed as an
ode problem or actually ivp
problem to be to be more precise to be
more correct so we have an idp problem
and we don't know y prime we don't know
that the dynamics of that
that the problem we don't know how to
do image classification or
rather we want to do image
classification but we don't know how to
change the input or we don't know how to
how
how the the rate of we don't know how to
define the rate of change
of the input in order to successfully do
image classification that means we don't
know y prime but what we know
but we want to learn y prime from data
via neural network and back propagation
so neural network being this guy so we
want to model
the derivative function using neural
network and then we want to learn it in
a way that it will successfully
help us achieve do the task whichever
whatever the test can be
so that is that is the spirit of
neurology so this is
a typical example which is a spiral
example so what we're doing is
this here this this spiral is the
true true data it's a true sample
so we have a task that we which we have
a task which is to
which is to learn learn to fit this
spiral data and we want to use a neural
od to do that so that means that we
don't know
we don't know y prime we don't know how
the how the how the spiral changes over
time we don't know how what the dynamics
of it
so we want but we have data we have a
lot of spiral data like this
this this we have a lot of like
different spiral data so what we want to
do is we want to use those data set
to train this guy
to fit fit this nicely
so as you can see as you this is like
epoch like one the z pop two epoch three
e pop four
this is the z part one epoch
two epoch three epoch four so as you
train
your your dynamics function which is the
neural network as you train it using
back propagation
so you can see that it is
fitting better and better and better
better better and better to the true
true true spiral through true time
series
so that's what we want to do with neural
od so once we have learned it
then we can use it to go further into it
or maybe go
go outwards like this so you can guess
how
how the uh how how the data how the
data or how the h
t or y t to be honest also so yeah
so this so once we have neurally
fully trained your low d we don't still
we don't know the true
yt because we don't have the analytical
solution to the yt but what we do have
is
we have a well learned y prime t we
well trained well trained
y prime t we do have this we we don't
have this but we do have this once we've
trained it
using data then once we have this we can
just simply integrate it over time to go
far further in or further out to see how
how y will change over time just like
you know just like calculating velocity
at some
certain time step t we can do we can see
where the trajectory will be at certain
time step t
it's just that we don't know analytic we
don't do it analytically we do it
numerically
so that's why we want to do neural
loading
so yeah so in order to do that we need
to see how we can train or update the
parameters
of this guy of this guy
parameter being this right so let's take
a look at this
so the input state or the the input
to the neural od model is h0 which is
the initial time step so
it's still ivp so we still need initial
initial state
and state then state dynamics or the
derivative function of h ht dht
dt which is this yeah sorry so yeah
the state state the rate of change or
state dynamics is this and
we are going to represent this as a
neural neural
neural network which is typically just a
multi-layer perceptron with some hidden
layers so it's a feed-forward neural
network with
one or two hidden layers with like you
know like
10 20 neurons or maybe 100 neurons it's
relatively a small
small size neural network so that's your
mlp
and the output state so your output
of your your lod model would be ht which
is the last time step
capital letter t can be written as
written as this as i've shown you before
so h
is just h0 which is your initial state
plus integration
over time and since we don't know how to
do it analytically we can do it
numerically using od solver so it could
be oil or silver it could be
runge cotta solver it could be dormant
prints over whatever
and the the argument to the pro that
program or the function is your initial
state
your dynamics function and your
dynamics function parameter and your
initial time and your final time and
actually i also forgot delta t
here you still need delta t somewhere i
mean
if you are to use euler solver if you
are to use arc the fixed step size
solver you need
you need delta t if you're using
adaptive step size solver
you don't you don't need this all right
so let's take a look at the model
architecture so let's say that we're
going to do an image classification with
neural od so
obviously you want to have a some image
so this is your input image and then
you it's probably a bad idea to use
directly in your low d
on top of this so you want to encode it
because this could be like
128 by 128 so it's a pretty it's uh
about 16k dimensional input and
currently neural ods cannot deal with
this level this high
high dimensional input so you want to
encode it or compress it into a
several hundred dimensional inputs like
100
or 200 dimension or 100 dimensions or
something something like that so you
want to use cnn to compress
your image into maybe 100 dimensions on
the output so 100d
so you're so cnn you still need to learn
cnn though so this is still learnable
it's a learnable cnn
it's a learnable conflict but what we do
is you you just compress your high
dimensional feature input
into a lower dimensional feature so that
becomes your initial value in term
in in perspective of your loading so
this becomes your h0
and then you use some some program some
program to solve it
and then you get ht the capital energy
then that becomes your final
representation of your image
and then once you have your final
representation or latent representation
you use soft mix layer to calcul
to classify it into hopefully a dog
so that is your neural lobe for image
classification
if you're doing time series line fitting
if you're doing time series
like mean squared error type of you know
update then you have
this uh time series data so
like the dots are your dots are your
your observation points
so you have these observation points and
then for example let's say that you
once you want you let's say that at this
particular example you start from here
you start from this particular example
here which is two dimensional inputs so
it could be like
if this is your your cartesian
coordinate this could be like
two point zero point five like two comma
zero point five or something
so that becomes your your input so your
h0 is a two two dimensional coordinate
input
and then you solve it with ode solved
like this
and note that there's a difference here
here the difference
this this is zero here in image
classification
your input time step input zero and t
but here in time series your input is
input time steps are zero
1 2 all the way to t and
your program your od solver program
whether it is it is
euler silver or whether it is the
dormant prince whether it is
you dictate how what you dictate
uh what kind of outputs you want to
obtain
from their program so if you dictate
like this then
what you get is you only get h0 and ht
if you put your if you feed this
argument into your program then you will
get h0h1 h2 all the way to ht
and why we do this is because we want to
backprop we want
this is time series so this is image
classification so you don't need any
intermediate
you don't need h1 you don't need h2 you
need only the latent state of the fight
you need only the final latent state
so that you can do classification and
then back prop but here
in time series you want to
uh actually yeah we should have started
from here so i'm sorry about that
not not here we should have started from
here because we're moving inwards like
this
moving inwards anyway so as i was saying
if you're doing time series then there
are a lot
multiple observation points and you want
to hit
all those observation points h1 h0 h1 h2
or it could be even h 1.1
because we're dealing with continuous
time h could be h 1.1
h 2.7 could be h
3.414567
doesn't matter as long as it it's all up
to you like
at which time point you want to evaluate
your age or your
or your state it's all up to you so you
just need to
dictate define that here in your in your
one of your arguments actually so once
you have h1 h2 h1 h is your h1 h2 you
want to hit all this
correctly so you want to take all this
and then do
mean squared error between true so i'm
just going to
substitute this y 0 y 0 with
uh with with this this this will be your
y
hat and there's also y 0. your y hat
one y through y one y hat two
through y two so you want to hit all
these
correctly two and then do it and then
calculate the mean squared error over
all the observation points and that's
why you want to take
a lot of time step you want to feed a
lot of time steps to obtain
obtain this and then do mean square
there over all observation points
and hopefully you will get a nice
looking thing like this
basically all right i
hope this is pretty clear this this is
pretty important important like
this is the this is the only difference
between the two here and here
but that tells a lot like depending on
what kind of task you want to do
yeah so yeah so parameter update so this
was forward propagation
and so you do a one for you do forward
you do backward and then you update the
parameter right so
now we want to do update now we want to
update the parameter and we need to
update
this theta so that f learns the correct
dynamics
so far we actually we didn't we didn't
really know if f was
learning a correct dynamics or not it's
because f is usually an mlp
randomly initialized right so we want to
update that so that
it conforms nicely confirms correctly to
the given data's
dynamics so you want to update theta
here which is here
here you want to update this and if you
want to update this that means we have
to go
we have to backprop through ode solver
the program
because theta is just a argument
to this program all the solver program
or functions so
we need to in order to actually in order
to update this
and also update this for for this
particular example here we don't have an
encoder but here we have an
image encoder so we not only i'll need
to update this but we also need to
update this guy as well so in order to
do that we need to go full
back prop all the way here
so can we do back for can we can we
backprop through this
this program ode solver that's the
question
and it turns out that for us for some
solvers we can't do backprop through
them
so euler's method we can backprop
because euler's method is after all
just a
yeah i'm sorry about this yeah euler's
method is just simply
just a another form of gradient descent
it's just
taking a fixed time fixed delta t
and then evaluating your function and
then up and then
summing it up so basically your euler's
method is nothing but just
multiplication and addition that's it so
you there's no
there's no reason we cannot do backdrop
so if we're doing euler's method
it only involves involves this involves
mult multiplication and summation
this is like actually more add up so
add multiplication operation and add
addition operations so
we can definitely go do back prop
through euler's method
and in the same manner we can also do
back props for room get outta because
record is just doing euler's method four
times
in one step so that also involves just
multiple age multiplication and
addition double pre-five i'm not really
sure i haven't
my memory of my memory sort of thing
right w5
does involve if and else if and else
but uh pi torch
is pretty flexible so if you even if you
use if and else doesn't you can still
go do backprop through doppler5 so i
think yeah
so for some solvers we can backprop so
these are the ones that you are
kind of like you can't achieve good
results
by doing backprop through these solvers
some
other solvers it's probably not a good
idea so i i
introduced some other solvers in the
previous slide right and
some slides ago so for some other
solvers it's probably not a good idea
because it's numerically unstable
so it's like pretty a complex involved
ode solvers they probably have a lot of
like you know
very intricate working parts so you
don't want to go
you don't want to you don't want to do
back prop through them it'll be
numerically unstable so
in that case what can we do like if we
want to use some solver
that is not friendly towards backprop
what can we do
so so uh
actually yeah oh not just that actually
doing back props through this song
like these solvers are friendly towards
backprop but
they also have have their own problems
so this this has their own problem this
also has their own problem let's do
let's take a look at that first so we're
just gonna
we're just gonna ignore this for now so
for some solvers we can do back prop as
i said
so here the these two are the fixed step
size over this is a
adaptive size solver so as i said for
these two solvers we need to set the
number of function evaluation function
evaluation meaning that you need to
evaluate your derivative function and
then take us
and then calculate the slope meaning
that you obtain the slope and then or
the gradient
and then you take a small step towards
the gradient uh in
doe pre-five dormant prints the the
solver
definitely adjust number of function
evaluation for you so you don't need to
worry about that but
given this knowledge given this
knowledge
the more nfv the more the smaller step
we take or
the more number of function evaluations
we conduct
the more accurate the solution will be
obviously right so like doing you know
like doing gradients and the smaller
step we take the more accurate the
solution will be
so what happens if number of function
evaluation
reaches like one million times what what
would that mean
what what does it mean to what does it
mean to take
one million small time steps to achieve
a very accurate solution
in your very accurate od solution what
does that mean
that means that your vram will explode
because one million
number of function evaluation and then
doing back prop on that is like having a
one million
layers in your resnet it's the same
thing
so we're doing back prop through euler's
method or roon get caught up
if if we're doing record it's even worse
actually but
let's just abstract everything always
just so we have od solver and we just do
we do
number of function values one million
times and we're doing backdrop through
that that means
you are going through one million layers
of resonant so and one million layer is
surely it'll it'll explode your vram
because you don't need you can't
contain all the activation values of
your 1 million layers in your vram
so that's just impossible so that that's
the problem with
backpropping through these solvers and
yeah resonant is only 50 layers and can
you actually can you
do you really want to do 50 1 million
layers that's just crazy
so how can we how can we use neural od
without using too much vram for
background so
how can we avoid doing backprop through
these solvers
and still train your theta
your derivative function parameters how
can you do that
so there that's when a joint sensitivity
method comes in so
the neural of the paper in your 2018
uh the best paper which got the best
paper the
the contribution of the paper is
actually this part
people already knew that od people
already kind of knew
that neural networks could be viewed as
ordinary differential equations and they
already knew that they can use backprop
to train the the derivative function
but then it is not scalable because of
this this problem so
the the the authors of the original
neural view paper in 2018 europe's they
came up with this
this technique to avoid that problem and
still be able to train your neural de
model
so here what so before we jump into this
what what do we need to actually update
the parameters
so we we need this basically right so we
need this and we we we also need this so
this
this is the gradient of the loss with
with respect to the input state
so we we first need this in order to in
order to
do image classification we just need
this in order to do time series we
still we we need this actually we need
all the intermediate observation points
so the the this the
joint system the the spirit or the high
level explanation of a joint sensitivity
method is
using od solver so we
in the forward in the forward prop in
the forward prop we use all
we use od solve to do that right we use
od zone to do forward prop but
in backdrop instead of doing backprop we
use something called a joint sensitivity
method
which enables us to use od solve again
backwards in time to obtain this
backwards in time so given given
given
given ht because we do know this because
ht is the last
last layer just before the softmix layer
right so we do know this we can
calculate this but the problem is
we in order to we start from here and we
need to go back all the way to
h0 right and in in along the way we
might need this as well so along the way
we might need
like uh h1 all the way to like
some some some some hd basically
so we need we can start from here and
then using something called a joint
sensitivity method we can
work our way back work our way backwards
all the way to the starting point and
in doing so we use od solve again
the same program that we use to solve
forward process
we use to solve this guy and and and
and this guy so we use the same room
cutter for or do pre-five or
older we use it again so that's
basically the the spirit of joining
a joint sensitivity method i'm not gonna
go into detail how we can derive that
it's just
very mathematic not not too much
involved but it it involves like
lagrange multiplier and
all that so you can look it up you can
look up the uh the original paper if
you're interested in that but basically
as i said the spirit is use od silver
again
but backwards through time starting from
large t
to to the point zero time step zero
and then obtain this guy and this guy
we need one more thing actually we all
we also we need this to actually
update the parameters of the derivative
function right we definitely need this
not only this but this so this is
gradient of the loss
with respect to dynamics function
parameter and how can you
obtain so these these we can obtain with
the joint sensitivity and sensitivity
method
this how can you obtain this what we do
is we solve this guy
and this guy at the same time together
at the same time so
when we call od solve backwards when we
call od solve backwards
to obtain these guy we also plug in
some additional variables to obtain this
at the end so we can just do it in one
go
so this is your final algorithm a joint
sensitivity method algorithm so
it's a reverse mode derivative of od
initial problem so ivp
so it's a reverse it's a reverse mode
so you put you you set up a certain
like variable you pack this you pack
these information into the variable
and then uh set and put this
and also you you you obtain this all
dynamics
this guy you set this function octane
alg dynamics and then put
this here and put this here
and then call od solver backwards so you
start from t1
and then you go to t0 and then you have
the you have the theta
which is the derivative function uh
derivative function is parameter
and then you obtain this you obtain this
because once you solve od solve you'll
get this guy you you start
you start from here you start from here
and then you you're solving backwards so
you obtain this afterwards
but along the way along the way you get
these and this guy at the same time so
this is what you
want this is what you need to update
your cnn encoder
and your derivative function parameter
so that's how you
do a joint sensitivity method so in
overall what you do is use
you co in the for you do one od solve in
forward so all these solve
you do what you call what we solve in
the forward process
so forward forward prop and you will do
back prop
so you just need to call od solve once
and twice
twice and then you can update your
model entire model without doing any
back propagation at all
so this is back propagation free you
just so this means that you're
you're approximating you're
approximating this value
through solving ode backwards in time so
this is approximation though
so obviously these values these gradient
values that
that you obtained by doing a joint
sensitivity method will be
less accurate than doing a full back
prop because this is a
this is a approximation to the backdrop
value
you're not doing the back prop uh act
you're not doing back prop
uh very uh accurate uh technically
you're not doing backpack because you're
doing you're just approximating
these value using a joint sensitivity
method so
using backprop will actually give you
better performance than using a joint
sensitivity method but
then again if you use a joint
sensitivity method you can save all the
vrams because you don't have to do back
prop so there's a trade-off there
right so some experiments so this is
doing image classification specifically
amnest classification so
this is the baseline is one layer mlp
resnet
rk net which is rk net is just ode with
backprop
od plus deck pro od
net is ode plus a joint
sensitivity method so you can see that
this guy uses constant size memory
because it's used
it's not doing any back props so it's
using constant size memory
uh this guy here is doing backprop so it
is doing it is using some
some number of it is using linearly
increasing
amount of memory uh the resin of course
a resident will
also use uh memory which is
which linearly which increases by the
size of the layer
here you can see l tilde because you
know because this is there's tilde here
because you decide
how much how many time steps you want to
take
so that's up to you and you can see the
test error so
uh resnet is area is about
achieving only 0.41 error and od in that
is
is achieving 0.42 error so uh the
performance is pretty comparable but
that's only amnest classification if you
go to imagenet then
resonant is resonant outperform zodian
odin that is nowhere close to
i won't say nowhere close but it's
definitely worse than resonance and what
resonance still
is you know so yeah
i mean yeah mnist classification is a
simple enough task so
od shows like comparable performance
with a reduced memory footprint
but if you go to like larger scale tasks
than odin od neural ods are not ready
yet so it's not as
practical as resonant now and people are
people are working towards it like how
to make it practical how to make it
scalable so it's an
active topic of research these days
uh the statistics of odinna so once when
you train it the number of
this nfe is a number of function
evaluations basically how many
steps you take and interestingly you can
see that
when you're doing forward and the
backward the
you take more and you take more you you
you do more function evaluations when
you're doing forward
as opposed to when you're doing
backwards so that's interesting
so as i said you do one forward prop and
you do one backward prop
back prop so you call od here you do od
od once and you call od twice here and
you can see that when you go when you go
forward
it takes more number of function
evaluation as opposed to going backwards
which is
kind of interesting yeah and as you see
as you train your model your number of
function evaluations in
forward this here increases so that
means that
your your ode func your derivative
function d
d y d t is learning more complex
functions over time
because the more complex means that
the more complex the function the more
number function
the smaller time step you need to take
to obtain accurate solutions as i said
so
so this kind of like indirectly
indicates that uh
yeah as you as you learn your model
parameter it'll
as you oh i'm sorry
yeah sorry about that so yeah as i said
this graph
indirectly tells you that
your model is learning more complex
function over time
you can also do a sequence to sequence
with od actually so this is the very
first sequence to sequence model using
od
so it is using rnn encoder and ode
decoder so
there's some some sequence information
put it put into the rnn encoder so
you you have some see like sequence of
observation points
then you compress it into a hidden layer
and then you
you can actually do variational
autoencoder styles so this is like
a vae but using sequence models for in
both encoder and decoder side so
if you remember va the va output the
intermediate layer va
is just the mu and sigma which is used
like you know all involved in like
re-permanent
reparameterization trick so you encode
your observation sequence of
observations and then you encode it into
a
fixed step size fixed zt 0 and then
using zt0 you start decoding it using
your load
so you you you integrate it with od
solver over time so that's how you do
ode sequences sequence and using this
you can actually try to learn a spiral
using sequence of sequence perform
interpolation extrapolation so here
the green lines here the green lines
here actually let me use a
actual green line here so green line
here is
is the ground truth and the blue dots
here the blue dots
are the observation points given to the
model
so you use you you input you encode
these blue dots
into the encoder rna encoder and then
you try to interpolate interplay meaning
that
you try to fill in the fill in the i'm
sorry
you try to fill in the gaps between the
observation points like here
like here here here that's the
interpolation and extrapolation is
uh you you keep keep on going keep on
going like this
even after the final observation so
using the od sequence sequence
uh the authors did spiral reconstruction
or interpolation extrapolation
and you can see that uh it is doing a
much better job than
rnn actually so are then kind kind of
understands what it wants to do so the
red is the extrapolation so
are they kind of understands that it it
is a spiral and goes like this
and maybe uh moving in a circle but if
you use
od then it is doing a much better job
like it exactly understands
the dynamics of this of the spiral so it
knows how to
do extrapolation as well so it's uh yeah
in
this kind of like continuous time step
like if you're handling continuous time
series model
then outperforms your low d in high
level
like high dimensional uh data actually
so
but then some like researchers are
walking working really hard to make this
make your load the whole neural d very
scalable so sooner or later it'll show
like similar i i i expect that sooner or
yeah all later so the conclusion is that
uh uh neurology is a new deep learning
paradigm so or
new new neural network paradigm actually
or new machine learning paradigm
and it's a great especially it's a great
alternative to rna when handling time
and
the the the pros of this whole thing is
that you can use a well-known guaranteed
od solvers like because as i said
there's like whole long like history of
od solvers and all these solving
techniques
in mathematics and physics so you can
draw you can borrow their knowledge to
do like very very powerful computation
and a lot of modern
modern and od solvers guarantee some
error tolerance like you
like you as as a parameter to the
program you
put a error tolerance like like
10 to the minus 5 or 10 to the minus 7
then you're so
then the solver will guarantee that
amount of error margin
and as i said yeah so there's a rapid
development these days is a hot topic
these days in machine learning community
all right so yeah this is the end of
today's class
and actually the last class of this
entire semester so
thank you very much again for
participating in this class and i hope
you
i hope you guys learned a lot and hope
you guys are ready to do
ai research thank you very much and bye
bye
oh by the way uh this in this thursday
well not thursday but the practice
session will consist of
uh implementing your implementing the
euler's over
our case uh the runge-kutta solver and
uh
actually implementing neural od yourself
and then training your neural od on
spiral data and then
trying out different solvers like
adaptive solvers and joint sensitivity
methods
all right all right thank you very much
bye-bye