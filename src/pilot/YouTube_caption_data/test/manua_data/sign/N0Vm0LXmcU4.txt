I'm excited to introduce now to you our second lightning talk. So
we are going to have Thadeu Luz, who is the Co-Founder and 
Chief Product Officer of Hand Talk, join us and share a little bit
about what he and his organization have been up to.
Fun fact about Thadeu is that Hand Talk is a Brazilian start-up,
they’re a social enterprise, and they actually were members of the
first ever Launchpad global cohort in 2016. So they are repeat visitors to
the Launchpad Accelerator program. Welcome. 
Hello, I'm here today to talk about a little bit more about the company
that I founded with my two friends and co-founders, Ronaldo and Carlos.
And we founded the company back in 2012 and currently we are a
happy team of 36 working from the sunny Maceió which is a city
in the coast of Brazil, with very nice beaches and warm weather.
[Laughter]
And the reason we are all together is to try to remove as much as
possible from the communication barrier that happens between
people that use sign language in people that use written, oral language
in their countries. So there are, according to the World Health Association,
there are over 460 million deaf people in the world. And an
interesting fact is that for many of them it is really, really hard
to learn the written language of their country. So 80% of deaf people
worldwide are either illiterate or semi-literate. 
Learning the written language of the country when you don't have the
benefit of hearing is considerably harder.
So that's why we have products that do automatic sign language
translation and is in production on many websites for companies in Brazil,
but we are really proud of the mobile application that we have, that anyone
can download for free and use it to learn sign language, so they can have
a conversation and talk to their daughters or sons or co-workers
and friends. So there are many problems that come with this - being
born deaf on a predominantly hearing world. But one that I think about the
most is that 95% of deaf children, they're born from hearing families. Like they 
have hearing parents. So, for the vast majority of them, the deaf, newborn
child is the very first deaf person that the parents have ever met.
and it's really important for them to have a good amount of
communication when growing up because if children take too long
to acquire their first language, more than five years, it can have
consequences like on their cognitive development throughout the entire life.
So learning sign language is also like not easy. It's like learning a new
language, but also in the different symbolic system.
So parents can usually use all the help they can get so let me tell you,
this is why we get really excited with stories like the one we hear from
Laura. She has a 30 year old deaf son and one day she was at work,
she works as a hairdresser in Brazil, so she saw on TV an interview
with Ronaldo, my partner, and he was telling about the app and how
you can use it for free. She downloaded it on her Android phone.
On the way home she learned a couple of signs, the ones that she
wanted to learn, and when she got home, for the first time after 30 years,
she was able to sit down with her son and say "You are my son.
You are welcome in my home. You can stay here for as long as
you want, and I love you." So those kind of stories really, really
resonate with us because it means that we are actually
building something that is having an impact on people's lives. So the
Google AI Impact Challenge has helped us like very much.
And they are three main fronts that we made lots of progress. So the very
first one is that we were able to build a strong neuro machine translation
system, which is the third translation generation of our translation
system. It works on TensorFlow, uses state-of-the-art technology, 
architecture, that's similar to what was implemented in Google
Translate in 2016. Everyone saw huge improvements.
But for us one of the main things was that it was we were able to grow
2.8X the amount of translations during 2019.
To train a machine translation system, and it's important because,
sign languages are not like signed English, they’re languages with
their individual grammar and they have their own structure, so you
need like Google Translate level translation to do a good job.
And for that, to train a machine translation system like this one,
we need data, of course. So the second thing we did that we're
really proud of was what we call Hand Talk Community, which is a
crowdsourcing tool that many people from all over the world,
since they are over 200 different sign languages in the world, it would
be really hard to just generate all this data ourselves.
So people all over the world can collaborate, providing video
translation of their own local sign languages.
Currently we have dozens of people working on this both in Brazil
in the U.S. So thank you Luciana. And we also built the tools to tag
all these data because it's really hard to find tag data on sign
language. So we also built a tool that can make this data structured 
so that we can train a translation system. And the third area where we
made lots of progress - it's like really something that we have been
dreaming for quite some time, which is we looked a lot into motion
capture in the past. But previous technologies were all like expensive
and they needed special hardware like gloves or suits or helmets with
cameras and you know, a bunch of stuff, but we were able to build
a capturing system, AI based, using only regular webcams. And for now
we're using this to generate more accurate animations for the character,
but in the future what we really want is to create a sign recognition model,
so that we can use to translate from sign languages to oral languages,
using only the app, no special hardware required. And the reason why
this is so important is, like Yossi Matias mentioned in the beginning,
that there were things that he thought that were impossible. But with time
it was clear that it really wasn't. You just needed the right tools and technology.
And this is one of the things that I have said before like, this is impossible,
we're never going to be able to have two way communication.
And I know for a fact that it's completely doable now. And the reason
why this is so interesting is because it really feels like we jumped off a cliff
and we ended up developing wings on the way down, like Jeremy likes
to say. [Applause] And the wings in this case, they're not only the technology 
or TensorFlow, which has been open source, or the beautiful Google
Cloud platform where we can train stuff and have it working.
But it's also like the Google AI program Google AI Impact Challenge,
because we're not sure how long it would take us to get there
if it wasn't for a program like this. So I would really like to thank
everyone involved, Jeremy, Brigitte, Mollie, Shiri, Hanako 
and everyone else, for being our wings. And so that in the future we can
maybe have that same deaf person or that baby girl,
That doesnt - that is deaf, or Laura's son. He can say back to his mother
that he loves her back in the mother's first language.
And so yeah, this is - I think this is it. Thank you very much. 