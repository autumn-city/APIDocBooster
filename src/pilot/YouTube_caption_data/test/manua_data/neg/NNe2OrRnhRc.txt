Welcome to GrabNGoInfo!
Sentiment analysis can be done with or
without building a machine learning model.
This tutorial will go over the Python
implementation of TextBlob, VADER, and
Flair for non-model sentiment analysis.
After finishing the
tutorial, you will learn:
What is TextBlob?
What is VADER?
What is Flair?
How to use Python library
TextBlob for sentiment analysis?
How to use Python library
VADER for sentiment analysis?
How to use Flair’s pre-trained model
in Python for sentiment analysis?
Comparison between TextBlob vs.
VADER vs.
Flair.
Let’s get started!
The first step is to install
and import Python libraries.
We need to install the
vaderSentiment package for VADER
and theflair package for flair.
After installing the packages,
let’s import the Python libraries.
We need to import pandas and
numpy for data processing.
For the sentiment analysis,
we need to import TextBlob,
SentimentIntensityAnalyzer
from vaderSentiment, and
TextClassifier from flair.
We also need to load the English
sentiment data from TextClassifier and
import Sentence for text processing
for the flair pre-trained model.
To check the sentiment prediction
accuracy, we need to import
accuracy_score from sklearn.
Last but not least, we set the
pandas dataframe column width to
be 1000, which will allow us to
see more content from the review.
The second step is to download
and read in the dataset.
The UCI Machine Learning Repository has
the review data from three websites:
imdb.com, amazon.com, and yelp.com.
We will use the review data from
amazon.com for this tutorial.
Please follow these steps
to download the data.
1.
Go to the UCI webpage for the
sentiment labelled sentences
2.
Click “Data Folder”
3.
Download “sentiment labeled sentences.zip”
4.
Unzip “sentiment labeled sentences.zip”
5.
Copy the file “amazon_cells_labelled.txt”
to your project folder
Those who are using Google Colab
for this analysis need to mount
Google Drive to read the dataset.
You can ignore the code below if
you are not using Google Colab.
Now let’s read the data into
a pandas dataframe and see
what the dataset looks like.
.info helps us to get the
information about the dataset.
From the output, we can see that
this data set has two columns,
1000 records, and no missing data.
The ‘review’ column is object type,
and the ‘label’ column is int64 type.
Next, let’s check the
distribution of the label.
There are 500 positive and 500
negative reviews in the dataset,
so we have a balanced dataset.
For a balanced dataset, we can use
accuracy as the performance metric.
If you are interested in imbalanced
dataset classification, please check
out my imbalanced classification
and anomaly detection tutorials.
TextBlob is a Python library for
Natural Language Processing (NLP).
Sentiment analysis is one of many
NLP tasks that TextBlob supports.
The sentiment property in TextBlob
returns a polarity score and a
subjectivity score for the input text.
The polarity score ranges from
-1 to 1, where -1 means extremely
negative, and 1 means highly positive.
A score near 0 means neutral sentiment.
The subjectivity score ranges from
0 to 1, where 0 means extremely
objective and 1 means highly subjective.
In this example, the sample text
‘GrabNGoInfo.com is a great machine
learning tutorial website.’ has
a polarity score of 0.8 and the
subjectivity score of 0.75, which means
TextBlob interprets the sentence to
have a subjective positive sentiment.
We can use .polarity to
extract the sentiment score.
VADER (Valence Aware Dictionary and
sEntiment Reasoner) is a Python library
focusing on social media sentiments.
It has a built-in algorithm to
change sentiment intensity based on
punctuations, slang, emojis, and acronyms.
The output of VADER includes four
scores: compound score, negative score,
neutral score, and positive score.
The pos, neu, and neg represent
the percentage of tokens that
fall into each category, so
they add up together to be 100%.
The compound score is a single score
to measure the sentiment of the text.
Similar to TextBlob, it ranges
from -1 (extremely negative)
to 1 (extremely positive).
The scores near 0 represent
the neural sentiment score.
The compound score is not
a simple aggregation of the
pos, neu, and neg scores.
Instead, it incorporates
rule-based enhancements such
as punctuation amplifiers.
VADER gave the sample text
‘GrabNGoInfo.com is a great
machine learning tutorial
website.’ compound score of 0.6249.
There is no negative word in the
sentence, so the neg score value is 0.
There are 63.1% of neutral words and
36.9% of positive words in the sentence.
The output of VADER is
saved as a dictionary.
We can extract the compound sentiment
score by the key ‘compound’.
Flair is a state-of-art NLP
framework built on PyTorch.
It incorporates recent researches and
provides an easy way to combine different
embeddings to various NLP tasks.
The pre-trained sentiment model
offers a tool for sentiment analysis
without training a customized model.
Unlike TextBlob and VADER that output
a sentiment score between -1 and 1,
flair sentiment output the predicted
label with a confidence score.
The confidence score ranges from 0
to 1, with 1 being very confident
and 0 being very unconfident.
Before predicting the sentiment
of a text, the input text needs
to be tokenized by Sentence().
After that, we can see the sample
text was split into nine tokens.
Next, we use .predict to
predict the sentiment.
The sample text ‘GrabNGoInfo.com is a
great machine learning tutorial website.’
has the predicted sentiment of POSITIVE
and the confidence score of 0.9895.
Since 0.9895 is close to 1, flair is
very confident about the predictions.
The predicted label is saved
as value and the prediction
confidence is saved as score.
We can use sentence.labels[0].value
and sentence.labels[0].score
separately to extract the values.
In step 6, we will apply
TextBlob to the Amazon review
dataset and see how it performs.
We first get the sentiment polarity
for each review and save the values
into a column called ‘scores_TextBlob’.
Then check if the polarity
score is positive.
If the score is greater than or equal
to zero, the predicted sentiment for
the review is positive (labeled as 1).
Otherwise, the predicted sentiment for
the review is negative (labeled as 0).
After getting predictions from TextBlob,
let’s check the prediction accuracy.
Comparing the actual label with
the TextBlob prediction, we get
an accuracy score of 0.688, which
means that TextBlob predicted the
review sentiment 68.8% of the time.
In step 7, we will apply VADER
to the Amazon review dataset
and see how it performs.
We first get the sentiment compound
score for each review and save the values
into a column called ‘scores_VADER’.
Then check if the compound
score is positive.
If the score is greater than or equal
to zero, the predicted sentiment for
the review is positive (labeled as 1).
Otherwise, the predicted sentiment for
the review is negative (labeled as 0).
After getting predictions from VADER,
let’s check the prediction accuracy.
Comparing the actual label with the VADER
prediction, we get an accuracy score of
0.768, which means that VADER predicted
the review sentiment 76.8% of the time.
TextBlob has a prediction accuracy
of 68.8% for the same dataset,
so VADER has an 8% improvement
over the TextBlob prediction.
In step 8, we will apply the flair
pre-trained sentiment model to predict
the sentiment of the Amazon reviews.
Firstly, let’s define a function that
takes a review as input and the predicted
label and confidence as outputs.
Then apply the function to
each review in the dataset.
We can see that the summary statistics
show that most flair scores are
close to 1, which means that the
flair sentiment model is overall
very confident about the predictions.
The distribution of the
labels is very balanced.
Before checking the prediction
accuracy, we need to map the ‘NEGATIVE’
value to 0 and the ‘POSITIVE’ value
to 1 because the Amazon review
dataset has true labels of 0 and 1.
After comparing the flair prediction
with the actual sentiment label,
we can see that flair predicts the
sentiment correctly 94.8% of the time!
The prediction accuracy is an
18% increase from VADER and
a 26% increase from TextBlob!
In this tutorial, we compared TextBlob vs.
VADER vs.
Flair for sentiment analysis.
In terms of methodology, VADER and
TextBlob are lexicon and rule-based.
Flair is model-based.
For the meaning of the scores,
VADER and TextBlob have sentiment
scores ranging from -1 to 1, where
-1 means very negative, 1 means
very positive, and 0 means neutral.
Flair has a score ranging from 0 to
1, where 0 means very unconfident
about the prediction and 1 means
very confident about the prediction.
If we compare the speed, Flair is slower
than TextBlob and VADER because the
computation algorithm is more complicated.
About accuracy, based on the results
of this project, flair has the best
prediction accuracy, VADER is the
second-best, and TextBlob is the third.
After reading the
article, you have learned
What is TextBlob?
What is VADER?
What is Flair?
How to use Python library
TextBlob for sentiment analysis?
How to use Python library
VADER for sentiment analysis?
How to use flair pre-trained model
in Python for sentiment analysis?
Comparison between TextBlob vs.
VADER vs.
Flair.
If you are interested in the nuance
differences between TextBlob and VADER,
please refer to my article TextBlob VS
VADER For Sentiment Analysis Using Python
If you found the information in this
tutorial helpful, please click the like
button and subscribe to the channel.
I publish tutorials on machine
learning, deep learning, and
big data processing every week.
If you prefer the written version of the
tutorial, please go to GrabNGoInfo.com.
I will put the link in
the video description.
This is the blog post for this tutorial.
It has all the code and
explanations in the video.
Thank you for watching.
See you in the next video.