in this video I want to show you how to
use tons of stencil flows belt and
Bernoulli distribution so let's say that
our task is like this we have a sample
and we think that the sample is with
that so we think it's Bernoulli
distributed and got to be in NZ so
essentially we're saying sample I is
Bernoulli takeoff for every eye right
and they're all independent so our goal
is here is to find the theta right so
find the maximum likelihood estimate oh
hey so what does it mean to find maximum
Blackie estimate well what you need to
do is you need to maximize the
likelihood or the log likelihood right
with that's our goal
so here's how we are gonna go about it
so first of all we need to define theta
so we don't know what theta is which
means that theta has got to be a very
red so theta is gonna be a variable we
can initialize it to 0.5 and then we'll
adjust it in order to maximize the
likelihood so we also need to input the
training set so what makes sense is do
and put the training set into a place
holder so let's define that so you can
find PI sample as a placeholder with
type float32 alright so now that we have
our data and we have the Thai sample
what we want to do is we actually want
to define the likelihood so we could of
course just code everything by hand but
here what I'll do is I'll use the T
outcome trip distributions belt anything
okay so how is that gonna work so what
they can do is I can define a PI so
that's going to be a distribution object
and it's gonna have the parameter theta
so here we'll say P which means the
probability is equal to theta so it's
important to say P equals 2 theta
because if you just say theta then theta
is the logit rather than the probability
which is fine except you won't interpret
it correctly later on so we'll say P is
equal to 8 now at this point we are
ready to actually define the likelihood
so how can you compute the likelihood
well if you have this Bernoulli object
what you can do is you can say PI dot
log drop and here you can plug in
whatever you want for example you can
plug in hi Sam
so what is that going to do that's going
to compute the log probability of this
sample using this distribution this
distribution has the parameter theta so
okay so let's define that as our log
likelihood
except what this is it's all the
likelihoods for every data point right
so actually in project for it this is
what you want but what we want here is
we actually want the sum right so this
is what we'll do
so say reduce some of those guys so now
the log-likelihood is a thing as a
single number note that this is not what
you want for project four okay
but here what we did is we computed the
likelihood of this data for in this data
point this data point and so on so this
was a tensor that contains all of those
likelihoods using p equals theta
whatever theta happens to be right now
and what we did now is we add up the at
the demo laps so now this tensor Jeff is
just of size one by one and it
corresponds to the log like okay so now
that we have the log likelihood what do
we need to do well we need to maximize
it right how to do it well the usual
wait so what we'll do is we'll find an
optimizer like so so we'll just use
gradient descent and we'll plug in some
alpha so let's say one one times ten to
the negative three and now we can define
our trained ups so the trainer is gonna
be minimize and now well we don't want
to minimize the one writer who you want
to maximize it so we'll just multiply it
by minus one
so that we are maximizing it instead of
minimizing that so okay at this point
everything is done so when we run train
off what what happens well what happens
is the variable theta so theta is the
only variable here that's going to get
adjusted so as to minimize this thing
which means that what you'll be doing is
you'll be maximizing this thing okay so
okay so now we can start so we'll just
heat up the culture will repeatedly
evaluate evaluate trade off right so
we'll say for I in range let's say 10 so
we don't really need a lot of stops here
well run train up by plugging in PI
samples so by plugging in the sample
into five sample right so by sample is
an example like that and now it makes
sense to maybe just show what the world
likelihood is currently just to make
sure that it's increasing because we are
evaluating training right so and
and here we'll feed the sample again to
PI sample so okay at the end what you
might like to do is you might like to
print the final theta but so in order to
do that all you need to do is you need
to run theta you don't really need to
feed anything here because theta doesn't
depend on in placeholders so we can just
say session run theta here and we can
also just print the mean of sample
because that would be the exact the
exact estimate for what they - all right
so let's try to run this okay
log-likelihood is not find that's just
because I misspelled it somewhere so
this is line 36 so just fix that and
here so as you see this was this this
was improving so here we have a little
bit of a problem on line 48 so this
wasn't 8 of course this was the example
so let's run this again and here it just
did not get printed so let's print it
and as you can see so the exact estimate
for beta is 0.7 and what we came up with
is oval 0.7 so 0.699 505 one so close
enough although obviously if we increase
the number of iterations will probably
get closer yeah there we are
so this is 0.7 this is 0.7 and as you
can see the log-likelihood at first it
was growing so from minus 64 to about
minus 61 and then it stabilized so how
did we use TF that conserved our
distributions well so what we did is
here we plugged it and in this case it's
a variable but it could be any tensor of
told and in fact in project 4 would be a
tensor that you computed before right so
we plugged it in here and then we
optimized it and this is kind of the
kind of thing that we're doing in
project 4 as well