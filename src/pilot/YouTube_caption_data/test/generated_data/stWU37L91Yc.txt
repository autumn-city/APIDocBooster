welcome to this series on neural network
programming with PI George it's time now
to learn about the weight tensors inside
our CNN will find that these weight
tensors live inside our layers and are
the learn about parameters of our
network without further ado let's get
started in the last couple of posts in
the series we started building our CNN
and we put in some work to understand
the layers we defined inside our
network's constructor ultimately our
next step in the overall process is to
use these layers inside our form method
but right now let's take a look at the
learn about parameters of our network we
already know about hyper parameters we
sold that hyper parameters are
parameters whose values are picked
arbitrarily the hyper parameters we've
used up to this point or hyper
parameters that we use to construct our
network's architecture through the
layers we constructed and assigned as
class attributes these hyper parameters
aren't the only hyper parameters though
we'll see more hyper parameters for sure
when we start the training process what
we're concerned with now though is a
different type of parameter called a
learnable parameter learn about
parameters are parameters whose values
are learned during the training process
with learn about parameters we typically
start out with a set of arbitrary values
and these values then get updated in an
iterative fashion as the network learns
in fact when we say that a network is
learning we specifically mean that the
network is learning the appropriate
values for the learn about parameters
appropriate values are values that
minimize the loss function when it comes
to our network we might be thinking well
where are these learn about parameters
all we have so far is a network class
with layers that have been assigned as
class attributes
well the learn about parameters are the
weights inside our network and they live
inside each layer using PI torch we
can inspect the weights directly so
let's grab an instance of our network
class and see this remember to get an
object instance of our network class we
typed a class name followed by
parentheses when this code executes the
code inside the init class constructor
will run assigning our layers as class
attributes and then returning the object
instance the name in it is short for
initialize in an object's case that
attributes are initialized with values
and these values can indeed be other
objects in this way
objects can be nested inside other
objects this is the case with our
network class whose class attributes are
initialized with instances of PI torch
layer classes after the object is
initialized we can then access our
object using the network variable okay
so before we start to work with our
newly created network object have a look
at what happens when we pass our network
to pythons print function the print
function prints to the console a string
representation of our network with a
sharp eye we can notice that the printed
output here is detailing our network's
architecture listing out our network's
layers and showing the values that were
passed to the layer constructors one
question is though how exactly is this
happening where is this string
representation coming from well our our
network class is inheriting this
functionality from the PI torch module
base class watch what happens if we stop
extending the neural network module
class
now we don't get the nice descriptive
output like before instead we get this
technical gibberish which is the default
Python string representation that we get
if we don't explicitly provide one for
this reason in object-oriented
programming we usually want to provide a
string representation of our object
inside our classes so that we get useful
information about the object when it
gets printed this string representation
comes from pythons default base class
called object all Python classes
automatically extend the object class if
we want to provide a custom string
representation for our object we can do
it but we need to introduce another
object or any concept called overriding
when we extend the class we get all of
its functionality and to complement this
we can add additional functionality
however we can do more we can also
override existing functionality by
changing it to behave differently we can
override pythons default string
representation using the double
underscore rep our double underscore
function this name is short for
representation
this time when we pass the network to
the print function the string that we
specified in our class definition is
printed in place of pythons default
string this is overriding in action when
we talked about oo P before we learned
about the double underscore init double
underscore method and how it is a
special Python method for constructing
objects
well there are other special methods
like this that will definitely encounter
in double underscore Rep our double
underscore is one of them all the
special oo P methods in Python typically
have the double underscore pre and post
fixes this is how we can distinguish
them as being special in PI torches case
this is how the PI tortes module base
class works as well the module base
class overrides the rep R function and
if we look in the PI torch source code
in the module class we indeed see this
[Music]
so let's take a look at this string
representation what's actually here for
the most part the string representation
that PI tortes gives us pretty much
matches what we would expect based on
how we configured our networks layers
for the convolutional layers the kernel
size argument is a Python tuple five
comma five even though we only pass the
number five in the constructor this is
because our filters actually have a
height and width and when we pass a
single number to the constructor the
code inside the layers constructor
assumes that we want a square filter
next we have this stride which is an
additional parameter that we could have
set but we left it out and when the
stride is not specified in the layer
constructor the layer automatically sets
it the stride tells the conv layer how
far the filter should slide after each
operation in the overall convolution
this tuple says to slide down by one
unit when moving to the right and also
by one unit when moving down for the
linear layers we have an additional
parameter called bias which has a
default parameter value of true and it
can be turned off by setting it to false
one thing to note about the information
display for our objects when we print
them is that it's completely arbitrary
information as developers we can decide
to put any information there however the
Python documentation tells us that the
info should be complete enough that it
can be used to reconstruct the object if
needed so that's what we want to shoot
forward when building our own classes
now that we've got an instance of our
network and we've reviewed our layers
let's see how we can access them in code
in Python and many other programming
languages we access attributes and
methods of objects using dot notation
this is dot notation in action with dot
notation we use a dot to indicate that
we want to sort of open up the object
and access something that's inside we've
already been using this quite a bit so
the mention here just gives us a label
for the concept something to notice
about this that pertains directly to
what we are just talking about with a
string representation is that each of
these pieces of code are also giving us
a string representation of each layer in
the network's case the network class is
really just compiling all of this data
together to give us a single output for
the network now that we have access to
each of our layers we can access the
weight inside each layer let's see this
for our first convolutional layer
[Music]
the output here is a tensor but before
we look at this tensor
let's talk Hopi for a moment this is a
good example that showcases how objects
are nested we first access the conflate
object that lives inside the network
object then we access the weight tensor
object that lives inside the complex so
all of these objects are chained or
linked together one thing to notice
about this output is that it says
parameter containing at the top this is
because if this particular tensor is a
special tensor because its values or
scalar components are indeed learn about
parameters of our network this means
that the values inside this tensor the
ones we see here are actually learned as
the network is trained as we train these
weight values are updated in such a way
that the loss function is minimized to
keep track of all the weight tensors
inside the network pi torch has a
special class called parameter the
parameter class extends the tensor class
and so the weight tensor inside every
layer is an instance of this parameter
class this is why we sold the parameter
containing text at the top of the tensor
output looking here in the PI torch
source code we can see that the
parameter class is overriding the dunder
rep our method by prepending this string
to the result of the tensor classes
string representation if we are
extending a class we can access its
methods using this super keyword and
that's what's happening here the way
this parameter class comes into play
with PI torch is that the neural network
module class is basically looking for
any attributes of a module whose values
are instances of the parameter class and
when it finds an instance of the
parameter class it keeps track of it all
of this so far is really just PI torch
technical details that go on behind the
scenes will see this come into play in a
bit for our under
now though the important part is the
interpretation of the shape of the
weight tensors this is where we'll start
to use the knowledge we learned about
tensors early on in the series let's
look at the shapes now and then we'll
interpret them in the last pose we said
that the parameter values we passed to
our layers directly impact our networks
weights this is where we'll see this
impact for convolutional layers the
weight values live inside the filters
and encode the filters are actually the
weight tensors themselves the
convolution operation inside a layer is
an operation between the input channels
to the layer and the filter inside the
layer this means that what we really
have is an operation between two tensors
with that being said let's interpret
these weight tensors which will allow us
to better understand the convolution
operations inside our network remember
the shape of a tensor really encodes all
of the information we need to know about
the tensor for our first call flayer we
have one color channel that should be
convolve dye six filters of size five by
five to produce six output channels this
is how we interpret the values inside
our layer constructor we did this last
time inside our layer though we don't
explicitly have six weight tensors for
each of the six filters we actually
represent all six filters using a single
weight tensor whose shape reflects or
accounts for the six filters the shape
of the weight tensor for the first
convolutional layer shows us that we
have a rank for weight tensor the first
axis has a length of six and this is
where we account for the six filters the
second axis has a length of one which
accounts for the single input channel
and the last two axes account for the
height and width of each filter the
way to think about this is as if we are
sort of packaging all of our filters
into a single tensor now the second conf
layer has 12 filters and instead of
convolving a single input channel there
are six input channels coming from the
previous layer think of this value of
six here as giving each of the filters
some depth instead of having a single
filter that convolve
all the channels iteratively our filter
has a depth that matches the number of
channels and so it's able to slide
across all of the channels in one go
[Music]
the two main takeaways about these
weights for these conflicts is that our
filters are represented using a single
tensor and each filter inside the tensor
also has a depth that accounts for the
input channels that are being convolve
so to summarize our tensors are ranked
for tensors the first axis represents
the number of filters the second axis
represents the depth of each filter
which corresponds to the number of input
channels being involved and the last two
axes represent the height and width of
each filter we can pull any single
filter out by indexing into the weight
tensors first axis
this gives us a single filter that has a
height and width of five and a depth of
six let's shift gears now and look at
the weight tensors for linear layers
[Music]
with linear layers or fully connected
layers we have flattened rank one
tensors as input and as output the way
we transform the in features to the out
features in a linear layer is by using a
rank two tensor that is commonly called
a weight matrix this is due to the fact
that the weight tensor is of Rank 2 with
height and width axes here we can see
that each of our linear layers have a
rank two tensor as the weight tensor the
pattern that we can see here is that the
height has a length that is equal to the
desired output features and the width
has the length of the input features
this fact is due to how matrix
multiplication is performed let's see
this in action with a smaller example
suppose we have to rank two tensors the
first has a shape of three by four and
the second has a shape of four by one
since we are demonstrating something
called matrix multiplication will note
that both of these rank two tensors are
indeed matrices with this set up matrix
multiplication works like this
[Music]
for each row column combination in the
output the value is obtained by taking
the dot product of the corresponding row
of the first matrix with the
corresponding column of the second
Matrix since the second Matrix in our
example only has one column we will use
it all three times but this idea does
generalize the rule for this operation
to work is that the number of columns in
the first matrix must match a number of
rows in the second Matrix if this rule
holds matrix multiplication operations
like this one can be performed the dot
product means that we sum the products
of corresponding components so we add up
the products of corresponding components
in case you're wondering
both the dot product and matrix
multiplication concepts are linear
algebra concepts the important thing
about matrix multiplications like this
is that they represent linear functions
that we can use to build up our neural
network specifically the weight matrix
defines the linear function and it is
also called a linear map it Maps a
vector space of four dimensions to a
vector space of three dimensions when we
change the weight values inside the
matrix we are actually changing this
function and this is exactly what we
want to do as we search for the function
that our network is ultimately
approximating let's see how to perform
this same computation using PI George
[Music]
here we have the in features and the
weight matrix both as tensors and we're
using the tensor method called Matt mole
to perform the operation the name Matt
mole as we can probably guess is short
for matrix multiplication in the next
post we'll see how to do this using the
linear layer itself but for now we've
covered the main learn about parameters
of our network a looming question is
though how can we access all the
parameters at once there is an easy way
let me show you
[Music]
the first example Network dot parameters
is the most common way and we'll use
this one to iterate over our weights
when we update them during the training
process our network inherits this
parameter method from the neural network
module base class and this is where what
we talked about earlier with the
parameter class comes into play it's
possible for us to quickly get all of
our learn about parameters like this
because of the work that the module base
class is doing behind the scenes the
second way is just to show us how we can
see the names as well this reveals
something that we won't cover in detail
the bias is also a learnable parameter
each layer has a bias by default so for
each layer we have a weight tensor and a
bias tensor if you want to learn more
about bias check out the deep learning
fundamental series there's a post on
deep lizard comm in that series that
covers bias and detail if you haven't
already be sure to check out a deep
lizard hivemind
where you can get exclusive perks and
rewards hit the like button to support
collective intelligence and I'll see you
in the next one
people sometimes ask me if it's
dangerous to make AI accessible to more
people what's dangerous is having an
exclusive and homogeneous group creating
technology that impacts us all we've
seen the harms being caused by companies
like Facebook Google YouTube Amazon
Palantir and others and we need people
from more diverse backgrounds to try to
address those harms we need people from
communities that have been
disproportionately targeted with
harassment to help create our technology
because they have a deeper understanding
of how tech can be weaponized against
the most vulnerable and of what
safeguards we need to put in place and
we also need more people who are experts
about people about human behavior human
psychology and human history the reason
I want everyone involved with AI is that
you know about problems nobody else
knows about and you have skills in a
background that nobody else has
I didn't know about using old cellphones
to protect the rainforest about the
suicide rate for farmers in India or
about the health of NGO daughters yet
these are all problems my students have
worked on I'm so glad that my students
didn't believe the myth that AI is only
for math prodigies but that they knew
their perspectives are valuable
we need journalists lawyers hospital
administrators hotel sales managers
sociologists CEOs historians and more to
understand the capabilities of AI it
doesn't matter if you didn't go to the
right school if math makes you anxious
if your friends and colleagues think
you're the last person that ever expect
to be working with ai ai needs more
unlikely people and the world needs you
involved with AI
[Music]
[Music]