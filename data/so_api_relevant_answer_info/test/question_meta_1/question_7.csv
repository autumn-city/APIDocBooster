label,sentences to be labeled,question title,question tags,question link,question description
,One can find the answer inside [torch.nn.Linear documentation (hyper-link)].,Using nn.Linear() and nn.BatchNorm1d() together,<pytorch>,www.stackoverflow.com/questions/57114974,"I don't understand how BatchNorm1d works when the data is 3D, (batch size, H, W).
Example
Input size: (2,50,70) 
Layer: nn.Linear(70,20)
Output size: (2,50,20)
If I then include a batch normalisation layer it requires num_features=50:
BN    : nn.BatchNorm1d(50)
and I don't understand why it isn't 20:
BN    : nn.BatchNorm1d(20)
Example 1)
[code snippet]
Example 2)
[code snippet]
Example 1 works. 
Example 2 throws the error:


RuntimeError: running_mean should contain 50 elements not 20

2D example:
Input size: (2,70) 
Layer: nn.Linear(70,20)
BN: nn.BatchNorm1d(20)
I thought the 20 in the BN layer was due to there being 20 nodes output by the linear layer and each one requires a running means/std for the incoming values.
Why in the 3D case, if the linear layer has 20 output nodes, the BN layer doesn't have 20 features?
"
,"It takes input of shape (N, *, I) and returns (N, *, O), where I stands for input dimension and O for output dim and * are any dimensions between.",Using nn.Linear() and nn.BatchNorm1d() together,<pytorch>,www.stackoverflow.com/questions/57114974,"I don't understand how BatchNorm1d works when the data is 3D, (batch size, H, W).
Example
Input size: (2,50,70) 
Layer: nn.Linear(70,20)
Output size: (2,50,20)
If I then include a batch normalisation layer it requires num_features=50:
BN    : nn.BatchNorm1d(50)
and I don't understand why it isn't 20:
BN    : nn.BatchNorm1d(20)
Example 1)
[code snippet]
Example 2)
[code snippet]
Example 1 works. 
Example 2 throws the error:


RuntimeError: running_mean should contain 50 elements not 20

2D example:
Input size: (2,70) 
Layer: nn.Linear(70,20)
BN: nn.BatchNorm1d(20)
I thought the 20 in the BN layer was due to there being 20 nodes output by the linear layer and each one requires a running means/std for the incoming values.
Why in the 3D case, if the linear layer has 20 output nodes, the BN layer doesn't have 20 features?
"
,"If you pass torch.Tensor(2,50,70) into nn.Linear(70,20), you get output of shape (2, 50, 20) and when you use BatchNorm1d it calculates running mean for first non-batch dimension, so it would be 50.",Using nn.Linear() and nn.BatchNorm1d() together,<pytorch>,www.stackoverflow.com/questions/57114974,"I don't understand how BatchNorm1d works when the data is 3D, (batch size, H, W).
Example
Input size: (2,50,70) 
Layer: nn.Linear(70,20)
Output size: (2,50,20)
If I then include a batch normalisation layer it requires num_features=50:
BN    : nn.BatchNorm1d(50)
and I don't understand why it isn't 20:
BN    : nn.BatchNorm1d(20)
Example 1)
[code snippet]
Example 2)
[code snippet]
Example 1 works. 
Example 2 throws the error:


RuntimeError: running_mean should contain 50 elements not 20

2D example:
Input size: (2,70) 
Layer: nn.Linear(70,20)
BN: nn.BatchNorm1d(20)
I thought the 20 in the BN layer was due to there being 20 nodes output by the linear layer and each one requires a running means/std for the incoming values.
Why in the 3D case, if the linear layer has 20 output nodes, the BN layer doesn't have 20 features?
"
,That's the reason behind your error.,Using nn.Linear() and nn.BatchNorm1d() together,<pytorch>,www.stackoverflow.com/questions/57114974,"I don't understand how BatchNorm1d works when the data is 3D, (batch size, H, W).
Example
Input size: (2,50,70) 
Layer: nn.Linear(70,20)
Output size: (2,50,20)
If I then include a batch normalisation layer it requires num_features=50:
BN    : nn.BatchNorm1d(50)
and I don't understand why it isn't 20:
BN    : nn.BatchNorm1d(20)
Example 1)
[code snippet]
Example 2)
[code snippet]
Example 1 works. 
Example 2 throws the error:


RuntimeError: running_mean should contain 50 elements not 20

2D example:
Input size: (2,70) 
Layer: nn.Linear(70,20)
BN: nn.BatchNorm1d(20)
I thought the 20 in the BN layer was due to there being 20 nodes output by the linear layer and each one requires a running means/std for the incoming values.
Why in the 3D case, if the linear layer has 20 output nodes, the BN layer doesn't have 20 features?
"
