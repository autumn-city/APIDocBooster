In this video we will see in depth the different layers of the convolutional networks,
if you are new to these networks I recommend that you stop right now and watch this video,
well, let's go!
We saw that networks are mainly divided into convolution, pooling, neural network and classification.
The convolution layer uses kernels, a matrix that runs through and multiplies the image
turning it into a different one, this mathematical processing is convolution.
To begin with we will use a simple example, if we want to detect diagonals in this
4x4 image, this 3x3 kernel will multiply each part of the image, represented numerically
it could be like this.
We take the first quadrant, multiply each cell and add it all up to get a number
that represents the detection of the diagonal.
Generally, the more positive it is, the more similar it will be to a diagonal, as it is
in this case.
We go to the next quadrant, multiply, add and obtain this time a negative number.
This indicates that what we have there does not look like a diagonal.
We continue with the rest and obtain an image that represents which parts of the image have
diagonals and which parts do not.
Normally, the goal is to get which parts resemble the kernel pattern
and to what extent.
That's why we usually use, right after, the reLU function.
This function converts any negative number to 0, leaving the positive ones intact.
With this resulting image we can know where the diagonals are in the original image.
The same convolution layer usually uses several kernels to obtain different images
that allow us to better understand what is inside the image.
If we have a diagonal, and a kind of cross, we can use two different kernels,
one that detects diagonals in this direction, and another that detects the opposite direction.
Abstracting ourselves with numbers, it would be like this.
If we apply the first mask to the two examples, and then applying the reLU function,
we can understand that the two images are the same, a diagonal.
Buuuut, applying the other kernel, we realize that the images are different,
in one it does not detect anything while in the other it detects the diagonal in the opposite direction.
If the result of applying the kernels was the input of a multilayer network, it could not
classify whether it was a diagonal or a cross with a single kernel; that's why several kernels are used
in the same convolution layer.
We have seen that when we apply the kernels the image is reduced.
To avoid this, we use padding, a technique that consists of considering the image
to be surrounded by zeros, in order to apply the kernel throughout the image, cell by cell,
obtaining an image with the same resolution.
After performing the convolution, we will apply pooling, which consists of reducing the size
of the image, something similar to resizing it.
Basically, we choose a mask size, and perform an operation on the numbers
inside the mask.
The most typical operation is MaxPooling that chooses the highest number.
For example, if we have this diagonal, after performing the kernel of the diagonal, and performing
the reLU operation we get this image which we will make maxPooling
with a 2x2 mask.
Another concept we have to take into account is the Stride, the displacement that the
kernel makes every time it is applied to the image.
If we make maxpooling with stride 1 we obtain this image,
and if we use a stride of 2, moving
two positions in each movement, we obtain this other one, that in this case, we see that it compresses
better the information of the original image with less pixels and allows to reduce the number
of neurons that the input layer of the network will need.
Continuing with the example of the diagonal, after the convolution, the ReLU function and the pooling
of the first kernel, this image is generated, and with the other kernel, this other one.
Now we must flatten these images into a single vector that serves as input to
the neural network, this is known as Flattering.
The pixels are runned through as we form the vector with each of the images, obtaining,
in this case, a size 8 vector.
By applying these operations, the network will have 8 neurons as input, instead of 16
if we had used the original image directly, apart from the fact that the network does not learn
about the pixels in the image but about the existing patterns in it.
The network is typically a multilayer perception to which a learning algorithm is applied
to relate the processed image and the category to which it belongs.
In this case, if we want it to determine whether it is a diagonal or an inverted one, this network
will have 8 neurons as input and 2 as output.
The coding that will be used as output is known as One-hot, a 1 for the corresponding
neuron and a 0 for the rest.
The selection of the hidden layers will be a matter of testing which one gives better results,
in this simple case we can use only one hidden layer with 3 neurons.
The set of the two types of diagonals is the training set, with which
the network with an algorithm like backpropagation, will learn to relate.
Finally, once the network is ready after learning the training set,
a layer called SoftMax is used to exponentially normalize the values
obtained from the network to a new entry, and thus, know the probability that it belongs
to each category.
To do this, the softmax function is applied, which simply divides the exponential of the value
obtained from each neuron, by the sum of all the exponentials of the outputs, obtaining
a number between 0 and 1.
For example, we pass this image with a small error to the convolutional network, the
outputs would be these, they are introduced in the softmax layer and the function is applied,
obtaining the probability that it belongs to each category.
Up to this point, the function of each of the layers that form the convolutional network,
a useful type of network, in the identification of patterns, would be explained.
If you liked the video like and if you want to see more videos about AI subscribe now,
see you!