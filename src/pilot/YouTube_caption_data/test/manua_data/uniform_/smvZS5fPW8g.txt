こんにちは、2020年SciPyの 
JapanPyNUFFTトークへようこそ。
私はJyh-Miin Linです。PyNUFFTプロジェクトのコーディネーターとしております。
PyNUFFTはPython non-uniform fast Fourier transformの頭字語です。
このウェブサイトを見てください。
または、PyNUFFTのインストールや利用に関連した問題がある場合は、
pynufft@gmail.comにメールを送ってください。
本日、サイエンティフィックコンピューティングについてお話させていただくということで、
Pythonがファーストチョイスと言えます。
なぜなら、Pythonは無料だからです。
そして簡単に使えます。
Pythonプログラムの共有は、
GitHubを使えばとても簡単です。
PyNUFFTは、Python NUFFTアルゴリズムを提供するためのコミュニティの取り組みです。
オープンソース版は2016年に最初にリリースされました。
プロジェクトでPyNUFFTを使う場合は、2018年に出版された論文を参照してください。
フーリエ解析はあらゆる科学分野で重要です。
高速フーリエ変換 (FFT) はFourier解析のための効率的アルゴリズムです。
ですが
FFTは均一データしか処理できません。
（FFTは）不均一データを処理できないため
不均一高速フーリエ変換が存在してきました。
これにより、不均一なフーリエ解析が可能になっています。
PyNUFFTプロジェクトの主な目標とは、
複雑なNUFFTアルゴリズムをPythonクラス内にカプセル化することです。
これで最終的なプロジェクトの目的がわかり、インストールは非常に簡単になりました。
この標準を使えば、
pipコマンドで
PyNUFFTパッケージのインストールをします。
それはホームディレクトリの中にあります。
次に、pynufftパッケージをインポートします。
そして
オブジェクトAを作成します。
A
および
基本的なパラメータを与えてオブジェクトを設計しました。
「om」とは、周波数領域 (k-空間) の軌道を指します。
Nd、Kd、そしてJd
画像の問題のサイズを示しています。
詳細はウェブサイトをご覧ください。
「A」オブジェクトが
設計されるとすぐに、
オブジェクトは順方向および随伴変換を実行できます。
PyCUDAやPyOpenCLデバイスを使うと
追加の
コマンドを使用して、このシステム内のデバイスを検索します。
ここには、device_listコマンドが表示されています。
helper fileの中では、
Zero (0) は最初のデバイスを意味します。
そして、
最初の装置を選びます。
デバイスを「device_flag」に割り当てます。
それから、NUFFTオブジェクトを作成します。
という感じです。
PyNUFFTパッケージでGPUコンピューティングを実現するために,さまざまなソフトウェアの組み合わせを試してみました。
2016年と2017年に
PyCUDAとPyOpenCLを試してみました。
ですがそこには
FFTと疎行列はビルトインされていませんでした。
scikit-cudaは、
cufftとcusparseへの
Pythonバインディングを移動します。
もう1つの選択肢は、
Reikan+PyCUDA+PyOpenCLの組み合わせです。
Reiknaは
PyCUDAとPyOpenCLの上に構築された
Pythonパッケージでした。
そして、それは
素晴らしいFFT関数です。
ご覧のように
PyNUFFTコードは
Reiknaシステムによって処理されいました。
"PyOpenCLかPyCUDAの”
どちらかに。
OpenCLバイナリは
CPUまたはGPUに送信できます。
ただし、CUDAコードはGPUにしか送信できません。
Reiknaパッケージの柔軟性のおかげで、
それは
PyNUFFTは様々なデバイスで動作します。
CUDAはNVIDIAのグラフィックカードのみをサポートしています。
ですが、OpenCLを使えば、ユーザーはより多くの選択肢を持つことができます。
AMDのグラフィックカードか
インテルCPUか
NVIDIAのグラフィックカードのいずれか。
これらはすべて
コンピューティングのためにクラウドに展開されます。
コンピューティングのためにクラウドに展開されます。
NUFFTクラス内のGPUパートはどこにあるのでしょうか?
そのルールは実行時のパフォーマンスを最大化することと、
GPUコンテキストの保持のため、
NUFFTオブジェクト使います。
したがって、GPUコンテキストを作成することが不可欠です。
GPU FFT
最初は
"そして、手書きの
CUDAやOpenCLのコードをコンパイルします。
最後にアルゴリズムを計算し
重要なパラメータをGPUメモリにオフロードします。
なぜならReiknaパッケージは
PyCUDAとPyOpenCL上に
ビルトされていたからです。
FFT機能はとても便利です。
次に、Reiknaパッケージからcludaモジュールをインポートします。
変換、関数、およびdtypeをインポートします。
私たちはレイクナFTをインポートします。
そして私たちは
APIと
opencl用のocl_api ()、
そして、get_platforms ()、
そしてget_devices　を作成します。ここで
デバイスに関する
コンテキストを作成します。
最後にFFTオブジェクトを作成します。
コンテキストでFFTオブジェクトをコンパイル。
パフォーマンスを最大化するには、通常、次のように記述する必要があります。
PyCUDAまたはPyOpenCLファイル内のC-code。
これらのコードはPyCUDAやPyOpenCLでコンパイルされていました。
そして、バイナリとしてコンパイルされるとGPUに送られました。
ここでは、ベクトル加算関数を示します。
ベクトルAとBを読み取ります。
それらを追加し、値を宛先に保存します。
このようにしてC-codeは
Python関数の中に、
ラップされます。
この関数を呼び出すと、次のストリングが返されます。
それは、
コンパイラに送られ、
バイナリにコンパイルされます。
より複雑な例は、疎行列ベクトル乗算 (spmv
およびspmvH)
"ここで、spmvは非ユニフォームデータに対して正規分布を計算し、
"
spmvhは非ユニフォームデータに対して正規分布を計算します。
詳しくは申し上げられませんが、出典をご参照ください。
re_subroutine.pyです。
次に、ベクトル化されたCSR spmvコードの詳細について説明します。
CSRとは、
Compressed-Sparse-Row Matrixフォーマットの頭字語です。
ご覧のように「wavefront」というキーワードは
openclにおいて、
これは、
CUDAの「warp」と等しいです。
Wavefrontは、どれだけのスレッドが、GPUプロセッサーにベクトルとして含めることができるかを表します。
次に、vecwidthという別のキーワードを示します。これらは、値をwavefrontに一致させるためのものです。
または
CUDA内のwarp
ここでは、ローカルメモリにメモリを割り当てます。
それはpartial_sumと呼ばれるものです。
ここでは、行列とベクトルを乗算します。
答えはローカルメモリ (partial_sum) に格納されます。
これがLOCAL_BARRIERです。
これは、
__syncthreads ()やCUDA,
またはバリアに相当します。
答えをローカルメモリに保存したので
これは、最終的な値を計算する必要があることがわかっているベクトルです。
reductionを使って。
ここではreductionを示しています
一方その間
bar > 0
私たちはreductionを行っています。
反復するごとにbarの半分の大きさになります。
partial_sumの最終結果が出力に書き込まれます。
以上です。
そして私たちは
ベクトル化されたCSR spmvを多次元に一般化します。
その結果
pELL spmv multi-coilを呼びだし、
コードはCSRマトリックスよりも複雑ですが、
私たちはここで詳細を説明します。
修正版にはまた、順変換と同じ記憶領域を
利用する
随伴演算があります。
メモリのサイズを2倍にする必要はありません。
ですがspmvhはatomic_add関数と
atomic_addを使います。
並列計算が正しいことを
確認してください
1つのスレッドが値を変更すると
答えはその他のスレッドに
左右されない。
アトミック加算は
並列演算が正しいことを確認します。
CUDAには
"値をアドレスに追加する
"
AtomicAdd ()という関数があります。
2和アルゴリズムは、
"単一精度浮動小数点計算の不正確さを緩和できます。
"
ですが、そのような原子付加機能はありませんでした。
単精度浮動小数点数の
opencl 1.2の中には。
そして原子複合体を
使用できます。
Compare-and-exchange (CAS) 関数
そしてそのtrickを実行するために、
unionも使用できます。
詳しいことは今は話せませんが、ソースファイルを調べてみてください。
at re_subroutine.pyです。
誤差の累積を考慮しなければならないので、2和アルゴリズムが必要である。
単精度浮動小数点演算においては。
この場合、残りの配列を保存するために別の配列が作成されます。
ここでは、GPUのコンテキストで作成された残差を確認できます。
それはゼロで埋めらました。
CUDAとOpenCLを切り替えると、クロスプラットフォームの問題がいくつか発生します。
たとえば、
複数のCUDAオブジェクトが、
コンテキストを
スタックの最上位に移動するには、
何らかの処理が
必要です。
ですから
このコンテキストを使用できます。
"もう1つの問題は、OpenCLの実装が異なると
"
動作が異なることです。
たとえば、
"
独自のIntel opencl SDKドライバは、"
通常、オープンソースのNeoやPOCLよりも
"パフォーマンスが良い。
"
AMDグラフィックカードの場合、状況はさらに複雑です。
オープンソースのROCm openclと
独自のドライバーがあるので。
このスライドでは
PyNUFFTはIntelのマルチコアCPU上で
Amazon Webサービス
最初の段階では、パフォーマンスはかなり良好にスケーリングされます。
1から32コア。
その時点で
平坦域に
届き、
パフォーマンスは非常にフラットです。
他のNUFFT/NFFT実装と比較して
PyNUFFTは
最も正確でした。
そして、パフォーマンスは最高です。
御覧のように、前方トランスフォームと随伴トランスフォームは
以下と示しています。
PyNUFFTが
gpuNUFFTとNFFTの中において
最も正確であると。
この図は、PyNUFFTとgpuNUFFTの間のGPUコンピューティングのパフォーマンスを示しています。
"パフォーマンスはgpuNUFFTに非常に近いですが、 
"
PyNUFFTはgpuNUFFTより少し高速でした。
ですが、CPUとGPU間のデータ転送時間を除去すれば
データ転送時間を節約できます。
なので、ここではブルーラインが
一番です。
PyNUFFTパッケージのほとんどはPythonで書かれていました。
一方、以前のパッケージは主にC++で書かれていました。
"ご存じのように、C++は
"
"コードを記述したりメンテナンスしたりするのがより難しいです。
"
もちろん、PyNUFFTの内部には手書きのCコードがいくつかありました。
"また、reikna/pyopencl/pycudaのジャストインタイム (JIT) コンパイルの
"
利点を活用できます。
そしてPythonコードは
は簡略化されています。
最近
Pythonにはより多くのNUFFT実装があります。
たとえば、
finufftとgpuNUFFTがあります。
両方のパッケージは新しい
Pythonバインディングを提供しています。
さらに重要なのは
高水準のルGPUコンピューティング用のpythonパッケージがあり、
例えばcupy、TensorFlow、PyTorchなど
ユーザーがPythonの下でのCUDAプログラミングを
心配する必要はありません。
この1年間で、これらバックエンド上に構築されたパッケージを
たくさん見てきました。
そしてSigPy
torchkbnufft,
tfnufft
tfkbnufft関数　があります。
だから
私たちはこれまで
高水準のPython GPUコンピューティングの台頭を見てきました。
次世代オープンソースソフトウェアのコントリビューターに向けて、いくつかのアドバイスがあります。
まず一つ目に、
オープンソース・プロジェクトに貢献することは、可視化を高めるための優れた方法です。
組織の評判だけではなく。
例えば、PyNUFFTプロジェクトはISMRMの再現性研究グループで使用されていました。
2019
この雑誌の元編集長は
このプロジェクトでPyNUFFTや他のパッケージがどのように使われているかについての論文を書きました。
次世代のコントリビューターへの2つ目のアドバイスとは
もしアカデミック界で働くことになったら、
論文をたくさん書いたほうがいいです。
そしててんびん座はパルマで
コードスプリントで
Hackthlonに疲れないようにしましょう。
最後になりましたが、ご清聴ありがとうございました。お気軽にご連絡ください。
テクニカルサポートについては、pynufft@gmail.comを参照してください。
コントリビューターと産業界や
大学での協力者の皆様に感謝いたします。
ここではPyNUFFTのインストール方法を説明します。
ご覧の通り、これはLinuxマシンです。
このマシンはボックス内にGPUを搭載しています。
「lspci」は
GeForce GTX 1070モバイルを搭載していると示しています。
プロセッサーです。
"まず第一に、CUDAコンパイラ (nvcc) が利用可能であることを
"
"確認する必要があります。
"
ただし、nvccコマンダは検出されません。
パスをエクスポートする必要があります。
これがCUDAがインストールされた場所だからです。
nvccコマンド
これでnvccコマンドを見つけることができます。
そしてて
Pythonのバージョンが正しいことを確認する必要があります。
python -V
Pythonのバージョンは3.6.11です。
望んでいたバージョンはどれですか?　pip-Vを実行してバージョンを確認します。
いいですね。これで準備が整いました。
ホームディレクトリ内のPyNUFFTをインストールします。
以下をインストールします。pip install numpy scipy--user
pip install pycuda pyopencl reikna pynuffff--user
NumPyとSciPyが利用できます。
このシステムではNumPyとSciPyが利用可能なので、ダウンロードしています。
pycuda, pyopencl, 
Reikna、pynufftなど。
パッケージをコンパイルするには、パッケージのビルドに時間がかかります。
インストールが完了したら、
GPUで加速をテストします。
今Pythonに入ってます。
そして
pynufft.testsをtとしてインポート
t.test_init(0)
0は、システムで最初に検出されたGPUを使用することを意味します。
では始めましょう。
Cudaデバイスを見つけることができ、
gxとgyの誤差は非常に小さいです。
加速度は7.77です。
CPUの7.77倍高速です。
共役勾配法を加速します。
それは、GPU上より5.43倍高速です。
インストールになにか問題がある場合は、
pynufft@gmail.comまでご連絡ください。