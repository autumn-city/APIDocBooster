Let's compare errors being larger than 1.0 in case of MSELoss and SmoothL1Loss.
MSELoss would give it value of 100 (or 50 in case of pytorch implementation), while SmoothL1Loss gives just this value of 10, hence it won't punish the model so much for large errors.
In case of value below 1.0 SmoothL1Loss punishes the model less than L1Loss.
