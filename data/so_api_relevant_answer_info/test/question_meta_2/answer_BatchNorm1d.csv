,BatchNorm1d needs 2d input?,<machine-learning><deep-learning><pytorch>,"I want to fix problem in PyTorch.
I wrote the following code that is learning sine functions as tutorial.
[code snippet]
Training is done without error, But the next line caused an error, ""expected 2D or 3D input (got 1D input)""
[code snippet]
This error doesn't occur if it is without BatchNorm1d().
I feel strange because the input is 1D.
How to fix it?
Thanks.
[code snippet]
",www.stackoverflow.com/questions/55320883
,PyTorch LinearLayer+BatchNorm1d with a 3D input,<pytorch><batch-normalization>,"I would like to apply a BatchNorm1d after a Linear. My input is a 3D multivariate time series of shape [batch_size, n_variables, timesteps]. The Linear performs the linear transformation on the third dimension so that the new shape is [batch_size, n_variables, LinearLayer_out_features]. My problem occurs with the BatchNorm1d, I would like to apply it on the third dimension but, for a 3D input, BatchNorm1d operation is done over the second dimension (even for a 3D tensor). Do you have any suggestion on how to do that?
",www.stackoverflow.com/questions/65398540
,PyTorch - unable to use batchnorm1d with Linear,<pytorch><batch-normalization>,"Using PyTorch's BatchNorm1D on a 1-D tensor gives the error:
RuntimeError: running_mean should contain 1 elements not 2304
Any suggestions on what might be wrong?
My Code:
[code snippet]
",www.stackoverflow.com/questions/56399151
,"PyTorch BatchNorm1D, 2D, 3D and TensorFlow/Keras BatchNormalization",<tensorflow><keras><pytorch>,"I want to use BatchNorm1D like in PyTorch in TensorFlow. I notice that BatchNormalization() in TF has axis=-1 as default. Which axis is the correct one for BatchNorm1D, BatchNorm2D, BatchNorm3D as in PyTorch?
",www.stackoverflow.com/questions/64629522
,how does BatchNorm1d() method whithin the torch library work?,<python><pytorch><torch>,"I'm learning pytorch, I don;t know if this question is stupid but I can't find the official web for explaining nn.batchnorm1d. I'm wondering how torch.nn.BatchNorm1d(d1) work? I know that batch norm is about making mean and variance of a batch of example to be 0 and 1 respectively. I'm wondering if there is nn.batchnorm2d, if so, what does it do? what is the d1 parameter ?
",www.stackoverflow.com/questions/61193517
,Output of BatchNorm1d in PyTorch does not match output of manually normalizing input dimensions,<machine-learning><batch-normalization><pytorctl>,"In an attempt to understand how BatchNorm1d works in PyTorch, I tried to match the output of BatchNorm1d operation on a 2D tensor with manually normalizing it. The manual output seems to be scaled down by a factor of 0.9747. Here's the code (note that affine is set to false):
[code snippet]
Output is:
[code snippet]
Doing the same thing for BatchNorm2d works without any issues. How does BatchNorm1d calculate its output?
",www.stackoverflow.com/questions/48991874
,"Expected more than 1 value per channel when training, got input size torch.Size([1, **])",<pytorch><batch-normalization>,"I met an error when I use BatchNorm1d, code:
[code snippet]
but I met:Expected more than 1 value per channel when training, got input size torch.Size([1, 60])
the error message is:
[code snippet]
I have checked and I found that in out = self.BN1(out),out.shape = (1,60),it seems that batchsize=1 is not permitted in BatchNorm1d .But I don't know how to modify it.
",www.stackoverflow.com/questions/65882526
,Pytorch - going back and forth between eval() and train() modes,<python><neural-network><deep-learning><pytorch><reinforcement-learning>,"I'm studying ""Deep Reinforcement Learning"" and build my own example after pytorch's REINFORCEMENT LEARNING (DQN) TUTORIAL.
I'm implement actor's strategy as follows:
1. model.eval()
2. get best action from a model
3. self.net.train()
The question is: 
Does going back and forth between eval() and train() modes cause any damage to optimization process?
The model includes only Linear and BatchNorm1d layers.
As far as I know when using BatchNorm1d one must perform model.eval() to use a model, because there is different results in eval() and train() modes.
When training Classification Neural Network the model.eval() performed only after training is finished, but in case of ""Deep Reinforcement Learning"" it is usual to use strategy and then continue the optimization process.
I'm wondering if going back and forth between modes is ""harmless"" to optimization process?
[code snippet]
",www.stackoverflow.com/questions/58447885
,Error trying to convert simple convolutional model to CoreML,<pytorch><coreml><generative-adversarial-network>,"I'm trying to convert a simple GAN generator (from ClusterGAN):
[code snippet]
But onnx-coreml fails with Error while converting op of type: BatchNormalization. Error message: provided number axes 2 not supported
I thought it was the BatchNorm2d, so I tried reshaping and applying BatchNorm1d, but I get the same error. Any thoughts? I'm very surprised that I'm having problems converting such a simple model, so I'm assuming that I must be missing something obvious.
I'm targeting iOS 13 and using Opset v10 for the onnx conversion.
",www.stackoverflow.com/questions/60917399
,How to run BatchNorm on a ragged tensor in TF 2.x?,<python><python-3.x><tensorflow><tensorflow2.0>,"I'm trying to run BatchNormalization on a batch of ragged tensors in TF 2.x, but seem to run into errors while doing this. (I can do a conversion to and from ragged tensors before and after the BatchNorm forward call, but I'm unable to run a to_tensor() in NonEager mode, which is a requisite for me to train the network efficiently).
Pytorch has a BatchNorm1D, but TF does not seem to have any such API, any suggestions/pointers would be helpful.
",www.stackoverflow.com/questions/66130598
,what is wrong with the following implementation of Conv1d?,<python><pytorch><conv-neural-network><batch-normalization>,"I am trying to implement a Conv1d layer with Batch Normalization but I keep getting the following error:
[code snippet]
The data is passed on in batches of 32 using DataLoader class and it has 40 features and 10 labels. Here is my model:
[code snippet]
I have tried given in other answers like unsqueezing the input tensor, but none of the models in such questions is using Conv1d with batchnorm1d so I am not able to narrow down the problem to which layer must be causing the error. I have just started with using Pytorch and was able to implement a simple linear NN model, but I am facing this error while using a convolutional NN for the same data.
",www.stackoverflow.com/questions/67089289
,Using nn.Linear() and nn.BatchNorm1d() together,<pytorch>,"I don't understand how BatchNorm1d works when the data is 3D, (batch size, H, W).
Example
Input size: (2,50,70) 
Layer: nn.Linear(70,20)
Output size: (2,50,20)
If I then include a batch normalisation layer it requires num_features=50:
BN    : nn.BatchNorm1d(50)
and I don't understand why it isn't 20:
BN    : nn.BatchNorm1d(20)
Example 1)
[code snippet]
Example 2)
[code snippet]
Example 1 works. 
Example 2 throws the error:


RuntimeError: running_mean should contain 50 elements not 20

2D example:
Input size: (2,70) 
Layer: nn.Linear(70,20)
BN: nn.BatchNorm1d(20)
I thought the 20 in the BN layer was due to there being 20 nodes output by the linear layer and each one requires a running means/std for the incoming values.
Why in the 3D case, if the linear layer has 20 output nodes, the BN layer doesn't have 20 features?
",www.stackoverflow.com/questions/57114974
,How to do fully connected batch norm in PyTorch?,<python><neural-network><deep-learning><pytorch><batch-normalization>,"torch.nn has classes BatchNorm1d, BatchNorm2d, BatchNorm3d, but it doesn't have a fully connected BatchNorm class? What is the standard way of doing normal Batch Norm in PyTorch? 
",www.stackoverflow.com/questions/47197885
,Create Analogous Head in Keras,<keras><keras-layer><tf.keras><fast-ai>,"When I create a CNN in Fast AI using transfer learning a head like this is created:
[code snippet]
I would like to create one as close as possible to this one in Keras, however I am stuck on the AdaptiveConcatPool2D part of this.  There doesn't appear to be any classes like this currently available.  Any ideas on how to replicate this as closely as possible in Keras?
",www.stackoverflow.com/questions/60518169
,Training Accuracy Increasing but Validation Accuracy Remains as Chance of Each Class (1/number of classes),<python><deep-learning><conv-neural-network><overfitting-underfitting>,"I am training a classifier using CNNs in Pytorch. My classifier has 6 labels. There are 700 training images for each label and 10 validation images for each label. The batch size is 10 and the learning rate is 0.000001. Each class has 16.7% of the whole dataset images. I have trained 60 epochs and the architecture has 3 main layers:
Conv2D->ReLU->BatchNorm2D->MaxPool2D>Dropout2D
Conv2D->ReLU->BatchNorm2D->Flattening->Dropout2D
Linear->ReLU->BatchNorm1D->Dropout And finally a fully connected and
a softmax.
My optimizer is AdamW and the loss function is crossentropy. The network is training well as the training accuracy is increasing but the validation accuracy remains almost fixed and equal as the chance of each class(1/number of classes). The accuracy is shown in the image below:
[Accuracy of training and test (hyper-link)]
And the loss is shown in:
[Loss for training and validation (hyper-link)]
Is there any idea why this is happening?How can I improve the validation accuracy? I have used L1 and L2 Regularization as well and also the Dropout Layers. I have also tried adding more data but these didn't help.
",www.stackoverflow.com/questions/68094943
,How to view Neural Network model internal architecture (embeds Module List) and (Layer) details in FastAi?,<neural-network><categorical-data><tabular><embedding><fast-ai>,"I am trying to view the internal architecture of my trained neural network in FastAi. My model is trained using FastAi Tabular. How can I view the internal details of the model? I need to see the Embedding Module List for my categorical variables. I found the output from a Blog, but they didn't have the code for it. The output looks something like this:
[code snippet]
",www.stackoverflow.com/questions/62681989
,Size mismatch in fully connected layers,<python><pytorch>,"I build the following simply model in pytorch as a first run and I am gettign a size mismatch error that does not make sense as out_feat always equals in_feat for the subsequent layer...
[code snippet]
I do not understand how I am getting this error when all the dimensions match does anyone see the issue?
[code snippet]
here is model summary
",www.stackoverflow.com/questions/64417660
,PyTorch: Dropout (?) causes different model convergence for training+validation V. training-only,<deep-learning><neural-network><pytorch><dropout>,"We are facing a very strange issue. We tested the exact same model into two different “execution” settings. In the first case, given a certain amount of epochs, we train using mini-batches for one epoch, and thereafter we test on the validation set following the same criteria. Then, we go for the next epoch. Clearly, before each training epoch, we use model.train(), and before validation we turn on model.eval().
Then we take the exact same model (same init, same dataset, same epochs, etc.) and we just train it without validation after each epoch.
Just looking at performance on training set, we observed that, even if we fixed all seeds, the two training procedures evolve differently and produce quite different metrics results (losses, accuracy, and so on). Specifically, the training-only procedure is less performing.
We also observe the following things:
It is not a reproducibility issue, because multiple executions of the
same procedure produce exactly the same results (and this is
intended);
Removing the dropout, it appears that the problem vanishes;
Batchnorm1d layer, that still has different behaviours between
training and evaluation, seems to work properly;
The issue still happens if we move from training onto TPUs to CPUs.
We are working and tried Pythorch 1.6, Pythorch nightly, XLA 1.6.
We quite lost one full day in trying to tackle this issue (and no, we cannot avoid using dropout). Does anyone have any idea about how to solve this fact?
Thank you very much!
p.s. Here the code employed for the training (on CPU).
[code snippet]
And here is the function that initializes the model and set the seeds, called before each execution of the code of ""_run"":
[code snippet]
",www.stackoverflow.com/questions/63815020
,mat1 dim 1 must match mat2 dim 0 - PyTorch,<python><pytorch><conv-neural-network>,"Im new to PyTorch and I keep getting the error mat1 dim1 must match mat1 dim0
this is my code for the network
[code snippet]
and where the print statements are:
[code snippet]
Any help/advice?
",www.stackoverflow.com/questions/65111622
,Get probability from predicted class pytorch,<python><machine-learning><computer-vision><pytorch>,"I have a network like this for image classification, for now i have 2 classes:
[code snippet]
then after i training my network, i predict the image using this code:
[code snippet]
how do i get all class probability of prediction image? so the result would be array of index with probaility like 0=0.1, 1=0.7
",www.stackoverflow.com/questions/62364328
,Issues converting Keras code into PyTorch code (shaping),<machine-learning><keras><deep-learning><pytorch>,"I have some keras code that I need to convert to Pytorch. I am new to pytorch and I am having trouble wrapping my head around how to take in input the same way that I did in keras. I have spent many hours on this any tips or help is very appreciated. 
Here is the keras code I am dealing with. The input shape is (5000,1)
[code snippet]
Here are the results of model.summary() from the keras code
[code snippet]
Here is what I have made in pytorch
[code snippet]
Lastly here is the model summary for what my pytorch model creates
[code snippet]
",www.stackoverflow.com/questions/55636138
,Python Error RuntimeError: expected scalar type Long but found Double,<python><numpy><pytorch>,"Firstly, I am fairly new to python/ML in general. I am attempting to utilize the model depicted at [stackabuse (hyper-link)] over my own data set.
Everything flows smoothly until I get ready to run the epochs.
In debugging I see that it is failing on CrossEntropyLoss function and I get the error expected long found double. The data set it appears to fail on is the my tdiff column that I calculated but I can't seem to figure out how to convert it to a long.
Is there something that I'm missing in trying to figure this out?
To be clear, this is what I THINK it is based on my extremely limited knowledge on the function:
[code snippet]
output:
[code snippet]
",www.stackoverflow.com/questions/64957007
,How can I calculate FLOPs and Params without 0 weights neurons affected?,<python><deep-learning><pytorch><pruning><flops>,"My Prune code is shown below, after running this, I will get a file named 'pruned_model.pth'.
[code snippet]
and results is :
[code snippet]
There are many zero weights existing. How can I calculate FLOPs and Params without counting calculations associated with these zero values?
I use the following code to calculate FLOPs and Params.
[code snippet]
The output of both ori_model nad pthfile is the same, as follows.
[code snippet]
",www.stackoverflow.com/questions/64551002
,"RuntimeError: Expected 4-dimensional input for 4-dimensional weight 128 256, but got 2-dimensional input of size [32, 128] instead",<pytorch><dimensions><generative-adversarial-network>,"I am working on creating an image generator using conditional GAN as the base model. I've run across an error that I don't understand how to debug, even after searching for solutions online. I'm not sure if I should change the settings for training or do some adjustment to my model, or something else. Any help on what to do would be appreciated.
The CGAN model I am using:
[code snippet]
Code for initializing the model:
[code snippet]
Code for setting up the training:
[code snippet]
Settings:
[code snippet]
Image size as input:
[code snippet]
Model structure:
[code snippet]
The error I got:
[code snippet]
I am using my own image dataset with 3 channels and 25 classes. I have tried to change the image size and kernel size but still got the same error. Any help on what should I do to debug would be highly appreciated.
",www.stackoverflow.com/questions/63275709
,Problem when converting Pytorch Image Classifier to mlmodel: Returns same softmax output regardless of img,<machine-learning><pytorch><onnx><mlmodel><onnx-coreml>,"I trained and tested an image classifier (Resnet34, Fast.ai, 3 classes) using pytorch and learn.predict() works as expected. When I convert pytorch -> onnx -> mlmodel it predicts the same softmax values regardless of the image I submit. 
Here's my pytorch model:
[code snippet]
To convert it to .onnx, I need to first normalize the image data and flatten it. I found [this tutorial (hyper-link)], which worked on a previous version of fastai/onnx-coreml. I do this with the following class:
[code snippet]
To construct the entire model, I concatenate my ImageScale layer, the model, and a softmax function like this:
[code snippet]
Which ends up looking like this:
[code snippet]
I convert to .onnx like this:
[code snippet]
And I convert from .onnx to .mlmodel like this:
[code snippet]
When I call predict using coremltools, I get the same output regardless of the image I input:
[code snippet]
Possible issues:
1. I'm not setting up the Sequential correctly before converting
2. Coreml or onnx cannot handle non-square images
I've tried a bunch of different inputs, but keep getting the same so any help would be much appreciated!
Here are screen shots of my head and tail from netron:
Head:
[ (hyper-link)]
Tail: 
[ (hyper-link)]
",www.stackoverflow.com/questions/58276161
,How to export fast.ai model from Jupyter Notebook hosted on external server(google cloud compute instance)?,<python><jupyter-notebook><fast-ai>,"I currently using fast.ai to create machine learning models that classify images. I am using Jupyter Notebook to do my training and it is hosted on a GCP instance that I created. 
Currently, I have finished training my model and whatnot, and I am ready to export it out of Jupyter Notebook so I can use it locally on a python file to do some image classification using predict().
[code snippet]
So I added this line:
[code snippet]
When executed, the line above returns the chunk below. However, I can neither find a .pkl file (the intended output from the export) on my Jupyter Notebook directories nor locally in Finder. 
So for one, am I exporting my model correctly, and more importantly, how do I export a file out from Jupyter Notebook into my local files?
[code snippet]
",www.stackoverflow.com/questions/62089123
,How to move data_parallel model to a specific cuda device?,<pytorch>,"I currently need to use a pretrained model by setting it on a specific cuda device. The pretrained model is defined as below:
[code snippet]
If I conventionally declare
[code snippet]
with device on cuda:1, then it makes error when forwarding:
[code snippet]
I think this is because the model was previously trained with data parallel utils in pytorch.
How can I properly set the model to the device that I specifically want?
",www.stackoverflow.com/questions/67298294
