what's going on everybody and welcome to
part 5 of the PI torch tutorials for
deep learning with Python in this video
in the coming videos we're going to be
talking about a new type of neural
network and that is the convolutional
neural network or really a new type of
layer because generally we tend to mix
convolutional layers with like at least
like dense layers or what we're calling
in PI torch are linear layers and
basically just your fully connected
layers typically you're mixing these
things together but anyway what are
convolutional neural networks used for
so traditionally we use convolutional
neural networks for image tasks but as
of recently and by recently I mean like
one to two plus years convolutional
neural networks actually appear to be
outperforming recurrent neural networks
in terms of doing sequential types of
data so obviously if you guys aren't
already familiar with the recurrent
neural networks that's totally fine and
we haven't really talked about those yet
but if you have heard of recurrent
neural networks I'm not even sure I'm
going to cover recurrent neural networks
in this series because convolutional
neural networks seem to be actually
doing better than recurrent Nets on
sequential types of data so and that's
one dimensional convolutional neural
networks anyway moving along typically
or the main use cases imagery so let me
explain how convolutional neural
networks work I'm gonna go give a very
high-level explanation of this if you
want to dig deeper again I think I'm
pretty good at teaching programming I
don't think I'm the greatest at visuals
so if my explanation and visuals aren't
enough for you there's tons of great
visuals online that you can just do a
Google search for to figure out how
these things work but anyway here we go
so let's say you've got an image of a
cat the way a convolutional neural
network works is you actually do pass
the image in its form so you don't have
to flatten the image like we did with
fully connected layers a convolutional
neural network accepts two-dimensional
input it also can accept
three-dimensional inputs so you could
feed through models like actual like
like 3d printing models right to a
neural network or you could or like for
example I did
while ago with Kegel there was a good
lung cancer detection and those lung
scans were three-dimensional so you
could pass that through a 3d confident
and so on but anyway again the most
typical use case is a two dimensional
confident so let's say you've got an
image and you're gonna pass it through
well first of all it's actually it's not
just an image it's pixels right so it's
this two-dimensional array of pixels and
then what happens is we apply these
convolutions so the convolution is going
to come over this image and basically
the convolution its goal is to locate
features of an image so in this case you
know this image is only what a 5 by 4
image so it's a little impractical but
it's just four examples so this window
is a 3 by 3 so generally you'll hear the
the window is usually called a kernel so
this is a 3 by 3 convolution kernel and
so it's gonna take 3 by 3 pixels and
that's going to look for a feature of
those 3 by 3 pixels so but in terms of
numbers like the Machine again neural
networks work on numbers not strings not
you know concepts like slant or
something like that but what it ends up
doing is let's say the first layer of
convolution filters basically are these
kernels it tends to find things like
edges or curves or maybe corner okay and
then it gets passed through another
layer which finds more complex features
that edges curves and corners build so
this would be things like circles and
squares and stuff like that but getting
back to our initial you know 3 by 3
kernel so what it does is it looks here
it tries to find a feature in this 3 by
3 and it generates a scaler and you know
some sort of number and then it ends up
sliding that window over and again
performs another convolution and
basically just keeps sliding that window
over the entire image and what it ends
up doing is basically condensing that
image so you'll pass an image and
generally you'll say hey
I have I want to I want you to find 30
features of this from this image
basically so but it's gonna do is it's
gonna go over and find 30 of those in
this case in fact it's basically
condensed into four so you've got a 2 A
1 a 4 and a 3 ok so after you do your
convolution you'll wind up with
something like this so it'll just be
this you know new condensed version of
your image where basically these are yes
they're numbers but to the Machine
they're features and then we tend to do
a pooling so you've got this and then
you pool again the pooling has a window
and the most common form of pooling is
max pooling so all it does it's a really
complicated algorithm but basically
inside the window it takes the maximum
value I know it's really challenging so
of this window that max value is a 4 and
then it just slides and does that and
for max pooling we take all of these and
we pull it and it becomes this so again
all this convolutional neural network is
really doing is drastically simplifying
your image and it looks for features of
the image and generally you're gonna
have two three four sometimes even more
than that layers of these convolutional
layers okay so again the first
convolutional layer is most likely just
going to find very basic features edges
corners curves then it goes to another
one which is a combination so that next
layer it's going to be making
convolutions that are combinate so think
of like like the first layer is all it
can do is generally like a 3x3 is a
pretty common kernel size or maybe even
a 5x5 anything bigger than that is
actually a pretty big starting kernel
size it's pretty uncommon that you'd see
that so just think about like what is it
what could you get from 3x3 pixels not
very much so that first layer the
features that it finds are combinations
of pixels so that's why it only finds
like a corner or edge or maybe a slight
curve but then it ends up to the next
layer that next layer sees combinations
of curves
edges in corners and it builds things
out of those right it finds features out
of those so it finds circles and squares
and so on and then the next layer after
that finds combinations of circles and
squares and stuff like that is it's it's
a little more complicated than that but
that's what it's doing it's kind of
reducing your image to very basic you
know building blocks and then finds
patterns of those blocks given how many
layers you have so anyway that's kind of
the concept of a neural network or a
convolutional neural network rather
let's go ahead and apply it to some data
also if you've got questions about my
explanation feel free to leave them
below or come into the discord and ask
so the image or the yeah the data set
that we're going to use you can get that
by typing cats verse dogs Microsoft data
set and we're gonna use this cats versus
dogs data set from kaggle and so if you
cats okay yeah so just go ahead and
click on that one go to download and
then it will just start the download
automatically I've already downloaded
mine and then just put it in the
directory that we're working in once
it's in there go ahead and extract it
and what you get when you extract it is
if I can find mine let me come over here
basically you get pet images here so
you'll click on this and then you get
these two directories one is cat one is
dog and as you might think inside you've
got images of cats and dogs so if I also
take note there's this thumbs dot DB
that'll become important later so here
you can see it's just a bunch of images
of little demons and then you come over
here and it's a bunch of images of
adorable animals otherwise known as dogs
so one thing you might notice right out
of the gate is you've got various sizes
of images and then you've also got color
and then also some of the images clearly
the dog is the main thing in the image
but then here you know there's a dog in
here but there's also a human in here
and there's just other stuff the dog is
not
really dominating the photo so anyway
you've got animals in various locations
but the goal will be to identify whether
or not like every image has either a cat
or a dog we don't have a nun but that
would be another challenge for another
day so every image definitely has a dog
or a cat in it and what we want is the
neural network to determine if it's a
dog or if it's a cat so that's what
we're gonna do but first we have to
build the data set so like I said before
just importing the data from from PI
torch and torch vision is basically
cheating because you're skipping
probably the most work that you're gonna
do with neural networks and that's
pre-processing so even this we're gonna
have a pretty easy time because these
are pretty images to detect on but I
will at least kind of reference some of
the things that you're more likely to
have to do on a more challenging type of
data set so like I said trying to slowly
ratchet up the complexity here because
on realistic problems you'll find that
neural networks aren't quite as easy as
online tutorials make them seem they
aren't just magical problem solvers so
so I mean they are but you have to work
at it
so coming over here what we're gonna do
is we're just gonna start completely
fresh also shouts out to vinson 7 for
sharing with me how to make the default
font size larger encode cells
you're a hero my friend thank you very
much so so so we're first we're gonna
make some imports we're gonna import OS
import CV to import numpy as NP and from
t qdm we're going to import TQ DM if you
don't have some of those those are
third-party libraries so if you don't
have those uh let me just pop up a quick
terminal here do a pip pip install
OpenCV - python if you don't have numpy
then grab numpy and if you don't have
Tiki diem grab TQ TM you already have OS
that comes with Python so once we've
done that the next thing we're going to
do
we're gonna make a little flag called
rebuild data I'm gonna set that to be
true for now but basically in your
pre-processing dataset you don't want to
build data every single time you run
your code so you probably just want to
run it one time often it will be the
case that you separate out your
pre-processing data set from your neural
network code but sometimes there's not
that much code to be written so you'll
use like a flag or something like that
but generally the pre-processing step
can take a pretty long time in our case
this is a simple data set and it's not
very huge so it won't take very long but
there are there's lots of times I've got
pre-processing step that takes more than
a day even to run so it can be quite
painful so yeah so you just want to run
it as few times as you as you have to
run it all right I'm back somebody at
the door they were trying to tell me
about the benefits of being a channel
member if you click that beautiful blue
join button apparently you get early
access to videos you get a special rank
in the discord as well as your own
little channel hidden away from all the
other amateurs
also clicking that subscribe button is
apparently also beneficial in certain
ways I guess you get notified about
videos and stuff especially if you hit
the little bell
anyway interesting information back to
the tutorial so so after her yeah the
flag basically we were gonna make a
class here I'm gonna say it's dogs vers
cats and you don't necessarily have to
have a class for what we're gonna do but
generally for doing image processing
many of the steps that you're gonna do
are steps that you probably want to take
with just about any image prediction
task so you're gonna do a lot of the
same methods every single time so
sometimes it can be convenient to have
something like this going but anyway we
probably don't even need this to be a
class but I'm gonna get a class so so
first of all we're gonna specify the
size of the image we're gonna go with 50
and basically we're gonna make images 50
by 50
so part of the problem is all of these
images are varying sizes and shapes some
are more portraits some are landscape
that's a problem we need them to be
uniform on the input there are ways that
we can get a round this but way more
advanced than what I want to talk about
so what we want is these to all be
normalized in the sense that they're all
the same size so the way that we're
gonna do that is just quite literally
let's just take any of these really
we'll take this little pup err and it
we're just gonna resize them so 50 will
make them all 50 by 50 and as you can
see that's still very clearly a dog some
of these uh will get relatively
distorted I'm trying to fears one well
that's already a terrible photo that's
just a sad looking dog let's resize I'm
trying to find here this one looks like
it might be good let's see what are what
are your dimensions good sir
even this one's not too far off but
anyway oh we want the smallest dimension
to be 50 right so it distorts the image
a little bit but it still is clearly a
dog trying to find like one that's like
really good like maybe this one although
this is this isn't really a dog this is
like a basically a cat but it should
still work for what we're trying to show
so if we said 50 you resize that oops
actually what we wanted to say is don't
maintain the aspect ratio 50 by 50 but
still clearly at least to me I would say
that is a attempt at being a dog it's
definitely not a cat so we'll close this
and that's basically what we're gonna do
now there's other things that we could
do I can't believe I was resizing those
without changing the aspect ratio but
whatever so so we'll do this image so if
we resize this image we want the largest
one to be 50 and the smallest one the
other thing that you could do is you
could just pad right so you could resize
and then pad with OpenCV that this is
pretty close to what it would do and
then you can pat it as either white or
black or whatever you want to do so
there's padding that you can do there's
also other operations that you can do
with images one thing you
can do is you can shift so you can just
shift over the image and then crop as
needed you can rotate images you can
flip them either vertically or
horizontally so there's lots of ways
that you can kind of augment your data
set and just and honestly it ends up
being like if you flip or rotate the
image enough where you change colors
enough you can act like it's it's it's a
way to take one image and make it like
four images so you can like 4x your
training data size so that's pretty
useful again not gonna do that we're
gonna keep that as simpler this as
simple as possible just know all those
operations exist and chances are if you
have a much more challenging task you're
gonna be doing stuff like that but for
now we're gonna do it really simply
we're just going to resize everything to
50 by 50 and luckily for us this is a
relatively easy task that we're asking
of the machine there are pretty definite
feature differences between dog and cat
so we can get away with this so what
we're gonna say now is we're just gonna
give the cats and then dogs directory
location so this is just pet images
slash cat dogs is pet images slash dog
and then we're gonna say labels and
we're gonna say cats oops
cats will say those are now is 0 and
then dogs will say that's a 1 class and
we'll end up converting these to be a
one hot vector but for now this is just
nice and simple so we'll do that now
because mostly this will give me the
opportunity to show you guys because
sometimes you will have training data
sets that are pre labeled but very
rarely are they pre labeled in one hot
vector format they're pre labeled with
just like class values like this and I
think one hot vector is just make more
sense I think the whole vagary of saying
hey yeah it outputs 10 but then we
somehow compute loss on a single value
that doesn't really make sense so anyway
those are the label or the classes that
we're gonna say cats are a zero dogs or
a one so now what we're gonna do is
finally we're going to say training data
and that's going to be an empty list for
now but that's what we're gonna populate
with images of cats and their labels and
dogs and their labels
finally we're gonna say cat count cat
count equals zero
dog count equals zero not one and we're
just gonna use this as a counter as we
append training samples to training data
we just want to count again because we
need to always be weary of balancé
balancé will tag you so many times in
this journey of machine learning and
deep learning
just get it ingrained immediately to pay
attention to balance it will it will
mess with you so so now hmm what were to
say is define make training detta past
self here and the first thing we're
gonna do is we're gonna iterate for
label in self dot labels so it's just
gonna iterate over cats and dogs so keep
in mind label this so for label and
labels this is iterating over the keys
of our dictionary the keys are cats and
dogs and those point to here so it's a
directory so for label in self dot
labels what do we want to do first let's
go ahead and we'll just print label just
so you can see what's going on then what
we're gonna do is we're going to load in
that image so see v2 dot M read and then
we want to read in well first we need a
minute let's make the path so we're
gonna say path equals OS dot path join
and we want to join the label and well
we also need to we need it or iterate
over the directories let me so for
labeling so now what we want to do is
for F in and then we want to iterate
over all the the images in the directory
so here we're iterating over the
directories what we want to actually do
is iterate over all of the image images
within the directory so for F in well we
want to say OS dot list Durer of label
because that's your directory but we're
also going to use T qdm so TK DM is just
a progress bar basically just so you
know kind of where you are that's it
you'll see it when we get there if
you've not seen me use T qdm before so f
will be just the
name itself what we want is actually the
full path to the image so we're just a
path equals OS top path join label and F
and then we're gonna say image equals CV
to M read path and then we're going to
compute convert that image to grayscale
so BC me to dot M read underscore gray
scale so we'll convert it to grayscale
again with with images and cons Nets you
don't have to convert to grayscale like
we did with M nest for example in the
regular dense layer a dense layer or a
linear layer or a fully connected layer
whatever heck you want to call those
basic neural network layers those will
require you to pass flattened data but a
convolutional layer it could be flat so
you can have a one-dimensional
convolutional network you can have a
two-dimensional convolutional neural
network you can have a 3-dimensional
convolutional neural network you're
gonna have an 8 dimensional
convolutional neural network you can
have any amount of dimensions that you
want
I don't think 8 is built in we might you
might have four dimensions built into pi
torch I want to say tensorflow has 4d
commnets just built in but you can make
them yourself as well anyway we're going
to do a 2d so it's just X&Y we're not
going to deal with color but if you want
color doesn't actually add another
dimension what color adds are channels
so whether we have color or not actually
doesn't really matter with a continent
but it's added data that we don't need
so one question that you would ask
yourself is is color a relevant feature
of defiant determining whether something
is a cat or a dog I don't think it is
like I just don't think so
that's like saying like is for relevant
I don't think so I think cats and dogs
have pretty similar coat colors the
things that are different in cats and
dogs are like the patterns right like
very rarely if ever have I ever seen
like a stripe 'add dog right but lots of
cats are kind of stripy so anyway I
don't think color matters so we want it
you always want to simplify simplify
I simplify with neural network so you
want to make it as easy as possible for
them to learn and the other thing you
always are trying to do is make a small
as possible of a neural network so
anyway we are going to go with greyscale
again that act that does make the neural
network also smaller it's simpler data
coming in but also because it's less
channels that's immediately smaller as
well
myname ways so we've got the grayscale
images but now we want to resize those
so we're gonna say image equals C v2 dot
resize we're gonna resize the image and
then two dimensions that we're gonna
resize to our self dot image size by
self dot image size so we have our
resized image now we're ready to self
dot training underscore data dot append
and we want to append the numpy array of
image as well as the class now we're
going to use one hot vectors this time
so the last time again we use scalar
values I think it's more clear if
everything's in a one hot vector format
plus we get to use better loss metrics
or ones that make more sense so that's
what I'm going to do now I just I think
it makes more sense to do that but just
remember you can go either way and
depending on which way you go you're
going to use a different loss metric but
anyway the way that we can convert
scalar values like this - one hot
vectors and again a one hot vector like
we've got two classes here so cats
equals zero dogs
equals one if we convert this to one hot
vector if there's two classes so the
vector in theory would be a zero zero if
there was no hot if it's a dog it's a
zero one if it's a cat it's a one zero
okay it's what index is hot so to speak
on so the way that we can convert things
- one hot vectors is with a function
called num pi I and if somebody knows
why specifically this is called I let me
know because I don't know but what this
is going to do
it's going to make a five-by-five with
the with basically ones diagonal so here
you have it one two you know just
basically the 0th index the first and so
on so what we can do though is now if we
have a class so cats are a zero dogs are
one so what we put here is it's there's
two total classes and then we're gonna
say the zeroeth index what that gives us
is a 1 0 if we say the first index what
it gives us is a 0 1 and this is true
for however many classes you have so if
it was 10 and it's a 7 this would make
the want this perfect one hot vector for
us so it's kind of a neat little trick
to giving us a way to make these one hot
vectors in literally one function call
so pretty cool so that's what we're
going to use here as well so we're gonna
say numpy i 2 and then the class that's
hot we'll just be self dot labels for
whatever that label is so here is your
full line again to text-based version of
the tutorials or in the description so
if any part of this you miss or
something or sometimes i code and my
face is in the way like this if that
ever happens
check the textbook text-based version of
the tutorial so so now we're appending
all this information to our training
data the next thing that we want to do
is if label is equal to self dot cats
we're gonna say cat camp actually it
should be self self dot cat count plus
equals 1 and then l if the label is self
dot dogs
let's do self dot dog account plus
equals one that way we'll get the counts
at the very end and basically our goal
is that these these two should be either
identical or very close if not we need
to throw away the sum of the samples
from the class that has way more samples
so you don't need a perfect distribution
but ideally it should be very very very
close or really better put anyone anyone
class should be
relatively close the other one so
sometimes you might have let's say a
hundred classes but if out of a hundred
classes one of those classes occupies
let's say three percent of the training
data that's huge compared to all the
other ones it's more than three times so
again as your neural network optimizes
initially it's gonna optimize for that
one class and then it's gonna get stuck
and totally lost so anyway just keep
that in mind we want these all to have
about the same number of samples so uh
so for labels so for F the other thing
we're going to do is I'm going to encase
this in a try and accept and I'm going
to pass accept exception as E but if you
want you can print stringy I'm not going
to because I already know what's going
on but what is going on is for whatever
reason some of these images are no good
so when you try to load them in you're
gonna get an error or maybe it's on the
resize anyways some of the images are
goofy they're either corrupt or they're
just empty like there's no actual image
there so you're gonna hit an error so
we're just gonna handle for that now and
because we're printing out cat count and
dog count we'll know pretty quickly if
something went terribly wrong but
normally you would print stringy there
for sure but I'm just letting you know
that I already know there's errors and I
know they're worthless so anyways I'm
just gonna pass there so once you've
done that basically you have this
training data which is going to be this
massive list of a bunch of cats with the
label of cat and a bunch of dogs with
the label of dog what we then need to do
of course is shuffle that data so
outside of here tab tab to two tabs over
so basically after we've run this for
loop what do we want to do we're going
to say numpy dot random dot shuffle and
we want to shuffle self dot training
underscore data this like random shuffle
as well shuffles in place so you don't
really place the next thing we're gonna
do is numpy dot save and we're gonna
save this as training data umpire npy
and then self dot training data is what
we want
save now let's print out print cats and
then we'll print self are actually yeah
self dot can't count self dot cat count
print dogs self dot dog count and I
think we're ready to actually run this
and willfully no major errors I'm sure
we'll get some so then what we're gonna
say is if we'll just say rebuild data if
that's set to true dog of the cats
equals dogs verse cats and then dah dah
let's make this dogs be cats dogs V cats
dot make training data let's go alright
so it's loading in pretty quickly
they're cool ok so we're gonna make sure
we don't hit any major errors hopefully
we don't at least want to see the counts
of cats and dogs but once we've done
that I think probably then we'll do the
next tutorial and actually start like
going through our data splitting it into
training and testing because that was
another thing that we didn't really have
to do and then passing it through the
network training all that iterating
doing batches all that kind of stuff we
got there's a lot more to go even but
still before we pass it through the
network but I think we'll do that and
pass it through the network in the next
video anyway
mmm so here we can see what the balance
is it's twelve thousand four hundred and
seventy six to twelve thousand four
hundred and seventy so as you can see
here we lost twenty four images well you
don't know this but the goal was to have
twelve thousand five hundred images of
cats twelve thousand five hundred of
dogs actually you could have read it
here the extra one is for the database
which we would have aired out anyways so
that was the other thing so yeah for
tryin except so so if I open this up
the other thing that we see here if we
go back to list mode and we sort by type
you'll see there's also a Thums database
I don't know why that's there but that
is there so so we will have tried to
open thumb's database with open CVM read
that will have failed as well but we
handled it because we're expert
programmers with our passes on
exceptions okay so so we've got some
training data so the next thing I guess
well let me just do this real quick so
let's do training data equals NP load
training data numpy so we've saved it
then to get it back in so we only
hopefully run this one time and we're
done we'll never run this again in this
tutorials so let's set this to false
unless we have some sort of other error
that we hit but now we try to maybe
object arrays can't be loaded in when
allow pickle is false why are we
allowing pick a little false why would
that be the case I wonder if something
which of these things would have not
allowed pickle huh let's let's just try
to throw and allow pickle to true I've
never had to do that let's try that cool
okay ready
so first let's print Len training data
let's just see what we've got yep about
25,000 so that's all of our samples so
then the next thing that we could do is
let's say print training data 0 that
should be the image in the class so this
should be an image of a cat let's do one
okay so it already goes to dog I'd
rather show an image of a dog anyway so
let's do that so then what we're gonna
say is import mat plot lib pipe lot as
PLT and then what we'll do
PLT 'don't em show we should be able to
just show this zero oh we have a name it
scaled this we might have to scale that
as well but I just want to make sure
that everything worked as intended and
so will just plot p.m. show and then PLT
show see how that works pretty hard to
tell it's a dog to be honest but it's
but for example dogs generally have
longer legs than cats the tail is
generally more fluffy and so on so I can
tell there's a dog but so one thing that
we could do is someone someone even
brought this up why why is it all funky
colored it's just because matplotlib is
first of all it's a charting program not
really meant to show images although in
this case it is kind of goofy that I
can't do it but it's because this is a
grayscale image that it it just doesn't
quite know what to do with it
so one thing we can say is we can say
see map for a color map equals did that
just get rid of my parentheses again why
does it keep doing that that's silly why
does it keep doing that we'll set this
to be great what what is happening I'm
losing my mind feel T - oh okay so now
it's like a grayscale so this is really
more what the neural network sees why
did that happen
that's super crazy is it because it
insert that I hit insert at some point
yeah I guess I must have hit insert
that's got weird behavior when you have
insert on okay so and then if we wanted
so training data 1 0 and if we print 1 1
you can see there's the classification
so now what we want to do is start
taking batches of this data passing it
through our neural network
optimizing and learning how to classify
this as dogs and cats and so on so
that's what we're gonna do in the next
video probably the only real new concept
is one how to make convolution layers
and then to batching data and then we
might start putting things on the GPU
will see you will see what I feel like
doing anyway questions comments concerns
whatever feel free to leave those
blow otherwise I'll see you guys in the
next video