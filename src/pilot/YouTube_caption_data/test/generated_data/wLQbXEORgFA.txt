today i will run test this small
cnn with the libtor c plus plus and gpu
enabled
and i begin with the with this
uh example i found here and i change
this code for adding a batch norm
i want to test batch norm layers and see
the differences
in in this small
convolution neural network so i begin
with the
making and directory
i call it hello tree
and then i will
will clone this repository
and if
to install the pos ability to
run the i have a guide in here
you can choose this guide
and um i have a video
also but it's a bit messy here
in part two so the video is
quite long but you can go through this
install the process and i have also
opencv there for further
investigation anyway
now we have our
uh things here hopefully
we have have our cmake and our main
and i start
we shall code
so
i modify my code with batch norm
layer here to batch norm and see if it's
changed and below here i
also have to remove all this
below here i make lot of printouts and i
will remove this because it's so
many printouts during training and so on
so i
change this now
i will only have
print outs for
the model and we will see
this so i have
done that and also i need to
change my directory here and
get some
some the libtors library here
i need that so i
copy that and all that stuff
is explained in the installation guide
i show you before so now we have that
one place our libtors and
we i will to change
this puff two
two
three and also i need
lead torch that was not
the right path i need
this path
now it seems better we will see if it
works
we try cmake
and that seems right and
then we do make
and if we start the program now we will
miss
the data set that delta set files
so we will need to catch up that also
download that
if we start here for example we will see
an error occur
that's because we miss these files
so we need to download that
first we can do a
make directory
and then we need to we could
download um a mnist
fashion data set so we will do that from
this repository
and then we see
we can do like this git clone
so we have our dot data set
um
so um we probably have our
fashion emanates data set and
in this fashion this
we can take these files and
extract it in our data
instead so if we extract here
then we could
then we probably could run this
and hopefully it will
yes we see now we have
print out our convolution neural network
structure here
and i have my batch norm
uh batch nor i think this is
uh the the
learning rate anyway i have this uh
batch norm layers attach and we see the
the accuracy here and then i will
compare that with without
the batch norm layers
so we end up at 10
epochs
and i have some daughters
who love when i do my own videos
that's nice to hear them love
about my swedish english
accent also
[Music]
now let's end up with this accuracy on
mn mnist the fashion data set
so now i try to modify
back to the original original
without this batch normalization layers
and my purpose is to build and
rest net later on
and then it contain
several things more than this
but one thing is batch normalization
so i removed that and the connection
as well for the batch normal
save and
make
hopefully it work through
i have some errors
let's see let's see
let's see what i have missed here
um
um
um
oh i i found the wrong thing
you can still have this
i uh
this should 43.
um
three
um yes now it works to compile
so what i was done was
i removed this line of code to remove
the
batch norm layer so it could be back to
this
and before we have our battery
normalization layers
but now i guess we should
have another situation
so we see we have removed our batch norm
and it start with an accuracy of
0.77 at the first
epochs and before it was
a lot higher accuracy
so uh the consequences
the result was that batch norm made some
progress in accuracy but of course it
take
a bit slower to go through
anyway uh
further i want to do a whole rest net
lay a whole rest net model but
that will take a time i guess
thank you anyway for watching