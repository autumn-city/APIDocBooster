>>Today ON.NET, we're going to
be working with Seth Juarez,
to find out magic numbers using
machine learning. Check it out.
[MUSIC].
>> Welcome to
another episode of ON.NET.
This is actually our first show
that we're shooting in 2019.
>>What!
>> Yeah. So, we've got
Seth Juarez who's going to be
telling us about machine learning.
>> Yes.
>> Py Torch, and stuff like that.
>> Yes, but mostly .NET.
>> But mostly .NET.
So, I actually think
this is a little bit
weird I'm interviewing you.
>>Why?
>> Yeah, cause well you're the pro
interviewer, here at Microsoft.
>> Who is this guy? I
mean you know I'm saying?
>> Yeah. So, I'm going
to try my best today.
>> Okay and if you disappoint
me you know that we're going to
have that thing that I said.
>> Yeah. Okay, for sure.
So, what is our our topic?
>> Okay. So, today we're
talking about the Onyx Runtime,
and how to use it inside of
.NET, and for many of you
this might be a little
confusing right,
but when it comes to
machine learning,
the cool thing about
it is that there are
two phases when you're doing
machine learning specifically
with deep learning.
>> Okay.
>> The first phase
is a Data Scientist,
or Programmer, or even you because
I think anyone can do this.
If you train a thing called a model,
and you think of a model as
a function, or an asset,
or a jar file or an assembly or
whatever it's something you call.
So, once you train that
model the question becomes,
well, now that it's done training
how do I actually use it?
>> Totally.
>> So, that's what we're
going to be focused on today.
Hopefully I'll get a
little into the training.
If you have any questions
I'd love to answer
any questions about how
these things are trained.
What it's doing, but once
you have that model file
all you got to think about is
bring the file into my project.
Put some stuff in,
and get the answer.
>> Right. So, it is a little bit like
a Gymnast trains for four years
does all of these contortions.
>> Yeah.
>>Then somehow they go to
a different city where
the Olympics are being held
and they actually like
basically do their model,
and they end up with a gold medal?
>> Yeah, one thing.
>> Yeah.
>> You're absolutely right.
There is a lot of contortions.
>> Yeah.
>> That's basically all
of machine learning,
literally the secret here.
But, yeah, it's a little bit
different in the sense that,
imagine you have a, let
me see if I can come up.
Imagine you'd like set together
your Sprinkler System, and
for those who don't know,
we have Automatic Sprinkler Systems,
in some part of us
and you turn it on,
and then water goes
through the Pipes.
But, imagine being able to
turn off enough Valves,
so that you can water
all of your lawn at
one time the best way possible.
>> Right.
>> So, what happens is a
model is basically like
the pipes where you turn the knobs,
is basically what we're doing.
We're trying out
a bunch of settings in
the knobs so that we can cover
all of the things in this case.
In this case we're going
to recognize numbers.
>> Okay.
>> So that's is it. So, you can see
here if we can go to my screen,
basically this is just Py Torch.
You can get this is a GitHub repo.
We'll put a link on it.
The Deep Learning with Py Torch,
and under my GitHub account
which is Seth Juarez.
Basically these are
the pipes I set up.
I set up this thing called a
Convolutional Neural Network.
These are the pipes.
Then what we do is on the interior
there's basically a bunch of
numbers that when another digit
that we drew comes in,
we multiply, we passed down.
We do some things we
multiply passed down.
We need to find what
those numbers are.
As you can see right now that's
basically what it's doing,
because I ran it before we started.
You can see that it's just going
through and trying to figure
out what are the best numbers to
multiply this digit we drew by,
in order to get the answer right,
and this can take awhile.
There's some models that
I've run before that
have taken days. Some take weeks.
But basically, once you're
done with the training,
you have this file with
a bunch of numbers.
>> Right. So, you have to say,
hey boss I can't do any work
for the next two weeks.
>> Basically.
>> I'm training this model.
>> Or you could use our cloud.
>> Yeah.
>> We rent by the hour I believe.
>> Yeah, something like that.
So, we actually should
give a pitch to VS Code.
>> Yeah.
>> So, is VS code a good IDE
or editor for Python?
>> Absolutely, I absolutely love it.
The reason why it's not just
because Python is sort of built
in and I can do some crazy
things like for example,
what's this "Module" thing.
>> Nice.
>> I can actually go
to the definition and
in Python like it will bring it up.
Right, like not just
like here's where
the assembly is because it's
literally this is the code.
So, a lot of the times
when I'm looking at how
this stuff actually works I can go,
and see exactly how it works.
Right. So, you can understand it.
>> Yeah. Absolutely. But again,
this is Python stuff,
and it may not be interesting
to you as a .NET dev.
The only thing I wanted to
point out is that we have
this loop right here.
You can see this loop
here going throughout,
is that we go through all of it.
So, we have 60 thousand
hand-drawn digits
that are 28 pixels by 28 pixels.
>> Okay,this is your test data?
>> This is the data we use to train.
>> Yeah.
>> So, what we do is we give
this thing all of
this test data it's like the water
going through the pipes.
This loop right now is going through
and adjusting all the knobs.
>> Right, trying them
in different ways.
>> Once it's figured out
the best way to do it,
imagine pulling that out of
the dirt with the knobs intact.
Then we're going to put it somewhere
and just turn the water off.
>> Right.
>> That's what we're
doing. So here, right now,
I'm running through this takes
about 15 epochs but it's
already about 98 percent accuracy.
>> Right.
>> But basically the output
that you get right here.
Let me go to reveal an Explorer Is
this thing called "model.onyx"
and if you zoom in,
this is a really cool
this is called Netron.
It's a really cool program for
looking at like Neural Networks.
You can see that their input is
this thing that they labeled "zero".
Then it basically goes through
the "W" what the size of it,
and that's just a bunch
of numbers the
"B" that we said we
multiply, and add with this.
We add this on then we make it
smaller. Then we run a function.
Then we do this all the way to
get an output that's of size ten.
You can see that one by ten here.
Basically we want to
see if that is between
zero and nine, and so there's ten.
So, in the 0th index if you
get a one there that
means that it's zero.
If it's not sure you just pick the
"Max Index", and that's
the right answer.
>> The reason that there's ten of
these elements is because
all of these images are
only go from zero to nine.
>> That's right.
>> So, if the images
were like zero to 99,
then we would actually have
a hundred elements to choose from?
>> We could, you could do that but
that might be a harder problem.
You could probably create
two machine learning algorithms one
to detect a box around
a single digit,
and then pass that to this model.
>> I see.
>> Do you see what I'm saying?
>> I see.
>> So, you could do both like i said,
because the most important part of
Data Science is like the Science bit,
where Science is literally guess and
check but more rigorous
and we write stuff down.
>> I see. So, the smart person
would do the thing
you said let's make
this problem simpler.
Let's take apart these two numbers,
but then still deal with
them as a single digit.
>> Maybe, I guess it depends
on how people write
numbers the same way.
But, let's just say it was
handwriting recognition.
The script was Russian.
>> Yeah.
>> Russian script is
notoriously difficult
to understand because everything
kind of runs together.
Maybe, it wouldn't work that way.
Maybe, it's better to learn words,
or maybe it's better to
learn something else.
>> So it depends?
>> It depends. Yeah. I'm
never going to say it.
So, now this thing I think
should be about It's
a one more epoch where you
can see that it's getting
98 percent accuracy on the test data,
because what happens is
once we trained on the data
we leave some other data out,
and we see how well are you
doing on this data that
you've never seen.
>> Exactly.
>> And that's the test data set.
The other thing that's important
is this Loss Function.
This Loss Function basically is
measuring how bad are we at it.
If the answer is zero then we're
zero bad at it which is great.
If the answer is
50 million or 50 million
bad about it which is not so great.
So, as this single
loops down what I'm
looking for is increased accuracy,
decreased loss, and loss just
measures the difference
between what we predict,
and what the right answer is.
>> Right, and so, It
sounds like there's
kind of a real relationship
between those two numbers
but not exactly because
they're determined in
two very different ways.
>>Yes. So, the difference
between the Loss Function,
and the accuracy is
the accuracy you think
of it as an absolute like it either.
The max index is either
right or it's wrong.
But, for the loss function
it's going to be
filling numbers out
through the whole thing.
So, when you subtract
those continuous values you're
going to get a continuous answer,
right, and for accuracy
it's either right or wrong
and you count that up.
>> I see.Yeah.
>> So, this should be the last epoch.
What it's going to do is it's
going to output that "model.onyx".
So, i better close this before
I get like a "File Open Error".
>> Because then we
have to start again.
>>> Yeah, Because we have
to start all over again,
but like I said it's pretty simple.
Just think of this as a AI you have
to pick a model shape apriori.
Then you pick
some hyper parameters like
the learning rate within
learning rate is like how fast do we
learn this stuff and another
batch size and epochs how
many, and then you run it.
Then it's either good or it's not.
If it's not good you
switch to different model or you
switch hyper parameter is wherever.
>> Right. As soon as
you get into this,
you either have to teach yourself,
those sorts of things so that
you can direct your efforts.
Or it would help to have
someone like Seth on your team.
>> Maybe.
>> So, that they could give
you tips on what to do next.
>> So I am like this
School Train Data Science,
and I had been making demo where
for the most of my career.
So, we have other people on
our Team like Francesca Lazzeri,
who is a bonafide Data Scientists,
they have a good horse sense
about these things right,
like they look at
the learning rate and they
look at the Loss Function.
If the loss function goes up,
they'll automatically be like
the learning rate is too high.
>> So he's like a model whisperer?.
>> Yeah, she is.
She's pretty amazing.
For example, if
your batch size is too large,
it might not be working,
or for example,
if you notice that it's not learning
very fast or the difference
between your training error or
your test error is either
too high or too low,
you start to get a sense for
what is actually going on,
and once you know what it's
optimizing it makes it
a little bit more sense.
But once you pick the model function,
once you pick the right
optimization method,
once you pick
the right hype-parameters,
then the output is this ONNX file.
>> Right. So, how do we use it?
>> That's a great question.
So, let me describe
what ONNX actually is.
Notice it got about 98.4 percent.
>> So, are you happy
with that as the?
>> No, there are some that do better,
but I wrote this myself the other
day and so maybe I should tweak
it a little bit better. Right?
>> What would make you happy would
be like we're done and this was good.
>> I think a 100
percent accuracy feels
wrong to me because it over-learned.
>> Yeah.
>> There's something
called over fitting.
But if you get 99.9,
I'd be okay with that.
>> Yeah.
>> So basically, what we're
going to do now is we have
this ONNX file that it just built,
and what I need to
do is I need to use
it inside of a .NET Application.
Now let me explain
what onyx is onyx is
the open neural network
exchange format.
Think of it as like the PDF
for neural networks.
So, anyone can build
anything anywhere,
but if you can export your model
which is like those pilots with
all the gauges pre-turned correctly,
then you can use that almost
anywhere and we happen
to have something called
the ONNX runtime that you can
literally just pull in
with the Nougat package,
just pulling in the Nougat package
for the ONNX runtime,
and I don't know where it
is that we're a system.
It's like system.runtime,
there it is the ONNX runtime.
>> Yeah. That makes more sense.
>> The perimeters for that
and lots of pixelation,.
>> And all this oh is that
that's pretty you like that?
>> Yeah.
>> I want everyone to see,
I could zoom in even more for you.
>> No. That's good.
>> So, there's two things
that happened once.
Once we do that, we
basically need to load
the file and wow this is
this feels like it's
really small. So, let me,.
>> It's a bit to do
this guy down here.
>> Enbigen this to 200. Okay.
>> Much better.
>> So, what I'm going to do is
the first thing is I'm
going to load the file.
Right? Because it said ONNX file.
I'm using wind forms just
because I wanted everyone to
know like this is just regular .NET
I think it's a .NET Core thing.
So, the first thing I do is I
create this inference session.
What I do is I keep that it globally
as a global variable inside of
the class because I might
do more than one inference,
and I don't want to have
to load this file Up.
I know it's not very big how
big is it let's see here.
It's like 99 K.
>> So, and that's not
going to kill you.
>> It's not going to kill you,
but there are some models
are like 250 megs.
>> Okay. So, it varies a lot.
>> Yeah, it depends.
This is a really small model
with not a lot of numbers.
So basically, once I loaded up,
I'm saying well I'm going to.
>> Can we just pause for a moment?
The reason is, because
your domain is small.
>> Yes.
>> Because you said the images
were like 28 by 28 or something.
>> 28 by 28 pixels.
>> Yeah, so that's
already a very small,
and it's basically black and white.
>> It is black and white grayscale.
>> Yeah. So, just the amount
of possibilities that can
exist in that space is very
small as opposed to a
model that is capable
of reading feature-length movies
and giving you some sort
of feedback on it.
>> Yeah. So, for example,
if you want it to look at
a feature length movie and
predict whether there was a
I don't know a dog in it.
That's difficult right
because now we just have
a single vector that 784 that
represents the pixels itself.
But now we have a 40 tensor for
the height, width, length, color.
So, RGB Or maybe even Alpha
channel and finally time.
So, it's a 5D huge thing,
and we got to pass this
in, and generally,
the more stuff you pass it
in like you've got to have
a better predictive model,
and these things tend
to get pretty deep.
>> Yeah. So, that would be bigger.
>> Yeah that would be a much
bigger or even simpler one would
be like looking at a picture and
predicting whether
it's a dog or a cat.
For example, the picture
is like let's
just say it's
500 by 500 pixels picture.
You have 500 by 500 by
three which is the pixel
depending on the channel as
a channel goes in the front.
So, it's three by 500 by 500,
that one goes into the network
and then it does multiplication.
But you have to a-priori
and this is the bit
that's cool is you have to
actually pick the model function.
I pick this one, for
this it's pretty small.
Other ones are much bigger,
and this is again we're speaking
strictly about computer vision.
NLP Natural Language Processing uses
networks which are considerably
different but similar.
>> Okay.
>> Yeah.
>> Okay so once it's, did
I answer your question?
>> Yes.
>> All right. So, this is basically
coming from the you can see
the inference session comes
from the the ONNX runtime,
and I load it up from
the file and that's it.
Then, what I do now is when I want
to actually do the prediction,
I have to get the picture.
So, what I'm going to
do is I think I set
strategically setup breakpoints
and I'm going to run this,
and the first thing I'm going to
do by the way it's all on GitHub
we'll put a link below
you can totally use it.
Somebody will load model,
and I'm going get this.
This is the output.
>> Right, does the thing
that you just did.
>> We literally just built it. So,
I'm going to hit this and look,
see it's using a local model here,
and now I'm just going
to with my finger,
draw the number three.
>> Okay and it's not, I mean to be
honest it's not even a
very well-written three.
>> Yes, and I knew you
were going to bring that
up because I did that on purpose.
It might not do a good job
because maybe it didn't
have enough digits or
maybe it never saw
something like this and
maybe it didn't reset
space of the optimization.
So, I'm going to hit recognize,
and the first thing we need
to do is we need to convert
that into a 28 by 28 pixel image.
>> Right, because that's all.
>> Because that's all it knows.
>> Yeah exactly.
>> So, notice that I'm
doing that I'm using like,
I think I used InkCanvas,
InkCanvas on a WinForms
application inside of like a,
I don't know what they call them
where they can put his XAML
inside of WinForms but I did that.
You can see I resize it to the
appropriate size which is 28 by 28,
and then a create a single float
array that's size by size,
and then for each one of them I take
the average of all of
the colors and subtract 255.
>> Makes sense because
the bitmap is color oriented.
>> Yeah.
>> Yeah.
>> This one is not.
>> This one is not.
>> Now, I return this thing.
So, if I go to run the cursor here,
you'll see that this is basically
just a vector or an array of floats.
>> It's just an array.
>> Yeah.
>> All right. So, now
let's go to the other one.
Let's see if I put a breakpoint
there because that's,
yes I did. So, I'll hit at five.
Notice that it gets
the digit in there which is
a float array and now we're
using standard .NET types.
The tensor of t is
a data type that was
introduced probably maybe
a couple a year ago.
>> I think it was in Dynacore 2.1.
>> So, tensor of t is a way of nicely
indexing into memory
as if it was an array,
but it holds it in
contiguous memories.
I'm not sure the internals,
but I think it uses span of
t in memory of t in order to
make sure you could do that.
In fact, you can use
tensors and marshal
memory into like C applications.
>> Yeah, which was a great
in the Office program.
>> Then when they write
the C program writes
into it because you're
using memory of t,
it's writing directly into
the memory space of
the .NET application.
>> Right. So, no copying.
>> Yeah which is really good.
So, for example, if I wanted to write
my own linear algebra package,
I could literally call into
Kubla law pack for example
that's written all in Fortran C,
and it will write into
that memory for me.
So now, we can build
some really efficient algorithms
that use all the stuff
that we it used for.
So, that's one of the cool things
that I like about this.
But basically, the reason why we
use tensor of t is because that's
what the ONNX runtime
expects for the input.
>> Right.
>> The next thing
I'm going to do is I
normalize the image because
that's how it's trained.
Now, you're probably running
wondering what that means.
Let me run the cursor, there you go.
Basically, what happens is instead
of training on zero to 255,
I divide all the numbers by 255.
So, because it's a number
between zero and one.
>> Right.
>> That's how we trained it. So,
that's how we have to pass it in.
Now, you're probably
wondering what is this bit?
Well, this is to describe the input,
and I'm creating it from this tensor.
I'm creating a tensor from
this named ONNX value and like,
where does that come from?
Well, remember when I said
we looked at this model and
there is an input that was named
zero that's the thing
that's going on.
I don't know why it called it zero.
When it exploited it just did that.
>> It doesn't really matter.
>> It doesn't matter, but
that's the name of it.
So, if you don't know what it is,
you're like, "Oh shoot what is it?
You can just look in
using this or you can
go into the session itself.
Did I right-click it
here? Let me see.
Lets go to "Quick Watch" right here,
and you can see that in the session,
we have this input data and zero.
>> Yeah.
>> So, that's how I knew.
That's the one to use.
Okay. So, now that we've done that,
we do the named ONNX value
then and I always
put this in a try-block just in
case something goes horribly wrong.
I do a session run but.
>> Yeah. So, here's a good example
you were talking about,
this is just running
on DynaFramework.
>> Yeah.
>> I can tell from
those version numbers.
>> I am going to circle
this so everyone
can see your phantom finger that
you will not see on the screen.
>> Yes.
>> Rookie mistake.
>> Yeah, totally.
>> Okay. So, now I'm going
do the prediction
here. So, I'll do F10.
I do a run and I just get
the first answer out,
and I go to tensor to
array and you can see that
now it's basically a vector,
that has a bunch of shoot.
Let me just do a quick wide
so it doesn't disappear here.
So, I always, there
we go, quick watch.
It's literally a vector of size 10,
and that's going to tell us
what number it thinks it is.
Right, and we pick the max index,
so what did it guess?
>> I'm guessing it's
this guy right here.
>> Yeah. I will point, I'll use.
>> Sorry.
>> Rookie mistake again there.
>> Yeah.
>> Gosh! This one right here, right.
>> Yeah. That's.
>> Because the other numbers
are very, very small.
>> Very small.
>> Even though they have a number
before the decimal place They're-
>> Minus 14.
>> Yeah. So.
> > Maybe you should
fix that like put like
a little bar chart or something.
>> Something like that.
>> Right?
>> So, it's extremely
confident that it is three.
>> That's right. What I
do is when I return it,
I basically return like the,
that it's not an empty prediction.
That the prediction is the Max index.
So. Array.indexOf, I'm bringing
pretty fast to loose with this
but I just wanted to show.
Then I select all the scores
then I make a list,
because that's what it expect to do.
Now, I don't have to do
that. I could just return
the array but I had to
set it up this way,
because this also will call into
rest endpoints to do
the same kind of inference.
So, I'll do F5 and you'll see
that it thinks it's three.
>> Right. We have that,
those scores shown in a bit
more of a human-friendly form.
>> Yeah. That's right.
>> Now, the 250 seconds,
that was more about how long it
took you to get them out of those.
>> Break. Yeah.
>> Yeah.
>> Let's do it again here.
So, we'll do recognize
and you- oh shit.
>> Yeah. I think you'd have to
turn off all the breakpoints just.
>> Turn off all the breakpoints.
>> Just saying.
>> Just saying.
So, recognize, right?
>> Okay. Now, we're
well under a second.
>> Well.
>> Well.
>> Under a second.
>> Yeah, because that's like.
Yeah. Seven one
thousandths of a second.
>> Let's do an eight here, right?
>> Now, do something like
do a letter instead.
>> Not only that. Let me just
start to screw it up. Okay.
>> Okay.
>> So, I'm going to do
this. I'm going to do this.
Then I'm going to like
a line between here and
see what happen. It's two things.
It's an eight but notice that there's
uncertainty that starts to come in.
Now, what I'm going to do is
I'm going to try to do this,
to try to make it like a seven
two and see what happen.
Right. Do you see how now
the probabilities start to
go a little bit down, right?
Because it's becoming less and
less confident about these things.
>> Yeah. It's interesting
to know that it's
leaning more towards three
than it is towards seven.
>> But here's the thing. I want
to be very clear about
this. It's not thinking.
It's basically when
you pass those 740,
700 A four numbers in,
the weights that are
picked to multiply
by and then function over and
then multiply a function,
that's what it's returning at
the output but it's not thinking.
AI has no feelings.
For of all those who talk about like,
"Is AI going to start thinking?"
No, I think people
should start thinking.
>> Yes.
>> Because you might as well ascribe.
>> That would be a good idea.
>> You might as well ascribe like
this kind of intelligence to
a rock and it would
be the same thing.
>> Yeah.
>> But we're basically doing
an optimization algorithm to come
up with something that will-
>> That spit something out.
>> Notice that it's guessing
three and I've screwed up.
I could fill the whole thing in and
it will still guess
something because again,
it's just multiplying matrices.
Oh look, it thinks that's a two.
Then there's times where it
will get things wrong too.
That's because it only train,
we trained it on specific digits.
If there's numbers away.
>> I see.
>> -that you write
differently, it will not.
>> So, this is interesting.
This goes back to
the non-thinking part.
This system doesn't really have
a way of saying, "I don't know."
Like you or me with
our AI system or just I,
we can see this, last thing
that you said, and said,
"Well, I'm not prepared
to say what number I
think that is because
this is gobbledygook."
Whereas this one basically just
says "I'm always going
to do best effort.
I will give you a statement of
how accurate I think this is,
but that is all I'm incapable of.
I don't have the his
is gobbledygook.".
>> I even hesitate to say like it's,
this is how accurate I think I am.
Basically, what I did is I forced
a function at the endpoint,
that forced them to look
like probabilities.
Is called the softmax.
So, I basically forcing it to pretend
to be confident with
those numbers, right?
So, it's not even like,
like I could have just
not done the softmax
and just pick the max number,
and you'll see that
some numbers are higher,
some numbers are positive,
some are negative, right?
But in the end like if you want
to ascribe like the unsuredness,
you would return a vector of 11,
and give it examples of
things it's not sure about.
>> Oh I see.
>> Then, it would return that.
>> Okay. But you didn't build that.
>> I didn't build that.
That's the thing.
You cannot do anything you did
not explicitly train it for,
with the right network, with
generating the right weights.
>> Okay makes sense.
>> All right. Any questions about it?
By the way, this is all
available right now PyTorch 1.0,
will natively export
the right ONNX format
for you to use inside
of .NET applications.
>> Right oh. So, in this case,
you use the ONNX runtime directly.
What about ML.NET, can it
also used these ONNX files?
>> So, the thing about ML.NET
is it's used for training.
>> Okay.
>> We got to separate the process,
but you can also use ML.NET to
do the inferencing as well,
but in your brain you should
still separate the two processes.
Training takes a long time
and is very tedious.
What was the word you use,
the gymnast used? The contortion.
>> Contortion.
>> There's a lot of contortionist
during the training.
>> I did that on purpose.
>> But when you are running
the model, we call it inference.
It's a separate thing.
It's pretty fixed.
>> Okay.
>> Yeah.
>> So, okay.
>> So with ML.NET, you can both train
the model and do inferencing.
ML.NET as far as I know does only
where it called shallow models.
It's not a bad thing. Shallow
models work really well
like decision trees or
logistic regressions.
It does those kind of
models, this for ONNX.
In particular, is
for neural networks.
>> I see. So, kind of
apples and oranges.
>> It could be. It
could be like yeah.
Like, remember how I- the example was
that you put down the
pipes and turn the knobs.
There's a fix class of
this style of pipes you can
put down and where knobs are.
>> I see.
>> For deep learning,
it's their neural
networks, there stack.
For other ones, there more shallow
but they get the job done to.
>> So just in closing,
can you tell us a little bit of,
are you working with
Microsoft customers today who
are using the sort of thing
that you just showed?
>> Oh absolutely.
This exact example,
no, because this came out at Connect.
>> Yes, but more like
other industries where you're
seeing this sort of
thing being picked up?
>> Oh absolutely. Like a lot
of people are using AI.
They mostly put it into
production in some other way.
Like they put a rest endpoint,
but people are using it
for fraud detection,
people are using it for
recommendation systems.
There's a lot of stuff like, think
of any algorithm that you've
had to write where there's a lot
of If statements and For loops,
and you feel like you need
to go home and take a shower
because you just kind of
guessed at what it would be.
>> Yeah.
>> Those are the kind of algorithms
that really fit well
with machine learning
because instead of you coming up with
a series of steps to
solve the problem,
you give it examples
of the right thing.
Like in this case, numbers
and the actual digit pixels
and the digit.
Then it comes up with an algorithm.
>> Awesome.
>> All right. Bud.
>> Okay. Well, thanks
for coming by. Yeah.
>> All right. Bud we'll
see you next time.
>> Okay. This has been
another episode of ON.NET
about machine learning
with Seth Juarez. Thanks.
[MUSIC]