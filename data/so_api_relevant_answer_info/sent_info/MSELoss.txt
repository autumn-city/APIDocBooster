According to the [Documentation (hyper-link)], nn.MSELoss() creates a criterion that measures the mean squared error, that you can use this way:
You can check that loss is an MSELoss class:
Yes, in this case it acts just like torch.nn.MSELoss, and it is called Huber Loss all in all.
Let's compare errors being larger than 1.0 in case of MSELoss and SmoothL1Loss.
MSELoss would give it value of 100 (or 50 in case of pytorch implementation), while SmoothL1Loss gives just this value of 10, hence it won't punish the model so much for large errors.
If you really want to set custom threshold for MSELoss and L1Loss you could implement it on your own though:
Everything below threshold would get MSELoss while all above would have L1Loss.
I can tell you that MSELoss works with non-normalised values.
So it is possible that with SGD optimizer and MSELoss it uses some different delta or backpropagation function, not the basic one mentioned above?
Thus the use of MSELoss isn't very optimal, I changed this to BCELoss which should be more appropriate.
