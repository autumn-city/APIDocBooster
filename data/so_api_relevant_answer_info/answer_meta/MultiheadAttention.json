[{"tags": ["python", "python-3.x", "nlp", "pytorch", "attention-model"], "owner": {"account_id": 9746148, "reputation": 1011, "user_id": 7226080, "user_type": "registered", "profile_image": "https://i.stack.imgur.com/ayRyG.png?s=256&g=1", "display_name": "Elidor00", "link": "https://stackoverflow.com/users/7226080/elidor00"}, "is_answered": true, "view_count": 409, "accepted_answer_id": 66176914, "answer_count": 1, "score": 3, "last_activity_date": 1615888785, "creation_date": 1613133106, "last_edit_date": 1615888785, "question_id": 66171956, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/66171956/number-of-learnable-parameters-of-multiheadattention", "title": "Number of learnable parameters of MultiheadAttention"}, {"tags": ["tensorflow", "machine-learning", "keras", "transformer-model", "attention-model"], "owner": {"account_id": 21727241, "reputation": 91, "user_id": 16036484, "user_type": "registered", "profile_image": "https://www.gravatar.com/avatar/b2a519297caf8dc9532df87e0e5f7a5d?s=256&d=identicon&r=PG&f=1", "display_name": "R. Giskard", "link": "https://stackoverflow.com/users/16036484/r-giskard"}, "is_answered": true, "view_count": 2366, "answer_count": 1, "score": 8, "last_activity_date": 1644312183, "creation_date": 1622636943, "last_edit_date": 1622643583, "question_id": 67805117, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/67805117/multiheadattention-attention-mask-keras-tensorflow-example", "title": "MultiHeadAttention attention_mask [Keras, Tensorflow] example"}, {"tags": ["python", "tensorflow", "pytorch", "transformer-model", "attention-model"], "owner": {"account_id": 13012178, "reputation": 31, "user_id": 9404761, "user_type": "registered", "profile_image": "https://i.stack.imgur.com/3LByi.jpg?s=256&g=1", "display_name": "Sebastian Di Ravello", "link": "https://stackoverflow.com/users/9404761/sebastian-di-ravello"}, "is_answered": true, "view_count": 479, "accepted_answer_id": 71912728, "answer_count": 1, "score": 0, "last_activity_date": 1650290054, "creation_date": 1650243562, "question_id": 71906629, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/71906629/multiheadattention-giving-very-different-values-between-versions-pytorch-tensor", "title": "MultiHeadAttention giving very different values between versions (Pytorch/Tensorflow"}, {"tags": ["tensorflow", "keras", "padding", "masking", "attention-model"], "owner": {"account_id": 10068118, "reputation": 11, "user_id": 7442633, "user_type": "registered", "profile_image": "https://lh5.googleusercontent.com/-outqdY8R9v8/AAAAAAAAAAI/AAAAAAAAACo/0ILwQtpQ7OA/photo.jpg?sz=256", "display_name": "Oscar Luaces", "link": "https://stackoverflow.com/users/7442633/oscar-luaces"}, "is_answered": true, "view_count": 1011, "accepted_answer_id": 68314424, "answer_count": 2, "score": 1, "last_activity_date": 1625822637, "creation_date": 1606484829, "last_edit_date": 1606491930, "question_id": 65038445, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/65038445/effect-of-padding-sequences-in-multiheadattention-tensorflow-keras", "title": "Effect of padding sequences in MultiHeadAttention (TensorFlow/Keras)"}, {"tags": ["python-3.x", "pytorch", "transformer-model", "attention-model"], "owner": {"account_id": 7748979, "reputation": 1742, "user_id": 5865579, "user_type": "registered", "accept_rate": 100, "profile_image": "https://www.gravatar.com/avatar/185a0b751c11ba968e2cf51ec30c37d0?s=256&d=identicon&r=PG&f=1", "display_name": "jason", "link": "https://stackoverflow.com/users/5865579/jason"}, "is_answered": true, "view_count": 1647, "answer_count": 1, "score": 8, "last_activity_date": 1626108694, "creation_date": 1614357913, "question_id": 66389707, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/66389707/why-embed-dimemsion-must-be-divisible-by-num-of-heads-in-multiheadattention", "title": "Why embed dimemsion must be divisible by num of heads in MultiheadAttention?"}, {"tags": ["python", "pytorch", "attention-model"], "owner": {"account_id": 13294406, "reputation": 1023, "user_id": 9704615, "user_type": "registered", "profile_image": "https://i.stack.imgur.com/txhOn.png?s=256&g=1", "display_name": "BenedictWilkins", "link": "https://stackoverflow.com/users/9704615/benedictwilkins"}, "is_answered": false, "view_count": 248, "answer_count": 1, "score": 0, "last_activity_date": 1647606250, "creation_date": 1647605148, "question_id": 71526792, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/71526792/pytorch-multiheadattention-error-with-query-sequence-dimension-different-from-ke", "title": "Pytorch MultiHeadAttention error with query sequence dimension different from key/value dimension"}, {"tags": ["python", "deep-learning", "nlp", "pytorch", "attention-model"], "owner": {"account_id": 21177493, "reputation": 85, "user_id": 15572535, "user_type": "registered", "profile_image": "https://lh3.googleusercontent.com/a-/AOh14Ggqq5vz7J8_Stvlhrt5AFblhzEfMCNdcWcVOy2v=k-s256", "display_name": "Yuki Wang", "link": "https://stackoverflow.com/users/15572535/yuki-wang"}, "is_answered": true, "view_count": 372, "closed_date": 1619534818, "accepted_answer_id": 67277768, "answer_count": 1, "score": 3, "last_activity_date": 1619503678, "creation_date": 1619495683, "last_edit_date": 1619496053, "question_id": 67276766, "link": "https://stackoverflow.com/questions/67276766/attn-output-weights-in-multiheadattention", "closed_reason": "Not suitable for this site", "title": "attn_output_weights in MultiheadAttention"}, {"tags": ["pytorch", "transformer-model"], "owner": {"account_id": 8880560, "reputation": 125, "user_id": 6632841, "user_type": "registered", "profile_image": "https://i.stack.imgur.com/nNV1S.png?s=256&g=1", "display_name": "JimSD", "link": "https://stackoverflow.com/users/6632841/jimsd"}, "is_answered": true, "view_count": 811, "answer_count": 1, "score": 0, "last_activity_date": 1606219666, "creation_date": 1606213969, "question_id": 64984627, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/64984627/the-definition-of-heads-in-multiheadattention-in-pytorch-transformer-module", "title": "The definition of &quot;heads&quot; in MultiheadAttention in Pytorch Transformer module"}, {"tags": ["python", "tensorflow", "keras", "transformer-model"], "owner": {"account_id": 12298896, "reputation": 12946, "user_id": 8973620, "user_type": "registered", "profile_image": "https://i.stack.imgur.com/7qt6R.jpg?s=256&g=1", "display_name": "Mykola Zotko", "link": "https://stackoverflow.com/users/8973620/mykola-zotko"}, "is_answered": true, "view_count": 145, "accepted_answer_id": 73679598, "answer_count": 2, "score": 5, "last_activity_date": 1663526719, "creation_date": 1662556452, "last_edit_date": 1662973289, "question_id": 73636196, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/73636196/masking-layer-vs-attention-mask-parameter-in-multiheadattention", "title": "Masking layer vs attention_mask parameter in MultiHeadAttention"}, {"tags": ["python", "numpy", "tensorflow", "keras"], "owner": {"account_id": 6474192, "reputation": 1935, "user_id": 5013336, "user_type": "registered", "profile_image": "https://www.gravatar.com/avatar/d627dbf935d8dcb71c8eff8a223e97cc?s=256&d=identicon&r=PG", "display_name": "Arka Mukherjee", "link": "https://stackoverflow.com/users/5013336/arka-mukherjee"}, "is_answered": true, "view_count": 47, "accepted_answer_id": 72875579, "answer_count": 1, "score": 0, "last_activity_date": 1657055456, "creation_date": 1657046319, "question_id": 72874122, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/72874122/reshaping-output-of-multiheadattention-tensorflow", "title": "Reshaping output of MultiHeadAttention - Tensorflow"}, {"tags": ["keras", "deep-learning", "nlp", "transformer-model", "attention-model"], "owner": {"account_id": 21866808, "reputation": 379, "user_id": 16156882, "user_type": "registered", "profile_image": "https://lh3.googleusercontent.com/a/AATXAJw2ITNnJwW9XlUhxnFNTF_fla3SZuw2GcgtWRf1=k-s256", "display_name": "Varun Singh", "link": "https://stackoverflow.com/users/16156882/varun-singh"}, "is_answered": true, "view_count": 465, "accepted_answer_id": 68282055, "answer_count": 1, "score": 0, "last_activity_date": 1625644307, "creation_date": 1625557432, "last_edit_date": 1625571224, "question_id": 68266490, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/68266490/dimension-of-query-and-key-tensor-in-multiheadattention", "title": "Dimension of Query and Key Tensor in MultiHeadAttention"}, {"tags": ["keras", "tf.keras"], "owner": {"account_id": 23395930, "reputation": 1, "user_id": 17459966, "user_type": "registered", "profile_image": "https://www.gravatar.com/avatar/22e025a6ed7c0b8f2a87028fd4978f1b?s=256&d=identicon&r=PG", "display_name": "Pierre Nugues", "link": "https://stackoverflow.com/users/17459966/pierre-nugues"}, "is_answered": false, "view_count": 480, "answer_count": 1, "score": 0, "last_activity_date": 1637495119, "creation_date": 1637352278, "question_id": 70040371, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/70040371/the-keras-multiheadattention-class-does-not-return-expected-values", "title": "The Keras MultiHeadAttention() class does not return expected values"}, {"tags": ["tensorflow", "time-series", "masking", "attention-model", "multivariate-time-series"], "owner": {"account_id": 65071, "reputation": 2466, "user_id": 191741, "user_type": "registered", "accept_rate": 93, "profile_image": "https://i.stack.imgur.com/eLHda.png?s=256&g=1", "display_name": "SnakeWasTheNameTheyGaveMe", "link": "https://stackoverflow.com/users/191741/snakewasthenametheygaveme"}, "is_answered": true, "view_count": 149, "accepted_answer_id": 73737623, "answer_count": 1, "score": 1, "last_activity_date": 1663538882, "creation_date": 1652365394, "last_edit_date": 1663366662, "question_id": 72217369, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/72217369/how-to-properly-mask-multiheadattention-for-sliding-window-time-series-data", "title": "How to properly mask MultiHeadAttention for sliding window time series data"}, {"tags": ["python", "tensorflow", "machine-learning", "keras", "tensorflow2.0"], "owner": {"account_id": 9047240, "reputation": 73, "user_id": 6739010, "user_type": "registered", "profile_image": "https://lh6.googleusercontent.com/-wMm7F-5DWXk/AAAAAAAAAAI/AAAAAAAAAFQ/60j-wrveGIg/photo.jpg?sz=256", "display_name": "GodProbablyExists", "link": "https://stackoverflow.com/users/6739010/godprobablyexists"}, "is_answered": true, "view_count": 518, "accepted_answer_id": 70578053, "answer_count": 1, "score": 3, "last_activity_date": 1649621823, "creation_date": 1641261778, "last_edit_date": 1649621823, "question_id": 70573362, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/70573362/tensorflow-how-to-extract-attention-scores-for-graphing", "title": "Tensorflow: How to extract attention_scores for graphing?"}, {"tags": ["python", "tensorflow", "keras", "attention-model", "self-attention"], "owner": {"account_id": 13124054, "reputation": 63, "user_id": 9480659, "user_type": "registered", "profile_image": "https://graph.facebook.com/10216247810777800/picture?type=large", "display_name": "Fourat Thamri", "link": "https://stackoverflow.com/users/9480659/fourat-thamri"}, "is_answered": true, "view_count": 405, "answer_count": 1, "score": 1, "last_activity_date": 1643125486, "creation_date": 1643121242, "last_edit_date": 1643125486, "question_id": 70850506, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/70850506/keras-multiheadattention-layer-throwing-indexerror-tuple-index-out-of-range", "title": "Keras MultiHeadAttention layer throwing IndexError: tuple index out of range"}, {"tags": ["pytorch", "tensor", "transformer-model", "attention-model", "huggingface-transformers"], "owner": {"account_id": 302279, "reputation": 107937, "user_id": 610569, "user_type": "registered", "accept_rate": 90, "profile_image": "https://www.gravatar.com/avatar/0e9087f2672b0e4f28d91266acf9ce57?s=256&d=identicon&r=PG", "display_name": "alvas", "link": "https://stackoverflow.com/users/610569/alvas"}, "is_answered": true, "view_count": 2934, "accepted_answer_id": 58558888, "answer_count": 1, "score": 2, "last_activity_date": 1579170346, "creation_date": 1571880513, "last_edit_date": 1579170346, "question_id": 58532911, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/58532911/why-is-the-input-size-of-the-multiheadattention-in-pytorch-transformer-module-15", "title": "Why is the input size of the MultiheadAttention in Pytorch Transformer module 1536?"}, {"tags": ["python", "tensorflow", "pytorch", "attention-model"], "owner": {"account_id": 13012178, "reputation": 31, "user_id": 9404761, "user_type": "registered", "profile_image": "https://i.stack.imgur.com/3LByi.jpg?s=256&g=1", "display_name": "Sebastian Di Ravello", "link": "https://stackoverflow.com/users/9404761/sebastian-di-ravello"}, "is_answered": true, "view_count": 335, "accepted_answer_id": 71925883, "answer_count": 1, "score": 0, "last_activity_date": 1650375273, "creation_date": 1650338052, "question_id": 71919267, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/71919267/trying-to-achieve-same-result-with-pytorch-and-tensorflow-multiheadattention", "title": "Trying to achieve same result with Pytorch and Tensorflow MultiheadAttention"}, {"tags": ["pytorch"], "owner": {"account_id": 9571817, "reputation": 181, "user_id": 7109231, "user_type": "registered", "profile_image": "https://www.gravatar.com/avatar/e8920f67b5fdfeba7817488049b3191c?s=256&d=identicon&r=PG&f=1", "display_name": "Rick Vink", "link": "https://stackoverflow.com/users/7109231/rick-vink"}, "is_answered": true, "view_count": 189, "accepted_answer_id": 70555256, "answer_count": 1, "score": 0, "last_activity_date": 1641119650, "creation_date": 1641113851, "question_id": 70554730, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/70554730/attention-does-not-seem-to-be-applied-at-transformerencoderlayer-and-multiheadat", "title": "Attention does not seem to be applied at TransformerEncoderLayer and MultiheadAttention PyTorch"}, {"tags": ["tensorflow", "attributeerror", "transformer-model"], "owner": {"account_id": 18073183, "reputation": 21, "user_id": 13137279, "user_type": "registered", "profile_image": "https://graph.facebook.com/3235608749799799/picture?type=large", "display_name": "Germ&#225;n Eduardo Baltazar Reyes", "link": "https://stackoverflow.com/users/13137279/germ%c3%a1n-eduardo-baltazar-reyes"}, "is_answered": true, "view_count": 197, "answer_count": 1, "score": 2, "last_activity_date": 1589454193, "creation_date": 1585335645, "question_id": 60892539, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/60892539/problem-running-tensorflow-transformer-tutorial", "title": "Problem running Tensorflow Transformer Tutorial"}, {"tags": ["keras", "mask"], "owner": {"account_id": 11910417, "reputation": 11, "user_id": 8715818, "user_type": "registered", "profile_image": "https://www.gravatar.com/avatar/33f7f2f660fe75ff90fc0171a93175a7?s=256&d=identicon&r=PG&f=1", "display_name": "\u9ec4\u6d77\u9f99", "link": "https://stackoverflow.com/users/8715818/%e9%bb%84%e6%b5%b7%e9%be%99"}, "is_answered": true, "view_count": 1910, "answer_count": 1, "score": 0, "last_activity_date": 1574265472, "creation_date": 1565580772, "last_edit_date": 1574265472, "question_id": 57455350, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/57455350/custom-layer-cause-tensorflow-python-framework-errors-impl-invalidargumenterror", "title": "custom layer cause &quot;tensorflow.python.framework.errors_impl.InvalidArgumentError: Incompatible shapes: [128] vs. [128,256,256]&quot;"}, {"tags": ["tensorflow", "keras", "deep-learning", "transformer-model", "attention-model"], "owner": {"account_id": 17225583, "reputation": 123, "user_id": 12471287, "user_type": "registered", "profile_image": "https://www.gravatar.com/avatar/df64c5bc8575d0c3aa6748ef29fc3f0d?s=256&d=identicon&r=PG&f=1", "display_name": "Amhs_11", "link": "https://stackoverflow.com/users/12471287/amhs-11"}, "is_answered": false, "view_count": 5885, "answer_count": 1, "score": 4, "last_activity_date": 1611709756, "creation_date": 1603697157, "last_edit_date": 1605249858, "question_id": 64532940, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/64532940/multi-head-attention-layers-what-is-a-warpper-multi-head-layer-in-keras", "title": "Multi-Head attention layers - what is a warpper multi-head layer in Keras?"}, {"tags": ["python", "transformer-model", "pytorch-lightning"], "owner": {"account_id": 25891240, "reputation": 11, "user_id": 19618607, "user_type": "registered", "profile_image": "https://www.gravatar.com/avatar/99fc1013b791807857e3fe820d5347cf?s=256&d=identicon&r=PG&f=1", "display_name": "LazyCoder11011", "link": "https://stackoverflow.com/users/19618607/lazycoder11011"}, "is_answered": true, "view_count": 132, "answer_count": 1, "score": 1, "last_activity_date": 1659877122, "creation_date": 1658761824, "question_id": 73111496, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/73111496/pytorch-lightning-misconfiguration-exception-the-closure-hasnt-been-executed", "title": "Pytorch-Lightning Misconfiguration Exception; The closure hasn&#39;t been executed"}, {"tags": ["python", "tensorflow", "keras", "attention-model"], "owner": {"account_id": 20953081, "reputation": 31, "user_id": 15394284, "user_type": "registered", "profile_image": "https://www.gravatar.com/avatar/9dfdeb2ae894e5e29b77b9e187676d30?s=256&d=identicon&r=PG&f=1", "display_name": "eam2020", "link": "https://stackoverflow.com/users/15394284/eam2020"}, "is_answered": false, "view_count": 627, "answer_count": 1, "score": 1, "last_activity_date": 1622529043, "creation_date": 1622125405, "question_id": 67724151, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/67724151/keras-layers-multiheadattention-gives-warning-the-following-variables-were-used", "title": "keras.layers.MultiHeadAttention gives WARNING: The following Variables were used a Lambda layer&#39;s call [], but are not present in its tracked objects"}, {"tags": ["python", "pytorch", "transformer-model"], "owner": {"account_id": 14078280, "reputation": 21, "user_id": 17736987, "user_type": "registered", "profile_image": "https://lh3.googleusercontent.com/a/AATXAJxiOzojS2MvKos5fY02yXVOLpX7nW1-hHPmbUx6=k-s256", "display_name": "samuel fipps", "link": "https://stackoverflow.com/users/17736987/samuel-fipps"}, "is_answered": true, "view_count": 113, "accepted_answer_id": 72688889, "answer_count": 1, "score": 1, "last_activity_date": 1655736445, "creation_date": 1655240819, "question_id": 72623363, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/72623363/pytorch-transformerencoderlayer-different-input-order-gets-different-results", "title": "PyTorch TransformerEncoderLayer different input order gets different results"}, {"tags": ["pytorch", "attention-model"], "owner": {"account_id": 13806412, "reputation": 1236, "user_id": 9965155, "user_type": "registered", "profile_image": "https://i.stack.imgur.com/VdWBQ.jpg?s=256&g=1", "display_name": "Anjani Dhrangadhariya", "link": "https://stackoverflow.com/users/9965155/anjani-dhrangadhariya"}, "is_answered": true, "view_count": 1210, "accepted_answer_id": 63250917, "answer_count": 2, "score": 1, "last_activity_date": 1640896889, "creation_date": 1596550936, "question_id": 63248948, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/63248948/what-should-be-the-query-q-key-k-and-value-v-vectors-matrics-in-torch-nn-multih", "title": "What should be the Query Q, Key K and Value V vectors/matrics in torch.nn.MultiheadAttention?"}, {"tags": ["python", "tensorflow", "deep-learning", "pytorch", "transformer-model"], "owner": {"account_id": 1011431, "reputation": 6680, "user_id": 1023928, "user_type": "registered", "accept_rate": 86, "profile_image": "https://www.gravatar.com/avatar/0f1373fbc48fce33158d19ed1a398132?s=256&d=identicon&r=PG", "display_name": "Matt", "link": "https://stackoverflow.com/users/1023928/matt"}, "is_answered": true, "view_count": 2169, "accepted_answer_id": 68478924, "answer_count": 1, "score": 3, "last_activity_date": 1626925995, "creation_date": 1626907803, "question_id": 68477306, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/68477306/positional-encoding-for-time-series-based-data-for-transformer-dnn-models", "title": "Positional Encoding for time series based data for Transformer DNN models"}, {"tags": ["tensorflow", "keras"], "owner": {"account_id": 6334180, "reputation": 314, "user_id": 4918159, "user_type": "registered", "profile_image": "https://www.gravatar.com/avatar/ddf2ade5a893eb1979f7ff20f955d111?s=256&d=identicon&r=PG&f=1", "display_name": "user4918159", "link": "https://stackoverflow.com/users/4918159/user4918159"}, "is_answered": false, "view_count": 648, "answer_count": 1, "score": 1, "last_activity_date": 1603899954, "creation_date": 1596466749, "question_id": 63231878, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/63231878/tensorflow-keras-mask-in-transformer-tutorial", "title": "tensorflow keras mask in transformer tutorial"}, {"tags": ["python", "pandas", "numpy", "tensorflow", "pytorch"], "owner": {"account_id": 19328176, "reputation": 163, "user_id": 14130365, "user_type": "registered", "profile_image": "https://www.gravatar.com/avatar/7c2404f62caef12b87dd572e305980a7?s=256&d=identicon&r=PG&f=1", "display_name": "emma", "link": "https://stackoverflow.com/users/14130365/emma"}, "is_answered": true, "view_count": 597, "answer_count": 1, "score": 1, "last_activity_date": 1623753642, "creation_date": 1623744193, "last_edit_date": 1623749715, "question_id": 67982333, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/67982333/typeerror-int-object-is-not-callable-when-calling-bert-methods-for-producing-e", "title": "TypeError: Int&#39; object is not callable when calling Bert methods for producing embeddings"}, {"tags": ["python", "tensorflow", "keras", "keras-layer", "tf.keras"], "owner": {"account_id": 13351042, "reputation": 81, "user_id": 9636252, "user_type": "registered", "profile_image": "https://lh3.googleusercontent.com/-se2aT8NeoNw/AAAAAAAAAAI/AAAAAAAAABI/EMsRhEk5SlI/photo.jpg?sz=256", "display_name": "Fengxiang Hu", "link": "https://stackoverflow.com/users/9636252/fengxiang-hu"}, "is_answered": true, "view_count": 46, "answer_count": 1, "score": 3, "last_activity_date": 1620426986, "creation_date": 1618873475, "question_id": 67170370, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/67170370/a-problem-and-how-to-deal-with-batch-while-creating-a-model", "title": "a problem and how to deal with batch while creating a Model"}, {"tags": ["python", "tensorflow2"], "owner": {"account_id": 17840224, "reputation": 1, "user_id": 12958256, "user_type": "registered", "profile_image": "https://lh3.googleusercontent.com/-b27WmXuydjo/AAAAAAAAAAI/AAAAAAAAAAA/ACHi3rcZs6l0vAfC-5qYipcsE7kvDJz0BQ/photo.jpg?sz=256", "display_name": "Hao Zhaojun", "link": "https://stackoverflow.com/users/12958256/hao-zhaojun"}, "is_answered": false, "view_count": 85, "answer_count": 1, "score": 0, "last_activity_date": 1608780805, "creation_date": 1604988859, "question_id": 64763763, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/64763763/subclass-a-customized-model-in-tensorflow2-cannot-convert-a-tensor-of-dtype-res", "title": "subclass a customized model in tensorflow2: Cannot convert a Tensor of dtype resource to a NumPy array"}, {"tags": ["python", "tensorflow", "keras"], "owner": {"account_id": 7476036, "reputation": 823, "user_id": 5682455, "user_type": "registered", "accept_rate": 84, "profile_image": "https://www.gravatar.com/avatar/04b9f593f5524d7403a5eca549ae158b?s=256&d=identicon&r=PG&f=1", "display_name": "konstantin", "link": "https://stackoverflow.com/users/5682455/konstantin"}, "is_answered": true, "view_count": 269, "answer_count": 1, "score": 2, "last_activity_date": 1577558789, "creation_date": 1576597030, "last_edit_date": 1577524689, "question_id": 59377538, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/59377538/attention-is-all-you-need-keeping-only-the-encoding-part-for-video-classificati", "title": "Attention is all you need, keeping only the encoding part for video classification"}, {"tags": ["python", "tensorflow2.0"], "owner": {"account_id": 13391178, "reputation": 4077, "user_id": 9663497, "user_type": "registered", "profile_image": "https://www.gravatar.com/avatar/a2146a2188db75aa6c8d552e7804ea30?s=256&d=identicon&r=PG&f=1", "display_name": "Vincenzo", "link": "https://stackoverflow.com/users/9663497/vincenzo"}, "is_answered": true, "view_count": 11698, "answer_count": 1, "score": 2, "last_activity_date": 1570475076, "creation_date": 1570474424, "question_id": 58275534, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/58275534/nameerror-name-k-is-not-defined", "title": "NameError: name &#39;K&#39; is not defined"}, {"tags": ["keras", "deep-learning", "nlp", "lstm"], "owner": {"account_id": 20088831, "reputation": 41, "user_id": 14729820, "user_type": "registered", "profile_image": "https://lh3.googleusercontent.com/-4xDgU4QQOfQ/AAAAAAAAAAI/AAAAAAAAAAA/AMZuucleZYMLhrUD_TOt37y2c4TU9dmg2Q/s96-c/photo.jpg?sz=256", "display_name": "Mohammed", "link": "https://stackoverflow.com/users/14729820/mohammed"}, "is_answered": true, "view_count": 76, "answer_count": 1, "score": 0, "last_activity_date": 1655651256, "creation_date": 1655597016, "question_id": 72673500, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/72673500/how-can-i-use-lstm-with-pretrained-static-word-vectors-on-aclimdb-dataset", "title": "How can I use LSTM with pretrained static word vectors on aclImdb dataset"}, {"tags": ["python", "tensorflow", "keras", "neural-network", "transformer-model"], "owner": {"account_id": 14246565, "reputation": 1193, "user_id": 10291435, "user_type": "registered", "profile_image": "https://www.gravatar.com/avatar/fa925201987d21a2dd54f7609930773b?s=256&d=identicon&r=PG&f=1", "display_name": "Mee", "link": "https://stackoverflow.com/users/10291435/mee"}, "is_answered": true, "view_count": 2494, "answer_count": 1, "score": 0, "last_activity_date": 1603509104, "creation_date": 1579306019, "last_edit_date": 1579307622, "question_id": 59796343, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/59796343/transformer-model-not-able-to-be-saved", "title": "Transformer model not able to be saved"}, {"tags": ["machine-learning", "pytorch", "bert-language-model"], "owner": {"account_id": 16815013, "reputation": 73, "user_id": 12157035, "user_type": "registered", "profile_image": "https://lh4.googleusercontent.com/-FiKJb51Ub5k/AAAAAAAAAAI/AAAAAAAAAAA/ACHi3reYwUiDpSTNmbyKGkFHopRC8EId1g/photo.jpg?sz=256", "display_name": "mecha kucha", "link": "https://stackoverflow.com/users/12157035/mecha-kucha"}, "is_answered": false, "view_count": 264, "answer_count": 1, "score": 1, "last_activity_date": 1595244361, "creation_date": 1595233769, "last_edit_date": 1595236499, "question_id": 62991456, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/62991456/i-have-an-error-while-training-bert-model", "title": "i have an error while training BERT model"}, {"tags": ["python-3.x", "machine-learning", "time-series", "pytorch", "transformer-model"], "owner": {"account_id": 7038592, "reputation": 335, "user_id": 8244472, "user_type": "registered", "profile_image": "https://i.stack.imgur.com/8YzTk.jpg?s=256&g=1", "display_name": "R Nanthak", "link": "https://stackoverflow.com/users/8244472/r-nanthak"}, "is_answered": true, "view_count": 770, "accepted_answer_id": 63870857, "answer_count": 1, "score": 2, "last_activity_date": 1600000647, "creation_date": 1599991653, "question_id": 63869529, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/63869529/training-loss-and-accuracy-both-decreasing-for-my-transformer-model-for-time-ser", "title": "Training Loss and Accuracy both decreasing for my transformer model for Time Series Prediction"}, {"tags": ["pytorch", "quantization", "static-quantization"], "owner": {"account_id": 874149, "reputation": 30566, "user_id": 924313, "user_type": "registered", "accept_rate": 96, "profile_image": "https://www.gravatar.com/avatar/14d86d9d0a97d8464d59eb42935838ae?s=256&d=identicon&r=PG", "display_name": "corazza", "link": "https://stackoverflow.com/users/924313/corazza"}, "is_answered": true, "view_count": 13, "accepted_answer_id": 73785433, "answer_count": 1, "score": 0, "last_activity_date": 1663670700, "creation_date": 1663665416, "question_id": 73784322, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/73784322/why-are-some-nn-linear-layers-not-quantized-by-pytorch", "title": "Why are some nn.Linear layers not quantized by Pytorch?"}, {"tags": ["tensorflow", "keras", "deep-learning", "chatbot", "transformer-model"], "owner": {"account_id": 13792703, "reputation": 94, "user_id": 9954654, "user_type": "registered", "profile_image": "https://www.gravatar.com/avatar/d2e837339113e68a801babb2ea46eca4?s=256&d=identicon&r=PG", "display_name": "botaskay", "link": "https://stackoverflow.com/users/9954654/botaskay"}, "is_answered": true, "view_count": 8779, "answer_count": 2, "score": 5, "last_activity_date": 1599553351, "creation_date": 1593249091, "question_id": 62608037, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/62608037/typeerror-expected-any-non-tensor-type-got-a-tensor-instead", "title": "TypeError: Expected any non-tensor type, got a tensor instead"}, {"tags": ["pytorch", "state-dict"], "owner": {"account_id": 13806412, "reputation": 1236, "user_id": 9965155, "user_type": "registered", "profile_image": "https://i.stack.imgur.com/VdWBQ.jpg?s=256&g=1", "display_name": "Anjani Dhrangadhariya", "link": "https://stackoverflow.com/users/9965155/anjani-dhrangadhariya"}, "is_answered": true, "view_count": 1400, "accepted_answer_id": 69045400, "answer_count": 1, "score": 0, "last_activity_date": 1630955453, "creation_date": 1626775889, "question_id": 68453123, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/68453123/runtimeerror-errors-in-loading-state-dict-for-dataparallel-unexpected-keys", "title": "RuntimeError: Error(s) in loading state_dict for DataParallel: Unexpected key(s) in state_dict: \u201cmodule.scibert_layer.embeddings.position_ids\u201d"}]