Max pooling does not dilute the location of the maximum pixel - instead consider it as a way of downsizing.  Max pooling is just a way to reduce dimensionality of the problem such that your problem fits into device memory. A nice side property is that it pools the strongest acitvations from your feature map.
"If max-pooling is done over a 2x2 region, 3 out of these 8 possible configurations will produce exactly the same output at the convolutional layer.  For max-pooling over a 3x3 window, this jumps to 5/8."
Maximum pooling produces the same depth as it's input.  With that in mind we can focus on a single slice (along depth) of the input conv.
"Max pooling does nothing more than iterate over the input image and get the maximum over the current ""subimage"". "
Max pooling decreases the dimension of your data simply by taking only the maximum input from a fixed region of your convolutional layer. 
In the case of bbox prediction it also reduces the number of proposed regions for bboxes.  Which later in a non-maximum surpression step would kill all redundant proposed bbox locations.
" And if you are familiar with Max pooling, then you know this is going to cut our image dimensions in half. "
There are 8 directions in which one can translate the input image by a single pixel. 
"They are considering 2 horizontal, 2 vertical and 4 diagonal 1-pixel shifts.  That gives 8 in total."
