 Yeah, as the last video for this week, I want to briefly talk
 about the geometric intuition behind the perceptron. So this
 is, I think, particularly interesting, because the
 perceptron rule is so simple. And yeah, here, we will briefly
 go over why it actually works at all. So if you recall, this is
 the perceptron learning algorithm. The slide is just
 copied from an earlier video. So it's just for recapping what's
 going on. So if the prediction is correct, nothing happens. So
 we don't need to update the decision boundary. However, if
 it's incorrect, there are two scenarios, scenario A and a
 scenario B. So scenario A is if the output, the prediction is
 zero class able zero, while the target is class label one. And
 scenario B is if the prediction is one, and the class label, the
 actual one is zero. So in both cases, we make a mistake. And
 then we have to update the perceptron. So in the first
 case, in this case, how we update the decision boundary is
 by adding the input vector, so the feature vector to the weight
 vector. So why do we have to add the input vector to the weight
 vector? And why does it help at all? So in this video, I want to
 briefly go over the intuition behind that. So here also, yeah,
 in code, just again, the outline of the learning algorithm, if
 it's more clear this way, so we initialize the weights with all
 zeros, or we can also use all small random numbers doesn't
 really matter. And then for every training epoch, we iterate
 over the training examples. And then we compute the prediction.
 And then you update if we make a mistake. So here we compute the
 arrow and then update. So that is the basic concept behind the
 perceptron that we talked about before. Now, regarding the
 geometric intuition. So imagine you have these two classes here
 on class zero and class one. And here that's the black line here
 is the decision boundary. So the weight vector turns out to be
 perpendicular to the decision boundary. Can you think of the
 reason why the weight vector would be perpendicular to the
 decision boundary? So perpendicular here means 90
 degree angle, why is there a 19 degree angle between the weight
 vector and the decision boundary, maybe pause the video
 for a few minutes and think about it a little bit, maybe you
 get the idea, if not, don't worry, it's a little bit, I
 would say, it's not immediately obvious.
 Alright, so the intuition behind it is why the decision boundary
 in the weight vector of this 90 degree angle is because if you
 think of our threshold, if we compute or look at the dot
 product, let's ignore the bias for now, if we just look at the
 dot product of the weights and the feature vector, we make a
 decision at zero, so whether it's greater or smaller than
 zero. So if it's smaller equal to zero, the net input, so this
 is the net input. If it's smaller equal to zero, we
 predict or return class able one, if it's greater than zero,
 we return one, so everything kind of hinges upon the zero
 here. And if we write the dot product a little bit differently
 as the length, magnitudes of the two vectors, and then the angle
 between them, the cosine of the angle, then we have the
 following equation, you probably have seen that from linear
 algebra classes. So in order, so in order not to have this dot
 product zero, like if we want to have it zero, um, yeah, what we
 would have is to have at least one of these two terms zero, but
 this is not the case, right? Because the vector is not zero,
 unless it's all values are zero. But um, yeah, so in this case,
 that would be one scenario where we might have a case of zero.
 Another case is where the decision boundary, sorry, the
 angle here between the weight vector and the decision boundary,
 when this term here becomes zero, and when is this term
 zero, the term is zero, if we have a 90 degree angle here
 between the two, right, because the cosine of 90 degree is zero.
 So by setting this part here, this part to zero, we get a
 weight vector that actually has some length. And that has an
 angle between the decision boundary and the weight vector
 of 90 degree.
 Yes, so what else does that mean? So if we think about the 90
 degrees a little bit more, so what we can deduce then is that
 there will be an angle smaller than 90 degree on this side
 here of the decision boundary. So by that, I mean, if you have a
 training example, or a data point that is somewhere, you
 know, on the right side of the decision boundary, let's say it
 can be here. So if we have a feature vector that is here can
 also be here doesn't really matter. So anywhere where we
 have a decision.
 Yes, so what else does this mean? So let's focus in a little
 bit more on the 90 degrees here that we just talked about. So
 now every input vector on this side here on the right hand side
 will have an angle with a weight vector that is smaller than 90
 degrees. So again, in blue, this is the weight vector here. And
 now if I take a training example, and put it anywhere on
 the right side of the decision boundary, for example, here, so
 if we look at this one, it has this angle that is smaller than
 90 degree. If we put it here, same thing is true. Or if we put
 it here, outside, maybe it doesn't really matter. Also, we
 have always this 90 degree angle. And also you note that it
 doesn't really matter how large the weight vector is. So if we
 scale the late weight vector by a factor of 100 or 1000, it
 doesn't matter, it will be still than the angle because whether
 this is longer or not doesn't really matter. The same is true
 for the training examples, if they are super large, if let's
 say one training example is somewhere here, still the 90
 degree angle, or smaller, sorry, smaller than 90 degree angle. So
 the magnitudes of the weights and features doesn't really
 matter whether we scale them or not. However, the updating the
 learning can be a little bit faster if they are scaled, which
 is why I had the standardization in the code example. But yeah,
 so there's one takeaway that the angle is smaller than 90 degree
 on this side. And on the left side here, it would be of
 course, greater than 90 degree, if we have a value here, that
 would be greater than 90 degree. So everything, again, hinges
 upon the 90 degrees here. Now, why is that again, interesting?
 So let's now focus on the actual prediction case before I just
 laid out where all the data set on the weight vectors are
 oriented. Now, let's take a look at prediction case. So we have a
 correct side and a wrong side. So let's assume we have an input
 vector with class label one. And like I've shown you before a
 weight vector for the correct prediction must be somewhere
 such that the angle is smaller than 90 degrees to make a
 correct prediction. Let me go back to just show you again what
 I mean. So notice here, we have all the ones on this side. And
 this is our weight vector here. So to make a correct prediction
 that is predicting a new training example like this one
 as class one, it has to be smaller than 90 degree, it has
 to be in within the circle here, right. So that's what we are
 looking at now. So we have here on this correct side. So if you
 think of this as the decision boundary between the wrong and
 the correct side, we have to have an angle between the input
 vector and the weight vector that is smaller than 90 degrees.
 So if we are within the 90 degrees, then we make a correct
 prediction, because the product then will be positive greater
 than zero, because um, yeah, because this term will be
 greater than zero. Yeah, now let's take a look at what
 happens if we make a wrong prediction. So here in red, I
 have now a weight vector that is not ideal. So that is a weight
 vector, where, when we make a prediction, where we make a
 wrong prediction, because the angle is not smaller than 90
 degrees, it's in fact, larger than 90 degrees now. So if it's
 between a value between larger than 90, up to 270, we will make
 a wrong prediction, because now the value of the cosine of that
 angle larger than 90 and smaller than 270 would be negative. So
 we would be smaller than zero. So we would make class zero
 prediction, which is what happens here. So we have an
 angle that is greater than 90 degrees. And then we would
 predict the wrong label, we would predict
 class level zero, although our input vector here, we assume
 that it still has class level one. How do we make this
 correct? And how can we correct this prediction that is by
 moving the weight vector to the side of closer to the side of
 the training example, so that the angle is smaller than 90
 degree. So how do we do that? So in the perceptron algorithm, how
 we do that is we add the feature vector. So the input vector, we
 add it to the weight vector. So here, the dash line here, that
 is the input vector. So here, that's the same input vector,
 I'm just taking the input vector and adding it to my weight
 vector. So maybe doing it step by step. So what we have is we
 have our input vector, and we have our wrong weight vector.
 What I'm going to do now is I'm taking this input vector, and
 I'm adding it to the weight vector, like this, and then my
 new weight vector will be like this, right. So then we will
 have this smaller than 90 degree angle, which is shown here. So
 by adding the weight vector, we can make the decision boundary
 correct for this case. So this is if I go back here, this is
 exactly what happens in scenario A. So we predict on the output
 is zero, although the target is one. So this is when we go back
 here, that is what we have, we have a label of one. And then we
 predict zero, because we are on the right, wrong side here. But
 we what we do is then we add the input vector to the weight
 vector, which is what I've shown you in the previous slide. And
 by that, we can correct the decision boundary. And yeah, if
 you want, or like, you can also play through the same scenario,
 if prediction and the targets are flipped. So the same concept
 applies there too. Yeah, to summarize, the perceptron has
 many shortcomings. So there are many problems with a perceptron,
 which is why it's not commonly used anymore in practice, some
 people still may use it in certain applications where
 computational performance matters, because one advantage of
 the perceptron is it's very simple to implement and very
 fast. However, nowadays, many problems that we have in the
 real world cannot be solved by this perceptron, which is why we
 have fancy and deep learning methods. So let me go over the
 shortcomings of the perceptron. So first of all, it's a linear
 classifier. So you cannot have nonlinear decision boundaries.
 If you think back of the x or problem, it cannot solve the x
 or problem. Or if I, for example, just have another
 simple problem where we have two classes like, like this, for
 example, class zero and class, one like this around it. So if
 we have these concentric circles, the perceptron cannot
 classify these very well, because it can only do a linear
 decision boundary like this or like this. And that is not
 helpful. What we need is we have, we need a nonlinear decision
 boundary like this, for example. So that is one shortcoming.
 Another shortcoming is that it is a binary classifier. So it
 can only classify two classes. But yeah, of course, there are
 also extensions where you can use multiple perceptrons.
 There's a method called one versus rest, or one versus all
 or one versus one. So actually two methods that I can just
 write them down one versus rest. Sometimes it's also called one
 versus all, where you can just use multiple perceptrons, or
 multiple binary classifiers. And one is called one versus one to
 have multi class classification. Yeah, but it is like one single
 perceptron cannot do multi class classification, because it's
 just returning either a zero and one. Another shortcoming is it
 does not converge if classes are not linearly separable. So what
 does that mean? So that is exactly the problem related to
 the convergence theorem that we have not covered. But in the
 convergence theorem, it says it only converges if the classes
 are linearly separable. So let me draw that out also. So if we
 have a case, again, like let's say this, it will find a
 decision boundary like this. However, if I have a data point
 over here, then there is no decision boundary such that I
 can classify everything correctly. So it will learn,
 let's say this decision boundary, but then it
 encounters this data point. So if we keep iterating, and then
 it thinks, okay, I have to move the decision boundary further to
 the right, like here, but then it gets these examples wrong. So
 it then it thinks, okay, I have to move it back to the left. So
 it will keep on moving the decision boundary back and
 forth, and it will never really stop updating. So in that case,
 that is also a problem if you want to have the final model.
 Okay, that's fluctuating. It's like the longer you run the
 algorithm, the more solutions you will get. So it will never
 really finish updating. Yeah, and then also, another thing is
 there are multiple solutions possible, if the classes are
 separable. So now let's assume you have a problem that is, let
 me do this a little prettier. Let's say no, you have a problem
 where you can linearly separate these classes, let's say, like
 this. So one possible decision boundary is like this. Another
 one is like this one is like this. So there are multiple
 solutions. And it depends on Yeah, where you start with your
 weights, which one is the best one, or which one is picked by
 the perceptron before it stops updating. And yeah, this is
 also kind of annoying, or can be annoying, there are multiple
 solutions. So that I would say there's a best one, the best one
 might be the one that is just in the center. Rather than
 something that fits, let's say, the data very closely to the
 left or very closely to the right, because one might argue
 that putting the decision boundary in the center helps
 with reducing overfitting, for example. But yeah, that is also
 something the perceptron is not capable of. And in your later
 lectures, the methods that we will be using, they are a bit
 better with that. Alright, so that is just the other
 conclusions on regarding the perceptron. So like, one last
 thing, like a little fun fact. So yeah, back in the day, the
 perceptron was used, or people try to use it to detect tanks in
 photographs. So here on the left hand side would be a tank. And
 here, there would be no tank. And they used the perceptron on
 images to classify whether there's a tank in the photograph
 or not. However, like we just said, the perceptron is very
 limited. So why would that work at all? People found that it
 worked. But there was like a little gotcha, a little mistake
 or conceptual mistake. So because people didn't first
 think about it very well. So what happened was that all the
 forest pictures were darker than the pictures with the tanks. And
 the perceptron simply recognized that darker photographs means no
 tank and brighter photographs means tank. Of course, it had no
 idea whether there was actually a tank or not. So if you would
 have a dark photograph with a tank, it would, of course, get
 that wrong. Yeah. And this was like a little fun fact about the
 perceptron. I got that from this interview with Marvin Minsky,
 who was one of the authors of this perceptron book I mentioned
 where they kind of said bad things about the perceptron that
 it was limited. So here's like a little excerpt from this
 interview. So basically, it was looking for a scene at a scene
 of a forest with which there were camouflage tanks in one
 picture and no camouflage tanks in the other picture. And the
 perceptron after a little training made 100% correct
 distinctions between these two different sets of photographs.
 Then they were embarrassed a few hours later to discover that the
 two roles of film had been developed differently. And so
 these pictures were just a little darker than all of the
 pictures. And the perceptron was just measuring the total amount
 of light in the scene. So it was just counting the pixel values,
 the pixel brightnesses. But it was very clever of the perceptron
 to find some way of making this distinction. Yeah, I think I
 would admit that it was actually kind of exploiting the fact
 that photographs were brighter and darker. But of course, it
 had nothing to do with whether there was a tank in the picture
 or not. It was just how they developed the film. Alright,
 with that, I want to end this lecture, which was a little bit
 long, I will, in the future, try to keep that shorter. But I
 didn't want to split this topic over two weeks. So in the next
 week, we will cover some basic linear algebra. I mean, just
 some ground rules that we will be using. And then hopefully
 also slowly get into implementing more
 sophisticated methods in pytorch.