hi my name is tovio roberts
and today i'll be giving some basis and
methods to observe the emergence of
euler's number
commonly called e we see e
in so many places and i think it's
helpful for students to have a reference
point so i hope i can provide some
foundation in that regard
as always i want to demonstrate some
algorithmic and analytic thinking
for all of this as that's what we expect
students to learn
in our prep programs for the galvanized
data science immersive
through these videos i'll be trying to
write python in a simple and
understandable way so maybe not as
pythonic or
clean as i would normally write code but
my goal here is to be
expressive and accessible not to write
the most elite code
i want students who are new to python to
grasp the concept and code as i go
when i'm done i'll put the code here in
a gist on github
so grab it there if you don't want to
type along with me
and i'll put that link in the
description
we're going to be describing e
and uh in general
we think of e as being
you know e equals 2.71828
right and so on we're going to think
about the nature of this number
we see it pop up in a number of places
including the normal
exponential binomial poisson
distributions in natural logarithms in
compound interest
and a bunch of other places generally we
think of e
as being this value right 2.71828 and we
plug that in
it's an irrational number so we can't
write it as a simple fraction
and you know those numbers go off to the
right infinitely
even though we can't write it as a
simple fraction we can estimate
it in a few different procedural ways
and really e has some interesting
emergent properties
for example the slope of y
equals e to the x so y equals
e to the x at any point
is the value e to the x
and that that comes in very handy
uh but let's think about this for a sec
right so um
if we're looking at at a plot of e to
the x
and there's going to be something like
something like that
the slope at the point x equals zero
right if x equals zero the uh
the slope um at x equals zero
is uh going to be one right because
any number to the zeroth power is one so
if x is zero
the the slope here is going to be one
and that's really cool
when x is one the slope is e
so uh yeah this comes in really handy in
calculus and
i won't be going into detail on that
here maybe we'll do that in another
video
instead we'll just be looking at places
where e shows up
uh one of the first places we're going
to think about this
is in bernoulli trials right so
we're thinking about bernoulli
uh binomial right
and if you want to refresher on that you
can look back in
our prep materials we have kind of a lot
on bernoulli and binomial
but we're going to think about bernoulli
in the kind of classic way we're going
to think about
a coin flip we're going to assume a fair
coin to start
so we can assume the chances of getting
heads is one out of two times right
so you know the probability of heads
is 0.5 and and we'll think about this
as we're going to get heads 1 out of
1 out of 2 times
we can think of a probability as 1 out
of some number of times in general right
say 1 out of 20 times which we would say
is the probability 0.05 right so 1 out
of 20 times
if we have a very very unfair coin right
1 out of 20
is the same thing as 0.05
and that's going to be helpful in a
little bit i'm just pointing it out
because
it will be helpful in a few moments
we're going to conceptualize something
through the binomial pmf
which gives us the probability of k
successes out of n
independent burn early trials we're
familiar with this
uh you you should be familiar with this
you don't need to memorize it or
anything like that for
our interviews but generally
we know this and we should be able to
recognize if we see it
the binomial pmf is n choose k
multiplied by the probability
to the kth power right multiplied by 1
minus the probability to the
n minus k
and notice what we need here is n where
n is the number of trials
and k is the
number of successes for which we're
looking for the probability
so let's let's modify this a little bit
and i'll just uh
maybe i'll just snag this
and set it up
set it up here we're going to reference
back to it a little bit
we're going to modify this a little bit
and we're going to replace p
with 1 over n which just means that we
expect
success 1 out of n trials all right so
um we'll do this we'll do
n choose k
multiplied by 1 out of n which
is can be made equivalent to p right
to the k multiplied by 1 minus
1 over n to the n minus k
in the uh situation we're describing we
initially expect success
one out of two trials right and we can
take this a step further and say that
the probability of winning
zero times right k you know
if we consider k to be zero
k equals zero we can uh think of that
out of two trials and we can
you know with this expectation of one
out of two trials being successful
we can uh rewrite this to discover the
probability of
uh success zero times right
so let's think about that
i'll just put this up here this is what
we're working with
okay and this is just going to look like
2 choose 0.
multiplied by one-half
to the zero zeroth power right
multiplied by one minus one-half
to the two minus zeroth power
we can show that uh in combinations n
choose zero
is always one so uh let's
let's uh demonstrate that i think that's
an important thing
to understand and
so we're going to take a quick aside to
look at that
i'll just put that there for the moment
we'll come back to it
so uh you know if it's good to know the
combinations formula
and i'm just going to put it here so n
choose k right
is just n factorial
over n minus k
factorial multiplied by k factorial
so if we want to rewrite this with 2
right 2 choose 0 2 choose 0
is simply 2 factorial
over 2 minus 0 factorial
multiplied by 0 factorial and
if we if we break this down this is just
2 times 1 right over
2 times 1 right times 1.
and we can see pretty clearly that
n choose k where where k is 0
is equal to 1 we could we could perform
this with any other numbers
and we're going to arrive at 1.
so you know i often like
showing this in terms of uh
counting in binary and you know let me
let me just be very clear here
uh uh the the point i'm making
is n choose zero
should always equal one i demonstrated
it with two but we could put in any
number here right if we put in
five factorial uh that's to be 5
factorial over
5 factorial times 0 factorial we would
see that that's 5 over 5
which would be 1. so
i often like showing
this in terms of counting in binary
where a failure is zero and a success is
one
right so if we're thinking about binary
we've got zero and one those are our two
possibilities
and uh we can count in let's say four
bit binary
and what what that'll show us is
all the possible in in four
trials all the possibilities for
successes and failures
i'm just going to count in binary really
quick and i'm i'm
driving this point home but i think it's
an important thing to understand and so
every chance i get to talk about this i
probably will so if we're counting in
binary
zero zero zero zero zero zero zero one
zero zero one zero zero zero one one
zero one zero zero zero one zero one
zero one one zero zero one one one and
then one zero zero zero one zero zero
one one zero one zero one zero one one
one one zero zero one one zero one one
one one zero one one one one
so uh if i did that right if i didn't
miss anything we should have 16
here great um
we can see in four trials
there's only one time where
where we have
no successes and this is going to be
true for
any length of binary there's only
there's only one
value there's only one binary word
that's going to have
all zeros and that's going to be the
lowest
value and so we can see we can
demonstrate right here
that there's only one time where we get
no successes so
n choose 0 is always going to be it's
always going to be 1.
anyway having driven that point home
hopefully
the takeaway here is if you put larger
numbers in for n it'll still result in
one combination
with zero successes so uh that takes
care of
of um combinations the combinations part
of
our calculation and so we can see
that you know in this instance right
here when we're thinking about that
um we can if we're thinking about our
combinations
2 choose 0 is just going to be 1 right
so let's say
now now we're left with one times one
half
to the zeroth power uh times
one minus one half to the two
minus zero okay if we're raising to the
zeroth power
as i mentioned earlier that's going to
be 1 so we can
we can rewrite this again
as just 1 times 1
times and here's the important part 1
minus 1 half
squared okay and this is
uh this is one of our goals here is to
discover
this we're left with this expression
right and this clearly indicates that
the probability of getting
zero heads in two flips of a fair coin
is
uh one half squared or right this is
just
one over four or 0.25
that makes good sense we we can see that
that that works
for our two trials and zero successes in
two trials
keeping that in mind however we can take
this a little bit further
if we're considering no successes in n
trials we can actually just replace that
2 with
n and so we get the general expression
1 minus
1 over n
to the nth power
okay so that's what we were looking for
we're going to interpret that as meaning
that the probability of winning
zero times out of n trials is one minus
one over n raised to the n okay
that's going to be helpful so i'm gonna
just uh
just grab that that's what we're going
to be working with
and i'm just going to probably get rid
of all the rest of these because we
don't need them
so we're going to define a function for
this in python and we're going to build
a dictionary
and observe the results of uh
essentially of doing stuff with this 1
minus 1 over n
to the n so let's jump over to python
let's define a simple function
called the probability of zero
successes in n trials
and this is just going to be 1 minus 1
over
n trials to the n trials right so that's
easy enough to write
1 minus 1 over n trials
and then we're going to exponentiate
that to n
trials um i
like calling things just to you know
just to make sure
that i don't have any uh any errors in
here
so probability of zero successes
in well what we were just looking at
we would expect 0.25 here so let's just
see
so python and we do get 0.25
easy okay i'm going to
give away the ghost a little bit i'm
just going to name this
convergence dictionary
and i'm going to put a max n in here and
basically what i'm going to do here is
populate a dictionary with
where the keys are n trials and the
um the values are the probability
of zero successes in end trials uh very
easy to write this
um i'll instantiate a dictionary and
i'll say for n trials
in range and we have to start at one
right because
notice uh zero trials the success for
zero trials is undefined which
makes sense intuitively and we'll go up
to the maximum number
of n plus one i'm just including the one
here because
we want to think of like well if we put
in 12
we want to see the probability of no
successes in 12 trials okay
and then for each of those i can say d
sub n trials
this is going to be the probability of
zero successes
as we defined above in n
trials and then we can just return
that dictionary all right
so let's look at this as uh
for the nth trial
yeah why not and the probability
in our convergence dictionary which i
just defined right
converges to convergence dictionary and
let's look at just a hundred keys
so we're gonna go from one up to a
hundred
dot items and let's just print
if you are in uh you know premium prep
or
if you look through our materials we're
constantly using f strings in this
pattern
um where we output something
uh we output the keys and values of a
dictionary so n
trial and the probability
okay so let's take a look
at that
all right now it may not be obvious
what's going on here
all right and and i'm just gonna uh snag
a few of these
i'll snag from 84 to 100. uh we're not
going to look
we're not going to think too hard on
this uh instead we're going to
demonstrate
uh something that's happening here
notice how
we're converging towards some
probability
as we increase the value of n right so
0.368 right we're getting close to this
uh
we're solidifying around point three six
six maybe
um let's run this again with even more
trials let's do uh
let's do a thousand and
see what that looks like okay
so as we do more trials
we are solidifying uh further and
further
uh the number the values in the decimal
places right so
we can see by trial 983 we've solidified
out to
[Music]
yeah it looks like 0.36769
i don't think nine is going to roll over
it might
doubt it at this point and by a thousand
trials 0.367695
okay well either way it looks like we
are
settling on a probability and the
greater we make this
the more settled i think we're going to
become and so i'm going to put 10 000
trials in there
and uh notice we're going we're
solidified down to 0.36786
104 okay okay so uh
as as we do this as we increase the
number of trials this
is going to converge towards some value
right
um if you're familiar with the concept
of a limit uh that's
part of what we're or that's really what
we're seeing there we are observing a
trend
toward a specific value now
it turns out that we are approaching one
over e
and i'm going to import from math i'm
going to import e
we're going to use that uh as we go
and uh i'm going to
at the end of all this i'm just going to
print a space and then i'm going to
print
1 over e and so we'll be able to see
this
see that we are getting to e
these look very similar
they're not exactly the same but my my
guess
is that as we increase the number of
trials right
we're at 10 000 now let's so we go up to
a million um
we are going to get we are going to get
this number
closer and closer to 1 over e so 0.36786
this is 0.36787
yeah so we're getting closer and closer
so let's uh let's take this a few steps
further
and you know essentially we're in the
same arena though
if we just divide one by the probability
we'll get a clearer idea that we're
approaching e and i'll
i'll go ahead and write another
dictionary function to show that i think
it's always a good idea for
for our students to get a look at uh
you know packing dictionaries with
values that's something that you have to
do in the technical interview
and it's a it's a skill that we
generally expect for you to have going
into the dsi
okay so um convergence uh toward
e and i'm gonna put in a max n again
and this is going to essentially be the
same function as above so why don't i
just grab that
instead of getting the
probability of zero successes i'm going
to get one
over the probability of zero successes
and then
this for loop right here well we can
just grab that again
i'll grab all of this
and we'll be able to see this pretty
clearly i think
all right so uh instead of convergence
dictionary i'm going to call
a convergence dictionary toward e and
we'll do 10 000 times why not and we'll
print out
the this isn't a prabha anymore this is
uh
i'll just call it toward e
and um i'll print e down here instead of
one over e
and so we'll be able to see this a
little clearly a little more clearly
than before
oh division by zero why is that
uh let's see
oh the probability of zero successes ah
the probability of zero successes for
one trial um
is for in the way that i constructed
this we're going to
get zero so i'm gonna start my range at
2.
i didn't have parentheses on my
dictionary declaration right there
that'll get you um okay
awesome all right so if i if i run this
now
and i'm going to go ahead and put
[Music]
a nice message in here the value of e
from the math module why not
now put e in there we should be able to
see
that we are approaching e okay
there we go so the value of e from math
is 2.718281
uh here we've got 2.7184
one so you know we could uh
increase our um
our uh essentially our number of
bernoulli trials here
um but we could
uh think about this in a different way
we're only
considering what 10 000 brand new trials
here
um we could uh try a
a number a much greater number something
that's approaching infinity although
we can't really approach infinity
effectively on a computer
we could try a much larger number and
see how close we can get to e
now we can turn that on its head a
little bit and
do something a little different we can
seek a value of n trials that gets close
to the level of precision
of the e that's imported from our math
module
so let's see roughly how many trials we
might need to do that
i'm importing e from math and i'm just
going to do this in a very procedural
way
i'll do n trials and i'll start that at
1 so
we'll do one trial and i'm going to say
wow one over e okay while this
uh the result of that which is a
probability or not a probability that's
like .3
something something something right
minus the probability of zero
successes over n trials
right is greater than zero
so while the difference of these
essentially while while one over e
is greater than this
we are going to increase the number of
trials
okay so number of trials plus gets one
and then uh at the end of this let's
just print out a nice message
um so for we're going to print out
wherever n trials ends up
okay um and we are going to print out
e from the math module and we are going
to print out
one over uh the probability of zero
successes
in n trials okay so
that should let me just
uh make sure everything is good there
oh we've got an extra parenthesis yeah
okay so we're going to print that out
and let's also just print out the
difference
between these two between our
value of e
and the value that we
that we breached in order to um arrive
at something reasonably
uh precise to e so um
we'll just do e minus
uh one over the probability of zero
successes for n
trials and that
uh i think that'll work it'll take just
a little bit to run
maybe i'll make this a little bit bigger
there we go and let's run that
so we're going to be looking at the
output of this
we're not going to quite get e but
that's okay
um we can also put in n trials plus one
right and we'll end up on the other side
of e and that's fine
um this uh we're just waiting on this to
finish
and the difference between
our e which is here this uh this big
string of numbers and uh math
the math modules e which is here um is a
very small number right 5.79
uh times 10 to the negative 13 right so
we would move this decimal point
13 to the left and that's the difference
between these two numbers
um there is a little bit of calculation
error because they're floats
um we can see that uh
we are good up until um
here right this is where we're seeing
the difference so five eight versus five
nine i think that's pretty good
if we look at what if we put in n trials
plus one we'll get on the other side of
e as i said
and why don't we why don't we do that
let's also
let's modify this a little bit i'm going
to comment it out
and we'll do this uh
end trials plus one
and this will take a moment to run as
well so
we'll be patient for it oh uh and while
we're waiting for that to run
let's consider this number of trials
right this is uh
um this is a lot of trials uh what is
that
um 94 million
911 151 trials
that's um how many that's
uh the value of n
that we put into this in order to
reasonably approximate e
as it is stored in the math module
so you know it's not super important or
anything but
i think that's interesting to see
that we can discover what it takes for
for us to be as precise as a previously
stored constant
and it looks like we have a result out
here
and uh in this case
we've exceeded e
by um 2.8 times 10 to the negative eight
right so we've gotten on the other side
of e
and you know we haven't exactly
approximated it in terms of how it's
stored on our computer
but that's okay i think we're close
enough in the calculation here given
that we're using discrete
inputs right the number of trials as
inputs to the probability function so
we can reframe algebraically what we've
done here a bit
and see this approach through through
other i's
we were thinking we were approaching the
value 1 over e
with our probability function but we can
approach e
instead in a slightly different way
and we'll think about it like this
so e
is the limit as
n approaches infinity
of 1 plus 1
over n to the
nth power and you know
when we look at these two uh next to
each other they're they're not
incredibly different right um in fact if
we wanted to work this out
uh we could say 1 over e
is the limit as n approaches infinity of
1 minus 1 over n to the nth power
either way this works we can go ahead
and test this out with python i think
this is the more direct way we might
think about this
but i just wanted to show through a
binomial process
uh you know series of bernoulli trials
that e
as numer is an emergent phenomenon so
what i'm going to write right now is the
let's say
one of the classical ways to show the
emergence of e
and i'm just going to do this with a
couple more functions so
we'll call this approximate e
and we're going to put n in there right
because we're thinking about this
just this value of n now and we're going
to
have n approach uh
approach infinity that's what we would
do to
best approximate e of course we're never
going to get there
discrete computers everything like that
yeah and we're just returning 1 plus 1
over n to the nth power
and let's again pack this into a
dictionary
so approach e dictionary max n
and we'll say for n
in range 1 to max n
plus 1. d sub
n is going to get the approximation of e
of n and we can return the dictionary
and uh throughout these videos i'm i'm
going to use this pattern
uh because we we do use this pattern in
the technical interview
um this general pattern of uh well
define a phenomenon
look at it through a dictionary
interpret the results
so we'll say for n and result in
approach e dictionary
and let's just put in the number 500 um
just because i'll say
print again this f string
where i put the key and then i put the
value
the value being res
and just like before i'm going to go
ahead and print the value of e as well
and we'll just do that to have them sit
side by side so we can see
so what we're seeing here
is by the 500th uh
by n equals 500 we're kind of doing okay
right we're we're not doing amazingly
well we've got 2.71
and of course uh if i put in how about
50 000
i think we're going to have a better
value
uh 2.718 we're at least getting that far
um so we can see that that uh that
framing of this works as well and
uh yeah essentially e is surfacing as we
increase the value of n
in the next video i'm going to take a
different approach towards e
using derangements