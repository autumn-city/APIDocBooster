hello everyone in the previous video we
had learned about implementing simple
linear regression using cycle
in this video we will be studying
classification with cycle a
classification problem is when the
output variable is a category such as
red or blue
disease or not repeats or spam or not
spam
right so a classification model attempts
to draw some conclusion from observed
values
given one or more inputs on
classification model
uh
classification model will try to predict
the values of one or more outcomes
for example when filtering emails spam
or non-spam when looking at transaction
data fraudulent or authorized
now there are majorly two types of
classification problems the first one is
binary classification now this is the
typical example of email spam detection
wherein if the email is spam then we
give it the value as one and if the
email is not spam then we give the value
as zero
the second one is multi-class
classification
uh this can work for handwritten
character expectations where classes can
go from 0 to 1.
now the main difference between
regression and classification algorithm
is that the regression algorithms are
used to predict the continuous values
such as price
salary age weather etc
and classification algorithms are used
to classify the discrete values such as
male or female shoe or false spam or not
spam etc
now the different types of
classification models are
knife based
stochastic trading descent
k nearest neighbors
decision tree
random forest and support vector machine
in today's lecture we'll be starting
with knife base cure
a nice base classifier is a
probabilistic machine learning model
using nice base theorem we can find the
probability of as given in the formula
probability of a happening
given that
b has occurred
here p is the evidence and a is the
hypothesis
now the question arises
why is this name knife base given
it is named knife base because the
assumptions made here
is that the predictors or the feature
values are independent which means that
the presence of one particular feature
does not affect other and hence the name
knight
now to understand the other formulas
phase theorem can be written as given
over here where
it has been given p of y given x equals
to p of x given by
multiplied by p of y divided by p of x
now variable y is the class variable
example if it is suitable to be not spam
variable x represents the parameters of
features now x can take multiple values
between 1 to n
and those have been substituted in the
second formula as you can see over here
so in the first formula we have
substituted the various values of x from
1 to n
now we are not interested in the exact
value of x
as we are interested in relative
relations with the other
probabilities thus
we can only compare the numerator as the
denominator is same
and that is how we are coming forward to
the third formula
there could be classes where
classification would be multivariate
therefore
we need to find the class y with maximum
probability
now this is the final formula which will
be used and we have omitted the
denominator here
now the different types of knife base
classifier the first one is multi-normal
knife base
this is mostly used for document
classification problem that is whether a
document belongs to the category of
sports politics technology etc
the features or the predictors used by
the classifier are the frequency of the
words present
document
the second type of knife based
classifier is bernoulli knight space
this is similar to multinomial knife
space but the predictors are boolean
variables the parameters that we use to
predict the plus variable take up only
value yes or no for example word occurs
in the text order
the third type of likewise is
portion of this
when the predictors take up a continuous
values
and are not discrete
we assume that these values are sampled
from a gaussian distribution
since the way the values are present in
the data set changes the formula for
conditional probability changes too
this approach is built on the assumption
of normal distribution of probabilities
now one of the very important factors
under nice base is laplacian correction
at times it can happen that the
numerator will give us zero value
right but
uh and then does making the probability
zero but at times it does hold some
significance and some importance and we
just cannot let that
probability
for this reason
we use laplacian correction
in this what do we do is we add plus 1
to the numerator and to the denominator
we add the number of distinct features
understanding all of this now let us
move forward to the coding part
these are the important libraries that
have been imported the first one is
train test
split where then we are splitting the
data set and we have taken iris as our
data set
thereafter we will be calling the
multinomial caution and bernoulli knife
base
the
models
and thereafter matrix as we had
discussed earlier in the earlier videos
we will need some metrics to measure
that how well our model is performing
these metrics does the same part
the first thing is caution netflix now
this is the formula for gaussian knight
base theorem we have loaded our data set
we have splitted it
we called the gaussian knife base we are
fitting our x and y values in that and
then we are predicting the x test values
thereafter we are
computing the prediction accuracies for
classification report and confusion
matrix
so this is how the output for our
gaussian knife base comes
uh
the similar way we have multi-normal
line space classification
and thereafter we have
bernoulli nice base classification
now we took the same data and we have
applied it on three different link base
let us compare the results that we are
getting
in case of caution life base our
accuracy score is 100 percent in case of
multinomial it is 97 percent
and in case of bernoulli it is just 35
percent
so why is this case
let's jump back to the
definitions that we had talked about
bernoulli works with only two kinds of
gloves yes or no right but in our case
we have three plus which is iris that
the problem that we are trying to solve
does not fit with the definition of
bernoulli space and that is how it is
giving us
wrong results over here
in case of multi-novel we do have three
classes and multi it fits well with the
multi-normal life based classification
also
but just to keep the weightage of the
caution distribution nature of the data
set that we have in our iris data set
the caution this knife base model gives
us better accuracy score than life based
classification
model
now in the example in the output here
see what accuracy exposures
classification report has
precision recall f1 score and then we
have confusion matrix
so
what all are these
terminologies
so accuracy is the most intuitive
performance measure
and it is simply a ratio of currently
predicted observation by the
total
observations
thereafter
we have precisions we call them f1
square
before understanding keystones we have
to understand four other different
terminologies
the first one is true positive
so
i'll simultaneously write over here
the first one is true positive so true
positive are the correctly predicted
positive values which means that the
value of actual class is e x and the
value of predicted class is also yes
thereafter we have two negative now true
negative these are also the correctly
predicted negative values which means
that the value of actual plus is known
and the value of predictedness is also
known
thereafter we have false positive
when the actual classes know and has
been predicted yes then that comes in
the false positive
and thereafter we have false
negative
uh this happens when the actual class is
yes but predicted plus is no
that is how we'll come forward to
decision now so precision is nothing but
the ratio of currently predicted
positive observations
to the total predicted positive
observations
now in terms of words it sounds kind of
messy let us just write it in the former
formula
to help you so it is the ratio of true
positive divided by the ratio of total
predicted positive observations which is
true positive
and thereafter we have to positive plus
true negative
uh sorry it is false positive as we are
taking the uh
total predicted positive observations
thereafter we will have recall now
recall is also called as sensitivity and
it is the ratio of correctly predicted
observation values
the positive observations to all the
observations in actual class
so let us write down this in the form of
formula so it is true positive divided
by two positive plus
false negative
so this is called our precision it
recalls next comes f1 score
now f1 score is the weighted average of
precision entry
therefore this forward takes both
positive and the false negative into the
account
so f1 score
can be written as
2 into
recall into
precision
and we'll just add this
into a bracket this will be a numerator
and our
denominator will be
recall plus
precision
this is that excel score
the next thing that we are saying in the
output is called confusion matrix
now the confusion matrix is the summary
of prediction results on classification
problem
so if we have just two classes uh then
all of these will represent the true
class and
the rows will represent the predictor
class and if we have two classes which
is positive and negative all the
diagonal values come under green and the
rest of the values are rendered red
which are which we don't want
but in our place we have three glasses
which is iris setosa versicolor and
virginica then how do we calculate the
confusion matrix
thus in our case let me just move to the
portion like this
in our case the first row is irisectosa
the second is vertical the third is
virginica the first color is that the
first column is satusa second is
versicolor and third is virginica
now all the diagonal values are the
green values and rest are the red values
which we don't want in our case all the
values in the case of caution all the
values lies in the uh diagonal and that
is how our accuracy score is one because
none has been predicted into a from
uh class
in case of multinomial naive bayes there
is this
one data point has been which has been
predicted wrongly so we can say that
a predicted class is iris particular and
the true class is iris
virginica
and that is how one data point has been
predicted wrongly
in the case of bernoulli knight base
only the first the setoza has been
correct has been correctly predicted
stressed all the values are predicted
from here that is how
we are landing up to the accuracy score
of just 35 percent
that is all for today do let me know if
you have any questions in the comment
box have a great day