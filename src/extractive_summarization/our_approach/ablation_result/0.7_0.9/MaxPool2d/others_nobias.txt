Pooling is of MUCH MORE IMPORTANCE in convnets. 
 But you see, max pooling used much more in the neural network than average pooling. 
Pooling is not exactly "down-sampling", or "losing spatial information".  Consider first that kernel calculations have been made previous to pooling, with full spatial information. Pooling reduces dimension but keeps -hopefully- the information learnt by the kernels previously.
But if you look carefully at what's going on you may notice that the after first convolutional layer the dimension of your data might severely increase if you don't do the tricks like pooling. 
