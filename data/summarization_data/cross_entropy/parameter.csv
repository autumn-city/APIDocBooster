"PyTorch's CrossEntropyLoss expects unbounded scores (interpretable as logits / log-odds) as input, not probabilities (as the CE is traditionally defined). "
So the weights are changed to reduce CE and thus finally leads to reduced difference between the prediction and true labels and thus better accuracy. 
" So our loss, if we just care about disease  (we're going to be passed the three things)   we're just going to calculate cross_entropy  on our input versus disease. "
" So the way you read this colon means every row,   and then colon 10 means every column up to the  10th. "
