And we can actually use both on either the  LSTM or the LSTM cell for implementing the character RNN.
Usually, people use LSTM layers in their code. Or they use RNN layers containing LSTMCell.
As it seems, the LSTMCell implementation is more hands on and basic in relation to how a LSTM actually works.
As we want to feed our LSTM Layers with a sequence, we need to feed the cells each word after another. As the call of the Cell creates two outputs (cell output and cell state), we use a loop for all words in all sentences to feed the cell and reuse our cell states.
This way we create the output for our layers, which we can then use for further operations.
Obviously, It is easier to apply parallel computing in LSTM.
