[Music]
in this video we'll discuss the
bernoulli distribution
and maximum likelihood estimation
consider a biased
coin flip the probability of heads is
given by 0.2
and the probability of tails is given by
0.8
it turns out that we can represent both
probabilities with one parameter
which we'll denote by theta theta is
also known as the bernoulli parameter
the probability of heads simply is given
by theta
and the probability of tails is given by
one minus theta
we can calculate the likelihood of a
sequence of events
by multiplying the probability of each
individual event to obtain the
likelihood
consider the following sequence of three
events
for the first flip we have a head and
the probability of observing a head
is 0.2 consider the second flip
we observe a second head for calculating
the likelihood of this sequence
we can simply multiply 0.2 by 0.2
for the third flip we obtain a tail and
the probability of observing one is 0.8
to obtain the likelihood of these
sequence of events
we simply multiply 0.2 times 0.2
times 0.8 which equals to 0.096
now let's consider the case where we
don't actually know the values of the
parameter theta
to start we'll consider two sample
values of theta i.e
theta equals to 0.5 and theta equals to
0.2
we have the first flip the likelihood of
observing a head for the first bernoulli
parameter is 0.5
and for the second parameter is 0.2
we observe a second flap in this case
it's a tails
for the parameter theta equals 0.5 the
value of the likelihood
is given by 0.25 and for the parameter
theta equals 0.2
the value of the likelihood is given by
multiplying 0.2
with 0.8 which is 0.16
for the third flip we observe ahead
again
the likelihood value for the parameter
theta equals 0.5
is 0.125 and the value for the parameter
of the 0.2
is 0.032 finally for the fourth flip
we observe a tail thus for the following
sequence
the likelihood values for the two
parameters equals
0.0625 and 0.0256 respectively
notice that amongst the two values of
the likelihood
the value of likelihood corresponding to
the parameter theta equals 0.5
is larger compared to the other value
this
intuitively makes sense as well in the
real world
if you flip a coin the probability of
getting a head or tail
is equally likely thus the value of the
likelihood
given by the parameter theta equals 0.5
is more likely to occur so it turns out
we can estimate the actual parameter by
considering parameter values that
maximize
our likelihood we can represent
our sequence of events by a mathematical
function
known as the bernoulli distribution
further
we can denote the event of getting a
head by zero
and the event of getting a tail by one
thus the probability of y equals zero
for a specific value of theta
is given by which equals
similarly the probability of y equals
one
ie tail is given by
note that both the probabilities are
functions of theta
so from the previous coin example we had
the following
expression for the probability of y for
a specific value of theta
here y could have two possible values ie
zero and one generalizing this equation
for any value of y
we get and substituting the probability
equation
for y from above we get the following
thus our goal is to find a value of
theta
that maximizes this function it is
helpful to visualize as follows
each of the individual probabilities is
a mathematical function
multiplied together the likelihood
function is represented by the
overlapping values
and the goal is to find the value of the
parameter
that maximizes this expression
it is usually difficult to maximize the
likelihood function
the log of the likelihood function is
much simpler to deal with
as the log function is monotonically
increasing
the location of the maximum value of the
parameter remains in the same position
the expression for the log of the
likelihood function
is given by we can use this equation to
obtain the value of theta
that maximizes the likelihood that's it
thank you for watching this video