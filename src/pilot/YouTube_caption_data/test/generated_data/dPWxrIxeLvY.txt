hello hello hello welcome to our new
video on
pytorch video series in uh
this series now we will be starting with
the
cnn which is convolution neural networks
and in this project we will be
working on some image classification
techniques
and also before diving deep into that
we would need some concepts to be
understood before
we step ahead so the major concepts that
we will be using
into this section will be data
set what is data set class a module you
can say
which is already available in by torch
what is data loader in pytorch
and we also need to know uh how to use
iterations uh patch size and
[Music]
we have to learn what is epoch as well
and
we will also see the steps that needs to
be taken
and after this we will be looking
forward to
activation functions and
we will be looking some other concepts
as well
so these are the things that will be
required further ahead in the coming
videos
and also we will be taking care of
multiple other things
as well so we will take uh
them step by step so this will take
three to four videos more
before we actually dive into the real
code that we can go ahead
to build a classification or a
convolution neural network for us
so today's video we will be discussing
on what is
data set and data loader so basically
what we do in
data set and data loader this is these
are the just modules that have been
provided
by uh you can say the pi dodge framework
and what we do is that data set is used
to load
uh whatever the data set that we have uh
and it uh combines further ahead with
the data loaded
so whatever data that we have we can get
that data set and using data
loader we can iterate through iterate
through to that
dataset that we have loaded above and
post that we can also use transforms
here
like if you want the image to be
transformed into some other
dimension or maybe you need to crop it
or you need to convert it
you can do that transformations here as
well
and based on these like whatever data
that we have like
we load the data with the data set
loader and
when the data is loaded we try to
iterate
through that data using the data loader
and using the next and enter attributes
as well
then we can also apply some
transformations and when we get all of
these
we try to go with the training loop with
these four functions
and when we are trying to define our
neural network we have been looking
forward to
what is activation functions so these
will be the
normal contents that we will look at we
will be looking for first
and uh let's not quickly waste our time
and
try to work on to things things so
firstly like what we will do is that we
have uh
we will like as usual we will go with
the data set and i'll go to my kaggle
website
and i will go with the famous iris data
set
i'm just using this data set to uh to
ensure like uh
we have something to work on so i have
this i
species data set here and this is the
classical data
set that has 150 rows with four features
and one labels
so this is the file you can click here
the download button and download this
data set
and this is how the data looks like i
have already downloaded this into my
local directory so i'll quickly start
working on to that
so what i will do first is let's import
the libraries that will be required
so first i will import numpy as
np i will import pandas as
pd also i will import maths
and what i will do is let's say we
import
torch we import
torch vision
and we import the data sets and data
loader
so this is present inside torch
uh okay torch dot
utils dot data
i should give from here from this
module we need to import
data set and we need to import
data loader so this is how we will be
working further ahead
and i think this will be all
let's see if if more libraries required
we can import those later
so let's quickly run this okay let me
restart and run all
give me one quick second yeah
so uh if required for more libraries
we'll
import them later and what we will do is
that let's load the
uh data file into this collab lab
collaboratory that we have here and i
will do that using
files what just happened files
dot upload and i will say
nls command here so i'll quickly
try to browse the file and upload it
back here this is my iris file here
and uh post this we will be writing our
own class
the data successfully loaded here as you
can see
and now we will write our class for the
model
that we'll be working with so i'll
define a class named iris and it will
take
an argument as the data set
and as usual like predefined methods we
need to go with it like we need to go
with
init method to initialize all the things
it should comb itself and for now i'll
just pass it but
don't worry i'll come back to it later
we need
the get item method as well
and this will take self again and we
will pass this for now
and also we need to define our
len method as well into this class
and it will go with self
again and it should return a value but
for now we'll just pass so
in get item yeah we will need an index
as well so let's define an index as an
argument here as well and let's quickly
dive in to write this class for us so
what we need to do is first we need to
initialize the data set here so that we
can read
the data and separate it out into
features and labels
so what we do is let's say
i go with df is equal to pd dot read csv
and okay i
have iris dot csv
so this will give me the data frame and
as you can see that i have
four columns here let me select this
outfit
these are the four columns that we are
working with or we are dealing with
right now
and uh let me try and copy this one
let's try
copy this and let's paste it here let's
see
what we are working with so this is the
first column
uh feature number one feature number two
this is feature three
and feature four this is our
the label that we have let's try to work
with the label first
let's try to fix our label
and map it to numerical values so
let's say df of species
is equal to df of
species dot map
and i need to map this to a dictionary
so i'll do something like this
the first class is zero the second class
is one and the third class is
two so what are the classes that we have
we'll just copy that from
kaggle again first is iris satosa
i'll just copy it from here and i need
to go
iris it also has zero and
what else we have we have versicolor
and we will have virginica as well so
i'll quickly copy that
as well so let's go for it
i will map this to one
and finally we have virginica
at the bottom so this will be my mapped
labels here so this is how i do it
we can go with one hot encoding if you
want but i'm just
keeping it short for now and what else
we need to do
is let's say i need to create x
so x should be
df of these four values from here
like first will be sepal length
and next will be sample width from here
okay just happened what just happened
yeah now we're back and
let's sample width as well
and we have petal length in centimeter
i will quickly join it down here as well
and what we have finally
petal with yeah that's it so these four
columns will be my x
and final column will be df of species
i'll quickly copy it from here no need
to write it again
i'll do something like this and also
i'll go with values
so because i need this as a numpy array
and also we will have to convert this to
a type floor 32
so let's do it in like when we try to
create the tensor
uh we'll go with self dot x is equal to
[Music]
torch dot tensor
will convert this into tensor and let's
say
i need to convert this x and should
be as type
np dot float
32 i'll do the same for y as well
let's go for it and i'll go
y so this will convert uh the data type
to float32 and it will convert this
numpy array to
a tensor again so this would be all and
let's
let's try to con let's try to build one
more parameter here
for the length so let's see what are the
samples do we get
uh we'll go with data dot shape of zero
even this would help and what we will do
in the
get item method we will return itself
of x of the index
and we will return self of
y of the index and
in here we will return the length which
is self
dot samples so
uh so far so good
let's try to run this and see what do we
get
and try to build a model sorry object
from this
so what will be the class would have
given the name it's iris right
so data set okay
data set is equal to iris
and what i need to do here is just
let's try to paint the first row like
what do we get as an output
it should give me something here okay
perfect so first row
this is the first row that was recovered
from here
let's try to see the 11th row
okay so this is how it's looking
let's try to see the hundredth row
okay okay perfect so
we are getting the data set perfectly
and also
let's try to do one more thing
okay never mind never mind let's try to
go with this one for now
we'll also let's do let's go for it len
of data set you just need to test this
len method here
so you can go with yeah 150 columns are
here
so now this is how you use data set here
and now this data set is clubbed with
the data
loaded so this data set now can be
modified
and you can add some batch sizes number
of workers and
do multi threading techniques or multi
parallel processing
techniques using the data loader so now
we will see how this can be accomplished
so what we need to do here is let's say
we create a
model uh sorry an object of the
class that we have written and in this
class like instead of creating just a
what you can say normal object or normal
data set
will pass this into a data loader so how
we will do that
is let's say we go for data loader is
equal to
data loaded and this will take some
parameters the first parameters as you
can see is
data set that we need to pass it here
and the next arguments will be the
batch size uh let's say i
need to go with the patch size of
i need to go with the batch size of
five let's say and i will say
shuffle is equal to
true and also
let's specify the number of workers
because we want
parallel processing as well let's
specify two workers
and what else we have call it pin memory
drop
let's not use that for a while so this
looks good so far and now the data
loader will have
the iterations for us or the iters so
that can
yield us the batch wise information so
we have now
five defined the batch size as five so
one time
five bad samples will be taken out from
this
and this is very very useful in some
cases because
when we have batches with this the
training is the training performance is
really faster
and that's why we use data loader most
of the time because data loader
gives this gives these options for us so
how we proceed further is uh
we go with the iterator object
we go with data loader
waiter on the data loader and we let's
say
i save this into a variable named row
wise
you can name it as per your choice it's
completely up to you
and let's say we go with data as well
and let's say row wise
uh dot next so it will give me the next
batch size and let's try to print out
data so
if you if you see the output now you see
five
samples have been presented as an output
and why this five was given as an output
because the patch size we have provided
was
five so when we entered into the data
set
we entered into the starting phases of
the data set and when we went for next
all the five samples in the next size
were returned back here
and basically the labels were also been
spread out from here
and how did we get these two values
this was returned from get item like we
return self
dot x self.y so these are all the x
values that we have
and these are the relevant y
values for those columns and also you
can see like everything is shuffled
previously it was just one two or
one zero one two like in a chronology
but now
everything is shuffled so this is the
advantage of
uh data loader that we can use
and how we can use this for our own
purposes which is like
training purposes and what benefits can
like how can we take benefits from this
uh into our training is let's try to let
me try to show you first
let me write the code like first we will
define the e-box
let's say i go for 10 epochs
it's just an example random example for
now and
let's say how many samples do we have
samples are
this is a len of data centric lenovo
data set
is the samples and what we can say
is for every batches i need to go with
some iterations
so i'll say the total no
the samples
divided by the batch size what with the
pad size was five
so this will be the number of iterations
that we will go through
and yes let's try to round this off as
well
because if it's a float that will be a
problem for us
math dot sale and
let's say yeah that would be all
let's try to print this as well to see
okay
samples how many samples do we have
let's see
and the sample should be 150 and let's
see what are the iterations
it should be 30
yeah right so this is how like what will
happen now is that
uh for 30 like for every epoch
the data set will be entered for 30
times
because it is divided into this batch
size of five so five batches will be
sent
one time then it will be sent again in
the next iteration
and this will be completing the first
epoch for us
so let me quickly show you how this will
be done i'll quickly show you the steps
as well what step it will take
so i'll just quickly print it i won't
put the training right now so let's
quickly define our training loop for
epoch in
epochs and
in this loop uh we'll have to go with
one more okay i made a mistake here it
should be in range right
okay and inside
this loop i need to write one more loop
which is for um
for features comma labels in
data loader
loader and
let's try to enumerate this as well
let's see
we can use this as a parameter for
further ahead
and let's try to get this into a tuple
and let's go for the count
okay if i try to print this now let's
let's try to see what do we get at the
end so
what is my epoch value is
something like this and
that epoch are
like what will be the total number of
epochs
and let's say what do we have next
is this is
what are the steps let's go for steps
and this will take
again these two values which will be the
current step and the total steps that we
have so let's quickly try
format this let's see what do we get as
an output
so first is epoch
and the total ebox the second one
is the iteration
and the total iterations is in it so
let's try to run this now let's see what
do we get
okay okay okay perfect
perfect so this is how the so
the steps will look like like if you can
see here right now
for the ninth or the final epoch because
i didn't
incremented by one basically i should
have done that
but for the final epoch that we were
having
it first started with the zeroth step
like the first five samples were sent
here and the second samples were sent
here so every five five five patches
were sent one at a time
and every time those were trained so we
passed the data into batches
this will give us performance
upgradations when it comes to training
so this is how it works the data loader
and data
set in the next coming videos we will
see what is transforms
iterations as well and the activation
functions as well
so do let me know if you uh feel any
kind of like any issues with this uh
video
and this is just a basic one for now
don't worry about it we'll be using this
in the further
next level as well in further steps and
further videos
and uh we will we will be dealing with
this concepts again and again
so don't worry if you didn't understand
just stay with me and
we will be using it so we will get used
to it and we will learn more according
to that
so this is how we proceed ahead with
data set and data loaded
it was just a basic idea on how things
are in pytorch
and we will use it for our own benefits
while writing a neural network
so this would be all for this video i
hope you liked it
uh if you please uh could surprise
us subscribe to my channel that would be
really helpful
because i'll be keeping update keeping
or keep posting my
videos by every weekend every week i'll
be posting at least three videos
and i will see you soon and thank you so
much for your time
i hope you stay safe thank you