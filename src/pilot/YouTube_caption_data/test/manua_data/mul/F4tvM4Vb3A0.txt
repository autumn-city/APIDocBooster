Hi everybody. Welcome to lesson two. Thanks for 
coming back… slight change of environment here,  
we had a bit of an “administrative issue” at our 
university — somebody booked our room — so I'm  
doing this from the study at home. so sorry 
about the lack of decorations behind me.
I'm actually really really pumped about this 
lesson. It feels like going back to what things  
were like in the very early days, because we're 
doing some really new, really cool stuff, which…  
you know… stuff that hasn't really been in courses 
like this before. So, I'm super super excited.  
So thanks a lot for coming back after lesson 
one, and I hope it's worth you coming back.  
I think… I think you're gonna love it! I 
am, yeah, I'm really excited about this.
Now remember that, you know, the course 
goes with the book, so be sure that you're  
following. I mean, not following along 
in the book, because we're covering  
similar things in different directions… but, like, 
read the book as well, and remember the book is  
entirely available for free as well. You can go 
to the fast.ai fastbook repo to see the notebooks,  
or through course.fast.ai you can read 
it there — for example, through Colab.
And also remember that the book… I mean… the 
book has a lot of stuff that we didn't cover  
in the course like, you know, stuff I find pretty 
interesting about the history of neural networks,  
some of which has some really interesting 
personal stories actually, as you'll read here.  
And at the end of each chapter there is a quiz. 
Remember it's not a bad idea before you watch  
the video to read the quiz, so if you 
want to read the Chapter Two quiz,  
you know, and then come back, that's not 
a bad idea. Then make sure that you can  
do the quiz after you've watched the video, 
and you've read chapter two of the book.
Something I didn't mention last week 
is there's also a very cool thing that  
Radek — who I mentioned last week 
— has written, called aiquizzes.com  
which is a site specifically 
for quizzes about the book.  
And it actually uses repetitive based learning 
techniques to make sure that you never forget.  
So, do check out aiquizzes.com. It's all brand 
new questions, they're different to the ones in  
the book, and they're really nicely curated, and 
put together. So check out aiqquizzes.com as well.
Remember, as well as course.fast.ai,  
there's also forums.fast.ai. So course.fast.ai 
is where you want to go to get, you know,  
links to all the notebooks, and kaggle stuff, and 
all that stuff. You'll also find on forums.fast.ai  
every lesson has an official topic, 
you know, with all the information  
you'll need. Generally there'll be a bit more 
info on the forums, we try to keep the course  
lean and mean, and the forums are a bit more 
detailed. So if you find — in this case you  
are gonna look for the Lesson Two official topic 
but here's the Lesson One official topic so far.
So from the Lesson One official topic,  
already, after just a few days since I recorded it 
— we haven't even launched the course so it's just  
the people doing it live — there's already a lot 
of replies, and that can get pretty overwhelming.  
So be aware that there's a button at the bottom 
of my post that says summarize this topic.  
And if you hit that, then you'll just see the 
most upvoted replies, and that's a really good  
way to just make sure that you hit on the main 
stuff. So there's the button, and here's what  
it looks like after you hit it. You'll just get… 
you'll just get the upvoted stuff from fast.ai  
legends like Sanyam and Tanishq. So hopefully 
you'll find that a useful way to use the forum.
So one of the cool things about this week is I… 
as promised, put up the “show us what you've made”  
post, and already a lot of people have posted. 
I took this screenshot a few days ago, it's way  
above 39 replies already, if I'm… if I remember 
correctly. I had a lot of trouble deciding which  
ones to share because they're all so good, so I've 
actually decided to kind of, you know, go the easy  
route, and I just picked the firsts. So I'm just 
going to show you the first ones that were posted  
because they're all so good. So the first, the 
very very first one to be posted is a damaged  
car classifier… so that worked out pretty well 
— it looks like. And I really liked what Matt,  
the creator, said about this, is that… you know, 
wow, it's a bit uncomfortable to run this code, I  
don't really understand yet but I'm just doing it. 
And so I'm like, yeah, good on you Matt for just…  
for just doing it. That's the way to get started, 
it's all going to make sense, don't worry.
Very nice to see that the next one posted was 
actually a blog post in fast pages — very nice  
to see — so just describing some stuff, some 
experiments that they ran over the week and what  
did they find. Next one was the amazing beard 
detector which if I understand correctly was  
mainly because it's very easy to get from bird to 
beard by just changing one letter to two, and this  
is doing a very good job of finding gentlemen 
with beards. Very nice. And then this one is…  
another level again, it's a whole in-production 
web app to classify food, which is kind of like  
extra credit . Apparently we're up to 80 replies 
now in that thread, thank you Sanyam, very cool.
So, you know, obviously… so this was actually 
created by Suvash who's been doing the courses for  
a few years now, I believe. And so you know, one 
day you too might be able to create your very own  
web app and put it in production. And when I say 
one day, more specifically… today! I'm actually  
going to show you how to do this right now! So 
it's actually quite a lucky coincidence that  
Suvash put this up there because it's exactly 
the topic that we're going to pick today.
So, how do we go about putting a 
model in production? Step one, is…  
well… you've kinda done step one, right? Step one 
is… step one, two, three, four… is to figure out  
what problem you want to solve, figure out how 
to find the data for it, go gather some data,  
and so forth. So what's the kind of first step 
after you've got your data? The next step is  
data cleaning, and if you go to Chapter 2 of the 
book, which I'm going to go ahead and open up now… 
So here is the book… so you can open it in 
Colab directly from the course, or if you've  
cloned it to your computer, or whatever, 
you can… you can do it there. So remember,  
course.fast.ai will run you through exactly how to 
run these notebooks, and so you can see Chapter 2  
is all about putting stuff in 
production, and so here is Chapter 2.  
All right, and so remember we hit Shift + 
Enter to run cells, okay? …to execute them.  
And so we're going to go to the part of 
the book where we start cleaning the data.  
So I'll click on Navigate, and we'll go 
down here… gathering data… there we are!
So we could do a quick bit of revision first. By 
the way, I will mention, a lot of people ask me  
what are the little tricks I use for getting 
around a Jupyter notebook so quickly and easily.  
One of the really nice ones as you'll see is 
this navigate menu, which actually doesn't  
appear by default. So if you install something 
called Jupyter Notebook Extensions - Jupyter…  
Notebook… Extensions… and so you just… you just 
“pip install” them, follow the instructions  
and then restart Jupyter. Obviously this… Colab 
already has a table of contents by the way so  
this is just if you're using something 
local, for example, then you'll see here  
that this “Nbextensions” thing will appear, 
and if you click on “Table of Contents (2)”  
that gives you this handy navigation 
bar. The other thing I really like  
is this one here called collapsible headings, and 
that's the one which gives me these nice little  
things here, to close, and open up. 
And actually that's not even the best  
part. The best part for me is if I hit the 
right arrow it goes to the end of a section,  
and if I hit the left arrow it goes to 
the start of a section. So it's like,  
if I want to move around sections I just press 
up left, down right, down right, very handy,  
and if you hit left again when you're here 
it 'll close it up. Hit right again here,  
open it up. So that's collapsible headings. 
Anyway, a couple of really handy things,  
and we'll be talking a lot more about getting 
your notebook set up today in a moment.
Okay, so one thing you'll notice is in the book, 
we use the Bing API for searching images. I've  
just gone ahead, and replaced “bing” with “ddg” 
because the Bing API requires getting an SDK key  
which honestly, it’s like the hardest thing in 
deep learning is figuring out the Bing Azure  
website, and getting that sorted out. ddg doesn't! 
So it's basically exactly the same… (and you can…)  
I'll share this notebook as well, on the course 
website in the forum but all I've basically done  
is I've replaced bing with ddg, and got rid of 
the key. So then, just like we did last week,  
we can search for things, and so in the book we 
did a bear detector because at the time I wrote it  
my then toddler was very interested 
in me helping identify teddy bears,  
and I certainly didn't want her 
accidentally cuddling a grizzly bear,  
so we show how here how we can search 
for grizzly bears, just like last week.  
Something that loops through grizzly 
bears, black bears, and teddy bears,  
just like last week. Get rid of the 
ones that failed, just like last week.
And one thing a few people have asked on the 
forum is how do i find out more information  
about basically any python or fastai or pytorch 
thing. There's a few tips here in the book. One  
is that if you put a double question mark next to 
any function name you'll actually get the whole  
source code for it, and by the same token if you 
put a single question mark you'll get a brief…  
you know… a little bit of 
information. If you've got  
nbdev installed (I think it's nbdev 
you need) then you can type doc,  
and that will give you perhaps most importantly 
a link straight to the documentation  
where you can find out more information and 
generally there will be examples as well.  
And also a link here to the 
source code, if you want to…  
(let's do that with a control okay) …a link 
to the source code and that way you can jump  
around. And notice that in github in the source 
code you can click on things and jump to their  
definition. So it's kind of a nice way of skipping 
around to understand exactly what's going on.
Okay, so lots of great ways of getting help.  
But what I promised you is that we're going to 
now clean the data. So I'm going to tell you  
something that you might find really surprising. 
Before you clean the data, you train a model.  
Now, I know that's going to sound really backwards 
to what you've probably heard a thousand times,  
which is that first you… ~(build/you/train) 
…you clean your data and then you train your  
model. But I'm going to show you something really 
amazing. First we're going to train a model and  
you'll see why in a moment. So to train a model, 
just like before, we use a DataBlock to grab our  
data loaders — there's lots of information 
here in the book about what's going on here.
There we go… and so then we can call 
show_batch to see them as per usual.
There's a little side bar here in the book, I'll 
quickly mention, which is about the different  
ways we can resize. I think we briefly 
mentioned it last week… we can squish…  
last week I used a string, you can use a string 
or this kind of enum like thing that we have.  
You can see with a squish you can 
end up with some very thin bears,  
right? So this is the real size, the shape, of 
the bear. Here its become thin but you can see  
now we've got all of its cubs… (are they called 
clubs? yeah bear cubs) …so it squished it to  
make sure we can see the whole picture. Same one 
here. This one was out of the picture, we squished  
it and this guy now looks weirdly thin, but we 
can see the whole thing. So that's squishing!
Or else this one here is cropping. It's cropped 
out just the center of the image so we get a  
better aspect ratio but we lose some stuff. This 
is so we can get square images. And the other  
approach is we can use “pad.” And so you can pad 
with various different things. If you pad with  
zeros, which is black, you can see here now we've 
got the whole image and the correct aspect ratio.  
So that's another way we can do it and you 
know, different situations, you know, result in  
different quality models. You can try them, all 
it doesn't normally make too big a difference.  
So I wouldn't worry about it too much. I'll 
tell you one though that is very interesting  
is RandomResizedCrop. So instead of saying resize, 
we can say RandomResizedCrop. And if we do that  
you'll see we get a different bit of an image 
every time. So, during the week… this week  
somebody asked on the forum… I'm trying 
to… (this is a really interesting idea,  
which it turned out worked slightly) they 
wanted to recognize pictures of French  
and German texts. So obviously this is not the 
normal way you would do that, but just for a  
bit of experiment (and I love experiments, 
so) they had very big scans of documents  
and they wanted to figure out whether it was 
french or german just by looking at images and  
they said the pictures were too big what should 
I do? I said, use RandomResizedCrop and that way  
you'd grab different bits of the image, and this 
is very nice because you could run lots and lots  
of epochs and get slightly different pictures 
each time. So this is a very good technique. And  
this idea of getting different pictures each time 
from the same image is called “data augmentation.”
And again, I'm not going to go into too 
much detail about data augmentation,  
because it's in the book, but 
i'll just quickly, you know,  
point out here that if you use this thing called 
“aug_transforms” so augmentation transforms,  
and here I have multiplied them by two 
– so I've made them super big so you can  
see them more easily. You can see that these 
teddies are getting turned, and squished, and  
warped, and recolored, and saturated, all this 
stuff to make every picture different. And  
generally speaking if you're training 
for more than about five or ten epochs,  
which you'll probably want to do most of the time 
unless you've got a super easy problem to solve,  
you'll probably want to use RandomResizedCrop 
and these “aug_transforms”. Don't put the mult=2,  
just leave that empty. I'm just putting 
it there so you can see them more clearly.
So I've got an interesting question here from 
Alex in our audience, which is: “Is this…  
is this copying the image multiple times? …doing 
something like this? …or something like this?”  
and the answer is “no we're not copying the image. 
What happens is that image… so each epoch, every  
image gets read. And what happens here is though… 
is… is kind of… in memory, in RAM, this… the image  
is being “warped”, right? it's being… we're 
cropping it and recoloring it, and so forth. So  
it's a real time process that's happening during 
model training. So, there's no copies being stored  
on your computer, but effectively it's almost 
like there's infinitely slightly different copies  
because that's what the model ends up seeing. So, 
I hope that makes sense Alex, and everybody else,  
so that's a great question!
Okay, so we've got… we're going to use 
RandomResizeCrop, we're going to use augmentation  
transforms, so that we can get at DataLoaders from 
that and then we can go ahead and train our model.  
It takes about a minute. In this case we only did 
four epochs of fine tuning, and we'll talk about  
why there's five here later in the course, 
but four main epochs of fine tuning. So we  
probably didn't really need RandomResizedCrop and 
aug_transforms because there's so few epochs, but  
you know, if you want to run more epochs 
this is a good approach. Under three percent  
error! that's good! Okay, so remember I said 
we're going to train a model before we clean?
Okay so let's go ahead and train it.
So while that's training… so it's running on my 
laptop, which only has a 4GB GPU, it's pretty  
basic, but it's enough to get started. While 
that's training we'll take a look at the next one.  
So the first thing we're going to look at is 
the confusion matrix and the confusion matrix  
is something that… it only is meaningful 
for when your labels are categories, right!  
And what it says is how/what category errors are 
you making. And so this is showing that the model  
that we've got at this point… there were two 
times when there was actually a grizzly bear  
and it thought it was a black bear, and there was 
two times when there was actually a black bear,  
and it thought it was a grizzly bear, and 
there was no times that it got teddies wrong,  
which makes sense right because teddies 
do look quite different to both.
In a lot of situations when you look at this, 
it'll kind of give you a real sense of, like okay,  
well what are the hard ones? right? So for example 
if you use the pets data set that we quite often  
play with in the book and the course, this 
classification [**] matrix for different breeds  
of pets, you know, really shows you which ones are 
difficult to identify, and I've actually gone in,  
and like, read wikipedia pages, and pet 
breeding reports about how to identify  
these particular types, because they're so 
difficult, and even experts find it difficult.  
And one of the things I've learned from doing 
the course actually is… black bears and grizzly  
bears are much harder to pick apart than I 
had realized... so I'm not even going to try!  
But I'll show you, the really interesting 
thing we can do with this model,  
is that now we've created this 
classification interpretation  
object, which we use for confusion 
matrix, we can say plot_top_losses.
We can say plot top losses, and this 
is very interesting. What it does is,  
it tells us the places where the “loss” is the 
highest. Now if you remember from the last lesson,  
the loss is that measurement – of how good our 
model is – that we take after each time we run  
through an item of data. A loss will be “bad” 
if we predict wrongly, and we're very confident  
about that prediction. So here's an example 
where we predicted… (here's the order here:  
prediction, actual loss, probability) …where we 
predicted grizzly and it was actually a black,  
and we were 96% sure (our model 
was) that it's a grizzly. Now,  
I don't know enough about bears to know whether 
the model made a mistake or whether this actually  
is a picture of a grizzly bear… but so, an expert 
would obviously go back and check those out…  
right? Now, you'll notice a couple here... it's 
got grizzly/grizzly, teddy/teddy… they're actually  
correct, right? So why is this loss “bad”? When 
it's correct? And the reason is… because it  
wasn't very confident. It was only 66% confident, 
right? So here's a teddy… it's only 72% confident  
right? So you can have a bad loss, either by 
being wrong and confident, or being right and  
unconfident. Now the reason that's really helpful, 
is that now we can use something called the  
fast.ai ImageClassifierCleaner to clean up the 
ones that are wrongly labeled in our data set.
So when we use the ImageClassifierCleaner it 
actually runs our models. That's why we pass it  
“learn”, right? And I mentioned that I don't know 
much about black bears and grizzly bears but I do  
know a lot about teddy bears, so I'll pick teddy 
bears. And if I click teddy bears it's now showing  
me all the things in the training set (you can 
pick training or valid) that were marked as teddy  
bears and here's what's really important: they're 
ordered by loss, so they're ordered by confidence,  
right? So I can scroll through just the first 
few and check they're correct, right? And oh,  
here's a mistake, right? So when I find 
one that was wrongly gathered I can either,  
put it…if it's in the wrong category, 
I can choose the correct category… or,  
if it shouldn't be there at all, I click delete. 
So here I'll go ahead and click delete, right?  
So you can see some reasons that some of these 
are hard, like for example here's two teddies,  
which is just, I guess, confusing since 
it doesn't see that often. This one here  
is a bit weird looking, it looks almost like 
a wombat. This is an awful lot of teddies.
This one maybe is just a bit hard to see from the 
background, but these, otherwise, they look fine…  
Fine, so we just look through the first 
few and if you don't see any problem or  
problems in the first year, you're probably 
fine. So that's cleaned up our training set,  
let's clean up our validation set as well. 
So here's that one it had trouble with,  
I don't know why it had trouble with that one but 
so be it and we'll have a quick scroll through…  
Okay I'm not really sure that's a bear so 
I'm just going to go ahead and delete it.  
It's a teddy something… but, you know, it's 
a problem. Okay, that's not a teddy either…
So you see the idea, right? So after we've 
done that, what that does is… the cleaner  
has now stored a list of the ones that we 
changed and the list of the ones we deleted,  
so we can now go ahead and run this cell. And so 
that's going to go through a list of all of the  
indexes that we said to delete, and it will 
delete those files. And we'll go through all  
the ones we set to change, and it will move 
them to the new folder, there we go, done!
So, this is like, not just something for 
image models. It's just… it's actually…  
a really powerful technique that 
almost nobody knows about and uses,  
which is, before you start data cleaning, 
always build a model to find out  
what things are difficult to recognize in your 
data and to find the things that the model can  
help you find data problems. And then as 
you see them, you'll kind of say “okay,  
I see the kinds of problems we're having” and 
you might find better ways to gather the next  
data set, or you might find ways to kind of 
automate some of the cleaning and so forth.
Okay, so, that is data cleaning and since I 
only have a 4GB GPU it's very important for me  
to close and halt, because that will free 
up the memory. So it's important to know…  
on your computer your normal RAM doesn't really 
get filled up, because if you use up too much RAM,  
what will happen is that instead your 
computer will start (it's called) swapping,  
which is basically to save that RAM onto the 
hard disk to use it later. GPUs can't swap.  
GPUs, when they run out of RAM, that's it, 
you're done. So you need to make sure that  
you close any notebooks that are using the 
GPU that you're not using and really only use  
one thing at a time on the GPU, otherwise 
you're almost certainly run out of memory.
So we've got the first few reds starting 
to appear. So remember to ask and,  
in terms of the yellows, it's important to 
know, as you watch the video, I'm not asking  
you to run all this code, okay? The idea is to 
kind of watch it, and then go back and pause,  
you know, as you go along. Or you can just stop, 
try, stop, try. The approach I really like — and a  
lot of students really like — for watching these 
videos is to actually watch the entire thing  
without touching the keyboard, to get a sense of 
what the video is about, and then go back to the  
start and watch it again and follow along. That 
way, at every point you know what it is you're  
doing, you know what's going to happen next. 
That can actually save you some time. It's a  
bit of an unusual way because, obviously like, 
real life lectures you can't do that, you can't  
rewind the professor and get them to say it 
again, but it's a good way to do it here.
So now that we've cleaned our data, how are 
we going to put it into production? Well in  
the book we use something called Voilà. 
And it's… it's pretty good! But there's  
actually something that I think most of you are 
probably going to find a lot more useful nowadays,  
which is something called HuggingFace 
Spaces, and there's a couple of things  
you can use with that. We're going to 
look at something called Gradio today.
And there isn't a chapter about this in the 
book but that doesn't matter because Tanishq  
Abraham — who's actually one of the TAs in the 
course — has written a fantastic blog post about  
really everything we're going to cover today. So 
there's a link to that from the forum and from the  
course page, so this is like the equivalent 
of the chapter of the book, if you like.  
And I would be remiss if I didn't stop for 
a moment and call out Tanishq in a big way  
for two reasons: the first is he is one of the 
most helpful people in the fastai community,  
he's been around quite a few years, 
incredibly tenacious, thoughtful and patient;  
and also because I have this fantastic picture 
of him a few years ago with Conan when he was a  
famous child prodigy, so now you know what 
happens to famous child prodigies when they  
grow up – they became even more famous fastai 
community members and deep learning experts.  
So you should definitely check out this 
video of him telling jokes to Conan.  
I think he's still only 18 actually, 
this is probably not that many years ago.  
So thank you very much Tanishq 
for all your help in the community  
and sorry for embarrassing you with that picture 
of you as a nine-year-old — I'm not really, haha.
Okay, now, the thing is for doing 
Gradio and HuggingFace Spaces, well,  
it's easy enough to start. Okay, we start over 
here on the HuggingFace Spaces page — which  
we've linked to from the forum in the course. 
And we're going to put a model in production,  
where we're going to take the model we 
trained, and we are going to basically copy  
it to this HuggingFace Spaces server 
and write a user interface for it.
So… let's go! Create new space. Okay, so, you can 
just go ahead and say, all right… so obviously  
you sign up… the whole thing's free. Basically 
everything I'm showing you in this entire course,  
you can do for free, that's the good news. Okay, 
so, give it a name, just create something minimal.  
I always use the Apache license because 
it means other people can use your work  
really easily but you don't have 
to worry too much about patents.  
As I say there's a few different products you can 
use with it, we're going to use Gradio, also free.
If you make it public then you can share it, 
which is always a good idea when you're a student,  
particularly to… to really be building up that 
portfolio. Okay, so we're done. We've created  
a space. Now, what do we do next? Well, Spaces 
works through Git, now, most software developers  
will be very familiar with Git. Some data 
scientists might not be. And so Git is a very,  
very useful tool. I'm not going to talk about it 
in detail, but let's kind of quickly learn about  
how to use it, right? Now, Git, you can use 
it through something called Github Desktop  
which is actually pretty great and even people 
who use Git through the console should probably be  
considering using Github Desktop as well, because 
some things are just much faster and easier in it,  
in fact I was talking to my friend Hamil today and 
I was like, oh, help, I've accidentally committed  
this two things by mistake, what's the easiest 
way to revert it, and he used to work at Github  
and I thought he was going to have some fancy 
console command and he's like “oh, you should  
use Github Desktop and you can just click on it.” 
Oh! That's a great idea. So that's… that's useful.
But most of the time we do use Git from 
the console, from the terminal. If you're  
a Linux user or a Mac user you've already got 
a terminal, very straightforward, no worries.  
If you're a Windows user I've got good news, 
nowadays Windows has a terrific terminal.  
It's called Windows Terminal, you 
get it from the Microsoft Store,  
so in fact every time you see me using a terminal, 
I'm actually using that Windows Terminal, works  
very well. God knows why you'd want it to, with 
all these ridiculous colors but, there you go.
Now, what do you want to be running inside your 
terminal? Obviously, if you're in Linux or Mac  
you've already got a shell set up. In Windows, you 
almost certainly want to use Ubuntu. So Windows,  
believe it or not, can actually run a full Linux 
environment and to do it, is right typing a single  
line, which is this… So, if you go to (just google 
for WSL install) run PowerShell as administrator,  
paste that command, wait about 
five minutes reboot, you're done.  
You now have a complete Linux environment. 
Now, one of the reasons I'm mentioning this  
is, I'm going to show you how to do 
stuff on your own machine now, and, so,  
this is like going to a bit of an 
extra level of geekery, which some  
data scientists may be less familiar with. So you 
know, don't be worried about the terminal, you're  
gonna.. I think you're gonna… find it really 
helpful and much less scary than you expect.  
And, I particularly say, like for me, I choose to 
use Windows and that's because I get, you know,  
all the nice Windows GUI apps and I can draw on 
my screen, and do presentations, and I have a  
complete Linux environment as well. And that Linux 
environment uses my GPU and everything, so for me,  
you know, my first choice is to 
use Windows, my second choice,  
by not very much, really like it, would be 
to use Linux. Mac is a little bit harder,  
but it's still usable. Some things are a little 
bit trickier on Mac but, you should be fine.
Okay, so, whatever you've got, at this 
point you've now got a terminal available.  
And so, in your terminal… (one of 
the really nice things about using  
a terminal is you don't have to follow lots 
of instructions about click here, click here,  
click here. You just copy and paste things.) 
So I'm just going to… you just copy this,  
and you go over to your terminal, and you paste 
it in, and you run it, and after you do that,  
you'll find that you've now got a directory. 
And so that new directory initially is empty  
and they tell you, okay, go ahead and create 
a file with this in it. Okay, so, how do you  
create a file with that in it, when we're in 
here, in our Linux environment on Windows,  
or in the terminal on Mac, or whatever? Well, all 
you do in Windows, if you just type “explorer.exe  
.”, it'll open up explorer here, or better 
still, on either Mac, or Linux, or Windows…  
So, yeah, regardless of what computer (type 
of computer on), you can just type “code .”  
and it will pop up Visual Studio Code and open 
up your folder. And so then you can just go ahead  
and… (if you haven't used VS Code before it's 
really well worth taking a few minutes to read  
some tutorials, it's a really great IDE) …and 
so you can go ahead and create an app.py file,  
like they tell you to, app.py file, containing 
what they told you to put in it. Here it is, here.
All right, we're nearly there. So 
you can now go ahead and save that,  
and then you need to commit it, to Gradio… 
(not Gradio…) to HuggingFace Spaces.  
So one really easy way is just, in Visual Studio 
itself, you can just click here, and that'll  
give you a place where you type a message, 
and you hit tick, and it'll send it off to  
HuggingFace Spaces for you. 
So once you've done that,  
you can then go to… back to… the 
exact same website you're in before:  
“huggingface.co/spaces/jhp00/minimal”,  
and what you'll find now is that — it'll take 
about a minute, to build your website. And it's…  
the website it's building is going to have a 
Gradio interface with a text input, a text output,  
and it's going to run a function 
called “greet()” on the input,  
and my function called “greet()” will return 
“Hello {name}”. So that's what it's going to do.
Now there it goes, let's try 
it! We'll say hello to Tanishq.  
I'm not always very good at remembering how 
to spell his name, I think it's like that.  
And there you go, so you can see it's 
put the output, for our input. So not  
a very exciting app but we now have, to be 
fair, an app running in production, right?  
Now, I told you we'd have a deep 
learning model running in production  
so now we have to take the next step which 
is to turn this into a deep learning model.
All right, so, first we're going 
to need a deep learning model.  
And there's a few different ways we can 
get ourselves a deep learning model,  
but basically we're gonna have to train one. 
So, I've got a couple of examples: I've got a  
Kaggle example and a Colab example. Maybe I'll 
quickly show you both. They're gonna be the same  
thing. And I'm just going to create a dog or a 
cat classifier. Okay, so here's our Kaggle model,  
I'll click on edit so you can actually 
see what it looks like in edit view.  
Now, Kaggle already has fastai installed but I 
always put this first, just to make sure we've got  
the latest version. And obviously import stuff, 
we… So we're going to grab the pets data set,  
a function to check whether it's a cat, that's 
our labeling function for our ImageDataLoaders  
— remember this is just another way of doing 
DataBlocks, it's like a little shorthand.  
And we create our learner, and we fine tune it. 
Okay, so, that's all stuff we've seen before.
So, in Kaggle every notebook has an edit-view 
(which is what you just saw) and a reader-view.  
And so you can share your notebook — if 
you want to. And then anybody can read the  
reader-view, as you see. And so, here, you can 
see, it shows you what happened when I ran it.  
And so, I trained it, it took… you know, the GPUs 
on Kaggle are a bit slower than most modern GPUs  
but they're still fast enough, I mean, it takes 
five minutes. And there's one bit at the end here,  
which you haven't seen before, which is 
I got learn.export and I give it a name.
Now, that's going to create a 
file containing our trained model,  
and… that's the only thing! Creating this file 
is the only thing you need a GPU for, right?  
So you do that on Kaggle, or on Colab. So here's 
exactly the same thing on Colab… you can see “pip  
install”, is_cat, our data, ImageDataLoaders, so 
I've got a show_batch here as well, just for fun.  
Create my learner and then export. So, while 
we wait I might go ahead and just run that.  
One nice thing about Kaggle is once you've run 
it and saved it, you can then go to the data tab  
and, here is basically anything you've 
saved, it's going to appear here,  
and here it is: model.pickle, right? So now I can 
go ahead and download that and that will then be  
downloaded to my downloads folder. And then I 
need to copy it into the same directory that my  
HuggingFace Spaces App is in. Now my HuggingFace 
Spaces App is currently open in my terminal,  
on Mac you can type “open .” or in Windows you 
can type “explorer.exe .” and that'll bring up  
your finder or explorer in that directory. 
And so then you can just paste that,  
that thing you downloaded into this 
directory. Something by the way,  
in Windows I do, which I find really helpful is, 
I actually grab my… my home directory in Linux  
and I pin it to my Quick Access and that way I can 
always jump in Windows straight to my Linux files.  
Not really something you have to worry about 
on Mac because it's all kind of integrated,  
but on Windows they're like, kind 
of like, two separate machines.
Okay, so…
Let's do… so, I created a Space called testing and 
I downloaded my “model.pkl” and I pasted it into  
testing. So now we need to know how 
do we do predictions on a saved model?  
So we've got a notebook for that… 
Okay, so we've got a notebook for that  
and… so I'm going to take you through how we use 
a model that we've trained to make predictions.  
There's a few funny things with hash pipe 
which I'll explain in a moment, just ignore  
those for now. So we import fastai as usual. We 
import Gradio as we did before. And we copy in  
the exact same is_cat definition we had before. 
That's important, any external functions that you  
used in your labeling, need to be included 
here as well because that learner refers  
to those functions, okay? It saves... that 
learner saves everything about your model,  
but it doesn't have the source code of the 
function, so you need to keep those with you.  
So, let's try running this. So, for example,  
I just grabbed… (as you might have seen in my 
explorer) I just popped a dog picture there.  
And so we can create a python image library image 
from that dog, turn it into a slightly smaller  
one so it doesn't overwhelm my whole screen and 
there is a picture of a dog. So, how do we make  
predictions of whether that's a dog or a cat? 
Well, it's very simple, all we do is… instead of  
training a learner, we use load_learner(). We pass 
in the file name that we saved, and that returns  
a learner. This learner is exactly the same as 
the learner you get when you finish training. So  
here we are, here's Colab, right? We've just been 
training a learner, so at the end of that, there's  
a learner that's been trained, and so we… We kind 
of froze it in time, something called a pickle  
file — which is a python concept. It's like a 
frozen object, we saved it to disk, we transferred  
it to our computer, and we've now loaded it, 
and we've now unfreezed thought it. This is our  
unpickled learner and we can now do whatever 
we like with that. So one of the things that…
One of the methods that a learner has is a dot 
predict method, so, if I run it, you can see,  
even on my laptop, it's basically ~(instance) 
instant. In fact we can see how long it took.  
If you — in Jupyter things that start with percent 
are called magics, they're special Jupyter things,  
so for example, there's a thing 
to see how long something takes.  
There you go, okay, so it took 54 milliseconds 
to figure out that this is not a cat.
So it's returning two things: is it a cat? (as 
a string); is it a cat? (as a zero or one),  
and then the probability that it's a dog, and the 
probability that it's a cat. So the probability of  
zero (false) and one (true) of is 
it a cat? so definitely a dog. So  
we now want to create a Gradio interface 
which basically has this information.  
So Gradio requires us to give it a 
function that it's going to call,  
so here's our function. So we're going to call 
predict, and that returns as we said three things:  
the prediction is a string; the index of 
that; and the probabilities of whether it's a  
dog or a cat. And what Gradio wants, is it wants 
to get back a dictionary containing each of the  
possible categories — which in this case is dog 
or cat — and the probability of each one. So,  
if you haven't done much python before, a dict 
of a zip may be something you haven't seen.  
Very handy little idiom well worth checking out. 
Ditto if you haven't seen map before, anyway,  
here it is. One slightly annoying thing about 
Gradio at the moment is that it doesn't handle  
Pytorch Tensors, you can see here Pytorch is 
not returning normal numbers, it's returning  
Tensors. It's not even returning Numpy Arrays. 
In fact radio can't handle Numpy either,  
so we have to change everything just to a 
normal float, so that's all that this is doing,  
it's changing each one to a float. So, for 
example, if I now call classify_image()  
with our doggy image, we get back a dictionary 
of a dog, yes definitely; cat, definitely not.  
So now we've got all that we can go 
ahead and create a Gradio interface.  
So Gradio interface is something where 
we say, well, what function do you call  
to get the output, what is the input — in this 
case we say, oh, the input is an image — and so  
check out the Gradio docs, it can be all 
kinds of things like a webcam picture,  
or a text, or you know, all kinds of things. 
Give it a shape that it's going to put it into,  
the output's just going to be a label so we're 
going to create very, very simple interface.
And we can also provide some examples, and so 
there's a dog, a cat, and a dunno — which I'll  
tell you about in a moment — which you'll see 
here there's a dog, and a cat, and a don't know.  
So once I launch it, it says, okay, that's 
now running on this url. So if I open that up;  
you can see now, we have just like Suvash, 
we have our own — not yet in production,  
but running on our own box — classifier. 
So let's check: dog, so you can  
click it and upload one, or 
just choose the examples…
Here they are! So it's running on 
my own laptop, basically instant.  
And I really have to tell you the story 
about this guy here, this is the dunno.  
Submit, wait, why is it saying 100? Normally this 
says like 50 50. That's a bummer, this model's  
got… messed up my whole story. So last time I 
trained this model, and I ran it on the… dunno,  
it said, it said like it's almost exactly 
50 50. And the way we found this picture  
is… I showed my six-year-old daughter, she's like: 
“what are you doing dad?”, like, I'm coding, “what  
are you coding?” Oh, you know, dog cat classifier. 
She checks it out and her first question is:  
“can I take your keyboard for a moment”, and 
she goes to google, and she's like: what is a  
dog mixed with a cat called. Like, there's no such 
thing as a dog mixed with a cat. Anyway, she goes  
to the images tab, and finds this picture, and 
she's like: “look there's a dog mixed with a cat”.  
She said: “run it on that dad!, run it on that!” 
And I ran it and it was like: 50-50. It had no  
idea if it's a dog or a cat. Now, this model I 
just retrained today, now it's sure it's a cat.  
So there you go, I think I used a slightly 
different training schedule or something, or gave  
it an extra epoch, anyway, so that's a dog-cat, 
but apparently it's a cat. I guess it is a cat.  
It's probably right. I shouldn't 
have trained it for as long.
Okay, so there's our interface. 
Now, that's actually running,  
so you actually have to click the 
start button to stop it running  
so otherwise you won't be able to do 
anything else in your notebook. Okay,  
so, now we have to turn that into a python 
script. So, one way to turn it into a python  
script would be to copy and paste into a 
python script all the things that you need.  
I need to copy and paste into a python 
script all these parts of this that you need,  
so, for example, we wouldn't need this — it's 
just to check something out, we wouldn't need  
this — it was just experimenting. This was 
just experimenting. We'd need this, right?  
So, what I did… is I went through and I wrote 
“hash pipe export” at the top of each cell  
that contains information that I'm 
going to need in my final script,  
and then — so they're the steps, right? And then, 
at the very bottom here, I've imported something  
called notebook2script from nbdev, and if I run 
that, and pass in the name of this notebook,  
that creates a file for me called app.py 
containing that script. So this is a nice  
easy way to — like when you're working with stuff 
that's expecting a script and not a notebook,  
like HuggingFace Spaces does. It's fine to just 
copy and paste into a text file if you like,  
but I really like this way of doing it because 
that way I can do all of my experimentation  
in a notebook, and when I'm done, I just have 
a cell at the bottom I just run and export it.  
How does it know to call it app.py? That's because 
there's a special thing at the top default export:  
default_exp, which says what python file name to 
create. So that's just a little trick that I use.
So now we've got an app.py. We need to upload 
this to Gradio, how do we do that? You just… you  
just push it to Git. So… you can either do it with 
Visual Studio Code, or you can type “git commit”.  
And then “git push”. And once you've done that…if  
we change minimal to testing… I think 
this hopefully might still be running  
my previous model — because I didn't push it, 
and that way, we can see our crazy dog-cat.  
All right, so here it is, you 
can see it running in production.  
So now this is something that anybody 
can — if you set it to public — anybody  
can go here and check out your model, and so 
they can upload it. And so, here's my doggy.  
Yep, definitely a dog. Cat, yeah I think I might 
have trained this for an epoch or two less,  
so it's less confident. Yeah 
definitely a cat. Dog-cat…  
hey dog-cat… hmm, still thinks it's 
definitely a cat. Oh well, so weird.
Okay, so, that is…Okay, so, that 
is an example of getting a simple  
model in production. There's a couple of 
questions from the forum, from the community.
Okay so one person's asking:  
“what's the difference between a pytorch model and 
a fastai learner?” Okay, that's fine, we'll get to  
that shortly. Don't know if it'd be the lesson, 
it might be this lesson or the next lesson.
And then somebody else asked, basically it's 
asking: “how many epochs do we train for?”  
So, as you train a model your error 
rate, as you can see, it improves.  
And so the question is: should I run more? 
Should I increase the number of epochs?  
This is doing three epochs, right? Here's 
my three epochs plus one to get started.  
Look, it's up to you, right? I mean, for this, 
is here saying: there's a one percent error.  
I'm… I'm okay with the one percent error, 
you know, if you want it to be better,  
then you could use more data augmentation, and you 
could train it for longer. If you train for long  
enough, as we'll learn about soon, and then… maybe 
the next lesson. If you train for long enough,  
your error rate actually starts getting 
worse. And, you'll see, we'll learn about  
why. So basically yeah, you can train until it's 
good enough or until you've run out of patience,  
or time, or run out of compute, or until you… 
or until the error rate starts getting worse.
Okay, oh, and then in Colab, 
how do you grab your model?  
All you need to do in Colab 
is, after you've exported it,  
is, if you go into their file browser  
you'll actually see it here, right? And 
you can click download. It's a bit weird,  
it doesn't like, pop up a box saying 
where do you want to download it to,  
but instead this kind of progress circle thing 
pops up, and so depending on how big it is,  
and so forth, it can take a few minutes. 
And once that circle fills up then it'll,  
the browser thing will finally pop up and say, 
okay, you can save it. Okay so that's how you…  
that's how you actually grab your model. So as you 
can see, the step where you actually need a GPU,  
you can use these totally free resources: 
Colab, Kaggle, and there are other ones we'll  
talk about in future lessons. And then you can do 
everything else on your own computer, including  
the predictions, the predictions are fast, 
right? So, you really don't need to use a GPU  
for that, unless you're doing thousands of them. 
Okay, here it goes, now it's asking me to save it.
Okay, so now one big issue is, we needed… 
to run it on our computer… we needed  
python and Jupyter Notebooks running 
on our computer, so how do you do that?  
Because this is where often people get in all 
kinds of trouble… “I'm trying to figure out how  
to get this all working.” So, the good news is 
we've actually got something that makes it very,  
very straightforward. It's called fastsetup. 
There's really only just one part of it you need,  
so let me show you…. it's… it's… actually a 
Git repository on Github. Github's the place  
where most Git repositories live. So if you 
go to Github fastai/fastsetup you'll see it.  
And so what you can do is you can now grab this 
whole repository, just by clicking here on code,  
and if you've got Github Desktop installed, 
click on open with Github Desktop  
and, as you'll see, it brings this up saying: okay 
I'm ready to save this for you, so I click clone,  
so it's making a copy of it. There we go…
So, basically, once you've cloned it,  
you'll then find there's a file in there 
called setup-conda.sh… which, you know, the  
details don't really matter, it's pretty short, 
but, that's the thing that's going to install  
python for you. So at that point you can just run 
“./setup-conda.sh” and it'll run this installer.
Now, if you've got Linux or Mac you've already got 
python on your machine. Don't use that python!!  
And the reason is because that python, it's called 
the system python, it's used by your computer to  
do computery stuff, right? It's actually… it's 
actually needed. You don't want to be messing  
with it, I promise you, like… it's, it always 
leads to disaster, always! You want your own  
development version of python, it's also going 
to make sure you've got the latest version,  
and all the libraries you want, and, by far, the 
best one for you is almost certainly going to be  
these conda based python distributions, so if 
you run setup conda you'll get the one that we  
recommend. And, the one we recommend at the moment 
is something called mambaforge. So basically  
once you run it, you'll find that you've now — 
you close your terminal and reopen it — you'll  
find you've now got one extra command, which is 
called mamba, and mamba lets you install stuff.  
So once you've run it, you'll be 
able to go “mamba install fastai”.
And that's gonna… actually we should probably, 
I should mention this, actually more,  
a bit more detail about how to install it 
correctly. If we go to docs.fast.ai, installing.  
Yeah, okay, we actually want to do “conda install 
-c fastchan fastai”. So let's just copy and paste.  
Oh sorry, not actually… and then, the other thing 
I'll say is, instead of using conda, replace  
conda with mamba because nowadays it's much 
faster. So “mamba install -c fastchan fastai”.  
Now, this is going to install everything 
you need. It's going to install Pytorch,  
it's going to install Numpy, 
it's going to install fastai…  
and so forth, right? And… so 
obviously I've already got it.  
And then the other thing you'll 
want to do is install nbdev,  
so you can do exactly the same thing for 
nbdev. You don't have to, right? It's just  
that… but that'll install Jupyter 
for you, amongst other things.  
And so at that point you can now, you can 
now use Jupyter. And so the way Jupyter works  
is — you can see it over here. This is my… (I'll 
go ahead and close it so we can start again.)  
So basically, to use Jupyter you just type 
“jupyter notebook”, okay? And when you run it,  
it'll say: okay, we're now running a server 
for you, and so if you click on that hyperlink,  
it'll pop up this, okay?, which is exactly what 
you see me use all the time. Okay so, you know,  
that hopefully is enough to kind of get you 
started with python, and with Jupyter Notebook…
The other way people tend to install software 
is using something called pip instead of mamba.  
Pretty much anything you can do with mamba you 
can also do with pip, but if you've got a GPU,  
pip isn't going to install things generally so 
that it works on your GPU, you have to install  
lots of other stuff, which is annoying, so, 
that's why I kind of tell people to use mamba, but  
you can use pip otherwise. Still a little bit of 
red. Please let us know how we can help you again.
Okay so let's see how we’re going with 
our steps. I forgot I had these steps  
here to remind myself. We created a space, 
tick. We created a basic interface, tick.  
Okay we got git setup, we got conda set up, or 
mamba. So mamba and conda are the same thing,  
mamba is just a much faster version and we'll keep 
some notes on the course website because at the  
moment they're actually working on including the 
speed ups from mamba into conda. So at some point  
maybe it'll be fine to use conda again. At the 
moment conda is way too slow, so don't use it.
Okay we've done dogs versus cats no 
problem. Yeah so we could also look  
at pet breeds (well yeah we'll briefly look at 
that.) Okay, we've used an exported learner,  
no problem. We’ve used nbdev, no problem. Oh! 
okay… try the api… alright this is interesting.
So I think we can all agree, hopefully, that 
this is pretty cool that we can provide to  
anybody who wants to use it, for free, a 
real working model, and you know, with gradio  
there's actually, you know, a reasonable amount 
of flexibility, around like how you can make your  
website look, you know, using 
these various different widgets.  
It's not amazingly flexible, but it's 
flexible enough to kind of… it's really  
just for prototyping, right. So gradio has a 
lots of widgets and things that you can use.
The other main platform at the moment that 
HuggingFace Spaces supports is called streamlit.  
streamlit is more flexible, I would say, than 
gradio - not quite as easy to get started with  
but you know, it's kind of that nice in 
between, I guess, so also a very good thing  
you know again mainly for, kind of, building 
prototypes. But at some point you're going to  
want to build more than a prototype. You want 
to build an app, right, and one of the things  
I really like about gradio in HuggingFace 
Spaces is… there's a button down here  
“view the api”. So we can actually create any 
app we want and the key point is that the thing  
that does the actual model predictions for us is 
going to be handled by HuggingFace Spaces Gradio,  
right, and then we can write a Javascript 
application that then talks to that.
Now there's going to be two reactions here … 
Anybody who's done some front-end engineering  
is going to be like, “oh great, I can now 
literally create anything in the world,  
because I just write any code and I can do it and 
they'll be excited.” And a lot of data scientists  
might be going “uh oh… I have no idea how to use 
javascript, it's not in my, you know, inventory.”
So this is again where I'm going to say: 
look, don't be too afraid of Javascript. I  
mean obviously one option here is just to kind of 
say, “hey I've got a model” and throw it over to  
the wall to your mate who does know Javascript and 
say please create a Javascript interface for me.  
But let me just give you a sense of 
how really not hard this actually is.  
So there's a… end point. There's now a 
url that's running with our model on it  
and if you pass it some data… an image… 
some image data… to this… to this url,  
it's going to return back the dictionary. 
So it's going to do exactly the same thing  
that this UI does but as an 
api, as a function we can call.  
And so it's got like, examples here of how 
to call it… so for example, i can actually…  
let me show you the api as an example using 
that minimal interface we had … because it's  
just going to be a bit simpler. So if I click 
curl and I copy that… copy that… and paste.  
So you can see there … (oh that's not a great 
example passing in hello world) …if I pass in  
Tanishq again, let's see how 
I'm going with his name Tanishq.
Here you can see it returns back “Hello 
Tanishq!” So this is how these apis work, right.  
So we can use javascript to call 
the api and we've got some examples.
So I've created a website, and 
here is my website “tinypets”  
and on this website as you can see it's not 
the most amazingly beautiful thing but it's  
a website. It's a start right, and up here I've 
got some examples, here we go, single file, click,  
choose file, click… and in this example I'm 
actually doing full pet classification. So I  
actually trained a model to classify breed, 
which we'll talk about more next week,  
rather than just dog versus cats. So let's 
pick a particular breed… and we run it…
Oh! And there it is! Now not very amazing right, 
but the fact is that this is now a Javascript App  
means we have no restrictions about what we 
can do. And let's take a look at that HTML… 
that's it! It easily fits in a 
screen, right, and the basic steps are  
not crazy, right, it's basically… 
we create an import for our photo,  
we add an event listener that says when you 
change the photo call the read function, the  
read function says create a file reader, read the 
file and when you finished loading, call loaded,  
and then loaded says… fetch 
that… now that path there… is… 
that path there! Right! Except 
we're doing the full pets one.
So this is basically just copied and 
pasted from their… from their sample.  
And then grab the JSON, and then grab from the 
data the first thing… the confidences… the label,  
and then set the HTML. So as you can see it's like 
(okay) if you haven't used javascript before these  
are all new things, right, but they're not… it's 
not harder than python, right, it's just… it's  
just another just another language to learn. And 
so from here you can start to build up, right!
So for example we've created  
a multi-file version. So with the multi-file 
version, let me show you… multi-file… choose…  
so we can now click a few… so we've got a newfie, 
a ragdoll, a basset hound, and some kind of cat.  
I'm not much of a cat person. 
So we chose four files and bang  
they've all been classified! Apparently it's a 
Bengal! (I wouldn't know) Here's our newfoundland.
So there's the multifile version, and if you 
look at the code, it's not much more, right,  
it's now just doing… it's getting all the files 
and mapping them to read, and now appending each  
one, so not much more code at all. And 
as you might have seen on our site here,  
there's a few more examples, which is 
some of the community during the week,  
has created their own versions. So this one 
here is… I think this is… the yeah… this is  
from one of the gradio guys... they called it 
“get to know your pet.” So if i choose a pet… I  
kind of… I really like this because it actually 
combines two models. So first of all it says,  
oh! It's a basset hound, and then it lets me type 
in and ask things about it. So i can see, “oh,  
what kind of tail does it have?...” search, 
and so that's now going to call an NLP model,  
which asks about this… it's a curved saber tail. 
There we go! “What maintenance does it need?”
So again, like here you can kind of see how (oh) a 
basset hound’s ears must be cleaned inside and out  
frequently. So this is like combining models.So 
you can see this is something that you couldn't do  
with just a kind of a… a ready to go interface.
And so the next thing i wanted to point out is  
how did we create the website? I showed you 
how to create an HTML file, but like how do you  
create those, and how do you make a website out 
of them? Well watch this! Let's… here's…. here's….  
here's the source code to our most basic version, 
okay! So i could just save this… there we go…
Okay so we could open that with Visual Studio 
Code… and… what we could actually do is,  
we could… here it just is in explorer or mac 
& finder. I could just double click on it  
and here it is! It's a working app!!
So you can see i don't need any software 
installed on my computer to use a Javascript App,  
right! It's a single file… I just run it 
in a browser… a browser is our complete  
execution environment. It's a got a 
debugger. It's got the whole thing.  
So here you can (yeah) here you can 
see it's… it's just calling out to  
this external hacking faces endpoint, so I 
can do it all sitting here on my computer.
So once I've got my HTML file that's 
working fine on my computer, in VSCode,  
how do I then put it on the web, 
so that other people can use it?  
Again, the whole thing's free. There's a really 
cool thing called github pages, which basically  
will host your website for you. And because it's 
just Javascript, it'll… it'll all work just fine!
The easiest way to create a 
github pages site in my opinion,  
is to use something called fastpages, 
which is a fast.ai thing! And…  
basically all you do… is you 
follow the setup process. 
So first it does it's… let's just go 
through it… so it says generate a copy  
by clicking on this link. So I click the 
link, all right, okay, give it a name…  
(I try to make everything public! I 
always think it's good good practice…  
you don't have to) …create repo,  
generating, okay, and then there's basically two 
more steps, takes about five minutes. We don't  
have five minutes, so I'll show you the one that 
I've already built, which is “fast.ai/tinypets”  
And so once it's done you'll basically end up with 
this empty site which, again, you just go “code”  
“open with github desktop” or “open with visual 
studio” whatever… so “open with github desktop”...  
or you can copy & paste this to your terminal… 
and so any one of those is going to get you this  
whole thing on your computer. You can save your 
HTML files there… push it back up to github.
And what you'll find is we… we've… FastPages 
will show you the link to the website that is  
created for you. Now, the website that's created 
for you, you can make it look however you want  
using something called a “Theme”. So you'll see 
it's created a file called config.yml where you  
can pick a theme. So, in this case, I picked a 
theme called “alembic” for no particular reason.
So Github Pages uses something called “Jekyll”, 
and so any “Jekyll” theme will, will basically  
work. So I picked out this theme, and so, as a 
result, when I now save things into this repo,  
they will automatically appear in this website, 
and the files automatically appear up here  
in this list. So, if you look at my index, that's 
the home page… the entire file is just this,  
right! The only slightly weird thing 
is at the top of every Github Pages  
file, you have to have three dashes, title, 
and layout, and three dashes. It's called  
“front meta”. And so, once you do that… and 
save it, it will appear in your website. So,  
something else I did then, I was like, okay, well… 
that's all very well that fast.ai has created this  
website, but I don't really like what it looks 
like. I want to create a different version.  
No worries. You can go to “fast.ai/tinypets” 
and click “Fork”. And, when you click “Fork”,  
it's going to create your own copy. So I did 
that under my personal account which is jph00.
And look! Now I've got my own version 
of it, and now I can make changes here.  
So I made a few changes. One change I made was: 
I went to config.yml and I changed the theme…  
to “pages-themes/hacker”.  
So once you fork, one thing you have to do, which 
normally FastPages does for you, is you do have to  
go to “Settings”, and click “Pages”, and actually 
enable “Github Pages”. So you basically have to,  
by default, it's turned off, so here you'll just 
have to turn it on. So use the “Master Branch  
Root Save” and then it'll say, “No worries, 
it's ready to be published”. And so I changed  
the config.yml file to point at a different theme. 
And so, if you look at now… the jph's Tiny Pets…  
it's different! Okay? So it's got the same info, 
but it's much more “hackerish” because jph00  
is a serious hacker, as you 
can tell from his website.
So, anyway, look, it's a very brief taste of this 
kind of world of Javascript and websites and so  
forth, but I wanted to give you a sense of, like, 
you know, you don't need any money. You don't need  
any IDEs. You know, you don't really need much 
code to get started with writing your own web  
apps, and, thanks to hugging face spaces, 
you know, they'll even host your model  
for you and all you need to do is just have 
the magic string, as a thing to call. Okay!  
So… signing out: Hacker Jeremy Howard. Thanks 
very much for watching, and, in the next lesson,  
we're going to be digging into some natural 
language processing. We're going to be doing  
some of the same stuff, but we're going to be 
doing it with language rather than pictures.  
And we're going to be diving under the hood 
to see how these models actually work. We're  
going to learn about things like stochastic 
gradient descent, and we might even be having  
to brush off a little bit of calculus. I hope 
I haven't put you off by saying the “C” word.
I will see you next time! Thanks all! Bye!