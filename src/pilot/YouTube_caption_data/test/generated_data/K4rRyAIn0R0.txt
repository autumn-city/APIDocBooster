yes in this video we are going to build
sentiment analysis API using our
pre-trained birth model and we are going
to deploy all of it behind a REST API
using fast API and the server you
Vacarro so let's start with a simple
demo in which we are going to have a
look at what the REST API is gonna be
look like and I'm going to go to this
project of mine this is from the github
repo I'm going to start the project and
now it says it's running I'm going to
open up a new tab I'm going to take a
review from this up tick tick so let's
just hunt for some of the newest reviews
right here and let's get this one so it
has four stars
let's try it
89 and I'm going to send some requests
with the HTTP PI library and our model
says this is the response we have a
confidence we have sentiment which is
positive which is correct and we have
very sorry very high confidence in our
model that this is actually positive
sentiment and let's try with negative
ratings let's try this one
but in here ads so if I put in the text
for this review we are getting a
negative which is great and we have a
very high confidence again if I go to
the three star category and let's try
this one
need some options you need to be more
organized something
so again these states that it is a
neutral statement which is again correct
so let's see how we are going to build
all this I'm going to create this exact
same project from scratch and we are
going to step through everything that is
required to create this rest api so let
me go open up a new tab right here and
cause everything here and here and i'm
going to go to a new directory create a
directory called birth sentiment
analysis okay and now that I'm here I'm
going to start Visual Studio code in
that and increase the font for you guys
so this is completely empty project and
I'm going to go ahead and copy the
contents of the PIP file right here we
are going to use PDF to create the to
specify the dependencies and you can see
that we have black I sort flake a3 down
and we have the most of the packages
that are required for the running the
application is going to are going to be
the first API UV current ID antique
torch and transformers and I'm going to
come come and explain what those are in
just sec so let me go here create a new
file called pip file and I'm going to
paste everything here if you are
wondering what extensions I'm using I'm
at least for this one I'm using the
Python extension which is provided by
Microsoft and I'm using the vim
emulation for Visual Studio code because
I like them
so now that we have the PIP file I'm
going to say that I want to use the 3.8
to version of Python using p.m. vocal
and next I'm going to install the
dependencies including the dev ones
including using pip and so while this is
running let's see what those
dependencies are so first API is a
framework for building api's and most
notably it's they at least they say that
is as fast we add as fast as node.js and
go and what I like about it the most is
that it really has a very simple and
clean API so it's easy to use and yeah
I've been using it for the last couple
of days I have I haven't got any like
real world experience with it but I
think at least for the purposes of this
demo it's a very good framework to
create a fast and simple API so next we
have our server which is the waiting
fast a SGA server and the name of it is
called if you reckon you might be
familiar with the unicorn server so now
you have the UV conserver and basically
this is SGI server which adds or
supports a synchronous programming and
there is a really good example right
here you can use the asynch and await
commands in python so this is really
good in practice but for this demo i'm
not really going to take any advantage
of using the sync and await commands
next we have pedantic or pedantic so
this thing is basically enforcing some
data validation during runtime for you
and I find it really good when for
example you are trying to type in some
things like
your request in your response next I'm
going to show you the reference you are
the reference repo which is provided by
this guy Marteen Marteen man i can't
really pronounce that name but thank you
most of the the project is actually
dependent on his code and another one is
this repo which is fast API and a
QuickStart which is provided by this guy
I think so this is TiVoed our banker
Thank You Man I mean like both of those
repositories have been a great reference
for me to show you how you can deploy
board and I'm pretty much following the
structure of the code that this guy has
well I made some changes to it I'm not
really I don't really agree with the
structure of the project but still this
guy has provided some great reference at
least for me so thanks to you guys okay
we have the dependencies now installed
and I'm going to run the pipe shell so
that we are making sure that the
environment is actually running with the
correct virtual environment okay I'm
going to go to the vs code project and
here I'm going to create a new folder
called bin and here I'm going to define
a script which is going to be download
model the first thing that we need to do
in order to run with everything is to
well you basically might want to just
start with an API but I want to make
sure that I am able to download the
model and I'm going to paste in
the script this basic Python script and
imports G down which we are going to use
to download the pre trained model
weights or the bitten model state from
my personal Google Drive and I'm going
to save the results into assets model
state dick bean so I'm going to go ahead
and create the we can use actually yeah
I'm going to go to the terminal
make the directory assets and I'm going
to allow the bin
downward model to be executable and next
I'm going to run it so this should go
ahead and start downloading our model
okay during this time I'm going to
create a new folder which is going to be
the main folder that we are going to use
to create our source code into and I'm
going to specify that the name of this
is going to be sentiment analyzer so
here I'm going to make a new file called
API doc PI and this will be the the rest
step this is this will contain the rest
API for our model at least and you might
notice that lint repellent is not
enabled and some other stuff might come
up but we are just having these files
these dependencies we have black eye
salt and flake eight so to make
everything work right here I'm going to
go to the project once more and I'm
going to paste to get the the source
code of this iced flag dot eight config
file
and I wanna give a shout-out to my
colleague moon - which basically shared
his configuration files for flake and
black
so thanks monkey and for I sort as well
so this will make sure that the code is
properly formatted and I want to edit
only the settings for this project so
I'm going to create a new folder called
dot vs called and here I'm going to
specify the settings dot JSON so this is
great and I want to copy the vs code
settings from my github repo so this
should give us the proper configs
so this should be working now I'm going
to exit the code editor and run it again
so if I go to the API top I and cause
other directories you can see that we
have the proper virtual environment and
we no longer get the warning for linking
here I'm going to start with a stopped
API so it will just return stopped
response and I'm going to import a fast
API we are going to create an app from
this and I'm going to define a request
handler
and this one is going to take a request
and do something here I'm going to take
an advantage of the pedantic data
validation and you've seen that when I
save this the formatting is
automatically enabled or done for us and
I want to import from pedantic the based
model so we are going to define two
classes that are going to represent the
request and the response for our predict
portion world this will be just the base
model and this will contain a text which
is going to be string so we are going to
take advantage of the Python typing
hints and I'm going to define sentiment
response here we are going to basically
define everything that we have shown you
into our demo so those will be the
probabilities this is going to be a
dictionary and I am going to need to
import that we are going to have a
sentiment which is going to be just a
string which can be sum of negative
neutral and positive and the confidence
which is the probability from our
softmax function from our model and I'm
going to import from typing the dict
type int annotation okay so once this is
saved you can see that again the
formatting is properly applied which is
just amazing so now we are going to use
the request and response models so I'm
going to specify response model here
sentiment response and for the request
I'm going to just say sentiment request
so this will
make the typing for us and here I'm
going to return a stopped version of the
sentiment response so the sentiment for
the this at least version is going to be
neutral the confidence is going to be
high like 99% and the probabilities are
going to be this dictionary using
negative equal to 0.005 neutral is going
to be 0.99 and positive is going to be
0.005 again so we have some error here
but that's okay
so everything should be working now and
I'm going to try out to start our server
and to do that I am going to just create
a new script here which is going to be
named stop server and I'm going to go
and copy and paste the script contents
from my report because every time I am
forgetting about it
so another bash script we have the
server running you become we are going
to the sentiment analyzer then to the
API and we are referencing the up
variable alright let's give this a try
so I'm going to use these two of our
server to run and it says that it's
running here ok I'm going to open up a
new tab and here I'm going to use HTTP
PI I'm going to send a post request to
this URL predict and here I'm going to
specify the text which is going to be
for this purposes a world and you can
see that we are getting our final result
or the response from our stopped API
so this is great and next we are going
to our model to this API so we are going
to predict some really useful segments
adding current model to the project
might seem easy at first but we have to
take into account that Bert is used and
to get predictions from Bert you need to
have some sort of pre-processing done so
for this we are going to create a facade
or some kind of abstraction of the logic
that is required to convert text into a
prediction using Bert and this facade is
going to be using our sentiment
classifier model that will define into
our previous video here we are going to
need to redefine this so let me start
with that I'm going to create a folder
called classifier and here I'm going to
create a file called sentiment
classifier dot PI so here I'm going to
define our model that is based on torch
I'm going to import this and I'm going
to need the birth model here as well
Rico lot into the constructor we were
requiring the number of classes I'm
going to call the super constructor I'm
going to define the birth model and here
we need something to tell us what is the
type of model that we are using and for
that purpose I've went ahead and created
a config file which is basically well
this might have been an earthquake so
into the config file config dot JSON we
are specifying a birth model the
pre-trained model part that we have
downloaded the class names in the mock
sequence land alright so now that we
have the config we are going to use the
JSON right here
library I'm going to open up the file
and store it into a variable
I'm going to get the birth model from
the config I'm going to define a drop
out there and recall that we've used a
probability of 0.3 and we have an output
layer which is just an N linear and in
the number of inputs out of input units
is going to be defined by the config
into the birth model and the output is
going to be the number of classes that
we have so this is great and next we
need to define the forward function
which takes the input IDs and the
attention mask here we are going to call
the birth model
get the poot output run this through our
dropout layer and return the results
from the output layer
all right I'm going to take the output
of the drop off layer and return the
output of this model and next we are
going to continue with the facade for
our sentiment classifier I'm going to
create a new file called model dot pi
and in it I'm going to use the birth
tokenizer and sentiment classifier that
we have but first I'm going to jump
right here and thank take the config
file wadding so this is pretty much
everything we need except that I'm going
to import torch as well and I'm going to
need the functional module from NN as F
so we are going to apply our softmax
function right here okay so let me
define the class and it's just a Python
class here I'm going to start with
defining the device on which the
computation is going to take place and
this will be CUDA
index 0 if toward CUDA is available CUDA
is one else this is going to be just a
CPU okay
so let me fix this I'm going to create a
tokenizer birth tokenizer from three
trains and again I'm going to use the
birth model from the config next I'm
going to create a crossfire instance and
this is going to be the sentiment
classifier and I'm going to need to
import that and this takes the number of
classes which are going to be the length
of the class names that we have and next
I'm going to what the weights for our
model which are already downloaded from
the Google Drive 3 trains model so this
will point to this file right here and
I'm going to specify another parameter
which is map map invocation and I'm
going to map the results from this to
the device that we are using and this is
required because you might have trained
your model on the GPU and then save that
and then you want to make influence on
the CPU or another or another device I
know and then you will need to pass in
the map location so that the data is I
guess properly read from that model
state next I'm going to put the
classifier into evaluation mode because
yeah we are just going to use it for
inference and then I'm going to create a
field for it and move
it to the device itself okay and this
model was have only or has only a single
method which is this called predict and
this will take just a single parameter
called
text so this will be the text of our
review first we need to encode the text
using the tokenizer and I'm going to use
the encode plus method I'm going to pass
in the text I'm going to pass in the max
length here max sequence length I want
to add the special tokens I want to
create Turin token types ID to be set to
false so because we don't really need
those i want to part sequences i want to
return the attention mask and I want to
return by tourists answers okay so I'm
going to take the input IDs from here
I'm going to move those to the device
I'm going to do the same thing for the
attention mask
and I'm going to use torch non grata to
probably speed up the computation a bit
and I'm going to take the probabilities
or the prediction from our model using
self dot classifier I'm going to pass in
the input IDs and tension masks and
recall these are not probabilities so we
have to apply f softmax to the result of
this I am going to apply that along the
first dimension and this pretty much
gives us the prediction from our model
next I'm going to take the most
confident result or sentiment using
touch Max and I'm going to pass in the
probabilities and I want again and I
want this again along the first
dimension so the predicted class is
going to be moved to the CPU and I am
going to take just the item so just the
wrong number and the probabilities I'm
going to remove on next two dimension
that they have and just get a list from
that alright finally I'm going to return
the name of the sentiments using the
config was names and the predicted class
I'm going to also return the confidence
and I'm going to return a dictionary
containing the class names along with
the probabilities or the predictions of
our model so this gives us the complete
model class and you can see that it's
pretty lengthy but this is mostly
because we are required to do a lot of
pre-processing
for our birth model
next I'm going to create a single
instance for a model model and define a
function called get model and I'm
basically doing this because the
initialization of our model is a really
heavy or computationally expensive task
so we are going to use another design
cutter we are going to use the singleton
pattern we are just creating a single
instance of the model and we are going
to use this function called get model to
return that single instance okay so we
have our model and we are ready to put
everything together to do that I'm going
to get back to the API dot PI file and
I'm going to import the model itself and
I'm going to import the get model
function all right but why do we need
the model think well I'm going to use
dependency injection that is provided by
by the first API library and through
that I'm going to need another import
which is depends from the first API
package and right here I'm going to say
that dependencies of the model is going
to be provided by the get model so this
will make sure that the injection of
this parameter model is done by the
function get model now that we have this
I'm going to call model predict and I'm
going to pass in the text of our review
which is taken from the request itself
so this will return the sentiment the
confidence and the probabilities and I'm
going to replace all this dummy data
right here
okay this like it all right so the
formatting has been complete and now we
should have our API let's try that bin
start server so this will just print out
a lot of stuff and it says that it's
walling weights from the hugging face
and then it should be loading the
weights from our own segment analysis
okay so let's go to the Google Play
right let me open up some up so let's
say that we are friends of tick tock and
go to the reviews I'm going to open up
all reviews and I want to get like the
newest reviews so let's get this one
great up with what features can please
up dark mode so let's run this I am
going to paste this and we are getting a
positive sentiment which is just what
you might expect so dishes are correct
one and we have a very high confidence
let's get some rating which is not that
good
[Music]
you can see that most of those reviews
are very very small in terms of words
that the users are typing let's get this
one for example and if I paste this and
it says that it is negative and really
it is and we have a high confidence
again let's try something that is a bit
harder I'm going to take some neutral
review let's take this one from Joshua
so it's again correct and it's really
confident about it
I mean like this is pretty amazing so
now you're ready to deploy your model to
production
well that's complete I mean
like you need a lot more stuff like
monitoring maybe docker you might need
communities you might need some alerting
you might want to have a way which tells
you how your model is doing in
production I mean like get the
predictions then evaluate those
predictions and compare them with the
ground truth data but at least this
project will give you a simple way to
start this whole process and depending
on the type of project that you're
working on you might really go ahead and
just deploy this first API a recipe and
be done with it thanks for watching guys
I hope that you really enjoyed this
video I'm going to link the text
tutorial down into the description along
with the detail people please like share
and subscribe to my channel soon next
one stay safe stay healthy stay strong
bye bye