And we can actually use both on either the  LSTM or the LSTM cell for implementing the character RNN.
So I just have something to keep track of the  hidden size. This is our embedding layer that goes from  the integer, the character integer to the embedding vector,  a real value vector of size, let me see of size 100. And the  hidden dimension is 128. Okay, so we have the embedding size,  and then the LSDM cell takes vectors of size 128, and has a  hidden size of one, sorry, of 100, and has a hidden size of  128.
The vectorize sequence of notes will be input into the first LSTM cell.
Usually, people use LSTM layers in their code. Or they use RNN layers containing LSTMCell.
Obviously, It is easier to apply parallel computing in LSTM.
