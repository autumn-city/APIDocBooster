Okay recording and we are live. Jason 
handing over to you. Oh yeah sure. So  
like Rosanne mentioned we did a project pitch 
day before. It was a similar event to this but  
we asked people to pitch research 
ideas and it was kind of like a pitch  
and a request for collaborators at the same 
time. That pitch day went pretty well, and we  
had a few collaborations come out of that 
and I think one paper about to be submitted.  
But we kind of heard some feedback from people 
that people wanted not only to pitch ideas but  
once a project gets started to be able to 
share updates with people to say like hey  
i made these plots and I got some results, what 
do you guys think. So this event is now sort of  
aiming to be a mixture of "I have an idea" — 
here's a big idea anyone want to work with me,  
and also "I made some plots" — I ran some 
experiments i got some results does anyone  
think they're cool maybe does anyone want to 
work with me too or maybe you're just working  
by yourself you just want an audience for your 
work and some feedback. So it's a little bit more  
generic. So the overall format for today there's 
going to be 11 presentations we had one person  
cancel last minute so 11. We'll all be in zoom 
at the beginning we'll see the presentations  
and then at the end we'll switch to discord where 
we'll have individual rooms for each presenter so  
if you want to talk to a presenter you can do so 
in discord and have a more extended conversation.  
Because we have 11 people the time is pretty 
tight so we have to be pretty strict about timing  
so each presentation will get five minutes 
and 30 seconds. So at five minutes i'll be  
timing at five minutes i'll draw on the screen 
30 seconds using a little pen annotator thing  
so you'll know that like you should kind of wrap 
up soon. Questions are gonna be a little tricky  
because we don't have too much time so if for 
some reason you give a two and a half minute  
presentation and you have a ton of time left 
you can do questions interactively with people.  
If say you end at five minutes you have 30 seconds 
left we will ask for any questions in the chat so  
if you have questions and you're in the audience 
please place them in the chat and maybe if you  
have time you can answer one of the questions 
from the chat. If you kind of hit the whole time  
at 5:30 then we will just ask people to meet 
up in discord after and that'll be nice because  
then there's no time pressure. All right so right 
before we get started just going to do the "how  
you can be involved" bit. So if you like MLC 
ML Collective and you want to be more involved  
there's a few routes to being more involved. You 
can join our reading group which is every Friday  
linked on the website. You can follow us on 
twitter so that you'll hear about events like  
this. You can join the open collaborators group on 
discord which is where we'll all be heading later  
and if you'd like you can present 
something at our next research jam.  
This would normally be in something like six to 
eight weeks but because of the neurips deadline  
we're bumping it to nine weeks so June 2nd 
it's the week after the neurips deadline  
and there's already a page for it it's the same 
url except for a 2 at the end so research-jam-2.  
If you want to present there let us know 
submit something via that google form and we'll  
add you to the schedule. All right let's get 
started so the first speaker we have is Lucia.  
Lucia if you want to share screen and start 
whenever you're ready and then for the other  
speakers just try to be ready when it's your turn 
so we don't lose too much time in the gaps. If you  
want to chat about anything or any questions 
feel free to type in the chat the whole time.
perfect all right feel free to take it away Lucia
okay i will need to sorry 
stop sharing for a second  
and then i'll do present presenter view and 
then i need to share again sure so this will be
actually
this is can you see well yes perfect excellent 
so this is our project it's called escher goes ml  
and it's completing the print gallery with image 
inpainting this is a project of machine learning  
applied to art so here you can see this 
is escher's work it's called print gallery  
and it's a lithography that escher made in 1956 
and he left the center blank for unknown reasons  
the painting is a great combination of art with 
mathematics our aim is to use machine learning  
to complete the center the value that we see on 
this is research on inpainting and researching  
machine learning applied to art so a little bit of 
background why this is new what we are proposing  
there has been some previous research done on 
the painting 10 years ago by dutch mathematicians  
as you can see by comparing the original print 
the original print gallery on the left with the  
completed version here on the right you can see 
that they replicated a similar version of the  
painting but the people who worked before on this 
they were not actually able to complete the real  
print gallery and because they tried to use a 
single formula to fit the entire painting and  
there is not a single formula that can match 
the painting very well and here in colors  
you can see where both the solution that they 
propose and the original print gallery diverges  
so what we are proposing is to tackle this as a 
two-stage problem the interesting thing with this  
painting is that there is a mathematical structure 
behind print gallery so we are trying to unveil  
this mathematical pattern and then the second 
stage will be to apply machine learning  
respecting the pattern so first let's see what 
is the mathematical structure  
behind the painting so here you have an 
animation of what we call a Droste effect  
this is when a picture repeats itself in the 
middle here we have placed the repetition  
of the painting itself inside the middle to 
recreate the Droste effect that is happening  
behind the painting as you can see the final 
repetition in the center is very very small  
in fact it is rotated by 160 degrees and is 
about 10 20 times smaller than the original size  
up to here we didn't apply machine learning 
so this is just the math structure behind the  
painting now we will see what is left the black 
and the white areas appear because when we repeat  
the picture itself in the center with a square you 
cannot fill in a circle so there are areas that we  
need to fill in beyond the mathematical structure 
and this is exactly where machine learning comes  
to play and the task we have at hand that we are 
presenting to the machine learning collective  
and looking for collaborators is how to create an 
algorithm that will learn how to paint like Escher  
in this particular painting in this 
way we need an algorithm that does  
art reconstruction in print gallery so this is 
a problem of image in painting how to generate  
an algorithm that will paint like Ecsher exactly 
in print gallery and what are some ideas to fill  
in the missing content that is the whole between 
the painting and the Droste patch in the middle  
so the preliminary idea that we have it's to use imaging painting which is like  
an active area of research and one of the 
best models so far is OpenAI's image GPT  
that it uses pre-trained models to generate 
a plausible an array of possible content to
fill in the unfinished image another state 
of the art model is taming transformers which  
supersedes image gpt so these are 
pre-trained models however you can  
do a layering of customized training on them and 
we plan to make a layer of training on them  
using fine-tuned models that fine-tune pictures 
that we're going to Escherize so we apply style  
transfer to Escherize other paintings 
and to content that mimics what it's already  
on the painting so for example hardboards art 
boat we Escherize and with this we train  
an image in painting model so we find that this 
will be exciting because it's a worthy opponent  
it exceeds the current state-of-the-art image in 
painting it is a major contribution to machine  
learning and art reconstruction and it's a great 
potential for scientific outreach since it brings  
machine learning closer to people's interest this 
is the team this is us and then there is the  
bibliography for people to to read and this is 
our presentation thank you very much for listening  
perfect timing thanks perfect uh i guess we 
don't have time for questions so we should go  
to the next one okay next we have Joaquín i 
learned how to pronounce ten minutes ago please  
okay thank you rosanne thank you everyone for listening so my name is Joaquín Cabezas  
i'm a phd student at the university rovira virgili in spain and today i want to discuss about
one of the things of explainability 
explainability is very very big i don't  
want to address the whole field but today we 
are looking at the at the particular problem of  
attribution which means getting to know which 
parts of the of the input data are responsible  
of the prediction of the output of the models for 
example this is a very famous example of using  
graph neural networks from uber eats and it's a 
it's a node classification we want to classify  
this node and use it in a recommend engine okay 
so a the idea of explainability here would be to  
know what parts of these of this graph is uber 
using so for example if they recommend a burger we  
can ask why okay and this answer would 
be because the the the the person wants to  
eat lots of carbohydrates like pizza doughnuts 
and so on and that will be a good point to  
to to get to know if that is the the proper 
situation so maybe for example in this  
case you should a propose a salad to to balance a 
little bit diet so one of the tools that we have  
is GNN explainer it's quite recent 2019 and it's 
quite the de facto standard most of the papers  
cite this and well using a information 
theory approach what they want to
obtain for this attribution problem is a subset of 
the edges and a subset of the features and to say  
okay this part of the graph is really the the part 
that is important for the for the prediction okay  
for the output of the model and luckily 
there is an implementation of GNN explainer in  
pytorch so if we like open our notebook we import 
the python geometric and we deal a little bit with  
the cuda libraries we are able to to execute the 
the example the example is using cora data set but  
this is the issue if we execute it okay this is 
the result this is the subset of the of the edges  
that are relevant we forget about the features for 
for this presentation but if we execute it again  
okay we see that there are differences okay 
these edges from 306 are no longer  
relevant so i wonder okay this is some bug this 
is a problem and then i executed 100 times and  
what we found is that sometimes it is relevant 
sometimes it is not relevant this table  
behavior is not what i was looking for so 
digging a little bit into the code i  
found a a fixed parameter okay so there is a fixed 
parameter that it is not working when the when the  
explanation when the neighborhood is small so if 
we have lots of of nodes connected to the to the  
node that we are explaining it works for example 
100 but if we have only 20 you see this component  
this green component that is in in charge of 
reducing the number of edges it is not working  
so the optimizer adam is not taking it into 
account so i think my guess here is that the  
they are using a fixed parameter because in 
the paper the original paper the distribution  
is around 100 so it works for most of the 
of the situations but in this cora data set  
that is the example for the pytorch implementation 
you see here the distribution is a scale free this  
is a the typical citation data set so it 
is not working so my proposal was to use  
a variable coefficient that depends on the number 
of nodes and we are able to reduce this proportion  
of best stability but and that's and now that 
was the i i made something i made a thing and now  
i have an idea my idea is okay there is a bias 
here because uh the the bigger the neighborhood  
we have more edges that are always irrelevant so 
uh if we have so like 10 edges that are vestable  
and then we have 90 or 100 edges that are always 
irrelevant my my metric of stability is going to  
be quite high it's going to be good so i will be 
happy but that's not the reality so my proposal is  
to to define a new metric for this stability 
uh so to avoid this bias and this is what we  
want to discuss in the research jam number two 
so i will leave this like an introduction i  
uh i want to to know if people are working 
similar things or they have ideas i will  
use three different sets of uh of edges i will 
propose some ideas with the with the candidate  
metrics like entropy or or looking at the variance 
and also if someone uh is interested but he or she  
found another research exam that is better these 
are my my contact a info so thank you very much
thank you all of our speakers on by the way 
will be holding a voice channel on discord so  
you can enter your channel and chat with 
them and jam with them about their ideas  
so you guys are perfect time managers all within 
five minutes so next one up is austin because our  
original number three canceled four is up austin 
if you wanna share your screen yeah let me see  
okay all right so um thanks for having me 
i'm gonna talk about hass torch which is  
the library for functional programming for 
neural networks and uh tensor computation  
um so what haskell is working with a collaborator 
set of developers here for a couple years now  
um bringing capabilities of pry torch which i 
think most people are familiar with to the haskell  
programming language and we build on top of the 
c plus plus core of pi torch with gpu support  
10 support support automatic differentiation so 
that that sort of core capability bringing it to  
a new programming language you might say you know 
why would we want to do this you know the whole  
ecosystem for machine learning is in python and 
that may be where you're most productive as a  
researcher and i think that's probably the 
the right thing for for for many researchers  
but i also think that you know the tools 
that we use influence the directions we  
uh take in research and there are some questions 
that i think we don't even ask sometimes because  
we're starting from a certain starting point from 
with our tools and when we start with a different  
programming language such as has torch haskell we 
have a different initial condition from which to  
explore and so what is it that we can explore 
in in a programming language like haskell um  
for this i need to say a little bit about sort 
of haskell's programming language so haskell  
is not that well known in the machine learning 
community but it is very widely used for  
programming language research and it's where 
kind of new ideas for programming languages  
are often born and later find their way to 
python c plus rus standards it is a type  
programming language which means that it models 
relationships in your data using a type system  
for people that are using python maybe you think 
of types as being very verbose in java or c  
plus but you know part of the benefit of haskell 
is from this programming language research we  
found ways of making types very expressive and not 
verbose the third kind of aspect to be aware of is  
this aspect of functional programming and that's 
a programming language where function composition  
is a core building block for writing programs 
and there's a deep connection between function  
composition and functional programming and how 
we think about building neural networks in fact  
um there's if you're interested in diving deeper 
into this there's a great blog post by chris ola  
about neural networks types and functional 
programming that i highly recommend  
so what are some of the things that people 
play with and what are some of these different  
directions that people explore and has torch one 
area that seems to be popular for a lot of people  
that are actively involved is program synthesis 
so here on the top right um kiara had a uh an  
europe's paper um and you know one reason people 
are finding program synthesis interesting is that  
haskell's type system can represent programs uh 
can be used to implement compilers in a very um  
um robust way and you can combine sort of 
that ability to write compilers implement new  
languages with sort of um synthesis capabilities 
of neural networks the second uh area here on  
the bottom right is a demo by torsten showing 
how because the compiler knows more about your  
model and knows more about your neural network 
it can give you hints and this is almost sort of  
like a next generation way of interacting with the 
neural network where the compiler could tell you  
oh you have a shape error here here's something 
you need to fill in to implement even before  
you run the program and um so it's really cool 
to kind of see these integrations help sort of  
user interfaces with visual studio code so this 
is just a sampling of some things that sort of uh  
people are exploring working on so uh juneji is 
updating we piggyback on all the pi torch updates  
so with the 1.8 update we updated hashtorch as 
well uh torsten's exploring implementations of  
transformers using type systems and what can 
you do with kind of uh type neural networks  
um and another thing here is that it raises uh 
google summer code we're looking at projects  
there so if anyone's interested in exploring 
potential google support code opportunities um  
definitely get in touch and um so i just want to 
end with a pointer to you know storage.org github  
repo here if you're interested we have active 
slack we're always looking for new collaborators  
um whether you're someone from machine learning 
interested in functional programming or  
you know a little bit of both and sort of 
interested in the space happy to get in touch
so uh thank you
how much time do you have jason
sorry my computer is frozen uh we have we 
have a minute left so if anyone has a question  
uh they'd like to ask
um the chat there was just one question for me so 
that that question that paper about um suggesting  
hints do the hints depend on the trained network 
or only on like the structure of the network uh  
yeah yeah so uh yeah yeah i think there's a little 
bit of an echo but um it understands the shape  
of the neural network before you do any training 
i've got a question if there's enough time in that  
minute um what was the most unexpected thing you 
learned from taking neural networks into haskell  
unexpected um uh well maybe with the most 
unexpected probably that there would be so many  
other people that were interested in it i mean 
when they started was just kind of a niche thing  
um yeah this really kind of 
pleasantly surprised how many  
people sort of some of these ideas resonated with
there are some challenges too we should talk about 
challenges maybe in the in the session afterwards  
happy to talk about that resource management 
is probably one of the biggest challenges for  
something like this cool you're welcome to join 
austin's voice channel on discord after this uh  
next up we have charles martin okay great i should 
share my screen sure okay give me a second here
okay i think we just built this from scratch
okay um give me a second i'm just not graded 
screen shares uh can you guys see my screen
um it's not free but it's okay it's 
not full screen i'm sorry give me uh  
is that better a bit better yeah yeah 
yeah i'm sorry yeah okay i'm sorry i i um  
i thought i didn't know who was going to 
share this slide i'll just go from here okay  
okay so um i want to talk about a project 
i've been doing in collaboration with  
michael mahoney at uc berkeley in our research 
into the statistical mechanics of neural networks  
and it's a tool an open source tool called weight 
watcher and it's a diagnostic tool for analyzing  
deep neural networks it's written in python you 
can install it with pip install weight watcher and  
we've uh built this tool to try to get the 
research out to the community and provide  
get some feedback from you so the idea 
is that the weight watcher tool allows  
you to analyze pre-trained pi torch and keras 
models so you can you can load a model in you  
can inspect models that are difficult to train 
you can gauge improvements in model performance  
you can predict what's one of the things that 
allows you is to predict the test accuracy across  
different kinds of models without having access 
to the test data so or even access the training  
data just by analyzing the weight matrices of 
the neural network you can predict pins and you  
can predict trends and the test accuracies 
of their models and this works for both um  
both in terms of adjusting hyper parameters or 
in say changing the architecture and you can also  
detect potential problems for example you can 
detect problems when you're doing compressing  
models or in fine tuning and the work is based 
on joint research done uh into why deep learning  
works using ideas from random matrix theory um 
statistical mechanics and strongly correlated  
systems which is really my background so the 
idea here is that i'm sorry it's a little too 400  
that's better the idea here is that um 
the the tool treats each matrix each layer  
as an individual it analyzes each individual 
layer and it looks at the spectral density in  
other words it computes the singular values of the 
eigenvalues for each layer for each layer weight  
matrix or each tensor slice and then it puts them 
on a loglog scale and it tries to fit them and the  
idea here is that you're looking at the shape 
of the neural network and the excuse me you're  
looking at the shape of the correlations the 
shape of the spectral density and i i think what's  
different between what you usually see in machine 
learning research versus physical mechanics and  
machine learning research you know statistical 
learning theory you're looking at the scale  
you know you're trying to create bounds and you're 
trying to find balance to get better regularizers  
in statistical mechanics you don't do that this 
one can actually look at the shape you look at the  
face base volume so the shape of the correlations 
actually tells you a lot of information about the  
neural network and in particular is a tail this 
region out here the tail of these correlations  
actually contains most of the informative 
components and so what weight watcher does  
is it computes the spectral density for each 
layer or each slice in some way then it fits  
into a power law and it uses those parallel 
metrics to tell you something about how your  
model is performing so the tool works simply by 
you know you import it you give it a model you can  
it will generate plots for you you can you give it 
some pre-trained model it will give you a summary  
statistics or it will give this i'm sorry 
this should say details it gives you details  
which are a data frame consisting of 
various metrics it computes for each layer  
or it can give you summary statistics which will 
give you you know average metrics so for example  
uh we you can compute like the average for genius 
norm might be a typical thing people look like or  
like the average spectral norm of a model would 
be something you might do in statistical learning  
theory in statistical mechanics you might look 
at something like the average alpha which is the  
average parallel exponent or the average amount 
of correlation in each layer or this weighted  
alpha so this is what the tool does um it's very 
easy to use and you can get these metrics out  
let me give you some examples of how you 
can use it i'm going to go a little smaller  
so one thing you can do is layer by layer 
analysis so for example here we can compare  
looking at the parallel exponents 
so somewhere between 2 and 12 is  
this parallel exponent for each layer you 
can compare models like gpt versus gpt2  
and you can see that in the in the later 
model gpt2 the parallel exponents get smaller  
they concentrate at a smaller at a smaller 
uh average by about 3.5 versus say four  
and you have less outliers you have less 
these very very large parallel exponents  
so this is a good example of how you can compare 
two models to see if one is poorly trained versus  
and determine whether your models are poorly 
trained or well trained here's an example we  
did talking with the group at intel looking at 
some of their compression algorithms and here  
we're looking for particular example using the 
intel distiller group regularization technique  
and you can see scale change so for example 
this is the baseline model they use and the red  
represents the model they compressed using their 
technique um and what you can see is we can detect  
potential problems these red and green dots should 
basically all line up to each other and when you  
plot say the spectral norm for each layer you see 
that certain class of layer something goes wrong  
and the spectral norm gets larger than it should 
be so you can see these kinds of scale changes  
the other thing you can do with the the tool 
is you can present say the average alpha or  
the average parallel exponent for each for a 
series of models so here we have an example where  
we're looking at a variety of models of different 
depths and we're varying a variety of different  
hyper parameters and you can see that our 
average alpha metric correlates very well  
with various hyper parameter changes uh once again 
this is being done without looking at the test  
or the training data so we can actually 
predict trends in neural networks uh deep  
you know pre-trained models simply by looking at 
the weight matrices themselves so we have a number  
of metrics like this that can do this and this is 
what the tool does and i just want to present this  
to you and give you a chance to ask questions 
and see if i can convince you to try it out
amazing are we going to be 
presenting i have a few questions but  
i'll wait i can't feel the discord to ask them 
okay okay let me um do i stop sharing is that  
that one i'm supposed to do here yes um oh yeah i 
think i did stop didn't i or am i still i'm sorry  
give me a second i've got to find the uh the um 
here it is great thank you thank you very much  
thank you beautiful um next up we 
have martin yes excuse me thank you  
let me get my screen up here um so my topic is 
on applying machine learning techniques adapted  
from metagenomics to determine whether dissipation 
driven adaptation is occurring in computer media  
so i have to provide a little background 
here genetic code is a symbolic logic media  
scientists tell us that dissipation driven 
adaptation occurs spontaneously when free  
energy flows through a symbolic logic media over a 
sustained period of time the first symbolic logic  
media on early earth were amino acid networks in 
liquid water driven by free energy flowing from  
geothermal sources and from the sun amino acid 
networks underwent dissipation driven adaptation  
and evolved over the course of approximately one 
billion years into rna dna and cellular light  
so systems undergoing dissipation driven 
adaptation are characterized by the following  
um description the rate of flow of energy 
through the system increases over time  
order and energy are stored in symbol groups 
in the symbolic logic media evolution favors  
symbol groups which reproduce faster and or which 
reproduce more parsimoniously and then lastly well  
it's not lastly but most importantly as order 
within the system increases the system exhausts  
disorder metagenomics and i hope some of 
you perhaps do ml for metagenomic projects  
metagenomic analysis performs the following it 
bends genetic code into contiguous code groups it  
maps sub components of the genetic code groups to 
logical functions performed by the subcomponents  
and then it identifies sequences of logical 
functions which can reproduce a code group  
or in other words have positive feedback with 
reproducing themselves and more of the symbolic  
logic media if you were an astrobiologist or a 
biologist interested in the development of life  
on earth and if you could go back in time to be to 
before the development of cellular life you would  
adapt the analytic techniques of metagenomics to 
chart the transition from brittle narrow purpose  
relatively inefficient amino acid networks to 
resilient general purpose relatively efficient  
dna and cellular life now i'm getting 
closer to the point here computer media is  
also a symbolic logic media a huge amount of 
energy is now flowing through computer media  
according to theories advanced 
by jeremy england and others
dissipation driven adaptation should 
occur in computer media spontaneously  
without us even intending to create it so 
rather than being concerned about artificial  
intelligence which is notoriously difficult 
to define and highly anthropomorphic we should  
use techniques from biology to measure 
whether dissipation driven adaptation  
is spontaneously developing in computer 
media as a byproduct of our behavior
so i'm getting even closer to the ask here
i would like i am asking for people to 
work on a machine learning open source  
tracing and event logging service which reports 
back to a public forum use machine learning  
to standardize identification of code groups 
across projects this is a problem already in  
tracing and event logging it's the 
standardization of the code groups  
that you're trying to probe using machine learning 
to instrument some of the code groups with probes  
then over time use machine learning 
to identify in public code groups and  
logical function interactions which exhibit 
positive feedback reproducing code groups  
and more computer media so i'm hoping that 
some of you out there you either work on  
instrumenting code for tracing or event logging 
or you've worked with metagenomic projects  
and i'm saying we could do a open source tracing 
and event logging service but instead of reporting  
back to an individual it's reporting back 
to a group and we look at it over time
i can't see the side of the 
screen so perhaps i run over time
you're fine you're right at four minutes 
fifty so maybe if anyone has one question
or i guess we can stick with uh some are asked 
what is the meaning of the flow of free energy  
here the flow of free energy is um an energy 
um and free energy is a defined term in physics  
and the energy is flowing through the symbolic 
logic media on early earth the example was  
geothermal sources pushing out hot water  
through the amino acids so there are geothermal 
sources of energy and electromagnetic radiation  
from the sun but the specific form in which 
the free energy comes is not important
interesting thanks for presenting that's 
great thank you those who are interested  
um please join martin in his voice 
channel or virtual realm later  
so next up we have casper okay 
can you hear me well great  
and can you see my screen yes that's great so hi 
everyone i'm conspired from warsaw university of  
technology and i would like to show you part of my 
phd project that i'm currently working on and the  
project itself is funded by microsoft research 
so the topic itself is about controlling human  
animation with trajectories and i will explain 
in a minute what the trajectory actually is
so currently when we approach animating a human 
we have the following problems firstly we have  
to create a model 3d model of a human a skeleton 
or whatever the process itself is at this point  
already time consuming of course we can download 
an asset from for example android engine asset  
store or something like that where we have already 
3d models but still we have to adapt this model  
and the second thing is that if we want to create 
an animation of the human we have you know as you  
can see in the video we have to move all these 
joints manually frame by frame move them in a  
particular motion and the problem is that creating 
a realistic motion itself is a very difficult task  
and if you can imagine by looking at games like 
cyberpunk or assassin's creed these animations  
can be sometimes junky or br can break entirely 
so what i proposed during my project is that  
if you assume that we have a particular initial 
pose a frame uh we can put it into the network  
together with some trajectories and this 
trajectories right now are described as
motions in time of a particular joint so 
you can decide how a particular joint should  
move for example a hand or palm or something 
like that through time so you have two inputs  
an initial post trajectories and you leave 
it to the network to generate an animation  
and realize the generation and you leave it to 
the network during the training so it learns  
realistic motions so does it work and yeah it 
works quite well if you put multiple trajectories  
and you can see from these visualizations that 
providing more and more trajectories create more  
like stiff animation where the body 
follows the particular trajectory  
and you can provide your own trajectories 
where for example you want a character to  
stand in a single place like in this 
last column on the of the second row
but i started this project quite differently like 
three months ago i wanted to move with videos  
because videos are abandoned in the internet 
but controlling them is very good there are  
of course different gun models but they don't 
allow you to control the video uh to put some  
trajectories some you know attributes that are 
quite explicit about what you want to achieve  
and you know my model can essentially generalize  
at this point to other skeletons like the 
full 3d body model and also images and videos
but existing approaches
rely on a paradigm of post transfer like in 
everybody dance network or first order motion  
model for image animation and there are several 
issues with these methods first thing is that  
you can't control these animations in the first 
place per se you have to have a driving video  
that presents some animation in the first place 
and then you can apply to your target video  
where you can generate that animation but what i 
would like to achieve is that you have and just a  
single frame of a person you draw a trajectory for 
example that corresponds to a particular key point  
for example you know mouth nose eyes and then you 
leave it to the network to generate this animation  
and the problem was that why i moved to skeletons 
if i started from videos because the problem with  
skeletons was a bit easier and i'm looking 
for collaboration additional people that i  
would like to work with on that firstly to you 
know to have more hands to work on that problem  
the second to brainstorm because the problem 
is you know still still hidden from other  
researchers i mean that no one tries to 
tackle the explicit control in animation
and yeah jason thank you for your attention 
and yeah i'm happy to talk to you afterwards  
perfect thanks so much that 
was great um i think we're  
a little tight on time so we 
should take questions um in discord  
okay um then we have uh carson who's up 
next uh can you see my screen no not yet um
how about now no still not it
yes great okay hi my name is carson 
this is external neural memory chatbots  
so the goal is this i want to teach an agent to 
be able to embed a concept so in this case my  
name and know when to capture that concept i mean 
to be able to store it and then also know when to  
retrieve that and then use it appropriately the 
reality is more like this though usually if you  
have a neural network that's trained on a dialog 
system usually it produces very grammatically  
correct responses and usually contextually very 
on point as well for example here it seems to  
know that i'm talking about a dog but it doesn't 
seem to understand that i'm trying to get it to  
learn or memorize the name of the dog and also 
to tell it back to me at the appropriate time  
um so you could probably come up with a couple 
solutions to this that are straightforward you  
know the simplest being just appending you know 
previous time steps to your input um you can carry  
forward the hidden states like an lstm in fact 
i'm aware of certain uh efforts to bestow lstm  
light qualities to transformers essentially get 
information that's used for previous predictions  
to kind of stick around for a bit longer and 
but i want to point to type of research that's  
very much related but i think pointed at a 
somewhat different goal which is that they would  
like to create a memory module that is decoupled 
from the working memory so essentially protect  
protected from unrelated current computations so 
so-called external memory um one piece of work  
that i think aimed directly at this goal was this 
work by uh deep mind called differentiable neural  
computers um related to the neural turing machine 
essentially they model memory as being a matrix  
and to read from this memory you're essentially 
doing a soft detention mechanism um and grabbing  
out a row that way very similar to the one that 
you would have in the neural machine translation  
and to write to memory uh you would essentially 
replace a row or append another row to this uh  
to this to this memory it's pretty complicated 
uh piece of machinery is very hard to implement  
for me there was another mechanism that was 
attractively much more simple in streamlines  
which is um by mondelight here essentially when 
you query your your own memory you provide it  
with the key vector and it gets pushed it's 
the input to the neural network and the  
output of the neural network essentially the 
value vector or the retrieved memory essentially  
uh so that's how you would read from 
memory how would you write for memory  
so as you're having this conversation with 
me right now it would be very inconvenient  
for you to have to run gradient descent steps mid 
conversation in order to just to memorize my name  
correctly so montgolai implemented this uh 
perceptron learning rule whereby at the time  
at test time you have to predict a learning 
rate b and you have to predict the preferred  
activations at every layer of the neural network 
that's z prime and once you have those things you  
can with the immediate update step um uh bind the 
the the uh the key to the value vector essentially  
and so the meta learning task here is to 
correctly produce b and and z prime at test time  
um so what i did was i uh modified a trend 
a transformer type of chatbot um and uh i  
used this uh memory external memory network to 
be its external memory source the transformer is  
a vanilla transformer the decoder portion of it 
at least that's modified to go from a sequence  
to map a sequence to a query vector and to a 
memory vector and also to map a memory vector  
a retrieved memory vector and a seek input 
sequence to an output sequence so essentially  
that way you can it can actually speak to you 
um so you know as a kind of sanity check um  
you know as a way to monitor the output this is 
just a very simple task very short term but um  
should work only if the memory system is working 
the way you think it would um so in here your your  
the the thing it's learning to embed or bind is 
a name and it's it's returning that betting at  
the appropriate time in the perf in in the right 
conversational sequence um so yeah i'm looking  
for scientists and mentors to join my team um you 
know people to bounce ideas off of and and hold me  
accountable um uh we have a couple other people 
but you know we all have full-time jobs this is  
more of like a kind of an artistic endeavor for 
me um so uh you please reach out say just say hi  
on twitter email me find me on linkedin and that's 
it thank you so much for listening appreciate it
perfect timing uh 35 seconds 
left anyone have one question  
i didn't see anything particular in the 
chat so you just want to ask carson directly
could you frame this as like a multi-task with 
like a qa task against the memory at the same  
time you're training conversation tasks explored 
something like that uh so essentially to train it  
for conversation but to respond correctly well 
i guess uh question answering well for question  
answering like there's one input you read the 
input and then you respond correctly and then  
i guess i'm trying to what i'm trying to do here 
is to to have several turns and then like have it  
remember things from several turns back before 
i don't think yeah i mean maybe you can talk  
more on the discord yeah i'd love to yeah i'll 
contact you on twitter do you have your dms closed  
oh okay thank you for letting 
me know i'll i'll open that up  
all right thanks thanks for 
presenting it was great thank you  
uh next up of emily if you're ready 
to share your screen okay so um  
this is a talk about mass language modeling for 
youtube captioning errors and first a warning um  
that this is both stale and a work in progress 
um i did this uh work about um end of last year  
while i was on a month-long sabbatical um and my 
name is emily i'm a machine learning engineer at  
facebook um but this is just my work for fun good 
advance um so the motivation is i don't know if  
you're anything like me advanced please thanks 
and you are a multimodal junkie you may notice um  
sometimes your flow gets interrupted when you come 
across um youtube caption errors like the one here  
where we all know that jeremy howard is not 
talking about stupid or notebooks he's talking  
about jupiter notebooks and you know come on 
youtube you're doing a fantastic job most of  
the time please know that jeremy howard will never 
be saying we'll never say the phrase stupid or uh  
advanced please or will he here four minutes later 
in the same lecture he mentions uh that students  
should not be discouraged if they think they are 
too stupid or don't have enough fast resources so  
advance please thank you perfect so clearly um you 
can't just copy and paste this type of problem um  
why not use something like uh a mask um a masked 
language model um to correct it um so here uh  
yeah so sorry so let me go just explain a little 
bit what the mass language model is so um i think  
it's people may be familiar with that it's more 
traditionally used um uh for pre-training large  
models such as burt um and it enables uh the 
model to learn a bidirectional representation of  
the word because it can use the context around 
the mass phrase to understand a suitable word  
uh however it may not be the exact word um because 
you know of course many many words could fill in  
um the one that has been masked um so subsequently 
it's uh there's often um pre-training that's done  
uh uh yeah fine for sorry fine-tuning that's done 
and resent you're just a little bit ahead of me  
um or jason um the cool things okay so um so so so 
it also is often done uh on self-supervised uh uh  
tasks where you know we have a huge language 
corpus and you mask whatever word you want  
here we have a specific word we want masked 
and we need a label you can change and luckily  
the label is provided so jeremy as well as 
many other creators and their followers have  
corrected youtube's uh captioning mistakes um 
and as you can see you could select that as well  
as they've done this in many other languages 
so here we have a data set you can advance  
um thank you so so i uh wrote a script to query at 
the channel granularity all of the videos that my  
favorite creators have put into playlists so i'm 
just searching playlists kind of hoping that i'm  
getting content that they have intended to be 
shared and not that they're using youtube for  
some other purpose um so the content they've 
organized into a playlist i checked each video  
on the playlist and i checked to see if we 
have an auto caption as well as a corrected  
caption if so i download all of that and i 
put it here and you can advance um you can  
click click if you want cool great and then i 
use diff tools basically stanford standard python  
library diff tools to create a difference between 
the two uh sequences of tokens you can advance  
and thank you and um you can download it 
as well and you can add your own libraries  
um i'm not super good with colab like downloading 
it to my drive and whatnot so if you actually try  
this linkedcollab it it's not going to actually 
download it to your own personal folder it'll  
you know download it to your collab memory and 
then you can download it you know you can use  
google drive or whatever to get it onto your hard 
disk but um but basically you just clone the repo  
you install the pip install these two libraries 
uh you click on the config file here you change  
in the repo that you've downloaded you change 
the developer key you put in the channel name  
of you know the channel you're interested in in 
this case it's actually jeremy howard not fast ai  
and then it just makes sure you know 
the script kind of checks to make sure  
it got the correct channel for you if so 
you click go and it'll download all of  
the raw transcripts as well as the labeling 
that's provided by diff tools and you know  
there's a fair bit of um a little additional work 
that has to go into that so you can do next slide
uh great thank you so we can revisit 
the error from before and you could see  
um that there's uh the data set includes a common 
to both sequence so you could that's the middle  
line you can read this thing for free as and then 
we see what was auto generated stupid or notebooks  
and we see the manual correction we see it three 
times jupiter notebooks jupiter notebooks jupiter  
notebooks so we see it three times because 
we have three tokens that were replaced uh  
with one correction and that two in the in 
the in the final column is because um there's  
two additional insertions so later you can go 
back so this whole thing is is non-destructive  
so in creating all these data sets you could 
always go back and and i provided the functions  
to then regenerate the original sequences 
both the auto-gen oh man okay so so um so  
and you'll notice here that there's an interesting 
mistake which was the jupiter stupider but it's  
also the uninteresting one was the which was 
the punctuation so advanced please um so i also  
added the data set to hugging face you can get it 
there advanced um and then i used it uh and this  
is just actually thanks to roseanne thanks to you 
guys because i put the data set up and i wanted  
to use it but i finally did to create a simple 
model so you can download the data set yourself  
from hugging face advance please um i did token 
classification with it basically just hugging  
faces trainer it's it's really um straightforward 
to use but because this is um token classification  
and there's not a lot of actual tools for just 
generic token classification um advanced please  
um so for example um to do both loss functions 
and to do things like accuracy uh i had to you  
know just just roll my own um most most things for 
tokyo classification are specific to named entity  
recognition and stuff like that and also this 
has a huge class and balance because you know 99  
of the um tokens are error free so the far 
majority of the tokens are yeah you're good  
that's good that's perfect that's perfect so the 
far majority of the tokens are are no diff but um  
you can't see in this normalized um um confusion 
matrix that the model is you know very simple  
model and it's it's a it's a burnt model you know 
a distiller actually um is able to um you know  
do some correct classification but it can still 
get a huge amount of mileage by just classifying  
everything as no diff um as you can see here um 
so so next steps is clearly the data set needs  
to get increased in size if you saw the severe 
overfitting that was taking place um deal with  
the fact that hugging face data set is a subset of 
the actual dataset on github token classification  
is what we quickly discussed but what i'd really 
love to do with this is a mass language model  
where originally we just use the errors identified 
in token classification to sorry use the errors  
that we know based on the label to try to put in 
a masked model and then eventually use the errors  
that are identified in the first model to actually 
correct it sorry for the technical difficulties
that's a really cool project i really 
like this uh data that you collected  
let's add install questions to discord and 
start with the next speaker okay next we  
am i muted okay next we have what's next dom 
you ready yeah i was just ambushed by a lot  
of exclamation marks i'm starting to understand 
what the problem was uh yeah system preferences
okay
are you using the app or the chrome plugin i am 
using the app i will have to reopen this i'll be  
back in a second okay probably some permission 
setting if it has four system preferences
it's pretty cool emily and now i'm glad that 
you you train the model because you have this  
pressure to to show your results otherwise 
probably leave it there for another three months  
but maybe people will help me yeah 
motivate me to proceed which would be great  
yeah i'm back and it's looking good nice okay 
okay so let's get going um all right hi uh my  
name is dom and uh first of all thank you very 
much to the organizers for the opportunity to  
share this idea and i guess straight on to that 
so i want to talk about um a um idea i had for  
imbuing convolutional neural nets with some kind 
of internal monologue or maybe uh kind of an  
internal sense of the global scene that it might 
be perceiving we can call that the mind's eye
so what's the problem we're trying to attack um 
well let's consider cnns first you can think of  
them as layered computations of local features 
just features computed from very small local  
patches but local features calculated in this way 
can be quite deceiving and to illustrate that i  
offer the example of this dress which became the 
internet's main character a few years ago when it  
divided the world into people who thought it was 
white and gold and those who thought was black and  
blue and what's interesting about that controversy 
is that they never really disagreed about  
uh something like the value of any individual rgb 
pixel they were talking about something that's far  
more subtle what's the true color of this dress 
kind of properly understood in its environment and  
you can you can even think about this because you 
can form a hypothesis in your head about what the  
uh global illumination conditions were 
at the time that the photo was taken  
you can have a hypothesis about the quality of 
the photography involved and you can use that  
too when you're looking at a local patch 
subtract say bad lighting or subtract  
deleterious effects of just bad camera equipment 
so what you see here is a combination of bottom-up  
um effects uh kind of creating a global sense of 
uh the picture by studying the pixels but then  
using this global understanding of the scene 
to influence those local features yet again  
it's kind of bi-directional bottom up top down 
and well can we somehow infuse our cnn's with this  
um many have tried in the past uh often with 
something like attention but attention gets  
super super expensive for the very very simple 
reason that if you have a humble one megapixel  
uh photo comparing every pixel to every other 
pixel using an attention mechanism is a trillion  
comparisons and you quickly run out of gpu memory 
so um let me uh let me make a small proposal  
into addressing that first of all i want 
to name check a few papers that came out  
very recently the perceiver and generative 
adversarial transformers which try to attack  
a similar problem using uh similar methods um 
in fact i feel like this whole thing is kind of  
in the air that by the end of this talk it 
might already be solved in precisely this way  
let's have a look at the neural network downstairs 
you see two strands there's a convolutional one  
and then there's an intentional one at the top 
and this convolutional one can be just your  
standard resnet right but this intentional 
uh branch acts on something we might call  
perhaps conceptual pixels or conceptual words 
when laid out in a sequence in this case is  
this three by three gray that you see uh in the 
very top row and every conceptual pixel in this  
grid can attend to every convolutional pixel and 
it can do we can do uh calculations in this very  
very small three by three space and then 
once that's done uh before you ship over that  
information to the next convolutional layer 
every pixel in the convolutional layer can  
be influenced by every conceptual pixel in turn 
and you can kind of see how that might at first uh  
kind of not mean much but soon perhaps these 
conceptual pixels will get the idea that the  
top left there's a corner and below it middle left 
there's some kind of circle and then further on  
as the data gets pushed perhaps this 
concept gets a little bit refined  
and the corner becomes an ear and the net 
notices that there's fear in this cat's eyes  
uh making it suspect that it might 
just might in fact be a lawyer  
all right so what's the challenges of putting 
this into place well you kind of need to specify  
how the tuners are gonna communicate one 
possibility is basically plugging it into  
a batch number of different normalizations such 
as done in the generative adversarial transformer  
i'm considering experimental design a challenge 
because experimental ml research is not where  
i come from and adapting this for tasks 
other than the simplest classification  
is is also a challenge but there's many many open 
opportunities uh classification itself seems to be  
quite a simple easy task in fact i have a 
prototype that's up and running you're looking at  
it training on a admittedly very tough data set 
um but the real goal for me is something that's  
a little bit more scene-based a little 
bit more scenic perhaps segmentation  
and to those of you who are interested in 
interpreting how neural networks uh reason  
uh perhaps the attention branch um 
with its conceptual pixels might hold  
some uh some interesting bits all right and 
finally if this allows me to go to the next slide  
what next well if you want to join up or just chat 
i'll be on discord after this or you can email me  
on this address if you want to collaborate 
well like you i can do a bunch of things  
i have published some research in a different 
field in theoretical physics and i can code i've  
been working in ml for about a year and a half 
and i have managed to secure some time of work to  
do this properly but i can't do it alone 
as i said experimental design is a big  
gaping hole in my knowledge and i would 
really appreciate talking to someone who  
knows how to tune transformers because i have 
no idea how to set those promises off reasonably  
and i'm always on the hunt for cool mentors and 
cool teammates so if you consider yourself to be  
one of those um i would be super happy to chat 
and that's it from me and back to each other
perfect thanks for that presentation um a lot of 
interesting ideas in there and uh someone posted  
a link in the chat uh we should wrap up though 
and move on with the next the next speaker next  
we have zach zac can you share your screen you're 
ready yep can you all see it yes okay awesome yeah  
so i did an exploration looking at the gradients 
of adversarially trained networks um so to start  
off just background on what are adversarial 
perturbations there's some signal that you can  
uh you can add to your model with a low sorry 
to your input with a low weight and it creates  
an output image that has a change not perceptible 
to humans but really throws off model performance  
and so there's this idea of adversarial training 
and the goal of adversarial training is to train a  
model that's robust to these attacks and one 
of the ways to do it is to train it on the  
adversarial examples themselves so in standard 
training our goal is just to minimize our loss  
just with the unperturbed inputs and the actual 
labels but in adversarial training our goal is  
to minimize the loss over our adversarial examples 
and the way we induce these examples is by adding  
some perturbation delta to our input with this 
constraint that the norm of delta must be less  
than or equal to epsilon and the idea behind that 
is to make it so the perturbation which we're  
adding doesn't actually change anything meaningful 
in the image um and the general pseudo code for  
going about this is for each input in your data 
set you initialize delta to some random noise  
and then for each step in some parameter attack 
steps uh you perform gradient ascent on delta so  
that it moves in the direction of maximizing the 
model's loss but because we have this constraint  
at each step we also have to project uh delta 
down such that this constraint is true if you're  
interested in this you should look into projected 
gradient descent but once we have our final delta  
we add it to the input we calculate our mos 
loss and then we update our model with that loss  
and so there's this really interesting property 
of these adversarially trained networks where it  
seems like the representations that they learn are 
more perceptually aligned with like what a human  
would see so if you look at a standard model 
and a robust model there's this technique for  
visualizing their feature representations and what 
you can notice is that the standard models their  
representations seem more like noise there doesn't 
seem to be any like high level features that you  
can observe but if you look in the robust models 
feature representations uh those representations  
seem to be a lot more salient and meaningful at 
least for from a human perspective and i guess  
this brings me to the idea of what i wanted to 
do i set out to just try and figure out what  
is it about adversarial training that would cause 
these models to learn seemingly more perceptually  
aligned representations and my initial hypothesis 
going into this was that adversarial training  
must do something really specifically to the first 
players because if you ever look at an adversarial  
example you'll see that it doesn't look like 
there's anything high level in it it seems like  
really low level signal and noise so the way i 
went about this was to basically uh view how the  
gradient changed per layer throughout training 
and i did specifically for the first epoch  
so this is for standard training and what you'll 
see here is each color is a different layer  
so the dark red is the earliest layer 
and the dark blue is the latest layer  
and then for uh for each thing i'm plotting its 
relative gradient and what i mean by that is for  
each iteration i take the actual magnitude of 
the gradient and then i divide it by the maximum  
gradient magnitude across this set of iterations 
and what you'll see in standard training is that  
especially the first layer it actually relatively 
increases throughout all of training and it looks  
like it's actually providing like there's a lot 
of signal and change happening to the first layer  
and the same is true for some other earlier 
features they also are getting more change or  
they're receiving more gradient than uh than 
the final uh final layers but the interesting  
thing is when you look at adversarial training 
it looks like it's actually doing a really good  
job of regularizing the gradient to these first 
features so i mean especially in the first layer  
you can see there's a significant dip down and 
now instead of increasing throughout training uh  
you know it decreases and then plateaus and the 
same for these other earlier features and so i  
wanted to actually look at the actual magnitudes 
as well so i did that for the first and last layer  
so you can see here for the first layer your 
empirical or standard gradients they continue  
to increase throughout your epoch while the 
adversarial ones look really well regularized  
but if you look at the final layer gradients 
there's not really much of a change here  
their magnitudes look relatively 
similar throughout training  
and i wanted to make sure that this wasn't just 
you know some artifact of whatever architecture  
i was using so i also did this for vgg and you can 
see the same thing here where the earlier layers  
their gradients uh tend up during the training 
so their magnitudes are increasing during the  
early part of training or sorry the early layers 
their magnitudes are trending up during training  
but then if you look at it uh using adversarial 
training you'll notice again that the uh early  
features their gradients uh seem to be really well 
regularized but again this is the relative change  
um and if you look at the final layers you'll 
notice that it actually doesn't seem like  
there's too much of a difference there so again 
it seems like it's an earlier uh it's an earlier  
layer uh regularization and so again looking at 
the actual magnitudes this time for vgg you'll  
notice the empirical one grows throughout training 
the adversarial one does not um but for the final  
layer it doesn't make much of a difference the 
adversarial and typical like standard gradients  
seem to be relatively similar and i didn't include 
it in this presentation but something i've been  
working on and the reason i didn't because 
i'm just getting preliminary results now is  
i wanted to like test this hypothesis again that 
it's just the first level feature so what i did  
is i i've been training models where only the 
first layer receives an adversarial loss and the  
rest are trained in a standard manner on the 
like the typical empirical risk minimization  
and it turns out that just training the first 
layer adversarially can actually recover most of  
the adversarial performance um but again 
that works uh preliminary and yeah if you're  
interested in this topic here's some like 
papers that i've been looking a lot recently
and and that's it cool uh how 
are we doing this time jason
not sure what's going on but  
pretty cool um we can move on and anyone who's 
interested in the research training and how  
gradients are regularized by us real training 
can talk to zach in his mind so next up we have  
help that's our last presentation of the day 
after that we'll hang out in just on discord
hi can you see the screen yes all right perfect 
hi my name is sankel gilta i'm a final year  
graduate student at the university of florida i'm 
presenting my work today this is a paper that's  
almost ready for publication but as i'll explain 
as the presentation continues we are looking for  
collaborators for downstream papers this 
is just the first of what we envision  
um to be multiple papers um the the title of the 
paper uh or the presentation is predicting um as  
image quality uh using environmental 
uh and telescope operating conditions
pardon me there we go uh basically 
translates to machine learning plus  
uh automating telescope operations gets you really 
good results um so what is this project about  
it's focused on a particular telescope called 
the canada france hawaii telescope this is one  
of the larger and more important ground-based 
telescopes in the world it's located in hawaii  
that's the outside view and this is the inside 
view um the aim of the project is to minimize the  
seeing or the turbulence that's induced by hot air 
inside the dome so if this is the telescope mirror  
right here where my cursor is and this is the 
slit where this part opens so you can see outside  
there is some hot air collected here just 
due to electronics inside the telescope  
and that induces seam or turbulence 
which is what we want to minimize
um just to give a quick um you know  
intro of what a good and bad scene looks like iq 
stands for image quality this is just a picture  
of jupiter um this is a good idea this is bad 
iq obviously for astronomy with like good iq  
and not bad iq um status quo this is uh the top 
and profile views for the telescope building um  
as you can see to tackle currently what they've 
done is they've installed six excuse me twelve  
vents in total uh which are either left 
completely open or completely closed uh  
based on the prevailing wind conditions if there 
are heavy winds they close them if it's reasonable  
to open they completely open all of the vents 
the idea is to let hot air out and cool mountain  
air in to reduce telescope seat however uh this 
leaves money on the table um if you could just  
feel free to ignore the legend what this basically 
means is uh the green curve is where we could go  
this is greek is the hypothetical lowest scene we 
could achieve again lower is better uh and we want  
to achieve lower seeing and red is uh where we are 
right now uh and we believe a large part of this  
is because this configuration of all open and all 
closed is not optimal so we use machine learning  
to optimize this as a function of telescope 
operating conditions and environmental conditions  
um quick recap this is what the data looks like 
it's heterogeneous it's tabular each sample  
consists of 119 features and one output which is 
just the iq there are no missing values because  
i've removed samples which contain missing values 
uh but there are some error sensor values uh this  
is an overview of the different sensors uh it's 
a there is time dependence between the samples  
imagine a camera taking pictures as a function 
of time uh in the night but we've ignored for  
our very first paper that time dependence 
since that complicates things a little bit  
and there are 12 vents which can be open or closed 
currently they're either all open or all closed  
but hypothetically a goal is to identify out 
of these 4096 possible configurations what's  
the best configuration as a function of time 
what we've done is we've used a mixture density  
network and a robust variational autoencoder 
both with beta likelihoods so i've normalized  
my inputs to be between zero and one technically 
between 0.1 and 0.9 to account for the outliers  
here we see when the mdn is trained uh this is 
predicted mpiq iq from one of the instruments  
called mega prime versus measured mpiq we were 
just wanted to see how well on the test that our  
predictions are i've used two separate kinds of 
uncertainties and and epistemic here i plot the  
confidence intervals as a function of the base 
npiq again lower mpiq is better higher is worse
here i uh plot uh show you plots for my robust 
variational auto encoder uh what we did was to to  
check if the uh auto encoder is able to separate 
and distribution from out of distribution samples  
correctly um injecting noise two types of 
noise constant noise and uh uniform noise  
um we see it's decent but there is certainly 
room for improvement this vertical line is the  
fifth percentile cutoff for the training 
set uh using this i select only those event  
configurations which are in distribution 
and for those in distribution samples i  
go ahead and plug them back into my ndn to get uh 
predictions here we see that for the optimal vent  
event configuration as a function of iq there is 
oops sorry there is a lot of room for improvement  
as uh nominal iq cruises with the optimal vent iq 
we see we can achieve lower and lower iqs uh this  
proves that in the earlier slide i said there is 
money on the table so this proof that there is  
indeed money on the table this is just a histogram 
of bench configurations it shows that for the most  
part uh ideal vent configurations uh are half 
open and half closed with hamming distance of 0.5  
uh this is uh just a a heat map showing uh 
for for for each bar it shows uh sorry uh  
yeah i have a question can you partially open yes 
but for the first paper i'm not taking that into  
consideration um here it shows uh what happens uh 
if you applaud not just the optimal configuration  
uh but all configurations uh which reduce 
iq at a given nominal iq uh it shows that uh  
for the most part high iq nominal iq values 
require you to close uh all the vents whereas  
lower iq require you to open most events 
lower is better um these are this is what  
we have so far they should be up on our kind 
of like two weeks or so seconds if we can
i'm sorry what's that oh we should just wrap up 
wrap up in a few uh yeah yeah this is a very this  
is a very last line uh i'm sorry i took a little 
more time uh that was allowed to be apologized  
um we are uh we are definitely welcome 
collaborators we are a bunch of self-taught  
ml researchers basically astronomers so we would 
appreciate feedback from uh you know uh pure  
ml researchers uh who know what they're telling 
if you will uh there are a number of downstream  
tasks and most importantly we want to the large 
picture is develop an open source software stack  
that can completely automate a scheduling 
of observations in our telescope and that  
we can also use for predictive maintenance you can 
reach me on discord or that's my email thank you
awesome uh thanks thanks um maybe we can thank  
uh sankalp and all the speakers 
actually we had 11 11 great talks so  
thanks everyone um many people are clapping on 
mute i'm sure so next we're going to head over to  
uh to discord so actually or someone can you 
paste the link in the in the chat the discord link  
so we're gonna head over to discord uh in discord 
each speaker will have their own uh channel you'll  
see them on the left side you can just hop 
into that channel to talk with the speaker  
um there's also a a general research jam channel 
and a research jam text channel you can paste  
things in the text channel or like hang out and 
chat with whoever you want in the global channel  
um all right i think that's it uh thanks 
everyone see you see you over on discord  
see you there thank you bye thank you thank you