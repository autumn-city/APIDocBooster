Welcome everybody, you're watching mr fugu data science. Today is a continuation of the  
Russian troll tweets. If you haven't seen the first one, click the card above and check that  
out. Today we're doing exploratory data analysis and a bunch of plots. This is allowing us to  
finish up on getting a handle of what our data are actually doing to help dictate how we should  
investigate natural language processing and what we should probably do. Feel free to hit me up  
here on instagram and twitter. If you'd like to help support the channel here's my Patreon,  
as well consider to buy me a coffee and there's the handle. I want to mention something first from  
the last video at the end i had this highlighted portion, it was actually unnecessary and it wasn't  
giving me the correct printout for i think it was, is one of these two tweets that had an  
additional double quotation inside of it. After i did that i decided well, let's try to fix it with  
doing a strip technique and that wasn't helping me doing a chain together strip. So i did a replace,  
and that took care of what i needed to do. That's the addendum that i had to finish at the end. That  
code is on my Github as well as today's. I also want to say thanks, to the recent subscribers  
and viewers. I greatly appreciate it, and the person who contacted me yesterday asking me to  
go a little slower in some of my videos for those who are learning. Thanks for the feedback. Here's  
the first imports that we're going to use today. Stop the video and use those it's pandas, numpy  
mat plot lib. These are the data that i fixed from last time where we took out the hyperlinks  
from the tweets. Because, later we're going to do in the next video natural language processing.  
Today eda and plotting. i'm only going to use the english language because, translating hundreds of  
thousands of these rows are a problem with the google api, it's not free. It's only free for  
a certain amount of 200000 entries or something like that per day. And dealing with making the  
function calls it just keeps messing up for me. So i decided i don't want to do the paid version. If  
anyone has a better technique that's free and fast let me know. The way that we subset these data is  
like this. We first call the column that we're interested in here. Then we do a double equals,  
and take the english rows and then we throw it into the data frame. Let's see what this looks  
like. i'm going to go step by step and kind of slow today because, i feel that that's probably  
going to help people a little more showing what the code's actually doing when explaining it.  
If you notice all of these rows are english, and we're going to also need to subset these by dates.  
We need to do some date time formatting which is going to be important. I noticed from last video  
we had a problem. I forgot to address this. I need to do some lowercase for the right,  
and for the left so we can coincide with these uppercase versions of each of them and to do that  
i just set this to a map function and take care of all of the names of those strings. Convert them to  
lowercase just replace the values in the account type column with our new values and then print out  
for sanity sake the unique values so we know what they are. But we notice that they're saved. But,  
we get this goofy kind of an error. And it's because of the way that i'm doing this. You  
can read the documentation. It wants me to do a dot loc. But i'm not really concerned with that.  
Instead i'm going to show you an error handling to deal with this. To get ready to do some plotting,  
we need to do some date time formatting. We call that in, and here the highlighted portion pd.set  
option allows us to deal with that error message from above. Where i have none, there's parameters  
you could put here. i'm not sure what they are because, i'm new to this one. But you could look  
at that in the documentation. Let's do this so we can go line by line and see what's going on  
so we can see that we're dealing with the string here, okay. That's fine. That means that we have  
to convert this into a daytime formatting which is what i did here and i did it in third date time  
format equals true. This one's kind of slow, and the problem is that i have; what like two million  
rows or something like that. I could have ignored this but, i wanted you to see this option. Then  
what we could do is we could print this out and see what it looks like. It's going to take a  
second to run. So we scroll over and it looks the same right. But let's do this, and you'll  
see this; this means that it's now a daytime formatting. Perfect. But, let's notice something  
else. Hold on these aren't formatted in ascending order. So that's what this is doing here. So  
put it in ascending order, perfect. Now we're at 2012, which is what we want. This is going to help  
us later, for the plots. I'm taking out the time stamp which is this, and i'm going to only take  
month day and year in the American format. But, it'll be changed later. You'll see. But you'll  
notice, that we have this date time, dot string f time. Which is part of this. I just put it on a  
new line there. So we got our publish state. But, now we scroll over. Now we got our new one but,  
this one is actually a string formatting for these dates. I wanted to emphasize, what was going on  
around the time of the elections. A little before, a little bit after to show you what it looks like  
for the time series of the tweets. That's why i took this right here. This is the date range that  
we have. Notice the parentheses that i did for each of those as well as the ampersand. I threw  
that in to take those columns. The columns for the publish date, and extract every row that fits in  
that date range. Then i sorted those values so we can look at that real quick. Here's what it looks  
like for our date values. Perfect, so this works. Then the next thing i did, converted this into a  
date time again and i got us ready for matplotlib. Now this is dot py plot. You'll end up getting an  
error if you don't use that for the labels. That we throw in here. So i'm doing a pretty  
big figure size, and then if you notice this when you do the value counts. It's going to take the  
column for this date and it's going to count every occurrence it sees of that date. We can look at  
that real quick, to make it clear. So here we are. Now we have a simplified list of all these days. I  
think it's 100 days or something like this. And here's all the tweets by those days. These are  
going to be important, and we're going to do a plot with this later. We're able to sort these  
days right here, and then we got this sort index. So what that's doing; is this would be our column,  
and these are the index values. That's what we're sorting by is this index and plotting it out.  
I took the x tick marks and i just rotated them and shifted the labels. Then i created the title,  
the x and y labels, as well as their sizes made a good formatting and printed it. I did the dot  
show, so you don't have that goofy little line that comes up after the fact or not line but,  
a little message. So we're from September 2016 to January around the first, if i'm correct of  
2017. On the y-axis we're looking at the number of tweets and you see this huge spike that's pretty  
prominent. And there's something interesting to mention with this. Around this day and the day  
before, there's some interesting things to happen with president-elect trump. Since, this was before  
he got into office for the first term. He met with the Mexican president, was talking about  
the border walls. He also was making a lot of disparaging comments against Hillary Clinton.  
A lot of people on twitter started tweeting a lot of things. That's this spike right here.  
There's some other stuff that was going on in this time frame. We're gonna look and investigate this  
spike and you'll see the election is around here. There's another little small spike right after  
the election when he won which is this. Here's the source for the information, and this plot is  
adapted from this person on Kaggle.l Now, let's investigate that spike where we're subsetting  
our english. We're using the subset english language. Here's the date range that i was  
interested here from the 1st to the 14th 2016. And these are the number of tweets that were in that  
date range. It's pretty significant, two days with quite a bit of tweets which is really interesting.  
What i did here was do that same formatting of subsetting our rows and chuck that in here, and  
then i sorted by the dates. Same exact thing i did above, and then i converted it into the timestamp  
and did a value count on it. Here exactly the same i did above. I just changed the date range,  
okay. But what about the groups of trolls who tweeted these days? That's what we're really  
interested in. Remember this is the english subset. There's a plot which is for Russians,  
and another plot which is the whole data. This specific plot is relative to the October  
7th 2016 tweets we subset just for that particular day with this conditional equal, equal parameter.  
And this is really easy. Because what i did was after i stored this variable of October 7th. Then  
i wanted to know i want this specific column of category, account category. Because, this deals  
with the type of trolls that we're tweeting. And then you just do that value count because, the  
value count takes anything relative to whatever column you are and counts every occurrence of  
c's of each one of those unique names. You just do a dot plot directly on your data frame and  
it gives this crude little plot here. And this is what we'll notice for October 7th. We had  
6 000 tweets and some change for the left trolls. The right trolls is around, i don't know two and  
a half thousand. And then it just goes down. But it'll let you know that the right trolls and the  
left leaning trolls are the highest proportion or highest proponents of our tweeting information  
doing the same exact thing for October 6th. Just changing this date here, and cutting and pasting  
everything else and changing this date. We're gonna see a big change. We see that there's  
more. Probably 12 and a half thousand left trolls, and then there's little over 4000 right trolls,  
which is crazy. Because, the day after, it's half of this number. So there's definitely  
some things going on in the media. What's interesting, is this. All tweets in english,  
i don't know what was going on in the Russian media. But let's will do a comparison real quick.  
I extracted all of the Russian tweets. I pulled out the publishing date, and converted it to date  
time again. I sorted the values, i converted it by month to year. This is cut and paste from what i  
did above for the english. So that's all you have to do. I take out the same date range once again,  
sort all of those, i take that date and convert it into a date time instead of a string.  
And here's all of our Russian troll tweets. Then into a plotting with a cut and paste of the exact  
same as above. I just changed the name here. We're basically taking this column, a public state only  
which is the month, day, year. Doing a value count for each occurrence of each date. Then i sort by  
the index. The index is the date when you do a printout of this. And then we just plot it off,  
and we'll notice a far significant difference of actual tweets that we're done. But,  
still you notice in this date range from a little after the 1st of October to roughly  
i don't know midway October. A little 
after midway October, you have this huge  
spike right here. Which is very significant, kind of coincides with what's going on in the english  
tweets. But there's an issue we don't know what's going on in the Russian media. We don't exactly  
know what's going on with these tweets unless we translate them. Therefore we can't exactly  
say that those two correlations coincide with each other. So be careful with making that statement.  
Let's zoom in and take those dates of interest, and look at the second to the eleventh of those  
troll tweets from Russia. We do a cut and paste of what we just did from above, same exact thing  
we take the subset dates. We sort the values of the dates. We convert it into date, time. Then we  
start doing our formatting for a figure size, and we do the value counts of the month day,  
year and stored by the index. Which is your date plotted off. And you notice that between the sixth  
and seventh, we do have a steady increase. Not as much as the one we had from the english ones. But  
then from the 7th to the 10th you have this really big peak. So obviously something was going on at  
that time. Now let's plot everything in regards to followers and following to see if there's any  
correlation. If there's something we could see any trend. This was adapted from the same person.  
This other particular plot on Kaggle. What's going on here is this kind of simple code? You  
call in your seaborn, your x is your followers, your y is your following and then your coloring  
based on the account category which is the type of troll. And then you just call in the whole  
data set, and it plugs those out the rest of stuff is the labels. So if we look at this real quick  
we can see that here's the legend for the type of trolls. And you'll see that there's these big old  
numbers of people that have a lot of following and they have a lot of followers. And those are  
the right trolls. Right trolls tend to have 
a lot of people who have similar numbers of  
following versus followers in proportion. We could also see that the left trolls which is this right  
here. This red one, i'll put an arrow for you guys. This one shows that it's steadily increasing  
and then it's pretty flat for the green one which is the non-english tweets. wWhich it seems like  
they're not following a lot of people but, they have a lot of followers which is kind of dubious.  
Maybe it's a business entity, who knows. Let's evaluate the top 10 users. The top 10 people who  
are throwing these tweets here. They are and see what we could investigate from this. I did this  
value count which gives us that table, and then i took the index values which gives us the names  
that we convert into a list. And that's what i did with this right here. I converted it into a list  
,and then i took the particular columns of interest for us to do our plotting coming up. And  
then i did this interesting thing and it saves me from doing looping. Which i almost did. But it's  
really convenient because, now i could 
take this particular column of author,  
this index of the specific names which are going to be in the rows. And only extract those this is  
really interesting and very helpful to have if you're doing subsetting. Because it allows me  
to use this column, and then this list of names and pull out any rows with that which is perfect.  
Exactly, what i needed. So here i decided to take the max value because, when you're doing this if  
you do a sum that's the wrong operation you don't want to do that. You're going to have fluctuations  
between each publishing date you may have multiple times during the day where it changes followers or  
following for the twitter person and you don't want to use the sum. Because, that's incorrect.  
And you don't want to do the average. Instead i say well, what was the max value? They had for the  
day; i could have did the minimum. But i chose the max. This is a multi-level table, these upper ones  
for follower and following those are your columns. These two down here, are your indexes. So you got  
to pay attention to that. So anytime you do that group by you need to have some kind of statement  
sum, count, min, max, etc if you've never done this before. And i always sort by the days. also  
not each one of these users had a follower, following for each one of the days. So that  
kind of threw me off, and i had to rethink how i would set this up for plotting and make it simple.  
So i converted this into a list so we could read in these names and recreate a data frame from this  
nested table or multi-level table we had above. I couldn't figure out an easy way to flatten it out  
simply. This isn't something i do every day. But i just converted into data frames like this,  
and then i concatenated everything together by columns so it just expands it wide. And then we  
start doing our plotting and since, it was using the seaborn this made it extremely easy. And we're  
going to do two plots one with the followers. The other with following, with respect to the author.  
Which is going to help us with our coloring and our dates and the rest of this is just matplotlib.  
Doing your labeling and legend information and this is allowing you to move the legend outside  
of the plot. Since here it's going to look ugly, and it doesn't really have a place to go. Here's  
our legend with respect to the top 10 people who are tweeting at this particular time frame here.  
And you notice that the amount of followers, isn't really changing. There's not a lot of changes.  
There's like a few slight gradual increases for some of these. Two of these users it looks like.  
But you're going to notice drastic changes with people who were following. Doing the same exact  
thing but, changing this particular column for your y and cutting and pasting everything else. We  
notice these really interesting changes with some of these people. Right before the election you see  
a pretty good increase right here. The range right here for the two large numbers of tweets  
i don't see really big volume changes. I just see the trend coming up to the election here with the  
groups of people following each other. Next video we need to decide what do we want to do for the  
nlp are we doing word clouds. Yes what kind of analysis are we going to do? Well that's going  
to be a little bit of a surprise there's a few things we're going to look into as well as some  
other plotting techniques. But we're going to show cleaning how you clean this kind of data,  
as well if you've never used natural language processing. But as always, i like to say please  
like share and subscribe and if you subscribe turn on that notification bell. Feel free to  
help support this channel there's my Patreon. Once again and also another option consider  
buying me a coffee. But as always i'd like to say thank you for watching see in the next video. Bye