this is the second lecture for uh
recurrent neural network
um
just go through a recap of what we did
in the last
session
so we talked about the fact
recurrent neural networks primarily are
used for processing sequential data like
text data time series speech
and videos
in which obviously the input is
based on time
and
these kind of networks are specifically
designed for sequential data
there are no other networks which are
designed for this purpose
like in the case of convolutional
networks we can share the parameters
across the different parts of the
recurrent neural network
that's what you need to understand and
that helps a lot in decreasing the
amount of work
that needs to be done to actually run
the model okay
so uh um
uh by sharing the parameters obviously
time to
decrease
generalization is also improved and we
can share the knowledge across the
different parts of the network
okay
uh then we talked about the fact
the
um
in the recurrent case uh
what happens at time t depends on what
happens at time t minus one
and that depends on what happens at time
t minus two and so on according to that
uh
formalism
so each member of the output is a
function of the previous data
of the previous cell
so we talked about the fed k in the
normal neural network i have the input
layer and i have the hidden layer
and i have the output layer and it goes
in this fashion
it's called a field forward yes
but there are no connections between the
neurons
of the hidden layer
in the case of the recurrent neural
network
i
have this connection
so now i have two connections one is the
normal feed forward and the other is the
connection between the
hidden neurons
um
which in this case we call as the
recurrent neurons though
like 90 degrees claw anti-clockwise so
this becomes my input layer this becomes
my hidden layer this becomes my output
layer
and now it is easy for me to see to
develop the connections between the
hidden units
so
that is the main thing that we are
you know aiming for and uh in this way
we create a cycle
um
which represents the influence of the
variable value on itself in the future
i can share um
[Music]
i can share the value of any parameter
across time
uh that is the main thing okay
what am i like for example
there's a human being so what is he
doing at age five
what is he doing at age ten what is he
doing at age 15 what is he doing at age
20 so it's the same human being but at
different time steps the human being is
changing
so this is exactly the stuff that we are
modeling
in the recurrent neural network
and we also talked about the fed k
we have this thing which is called a
computational graph so this is the
example of a computational graph
and in the case of the recurrent neural
network we are actually unfolding the
graph
because i may unfold
i
have different time stems
because i can unfold it over time so
this is uh this is one example of the
unfolding scenario
in which i have unfolded one thing over
different timestamps
okay so when i unfold then i develop
this computational graph so
all the graphs that we saw in the last
class they are called computational
graphs
and they happen because of unfolding
there are different time stems of the
same
thing
in this case that's the state of e
neuron
is the state of the neuron
you need to understand this unfolding
concept very clearly
so i am basically repeating the same
concept but at different time stamps so
it this in this way it develops a chain
uh so for example if you are doing nlp
then this could be some word at time t
minus 3 k at p minus 2 at t minus 1
and then
at time t and type t plus one and so on
and so forth okay
so unless you have this sequential
structure you cannot use the current
neural networks
so is
due to this unfolding i can share the
parameters because the thing is the same
i mean the cell represents the same
entity the same human being like i told
you
so therefore i can i can share the same
parameters
across different timestamps
so that makes it very convenient for me
because otherwise i would have millions
of
parameters to learn
but in this case i just have several
thousands of parameters to run if i
share the parameters
so your example dk
the state at time t is a function of the
state at time t minus 1 and the set of
parameters
okay
so this is the same thing uh just uh
described in another in another way
according to s3 s2 and s1 so you can see
s3
s1 contribution rj
so if this is the state at time t plus 1
then you can rest assured that this
contains information also from t minus 1
and t minus 2 t minus 3
all the way up to the start of the chain
so yeah this is
yeah so this is one of the best things
that can happen
um
otherwise as you know in the case of the
time series
in the case of arima models you know
okay i'm just i just find out the lags
so we try to find out the lag which is
related to the current action typically
it is lag one two three four five just
that
like and there's no guarantee that arima
is going to save the state right from
the beginning okay so therefore this is
the reason recurrent neural networks
have shown a good performance
over arima in many situations
although still you cannot generalize
so this is this is the same thing so
about now we are developing the system
so
this is unfolded
this is folded and this is all unfolded
so you can see
here there is no concept of time while
here we have the concept of time okay
so um
right so
uh this is the input layer
uh now there are questions regarding how
to make the input layer so you will get
clear about that
in the hands-on exercises
okay how to select the input size
um
i mean when to predict and when not to
predict so we'll see how that happens in
charlotte
so now it's the same thing i just told
you we invert the normal fluid forward
network so this is the input layer
i'll just put the i here and this is the
hidden layer which is called the
recurrent layer
or again recurrent neural network is a
general concept
so we can have different types of
recurrent networks like for example
gated recurrent unit lstm bi-directional
stm
um attention-based networks blah blah
blah
transformers
that is based on the attention mechanism
but we'll deal with them later on
so
the different rnns will define the
dynamics of the recurrent network okay
but right now this this is pretty simple
to understand i hope none of you have a
problem over this k all the things are
shared you you can you can see the
function is the same
so if the function is the same that
means i'm sharing the parameters that's
it as simple as that okay
so it's pretty much the same thing here
uh nothing different rnn is required to
predict the future from the past
uh so it uses ht
as a lossy summary of the relevant part
of the pass sequence of inputs up to d
z
i can't expect it to remember everything
that has happened in the past
it will only remember a portion of
everything that happened let's say
five minutes ago 10 minutes ago 15
minutes ago 20 minutes ago 25 minutes
ago 30 minutes ago
because of the way this thing is working
okay so it is possible that
uh in the case of the
when i apply the back propagation on
this model
then the gradients will start to vanish
so yeah so if the gradients start to
vanish then you know i i cannot
guarantee
that this ht plus one is going to
remember everything from h t and s t
minus 1 s t minus 2. i i cannot give
that guarantee so that's fine
but it is still better than the
traditional
uh nlp models or the traditional arima
models
so that's what you need to remember it's
a lossy summary
prediction
that's the main thing
and this is this is the simple math for
it right like x t x t minus one x c
minus two blah blah blah all the way up
to x one so this is the input above the
input
function
or http function
like
because
why this is happening this is happening
because of the fat k
i am now adding layers
so adding layers means can adding the
connections i'm adding edges so when i'm
adding edges then that means i have to
add the weight matrix for those edges
so yeah so pitch 3 diagram came there
there was no input layer so we just
needed one function but now i've added
the input layer so now i have these
connections
i need to define a weight vector for
these connections and learn the weights
similarly i need to define the weight
vector for these connections and learn
the weights if i have another layer here
which is the output layer again i will
need to define the weight vector and run
the weight so
if the layers the more layers you add
you have to
you have to also create a weight vector
for that and learn the weights although
the weights will be shared across all
the cells okay
so this is what we are looking for here
on the last time discussed okay this is
the without any time and this is good
time so this is unfolded here
so the zoo vector is the weight vector
from the input layer to the hidden layer
which is the recurrent layer
the w vector is the weight vector from
the previous hidden cell to the
current retention and it remains the
same
so it's it's
it's because of the w vector that i'm
able to carry the information forward to
the next cell okay
and v vector is giving me the
information weight vector from the
hidden cell to the output cell or output
cell
i compute the loss you know by giving it
the
uh the ground truth or the actual actual
data
and this is obviously the calculated
from the predicted data and then you can
back propagate and find out the bits and
biases etcetera etcetera okay
so uh yt soft max i told you okay why
this is soft max because of the fat k
we have to output the probabilities
in the case of test recommendation or
test prediction
uh sorry text prediction
in the case of text prediction so i have
to predict the next word but how many
possible words i can predict let's say i
have 120 words that i can predict
so at
each output
at each output i am going to have a 120
element vector
with the probabilities of each
vector
of each word so here also i i'm going to
have that vector
here also i'm going to have that vector
here also i'm going to have that vector
uh
joe probabilities
so it is expected that the loss is going
to reduce
and some of the words are going to get
more probabilistic as compared to the
other words
so yeah so i'm uh i'm outputting the
probability distribution
here here here and at every output i'm
saying
while designing the recurrent neural
network
this is not the normal scenario that i
am outputting
everything at each cell
so yeah typically what we have is we
give input for some time let's say
p1 t2 d3 scope net we break up the time
we break up our data into timestamps for
example
i will say okay
three observations of time or iot
sensors form one reading okay so i will
have three input neurons
and
three input neurons giving like for
example
zero one two
so zero one two major reading
and then i'm going to predict the third
so in that case i'm just going to have
the output here so please keep that in
mind oh my god
so let's say okay i keep the input
vector as this i'm going to use three
readings
at time stem 0 1 2
and i'm going to put 0 reading here one
reading here 2 reading here
but
the output neuron is just going to be
one together that this output is not
going to be there this output is not
going to be yeah opposite of something
like that this is the output that is
going to be there and this is going to
predict the third
element value or the third value
the value at the third timestamp
training
in the case of words ditto the same case
so i will say i formed the trigram model
so trigram model me word one word two
word three
predict the fourth word
then word two
word three word four predict the fifth
word
then word three word fourth word five
predict the sixth word and so on and so
forth yeah my training data came that
this is what is going to happen okay so
what happens is okay
uh when i apply the soft next function
all possible outputs
so the softness is going to know
what are the possible outputs and what
are their probabilities so at every time
stem when you present one input in the
recurrent neural network it is going to
output something here
and you're going to compare that with
actual value because of the pro you have
designed the problem in that way and
then you're going to back propagate
after the badge is over and it will
learn the weights
so that is how it happens the loss
function primarily we have seen that it
has to be
more or less the quadratic function so
you can have the mean squared error blah
blah blah whatever so i hope that this
is clear
uh
so this is the first type of recurrent
neural network the second type of
recurrent new network
we can pass another signal
uh there is no direct connection between
edge because that is computation
intensive but the w vector is now
shifted to giving the output previous
output to this hidden vector
so
it's just you know a way of modeling the
problem
although the information is being passed
but now it is being passed through this
cycle
uh or through this loop you can say so
it's it turns out okay
this is much easier to train on because
the timestamps are now decoupled
so that the time values is decoupled now
so i
i can update each
line here
independently in parallel which was not
possible in this case because i cannot i
cannot update the uh parameters for ht
minus one
until i update the parameters for ht and
i can't do it here until i update the
parameter for this one so the back
propagation is very very slow because i
have to wait for everything to finish
here before i can go here
okay but when i have the second
rnn here so in this case uh the best
part is that uh you know i can remove
this uh w connection
uh and then replace that by this
connection and that makes it easy for me
to decouple everything
and then i learn the weights for each
in sequential
because there is no coupling up between
the layers like that so basically it's
like a normal neural network now because
there's no connection between the
uh you know
there's just very sparse connection now
there's no connection directly between
the hidden layers so that eases things
very much again
obviously
it is limited
can only pass specific information uh of
the output to the input
this line is very strong
because i'm passing all the previous
information directly to the next time
step here i'm going through this loop so
there's a loss of information in there
so obviously your accuracy can be
compromised with this model
and this is what we typically use like
this is the third model that we
typically use
which i explained to you okay this is
basically the input that i'm generating
so i do have the input like two three
four five
level input i could have even more
so
this uh
thing could be eq
but you can you should ask me this
question okay let's say i have this time
series
okay so this is the time uh stem and
this is the value okay
so you will say okay
why not do it like this okay okay this
is the first value
based on the first value predict the
second
based on the second value predict the
third based on the third with the fourth
why you are taking three or four
because i told you this is what we need
for the warm-up period
so yes
you have to give something as a warm-up
here
uh this this can be labeled as the
warm-up data because you have to allow
the system to train like you've got
still thousands of parameters
if you start training on one output
one input one output one input one
output then it is going to grow very
very complicated
in convergence
say so that's not the way to go about it
so you need to have a warm-up period so
this is the warm-up period so in this
case for example you can define 23 time
stems as the warm-up period
so in the first case the first 23 cells
will go in and then it will print the
24th
then the next 23 and 25th then the next
23 and 26 and so on and so forth all the
way up to the end
okay so keep this in mind you have to
define a sequence it's just not
a
just keep that in mind
and uh no this is pretty simple now
because the equations i discussed last
time with you with you guys as well
so um in this case i told you okay we
have three weight vectors
uvw i have already explained to you okay
there are two biases
one is the bias at the hidden
layer which is the recurrent layer and
one is the bias at the output layer
where the activations are being applied
okay so the activations are being
applied at the hidden layer
ht so
that is the bias there which is b
and the other bias is being applied at
the output layer in which we are using
the vector v
so i got three
weight matrices and i got two biases
that i have to learn so these are the
parameters that i have to learn
and uh
yeah so
these are the parameters gen key value
how many estimate currently are using
stochastic gradient descent okay so
that's what we have to do but the
the problem is k in this case
we have to change our strategy a bit
okay the chain rule will still be
applied
the chain rule is still be applied
and it is going to be applied in such a
way to facilitate the back propagation
process okay so just keep this in mind
okay
is the um
is the activation
of the hidden layer right so what is
happening here b this is one b b plus
w into h t minus one obviously w is here
so ht minus one is here so okay let's
let's do it here okay so w into h t
minus 1
and obviously it's the same b here as
the for the next cell
uh plus obviously u is also there u into
x t okay so this is this is what is
activation
coming out of ht
okay and then i put this activation to
the hypervolume tangent function to give
me the actual hd value
uh which is this value which is here and
i use this value multiplied by v to
calculate the output obviously uh in the
output you know that i have to apply c
as well
okay that's the pi is there so
whenever we have this sort of activation
thing so then i have to
and i put the output in this horse max
to find out the probability vector and
that gives me the predicted value i
compared that with the ground truth find
out the loss and then backward
that's it
so you these equations are pretty simple
to remember there's nothing
complicated about it okay
so we have already seen this
uh yeah so
this model i told you this model does
not work so you already always have a
warm-up period okay and this is the you
know uh
yeah so this is the this is the
prediction that we want after a momma
period and these are the equations that
we already wrote if someone insists on
this model
then you know you've got to add up the
predictions to this point
the loss sorry
these these losses then you have to sum
up together to find out the total loss
at this point because you have to define
a place
you have to define a timestamp
in the case of recurrent neural networks
it is not easy
to do things in parallel unless i have
the connection this one which we don't
have typically otherwise you know it's
not going to learn that much so this is
we don't have that case here okay so it
will take time so i have to i have to
wait for this layer to finish before i
can do
the learn the update the parameters at
this layer okay
so therefore we have to define some
point
uh some time step at which the process
will start so the process will start at
say here
so sequence without defining the
sequence it's not easy to
uh i mean envision that although you
could have the same thing at the single
time stamp as well but it is better to
give a warmer period okay
so
let's see how this works start to give
given basically i just ask you a
question okay
i told you last time about the
likelihood function
so the concept of likelihood
okay what are the values of these
parameters that are going to make this
output most likely
that is what we have to find out right
and that can be done using maximum
likelihood estimation so in order to in
order to calculate the likelihood
function i need the probabilistic vector
that is why i apply the soft max so
therefore this probability can be
calculated by using this probabilistic
vector which is given by the softnext
function based on that i can estimate
the likelihood function
to minimize this loss function through
back propagation it will take order of
tor time where draws the total number of
uh
the time stamps that we are using maybe
23 24 25 so that's an expensive
operation and we already know that
cannot be parallelized so we use that
approach which is called back
propagation through time okay so how
does that approach work
but yeah that's a side story here this
is called teacher forcing so in the case
of teacher forcing
i can find out the actual i do have the
actual value the true value which is at
this timestamp and instead of giving ht
minus 1 here i give y t minus 1 so i
give it the actual value
in the case of the second recurrent
neural network i was giving this one but
i can also give the output here so that
is
in us in a way that is called teacher
forcing so to buy a teacher forcing
because this is the actual teacher this
is the actual value right that we want
the system to predict so i'm putting
that actual value directly in this cell
which is not a good approach frankly
speaking
um because we are forcing it to learn
uh without thinking about the fat k i
have u i have v i have w
i have lstm which can do things very
quickly so this this might be a thing
which you have to model yourself i don't
know whether there's an algorithm
available for this or not so but i think
you will have to write your own
recurrent neural network to implement
teacher forcing if you want it's just
for your own knowledge that we can do
different things uh with deep learning
okay
so let's let's take this graph to make
things very easy for you to understand
it's i don't want to complicate things
that much
so in this case uh we already know okay
we cannot learn the function without
uh the
uh chain rule right so chain rule
the function cannot be learned so yeah
so uh apply the back propagation to the
unrolled graph
so we have these parameters blah blah
blah
at each node we compute the gradient
recursively
so the gradient this is the inverse
gradient if you remember from the
notation of deep blending
that we learned that we did in the first
hourly
so this is the
the inverse gradient
inverse gradient what did it represent
a
[Music]
inverse gradient of c
yeah
but what about delta c
yeah so it was the it was basically the
partial derivative
i think of the
uh
of the loss with respect to the
activation function or something like
that
yeah
so it represents basically the partial
derivative of a
bond
so um now we have to start writing the
chain rule equations you have to listen
to me carefully to understand again so
this is what we are targeting we are
targeting the cell which is ht
and we have computed the loss
and now we want to back propagate and
update the values for u v w c and v
that's what we need to do okay so at the
final load which is our output node any
let's say came at
18 uh i give three inputs and i then i
tell it to output the fourth value
add the third out at the third input
okay
so then that means k add the third layer
to this layer vertical rea
so in this case for example
i'm talking about this layer
in this case ht is this one but this is
if i'm using a size sequence of three as
the input so i'm talking about this
layer so obviously
at the node immediately preceding the
final loss dl over dlt equals to
how does that happen
g
so i have the loss function here
which is the total loss that i compute
which is l
and if i
uh derivate that with respect to the
loss at this particular time stem
so it is going to is going to do that i
am just going to get the value one
because
because of the fed k what i have done
here i have not initialized these
neurons
i have just used this neuron
okay minister of gear neuron
which is primarily summing up the loss
this but i'm actually computing the loss
only at this particular time stem so
that is why dl over dlt equals to one
job
if someone wants to use them they can
use it but the point is k
i am going to start computing the
gradients only from here
that is the main thing because i have to
give a moment period
otherwise the system is not going to
train properly
again so
i can't start it everywhere right
so in this case that problem design
requires me to input three sequences and
then get the fourth one as the output so
i'm going to start from here i assume k
at every at
every
um
jacket new school every training
instance consists of three things over
three different time stamps that is the
main thing
um so in this case
i am computing the loss only here
if these neurons exist i will not
compute the loss here i will not come
with the loss here so i am computing the
loss at lt plus one
so dl over dlt plus 1 equals to 1 qk
when a lossy one compute here so l
even though it is the complete loss but
it is actually lt plus 1 because the
loss is only computed at t plus 1. so
therefore dl over dlt plus is equals to
one is the same loss again
now the main thing is k
how to
you know i have two things
one is the internal node
internal load method only two the output
node and the hidden node
so these are the internal nodes output
node and the hidden node
first i calculate the gradients at these
internal nodes
then i use these values to update the
parameter nodes which are c b
u v w
okay so first i have to apply the chain
rule at output node and then at the
hidden node
calculate all the relevant factors
and then use them to
update u v w c and v that is what we
have to do okay
so now what is going to be the equation
so i have to find basically
derivative of loss with respect to o
which is given basically by this
equation
okay dl over dlt into dlt over dod i i
can compute the loss with respect to ot
because i have computed loss
so therefore i can find this derivative
out and i have d l over d o
then i also need dl over
dh
and how will i get that that d l over d
o into d o
over d h that is the chain rule
application here and how do you find d
over d h i already have the equation so
we can find these out
equations
is the same equation
but they have written that in a
different way you just understand the
concept here what is the concept
that the derivative of loss
uh with respect to the loss at this
particular time step is simply one
because i am computing the loss only at
t plus one because i have a bomb of
sequence of three uh at each uh instance
that i present so every training is
considered of three time stems
two you will have to add this to the
loss here and then that will become the
total loss and the derivation is going
to start only from here
that is the thing that you guys need to
understand only from here so therefore
dl is not bl but it is actually only dlt
plus 1 if i derived it that with respect
to dlt plus 1 that is equal to 1.
so first i find out dl over do
to find out dl over do i have this
formula and then i find d l over d h d l
over d h equals to d l over d o into d o
over d h and i can find those
derivatives out to find out their over d
h okay so once i have these parameters
then i have the things in my head to
compute uh
d
l over d c
d l over this is what it means d l over
d c is this one
the the negative gradient here this
means d l over d c because until i have
this i will never be able to update the
the the bias
similarly this means dl over db
so dl over dc
dl over dc
equals to dl over dlt into
dl t
divided by d o
multiplied by d o over d c
that's it
this is the summation d over dc over
across the time
we are summing up here
because of the fat k
this thing contains everything that
comes from the back
how cubase
like i told you here i am summing up the
dos here at t plus one
by using the losses at each of the
previous timestamps similarly
the the gradient that i am computing
here
basically can be achieved by summing up
the gradients across all the previous
time steps
that is what we need to understand okay
it is it sums up over over the time
because what why is summing up because
we have unfolded
i'm just unfold here so therefore we
have a right to
because this is what it
the this is the real thing that i'm
worried about not this one to solve this
i have unfolded across the time and
therefore i can sum up everything so if
i have to find out the total
derivative of loss with respect to c
and making
because i'm sharing c across the whole
network so just give me one figure what
is dl over dc
so that is dod over dc across all the
previous times time i sum them up
multiplied by this vector
which comes
foreign
period
why do you want to average us
every entity
is important for me
okay
a single time stem will be used to
predict the next time stem
in that case i can take the average
again but i what i'm saying is k i will
use three values
i will use three rows of the training
data
which are divided over different times
right t zero t one t two
and then make a prediction for the
phones
so t0 t1 t2 is basically the same thing
therefore i have to sum up the losses
there i can't average it
they are because they are atomic someone
vary it 0 1 2 atomic hair one two three
atomic hair two three four atomic cheese
three four five atomic cheese and there
is no everything it's just one thing
therefore i have to sum up
so similarly i will have to sum up over
all the
things so yeah
so in this case
what you should be able to understand is
that you should be able to find out the
equations
so dl over dc equals to dl over dl dlt
into dlt divided by
uh dot into dot over dc so i can define
this because of the equation i have and
i can sum them up over everything
again
you will do the back propagation
again you will find these gradients
across the different time but
when you update the weights you have to
sum them up because they are unfolded
sequences
so you have to sum up the partial
derivatives dl over dc across all the
times
and then
use that to update update c because c is
just one thing being shared across the
different times
then i will never be able to sum this up
because there are different parameters
but i am summing them up because it is
the same parameter which is
basically flowing across the time
so therefore i can sum up the gradients
that have been discovered through one
back propagation pass and use them to
update the c once
i don't have to update the crt's
timestamp i will update the c only once
after summing up all the dl over dc that
i have found out
similarly i can define b
it with respect to d h over d b because
b now i'm scared so what is dl over db
dl over dp equals to dl over dlt
into dlt divided by dot into dot divided
by dst into dht divided by db
so you must be able to divide
figure out this chain chain rules
question
right write down the chain rule so uh
we don't have the time to go into that
that much detail but that is what is
primarily happening up online because
videos they have bbtt
so they are just going to mention the
chain rule over one or two uh
one or two layers that's it
to explain to you how things are
happening
what about
d l
over
b
[Music]
that's the main thing the v is only
related to the output layer from the
hidden layer so this these are these are
a set of connections here
so v has nothing to do with that point
so dl over dv equals to dl over dlt
into dlt over d o t
into d ort divided by d v d that is it
because uh i can represent o
in terms of v
calico
this here
ot equals to c plus v h t so i can
represent o in terms of v right i can
find out d o t over d h t i can find out
d o t over d v
but
summation here
what is i what is oi
ditto for w d w l is the same thing d l
over
uh d l d into d l t over d o t
into dod over dht into dht over dwt that
is it again i need four equations just
keep watching
due to this excessive chain rule
application
but what i'm asking is k that is
understandable for me that i'm summing
up over time
and then i i can use this to update the
weights for example
uh
but why what is i what is the item what
is
in order to update the v weight vector
i am summing up
over time that is understandable
i am also summing up over i so at each
time stem i am also doing another
summation
so i am doing a summation over i here
i am doing a summation over i here i'm
doing a submission over i here what is i
what do you mean by oh i
think
[Music]
what i believe is okay
this is actually the fat k in od plus
one
in calculating ot plus one i have the
data for ot and ot minus one as well
because we have talked about the fact
okay
the previous
timestamps are giving information to the
next timestamp
in this way at the final timestamp i
have information
across all the previous time stems
so my guess is that uh
this is
if i am derivating dl with respect to do
then i have to
derive that with respect to all the
possible values of o which have occurred
previously in the past
so for example here i'm going to have o2
o1 and o0
here i'm going to have one and oh zero
and here i'm just going to have o0 at
that particular time step
so that might be a requirement that i'm
summing up
over this and then i'm also summing up
over time
so because the value of o is different
uh for each of the previous cases
output to change
because
we are not actually
assuming that this exists
if if we assume this does not exist then
all the things that is happening is is
happening through here
so at each time stem
i have to find out the derivative of
loss with respect to o
uh with respect to each other which is
existing at this point
so yeah
or i have i have to sum up the same over
time so at this point i calculate
something
i get this point i calculate something
at this point i calculate something
or every time i calculate something i
have to sum up over all the values of o
which have existed previously
and then i sum up all these three things
together this one this one and this one
that's that's the summing up over time
and i is the summing up over the
different o that existing at this
particular point
so here so
that is back propagation through time
similarly w can
i have to use the same double summation
and similarly for u
so it turns out okay
when i am updating the weight matter
says
then i have to actually
uh
sum up
over the parameter nodes
over all the previous times because o
and h are parameter nodes so i'm using o
in estimating delta v
and i'm using h in estimating delta w
and again i'm using h and estimated
delta u because u and w are related to h
and v is equal to o
so we have to keep this thing in mind
that in back propagation through time
i have to find out the derivative with
respect to all the previous values
of the output or the hidden cell that is
existing at this particular time
okay so that is going to give me one
value when i do that
and then i do the same for here i do the
same for it and then i sum up all these
three i have to get out the final value
here algorithm you will have to listen
to the video again probably
to understand what i've said but i don't
think so that is going to be very
difficult if you listen to this these
words two or three times
okay
so it's a it's a double game basically
to in order to estimate the
ideal values for the weight vectors
we have to find out the derivative
with respect to the loss
of the parameter node which is either o
or h
with respect to each value of the
parameter node that is existed
previously
again
at that particular point so if i'm at if
i am here t plus 1
so what was the value of
4t and ot minus 1 at this point so i
have to derive it with respect to that
as well
and then i just sum them up similarly to
the same here same here and then i got
three values as i just sum them up over
time
to find out the actual delta vl
so yeah so that's what you need to keep
in mind okay
uh you have to do a double summation
here
and that is essentially is back
propagation through time
okay i am summing up over time because i
have unfolded the same thing over time
intervals therefore i have to sum them
up even in the case of bias i sum it up
under the case of b w and u i have to do
a double summation
say away
is
foreign
it's a bit complicated but uh
you have to understand the chain rule
that is the most important thing
and the other thing that you have to
realize is the fact
you have to sum up over time
to find out the partial derivatives
uh because
i have to find out d l over d c b u v w
i have to find out these
five partial derivatives to update
the parameters
i can find each one of them using the
uh weight
uh
using the
um
that propagation right so i can find out
each one of them using the chain rule
but one extra thing that we are doing
here is that
we are summing up over time
to update each parameter that is the
main thing that you need to understand
so because the parameters are being
shared so i have to sum up
so i will i will find out let's say d
dc over dl here
i will also find out here i will also
find out here but i'm going to sum them
up to get a single value
and i'm going to use that single value
to update c because c is a single
parameter
similarly i'm going to have d l over db
here dl over db here dl over db here but
then i'm going to sum them up to get a
single value
i will use that single value to update
the value of b because it's the same
parameter ditto use case for del w
v
and u
the only thing is k in the case of
weight matrices i take the other
dimension as well the first dimension is
the normal time dimension that i'm
taking
but in the case of in the case of the
weight matrices
you got information for ot as well as
for rp minus one
i can write the equation that way right
so therefore i will be able to
find out the derivative
d
l over d v
in which i will use d o 2 d o 1 and do 0
similarly if i find out the derivative
dl over dv at od
i will be able to find out the
information dl over d o 1 and d l over d
o 0
all the previous values that i have
there they are being feed forward so in
the case of weight mattresses
i have to see which parameter node is
being propagated and i have to derive it
over
each value of that parameter across all
the previous timestamps
because we frankly do not have the time
to do this in in my new detail
we have already done that in the
previous uh in the first example here
you just have to understand how the back
propagation works
so yeah so these are the two things you
need to keep in mind if there is a
confusion then
just listen to the video again or just
ask me
okay just uh just a two minute break
okay just two minutes
okay so
okay so this is the animation
yeah that means basically the you know
uh the flow from one direction to the
other so this is the bi-directional use
case in fact
okay um
the lstms
they are able to deal with the vanishing
gradient problem
so yeah
how they are able to deal uh will have
to understand that uh you know very
thoroughly
but the problem is they can still suffer
from the exploding gradient problems so
the gradients can grow out of control
during back propagation
so they might explode into unknown
territories
it is insensitive to gap length so gap
length means the warm-up period
uh it can be 10 times times 13 14 20 23
50 60.
it is insensitive to that so hence it is
very much applicable for time series
data because in time series data you
never know what is the ideal gap length
that is the reason
in the case of uh
lstm i have used the concept of gates
maybe some of you have already seen the
videos of lstm
so i have three gates one is called the
forget gate
the other is called the output gate and
the third is called the input gate right
and there is another thing which is
called c which is the cell state
that's a new concept that we have
introduced so we'll see how that happens
uh
so the
why do i have the gates because i want
to control the flow of information
into and out of the lstm cell
so lstms were designed to deal with this
problem so therefore one of the ways we
can deal with this problem
is to have a sentry or a policeman
so so these three are policemen
basically
so they will decide okay
the recurrent neural network cell or the
lstm cell what goes in
and what comes out
so they they will make the decision
we have also included this cell state
which we represent by
the symbol c
it's a it's a separate thing that is
coming across the whole network
um
if the derivative of the activation
function which is used in the gene rule
is less than one
then the gradient will vanish
so that does happen with the hyperbolic
tangent and the sigmoid function which
is used in the recurrent neural networks
so the reason the gradient vanishes is
primarily because of this one
you remember okay we have to derivate
the activation function as well in the
chain room
and as we flow across backwards
that derivative starts to go less than
one and then it vanishes
in the case of lstm the activation is
the identity function at the forget gate
so lstm kendall probably this is the
most important gate
the forget gear
so at the forget gate
the
the the reason this happens
the reason that the derivative
goes to 1
we just terminate that reason and how do
we do that
i
at the forget gate my activation
function becomes the identity function
and not the sigmoid or the tiniest
function
so the derivative of the identity
function is that function itself
it's it's not going to go down at all
so if i take the derivative of the 20
function it is that random function so
that gradient is never going to go down
so this is the formalism that i use in
order to avoid the vanishing gradient
problem
so it remains very close to 1.
we use addition
chain rule here multiply this by this
multiply this by this this by this this
by this so it keeps on getting smaller
and smaller and smaller
but in the case of lstm at the forget
gate in the activation i compute the
uh
output by using the plus sign
so that
prohibits this use case in which i am
always multiplying multiplying
multiplying multiplying
and allows me to maintain the gradient
which is very close to one
so yeah
so
in each lstm cell
there is a whole connection of errors
is basically the merry-go-round if if
you know what is that that's a ride
right for the kids
so very good on me i have this pole and
all the
all the animals are just revolving
around that
the same concept is here as well okay
i have the different lstm cells
this is our recurrent cells and they are
all connected to each other with the
normal use case that we use
but the point is k
um
due to this idea okay vanishing gradient
um
so
the errors just stay here
okay because i have the gates above this
logic for someone
okay because i have the gates
so due to the presence of gates
i control the errors
then again that problem is going to
occur
but i restrain the errors in my cell by
using the identity function at the
forget gate
again that prevents the
derivative of the activation function
from going towards one
of less than one it just keeps it near
to one so vanishing current problem
finishes up
and also i can use the errors in my own
way
in the cell to update the weights that i
have
so errors do not get back propagated
they will get back propagated obviously
but i am now controlling the pack
propagation of the errors through the
gates that's it so
foreign
that is the main concept of lstm that is
so famous
that it basically uses the gears to
regulate the flow of information into
and out of the cell
and due to that regulation i am able to
overcome the vanishing trading problem
as well
and to generate extremely good
predictions
in the case of lstm i have one other
thing which is called c which is the
cell state
separate the cell feedback from the
output generated from that cell
so every every ah every lstm cell is
going to have an output
but that output is going to be different
from the output of this cell state so
i'm going to have two outputs now
one is the output at ct which is the
cell output
and the other is the out normal output
which comes out of the orange cell
that is the thing that you have to
understand now so just keep in mind that
we have two things
one thing is that i'm using the concept
of gates to regulate the flow of
information
particularly i'm using the identity
function at the forget gate so that my
derivative of the activation function
never goes below one
and the third thing is that i'm
maintaining a cell state as well
which makes which distinguishes itself
from the output so my stealth cell state
it becomes more important to me than the
output state or you might accumulate
your initial problems are back
propagation okay
i want to solve them through this
formula
so the cell is more or less independent
of the output
but i use the information in the cell to
do many things that we're going to look
at now
so
now this is the now you have to
understand this very carefully because
if you don't understand this then
it will be a huge loss
so
i told you okay we have a cell state so
ht minus one you already know from the
previous diagrams that we have done
today okay and this is ht so you know
okay this is one cell that we saw
this is x t b
input layer city
so
i have the
ct minus one coming from here which is
the cell state which i initialize
separately
it has nothing to do with ht minus one
by the way in order to initialize the
first edge i have to initialize the
first edge let's say you start with html
as t equals to zero
so i have to initialize similarly you
have to initialize c t zero
so you have to give it a random
initialization that will start the whole
process again i forward to tell that
so now we have this gate here so what is
happening is that these equations are
very simple like the equation
so this is the lstm complete lstm with
the forget gate so
what is the purpose of the forget gate
just try to understand that at the
forget gate i have the sigmoid
at the input gate i am also using the
sigmoid at this input gate assembly
this is the forget gate listen
carefully this hole is the formalism
sorry about that
this hole is the formalism for the input
gate
and this hole is the formalism for the
output gate
so at the output gate
um
yeah so
i'm using three sigmoids and two
hyperbolic tangent functions so let's
see if your concept is
now
this is the main forget gate that we are
looking for so what is happening here
the weights are shared wf the weight of
the forget gate the weight of the input
gate the weight of the output gate the
weight of the cell state
similarly
uh
w f so yeah so w is somewhere here i
guess
x multiplier w is somewhere here
okay so w f i'm sorry to say that
yeah so w f into x t which comes from
here
plus u f into s t minus one so
zhu is the you know the formula is
f is here
and bf is obviously here which is this
neuron
so what is happening here
so i'll just put this down so u for this
one
and w for this one
for each gate separately okay so for the
forget gate this is the for forget it
forget gate
this is the activation vector for the
forget weight which is ft
okay
how much input
am i supposed to remember from the
previous one
so wf xt
previous input
u f h t minus 1 previous activation plus
b f
and the sigmoid of that
so the logic of the forget git is
ok how much am i supposed to remember
from the history
history
that is the forget gig
that is why i have included the forget
game so the history is being
the history is coming from here w f into
x t
plus u f into s t minus one plus b f
which is basically the uh the recurrent
cell this cooperation is a computer
so yeah so how much of the previous
input i have to remember
that is basically
uh
the matter which is happening at the
forget game okay
then
uh
input gate input gate i told you two
portions one this is this one and the
other one is this one
in in the first case i have w i x t so
again so w i
w f
w o
and w c
similarly
uf
ui
uh uo and uc
so here because i have four uh factors
to consider i have four parameters okay
so therefore i i
i do that okay
so
similarly for this one
w i
into x t
at this particular time so of a vector
change okay
that's pretty understandable give it the
function here
uh
this one is actually the hyperbolic
tangent i think it is this one
which is directly they can mapping to
the cell state
okay so w c into x t plus u c into h t
minus 1 plus b c
so this one is
so this one is bc someone maribot key so
here i'm using the sigmoid here i'm
using the sigmoid here i'm using the
hyperbolic tangent
and
in this case
w o in this one i'm talking about this
one w o into x t
plus
u o
into s t minus one plus b o so in this
case i'm using this sigmoid
and
to calculate this is the signal so i'm
using the sigmoid here
and then to calculate the actual output
the cell state sorry
cell statement
ft
how much of the previous cell state you
will remember that depends on the value
of ft
in computing the current cell state
and obviously
it depends also
on
uh the current
value of the input gate
is is basically the calculation for the
cell state
so
input into the cell state
plus prana
and then obviously i have to see here
how much of the previous i want to
remind it that is for the frontier so in
calculating the cell state i am using
the forget gate and i'm also using the
input gate
okay
and based on this value of ct i am
finally calculating the value of the
output object
and from every cell i am outputting two
things and i am inputting two things i
am inputting ct i am inputting ht both
at t minus one
and i'm outputting c and i'm about to as
both at t this is exactly what is
happening throughout the whole chain
okay so
at the forget gate input gate output
gate and the cell state i have the
fate mattresses w f i
w
uh sorry w f i o c
and similarly u f i o c u is for the
hidden
hidden internal node and w is for the x
internal node
so i have basically four
w matrices four zoom addresses and four
biases to learn here
that makes it total of 12 parameters
only across maybe hundreds of lstm
neurons
it's just a recommendation
that is how lstm has been implemented
and has been showing good results
because
i'm using the 10 h wherever i have a
relationship with the cell state
because 10 h is going to map the value
between -1 and 1.
so
i want to maintain a very close uh guard
on the cell state therefore i i do this
10 h
so i have the hyperbolic tangent
function variable so
here this is the hyperbolic tan function
this is the hyperbolic time function the
other are all the three sigmoids
and these are all the activation vectors
of the forget gate input gate output
gate
ht the hidden state vector cell in cell
input information activation vector cell
state vector ct ct is the cell state
vector this is the cell input activation
vector
uh this is called the output vector
input vector for that vector
sorry overall
switzerland okay schmidt humor works in
switzerland
so
this is a very famous guy
or a deep learning community
america that is benjio and all those
guys
um joffrey hinton dangio and uh
this guy who invented the gans
what's his name we are good fellow
so they have their own community and
this guy has his own community but lstm
has been a really good success again
so
schmidt uber said that we can also have
the people connections in the case of
people connections we're going to simply
change
in the case of vanilla lstm i am using
the values of the previous hidden
uh cell
in updating the u vector
but in the case of people connection
they are saying that you can use the
previous ct minus one to do that
so they are now forcing the c into the
update equation that is the basic
difference that you need to keep in mind
i don't know whether python has
implementations for the people
connections i really don't know
uh but
that is what it basically does
i can also have a people convolutional
lstm
in which i apply the convolutional
operator
uh where i think this is the
convolutional operator
so the star can be the convolution
operator so i can have the convolutional
lstm i can convolve w
with the current input so i will say
okay rather than do the product
just do the convolution convolution you
understand how that happens now very
thoroughly we have done right
so it's a different mathematical
operator as compared to this normal
hammer dad product
or whatever so i can have the
convolutions here as well so these
extensions are all available i think in
python
convolutional lstm peephole lstm
later on so let's take a break for some
time okay
you will have to bear with me today
because we have to finish many things i
have to show you
at least four hands on activities it's
very important okay so let me see how
much is it
we'll just do this just let's come back
in like 10 minutes okay
okay so
we saw the lstm uh in
the previous
uh with this uh in these slides
one of the other extensions of
one of the extensions of lstm is the gru
which was discovered in 2014 by show
um so what the group does is
it is an lstm which is uh without the
forget gate
oh sorry uh lstm with a forget gate but
it has
uh fewer parameters as it lacks an
output gate so there is no o parameter
here as we had in the case of lstm
it has shown comparable performance with
lstm over things like music modeling
speed signal modeling and nlp tasks
so the guys who are working in nlp
should definitely explore this
as well
because it has shown comparable
performance with lstm and it's
still has fewer parameters so it's
easier to drain
it's good for smaller data sets
so in this case it's pretty much the
same but i think we have two formulas
here so one is this part
and the other is this part
so by looking at the equations you will
understand so one is the z
and the other is the r
that's what we have to understand so we
have two portions so what is the first
portion
w z into x t
which is the same thing as the lstm plus
uz
into ht minus 1 plus vz so we have
the variable z which is more like the
cell state that we had for the lstm
and we have the ditto use case for r as
well so we have another state r
which is internal to the node in fact so
this is the z
and this is our
so
in that case
i calculate these two quantities
internal to the cell you can see there's
no c state here
and then we have we find out the
[Music]
h dash d which is again an internal
state
not the actual state which i want at h t
based on s t minus one but it is an
internal h dash state
which is uh the
hyperbolic tangent function
which is i think this one
so in this case i am summing up what i
am doing is w h x t
uh which is the weight vector h
plus uh into not st minus one rather rt
dot ht minus one
so how much contribution of rt
i'm using
uh
how much of the previous
hidden state i am using that is defined
by the rd
so in calculating ht
how much information from ht minus 1 i
am using that is based on rd
similarly to the forget gate you know
plus obviously the bias
and once i have ht i can find out
h cap t
i can found out h t from this formula in
which what i'm doing is that i have
z t into h dash d
so i have a double check now
tell a check
in order to compute h
cap p
how much h t minus one i should use that
is defined by r d
okay
so i find that out and then
what is that going to be the actual
value output from the cell
us
that is defined by z so that is more of
a weight
so zt and rt are acting like
are acting like weirds basically right
and uh one minus zt also tells me here
what weight i have to give to the
previous one so
basically
what we can understand from these
equations is that
zt and rt are acting like weirds
uh
to select the previous cell
state
so in the case of h cap t
i'm able to use uh
rt to decide
how much st minus 1 i should use
and in the case of computing the actual
output from the cell i'm able to use zt
to find out k h cap kidney st
now how do these equations came into
being obviously through lots of
experimentations and lots of mathematics
etc etc
so initially we have to realize
something and you know this is the
formalism that has been written above so
these are the variables
this is called the fully gated version
of the grg
so yeah so again i will recap that in
the case of dru
we are calculating two weights basically
based on the normal
full feed forward equation
in which i have using two parameters for
the weight matrices and one
two parameters for the biases
okay
so basically i have total of six
parameters
that are shared across the whole
timestamps or each time step
and uh sorry there's also have this
third parameter with respect to h cap
t so in a sense one two three four five
six seven eight nine so i have nine
parameters
uh which are calculated
uh at each time stamped in the back
propagation phase
uh so this is the fully gated version
this one
it also has its variants
so this is fully created this is type
one type
they are different with respect to how z
and r are calculated because they are
the gates
so in type 1 i'm not using the x
input here like
w z into x t i'm not using that
similarly i'm not using w r
into x t here
so i've just skipped that part
and
in the case of type 2
i have removed the biases as well
and in the case of type 3 i've removed
this weight mattresses i've just written
the biases
s
it
it has its applications in typical
you know speech data and other data so
if you want to do something lightweight
i think you can go for the gru mod
mechanism it might not give you that
much accuracy looking it will be faster
to train
and it has these three different or four
different versions that you can use
i think it will be good to experiment
with that i personally have not done
hands-on with gru as yet
so we have to do that as well in the
course
so it has the fourth version as well
which is called the minimal gated
version
and the minimal created version is the
similar to the fully gated except that
the update and reset gate vector is
merged into a forget gate
so
these are
update and reset gate
the number of gates
so i merged them into
uh just the forget gate so forget gate
is the sim simple one there w f x t plus
u f h t minus one so there is no
separate
set and r now so i'm just using the
forget gate to
uh basically control h cap t
and i am using the forget gate to
control ht
so that is called the minimal gated
version
so one of you might come up with another
version research which is very well
suited to some
nlp task or some speech task for example
and uh you know that will be
that will be correct because if you are
able to justify do things mathematically
then it is okay
so yeah
now for the
biodirection lstm
uh in this case the
it's a sequence processing model that
consists of two lstms
so one is the forward lstm and the other
is the backward lstm so it's a cycle
basically
so one takes the input in a forward
direction and the other in a backwards
direction
the forward learns the sequence of the
input provided
and the second one learns the reverse of
that sequence
now this is very important in the text
case right because
if i want to predict for example the
heart is not enlarged let's say the next
word is enough
so i want to
enough to for the person to die for
example
again so i want the system to predict
the fifth word
but
may assume
this sequence is correct the heart
followed by is followed by not followed
by changed
maybe it is correct the reverse sequence
is true enlarged
preceded by not preceded by is and
preceded by heart maybe
this is the thing that is a better
predictor for nf than the forward phase
so
you never know so effectively increases
the amount of information available to
the network
improving the context available to the
algorithm
for example you know
you know both the things now
in the case of feed forward you only
know one thing the similarity to a times
similarly for the time series as well
so in the case of time series
um
so you got the value 2.1
1.9
so 2.3 4.4 so all of these are time data
that you want the system to predict
okay so but um
this case may
you will know okay 2.1 followed by this
followed by this followed by this but
maybe you also need to know this
sequence
in order to predict the fifth value
so you never know so this most of the
applications of bi-directions are in the
case of
uh i think textual
uh data
but uh they also serve
to
data okay it learns both the ways
okay
so
it really needs to be tried out okay
is better
you never know but
so these are some of the models in the
recurrent scenario that
i wanted to finish today and we have
done that
although we have done some
generalizations but we know now what is
recurrent neural network we know the
internal dynamics how does back
propagation through time work
we know lstm gr2 and the pythagorean stm
i think that is enough information so
now let's go to the hands-on activities
yeah so uh
start off with the most simple one by
the way i took all these examples online
but they were giving like huge errors
so
you have to figure out how to solve this
problem
is for the tensorflow
the latest version version 2 or whatever
so if you're using the version 1
data then you know you have to enable
this disable the eager execution
uh this is some sort of check that you
need to do
for a particular error
so you just have to you know just check
the memory
uh
sometimes that works to solve some
errors
but these are the
uh main apis that we have to use
and there's also for the i think
american airlines
i don't know where that is
i think this this is the one
the way the time series data works this
is this is childish stuff
you need to have you need to scale the
data at all costs
option here
i think this is pretty heavy
so open high low close and i think there
are maybe yeah one two five nine so this
is not the heavy one
in any case learning here
um
yeah so let's proceed ahead so here we
have the we just see that the open high
arm third pages stock values and they
are recorded like this open high low
close and volume this one is a new one i
saw justin
at justin close i think
so this is a new one but typically we
have these five
so as we have like one two five nine so
we set 800 as the trading data and the
other as the testing data
and we just predict the open because one
is the open column right zero is date
uh so just we see the training set here
for some time so 52.44 is the first
value here so this is the same area
and then we say the min max scaling
between zero and one or you can do
between minus one and one both are
correct it does not make much difference
i think to the final output
uh you you visualize the scalar and
apply the fit transform function to your
data set
uh and it gives you the scaled version
so you can see
what is there at 60 comma 0 the 60th
number is this one
so scale between 0 and 1 okay
now this is the thing that i was telling
you about k
you definitely need to have
a warm up period
so in this case we create 60 time stamps
that means i have input from x 0 to x 59
and then i output x60 to for the
prediction
so in the first case x0
to x59
uh as the input vector
outputs x60
then i have x1
to x60 as the input vector output x61
then i have x2 to
x61
output x62 so this is how the trading
data goes on he can summon variability
so you need to keep this in mind but
so i i do the same i say range from 60
to 800 because i have 800 in the
training set
so i create i minus 60 to ie
and i say
0 to 59
and i goes to the by train obviously
bother and i repeat that for all the
time so this is exactly what i'm doing
and then i create the array over this uh
and then i reshape them
uh to to use them in the fit function
so i reshape them with respect to x
train shape zero i think is uh
is i think 60 and train ship one i think
is one
no trench of zero is 740
because i have 740 now from eight
hundred the sixty sixty percent
seven forty instances
so i have seven forty instances with the
shape sixty comma one so the extreme
and then we initialize the model model
equals to sequential
uh
now this guy has done something which is
really complicated so
for this simple data consisting of just
1 000 time stamps
and 740 trading instances we don't need
to have multiple lstm leaders
so i'll just give you some assignment
later on just you can play around with
this or you can develop your own
playground based on the hands-on
for the lstm you have to input the shape
this is like 60 comma 1 is the shape
number of instances
50 units
then add a second lstm layer so this is
the input layer
this is the first lstm layer this is the
second lstm layer this is the third ls
gmail register
he has taken 50
which is sort of verbose i think
and uh yeah the fourth also he has taken
15.
okay so that's the model that he has
done
with the return sequences equals to true
i think this is for the
uh for some
output to be shown i think
return sequence is equal to true
let me let me check this out i
i think this is related to
the back propagation thing
yeah it still returns it returns the
states of the neurons at each time
um
feature stm cell
will output one hidden state and
for each input that's fine
this very very small model
let me just
[Music]
so let me just get us
your return sequences
whether to return the last output in the
output sequence or the full sequence
default is false whether to return the
last output
so
can you guess why the return sequence is
i want to return the last output here
here here
or not here
why not
i am putting the dropout at the even
after the fourth layer
by default the return sequences will be
false i don't want to return the last
output here
um
at the fourth layer
lstm4
[Music]
and this is the input layer so i'm
returning the output here here here
returning the output here
so this needs to be discovered what will
happen if i put return sequence is equal
to true here as well is that always the
case here so we'll see other examples
and then understand okay currently we
can't figure it out in this way
typically you add this dense as just one
unit
so after 60 i'm going to make a
prediction
okay so you can envision now that i have
60 in the sequence here
and then at the final one i have the
output here that's the that's my model
that's that's been created here
and optima atom is the default one these
days bean squared error you can say
and the dot fit has this built-in
mechanism to output this everything so
epochs 100 does size 32
so you can see that the loss is
decreasing
increasing quite rapidly
over 100 iterations and the end is
0.0035
okay
uh and then we'll write this function
because in the above we did not create
the test set
but now we use the i log to create the
test set as well i think we also
transform that using the same
uh
converter as for the training data
and i use the same mechanism my
i minus 60 whatever this is the total
size of the test set
that's why it's written 519.
and we do the same mechanism for 59c so
i have 459 instances of size 60 comma 1
and i say model dot predict
x test and previous stock prices
i in the case of cnn
uh so real stock tesla this tesla and
you can see that things are not good
here
because i think this guy has done too
much by adding four layers
and we still do not know why return
sequence is equals to false in the
fourth lstm layer
uh it fit it fits the data pretty well
we can put the size here
but you can see
it's fitting well up to a particular
point but i think for the training data
testing data maybe
so that the performance is not good
so yet
you can find out the differences of
what is happening here is
this guy has done too much i mean we
don't need four lstm layers we
definitely don't need 50 neurons in each
layer
so maybe you can play around with that
to improve the performance here okay
yeah so this is really
so this is the data for nyc
uh new york uh can the taxi passengers
kidney how you go here
so it import the regular data here we
import the type
uh sorry import the data shape and d
type so timestamp is object here it's
not it's not a date
i have 10 000 instances here which is
much better than the tesla one tesla one
you can download from yahoo finance okay
uh
i convert that to timestamp first or dot
to date time as simple as that
i can use the timestamp to extract these
year month day hour so
if you're using time series data you can
use
any of these to make the prediction
uh they're gonna have the
ear remains the same so it can't be used
as the value
maybe you can take our as as a
prediction thing
your time stem
you can combine them as well
so unique i have
data for 2014 and 15.
i have months from july august september
october november december january i
think that is seven months
and all the days i have the data unique
number of hours over all the days and
hours
the mean value of the number of
passengers is 15
127.
that's the average value
because this is this is the value that
i'm talking about so
um so i got 10 000 here on this
particular day
i think this is the
yeah the number of taxi cars i think
the number of taxi cars or whatever
so just plot the demand value so you can
just fix the size of the previous one
here so you can see that there's a very
clear pattern to it and it is easily
predictable
obviously
i mean
so you can just plot the specific values
here so you can see them in more detail
more granular detail here so just
just you know
ah
you can see it there's a pattern to it
but it's not a i mean it's still a very
difficult pattern
when you do it more granularly
but still it is not easy to fit it
exactly like that
yeah so this is how it is happening
so that is how the time series looks
like
so this is not easy i mean i mean this
this is not a straight line to fit i
mean
how many measurement i have so that
comes up to 48.
so i take that as a factor of 48
and i find out the uh
i have 48 measurements per day i have
seven days a week so weekly i have these
measurements and i want to find out the
weekly lag
so in the case of time series we have
the
uh
[Music]
the auto correlation function from the
statistics library but the
data frame also pandas data frame also
has this autocorrelation function
where lag equals to dt
where dt is the you know
[Music]
dtk dt is the timestamp no just let me
assume it's tf ah for sorry for dt in
time lag so dt is timeless that's the
lambda function
so time lags i have this many time lags
in in a according to the week
of them time lags okay and i'm just i'm
discovering the autocorrelation
and i plot the autocorrelation here so
it's a time lag in weeks
so you can see the autocorrelation is
one
in the first week and then
the lag is
is coming down a bit
to the to the second to third week
so there is a clear trend here for the
autocorrelation function it's decreasing
like this
and then again increasing
at the weekly level
so i'm talking to we're going to be
doing the
uh auto correlation plots as well as the
partial autocorrelation plots
they find out the average hour day by
combining the weekday with the hour
so weekday hourglass 1 0 1 0 1 1 so just
make a function of that
and then i convert that to an actual
numerical value
so i'm taking the average over each
unique average hour day level
that is what they want to do although in
our case we just go with the value
prediction directly so yeah what is the
transformation
and then i create this day time as well
as i want to create a time variable okay
between 6 am and
10 pm that is the day time and otherwise
it is the night time so we make a pie
chart so most of the values are in day
time and the night time so where the
labels are here okay so all of this
plotting is done by this df dot group by
the df functions we can also plot the
the probability distribution
of the
day time
uh sorry of the value
i'm going to go to the power
distribution of the value
uh with respect to day and night so this
is what the
i think the first one
is uh
is the first one is for the night
the blue one which is the the
distribution is pretty skewed
and for the day you can see the
distribution is is very
is very normal
then you can see this modified we just
had two values but now we have so many
columns
again that's the same thing we do the
standard scalar
uh we do the fit transform updating i
scale that up
we did not take all the variables here
uh we took our daytime weekday average
hour day and value so this forms my
input
so after scaling i think standard scalar
between minus uh
i don't know it's been not between minus
one and one
it's a standard scalar z transformation
okay
so i just take five values as the input
i make a copy of the of the data frame
and put that to the scale df
uh
and then i just you know put the hour
daytime etc etc
they are scaled properly
so time step equals to one how many
values to predict
that's uh
just one step into the future
um
so the 90 percent of the
of the data is the training data
the other is the testing data okay so
this is this is the division
so i can see the testing data here which
is from 9288 to 10319
and
so we can see the testing data here
let's see if our variables are it's a
training where i just created the
training one just wait
i think i did not focus on that
sorry about that i mean
yeah so it's uh it's here the training
testing are created here
zero to training size where training
size is this one so it's from the scaled
df
so i'm considering all the variables as
yet as of now
let's see what happens later
so testing the object
training print testing you can print
them
but now you see
now i am following the x train
x train i'm just considering three
inputs value hour and day time that is
my input data
and i'm just making a prediction for the
next time stem so i'm not
basically i'm not giving any warm-up
period
so i'm just doing this uh
scale df time step testing index value
from zero to nine to eight seven is the
last training
so
basically
um
so let's uh ignore him
so i record these three values at time
stem t equals to 0
and the value at timestamp equals to 1
becomes my
y drain
i record these three at time stem t
equals to 1
and the value at equals to 2 becomes my
y train
so i'm just predicting the next value
there's no warm-up period basically
similarly i can initialize x train x
test and y test as well
in the same way
you can take 75 80 percent that's up to
you so these are the x strain y train x
test and why does snapshots all of them
are stainless steelized
now just plot them here uh but if we
plotted here x strain
uh and x test
so x train indexes so the last 10
percent are the x test and the first
90 are the extreme okay
i said now
uh
what we do here is that you know
we create that i have two
i have two readings per hour here
it's like more way ahead
yet again
two readings per hour
zero zero to zero thirty i have two
readings
thirty two one
so this is not there but one one is
one thirty and 32 so i have in fact
from 1 to 130
130 to 2 so average i have two readings
per hour so this seems to be a problem
one one reading at this time one reading
at this time or anything is probably a
reputation
so
yeah this one zero zero hour they can
zero zero
and zero one
so per hour i have three readings in
fact not two readings
so we want to we want to create one
sample per hour that's
like
again
so how do we do that
yeah so we define this create sequence
in which we have this two readings per
hour in fact it is three readings per
hour
and we give it the length 48
buy a 48
because it
i was recording three readings in one
hour
but now i'm just going to equate that
with one reading per hour which is this
going to be given by this function
that's easy for me right
so these three rows are going to be
considered as one in the stream
so i can create this sequence now they
have your arrow now
i have a triple array now here
so
does the size originally was i think i
don't know uh it was 60 or something
like what was that
i forgot the size let me see where
[Music]
48 into 3
48 into three
so the three dimensional input amir pass
up that is why i have three arrays here
now
uh so i just print this white range it's
the same thing i've plotted but i've
plotted x strain
versus white drain
i know that's the scatter here the
scatter is the huh yeah to extraneous
this is the next point that it should be
able to predict this is coming from the
y train take care
and
shape is 9 2 4 0 which are the number of
total instances
but 48 sequences of three rows each
that makes it one instance right
so that is how we give a um
okay that is that is 48
and this is the last one minus one that
is three you always give 48 into three
return sequence is true that it's 64
followed by dropout and then 20 that
makes sense
because the most of the learning will
happen here then i can reduce the
neurons here
and return sequence equals
the last lstm layer
always has written sequences equals to
false
because
you don't want to return anything now
because now you're going to predict the
output you want
and blah blah blah both sides
you know
uh so yeah you fitted it started with
0.5
and
0.0691
the summary is here you can print out
the summary
the predictions are here
all the prediction predictions are here
so we'll have to inverse transform them
i think
this is
horrendous i just printed all of them
yeah so prediction for a particular case
the first prediction evaluate prediction
in a basically
they took this approach that they have a
difference
which is the actual difference that we
want from the ground truth and they also
made this ratio here
tk
and they have the outliers the outlier
percentage is given by the user
so uh
in land differences
the length of differences uh
differences compute
convert that to integer
multiplied by that and that is the
number of outliers
so
if the differences i have there is a
difference
so one percent you have outliers in one
percent of that is the outlier
percentage
so
i don't know
you can print the differences here the
differences are here
so it's a very fish flash pattern
and
this basically tells you the predictions
with respect to y test so y test is
actually the color blue
but you can try to see that when i plot
the differences are varying between 0
and 0.6
the outliers will remain there so we can
just uh skip the outlines here
i don't know whether you shall take any
synthetic so yeah so you can see it gets
between 0 and
0.6
has a probability distribution
so even the error that is coming here
uh the predicted values or the error
values they have a probability density
which we can use in machine learning in
a very very good way
to update the model
the other is the the same data for the
bi-directional use case exactly which is
but in this case you can see the loss
goes down to 0.03 i don't know what was
the loss here
let me check here
everything does not work well in every
situation you need to have multiple
output parameters
not just the
very or very nice
mean squared error but we definitely you
need to have the root mean squared error
root mean squared errors
large deviations
content
therefore it is better
so this is not working out although you
can see that over all your all three
differences are able to come in you can
um
you know it's it's over all your fitness
or differences are they happen
many people have this idea about stock
market prediction or
bank workshop
this is for your understanding because
many people are
the stock market
please remember one thing with the
experts are saying
okay
a blindfolded monkey throwing darts at a
newspaper stock listing
because the stock market prices are
highly unpredictable and volatile
there are no consistent pattern the data
that allows the model stock was over the
time near perfectly
so yeah why do you want to model these
stock prices so that you can reasonably
decide when to buy the stocks and when
to sell them
to make a profit
now yeah
to get the data from the stocks at
different time intervals
it has a free api key
uh for some limited usage
okay so you can subscribe to this
advantage
we use this
so loading delta from the alpha point is
so i have two sources here one is the
uh
hpq i think i also have hpq here hpq
but i have not yet we have not used this
for prediction i might give this as some
assignment
i've actually used the alpha advantage
api so you give the api key
you give the stock name you give the
string
string
blah blah blah stock market data
and then you write this uh code here
to get the data
that existed or when you can't use it
here
sort with respect to date you have here
the shape is 4055
or your latest 10 2005 selected 2 000 21
30
4055 values
um
now it's a long process here just wait
in this case uh
low plus height divided by two that's
one way to create another variable just
a pus case with taxi volume they created
the other variable so it's up to you we
just have to experiment with different
things so they are looking at the
timestamps here
this is how it looks like although it is
in inverse primarily
uh
that makes the prediction art starts
from here and it's going there
um
so i create this uh array which is mid
prices high plus slow divided by two i
just create that the first three
thousand are for the training and the
the remaining ones are for the testing
uh i apply the min max scalar i reshape
to convert that to the array
so now if they said it's better to split
the series into windows for analysis
series is too long and there are
different patterns in different time so
okay
there are different patterns over
different time so
just take a window based approach give
just a there's a first window
right
and this is the second window then this
is the third window
this is the fourth window this is the
fifth window and so on and so forth so
if you if we analyze all of this with
respect to the window size it's going to
be good
okay if i am windowing then i'm able to
detect different patterns in the window
otherwise
we take 300 as the window size because
we have 3000 as the training size
and we just fit the scalar with respect
to the window size
in the training data that's the code for
that so we create the window
and apply the scaling data to each
window separately so now the data is
scaled now
i i reshape the data and i transform
that
i should do the same for the test data
as well and reshape that okay
so train data
now um
your time series prediction can be one
of the best algorithms
uh is exponential smoothing
uh moving average is the simple version
but exponential smoothing is one of the
best time series algorithms which is
being used globally
not lstm
so i create the formula for exponential
smoothing and i map the training data
accordingly
um
so i i create this expression i have the
gamma and ema and ema i calculate with
respect to this i smooth out with
respect to the window size okay
uh
one step ahead prediction via averaging
averaging mechanisms allow you to
predict by representing the future stock
price as an average of the previously
observed stock prices
doing this for more than one time can
produce quite bad results so if you are
creating just one time step ahead then
everything is better
so yeah so let's see how that happens so
averaging that that's what i'm doing
here
standard average prediction so i just
calculate the average here
so
you can see it's not a very good fit
it's just an average
each window take the average predict the
next value each window take the average
predict the next one
then we have the exponential smoothing
exponential smoothing can there be about
all these things
exponential moving average sorry
you see it's an extremely good fit
the exponential moving average one
so one of the moving average the other
is the exponential moving average
exponential smoothing is is i think is a
generalization of this concept
but
why do you want to do better if it's an
almost perfect fit
but
mostly we do not want the exact stock
market price for the next day
because all of these algorithms
exponential moving average
uh
and this this uh exponential moving
average and the typical
concept is me
standard average standard average and
the exponential moving average okay so
don't know
models
they are able to predict the next time
stem very
effectively
again but i would like to stock my
classes go up and down in the next 30
you calculate days i just have a look at
that
so we did some work here
um
exponential moving average smoothing
so this is the formula which is here
i concatenate so this is one step here
but i don't know whether we are using
this same
candidate
[Music]
so this is this is calculating the
average
for the window
and then finding the
uh
last
average is the best prediction for the
next time average of the previous
timestamps is the best prediction for
the next time
so this is not this is not good but in
the case of the exponential moving
average i use this formula
uh which is able to primarily do things
this is this is the formula running mean
nikola nika
so this is pretty good so here for the
msc error for whole is
0.0021 while for this case is 0.02 so
it's it's very good and you can see here
why it is good but emf fails when i want
to do this for example let's say k
at time x t equals to 0.4 that's the
input ema equals to 0.5 gamma equals 2.5
output xt plus 1
is equals to 0.45
so the next the next prediction then
becomes
if i want to say x
x t x t plus 1 x t plus 2 x plus c
charlotte curve so it is going to
predict the same value
for all the next time step so that's why
it fails
although moving average is a very good
mechanism
but it is able to predict the
next time effectively
you make the prediction this one and
after that prediction goes like this
sometimes it is able to predict even
better
but usq
it is not able to predict very far into
the future because it does not remember
anything here except the moving average
so that that mechanism only exists in in
the lstm
so lstm we already know about this cell
state
you can go through this for your own
knowledge these are the occasions
um
yeah so the rolling ones these are the
how we roll the model
so i don't need to show that right now
let's understand from the code
i've been known
generator sequence which is going to
generate the data this is the
constructor
select the next badge unroll the badges
reset indices
so in order basically
so
let's see how these functions are used
so
you can see here
zero point zero six four zero point nine
zero point two nine zero point two four
zero point one five
so that is the input and this is the
output
in the in the next case
i have point one one point eight five
point two nine point this as the
unrolled index one
and this one has the you know
this one has the output
and similarly for the other cases so
i've been on an unrolled kiss like you
would have to see how they have unrolled
it
unroll the badges get the next badge and
form the basically running formulas and
use kia
x0
1 0 2 0 3 0
x 1
1 1 2 1 3 1 x 2 1 2 2 3 2 that is the
unrolling that is that is happening
so basically they have created the
unrolled
one zero two zero three zero one one two
one z one and one two two three two
although we don't need to do this much
you know you already know how things
work out
number of unrollings bad size number of
nodes number of layers dropout
just preparing still training input and
training output
up here this is the old version lstm
cell so they are initializing that with
respect to the number of nodes state is
tuple initializer
golord normally both piranha version i
will not recommend to use this although
you can run this file to understand
things on your own
so dropout wrapper for the lstm cell
they also use the multi-rnn cell
for some reason and blah blah blah is
very complicated here
so they have created this weight vector
and the bias that they want to update
here it's very it's very confusing all
of it defining the training laws etc etc
optimizers running great decay operation
all done here finally
and the predictions are here sample
prediction all done view we
initialized every law so these are the
uh valid summary here is one so just
let's see what's the output here
yeah so this is going to decrease
average test msc one point five six one
point three six one point three five one
point two eight out there
take a step
under very fast
so our three testimony point two nine
this is not good it should be point
double zero something but
so you can see evolution of test
predictions over time so predictions are
going down here
probably because the model used is very
uh you know it's it's the best one was
that dominated
i think
we're finished with this uh
uh rnn thing you can go to my
you can go through them to understand
how things are working out you will have
to develop your own playground for stock
prediction or whatever prediction you
want to do
you can take help from these files
develop your own uh to get the functions
i want you to develop your own functions
in the assignment
and then you know you can work with the
same
files which i will send you here
uh
comparison and try to improve the
performance more try to do more
abuse your output parameters would they
clearly define me
so yeah so you try to do more and then
we'll see how things will roll out this
is not a good prediction
um
on this problem the model is 3k away
okay there are multiple things over this
to predict
but right now my mind is not working but
you can see it's not catching it that
way
your
is this thing clear now any questions
for the others
um so i'm going to give you an
assignment you can work with textual
data if you want
there's also speech data there's also
the develop that let's leave that to the
project my bold assignment data
i just want you guys to create your own
lstm playground
um
in which case you have
[Music]
though
i don't have that
this time
i understand the assignment was pretty
tough
so i'm going to give you you have to
create your own playground for using
lstm or the bi-directional
and then you can start working this is
all assignment is going to be very very
critical
okay
so the next topic we're going to start
with is auto encoders inshallah on
friday